{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f413f8e1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f04f546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T09:44:56.512219Z",
     "start_time": "2022-08-27T09:44:56.498257Z"
    }
   },
   "outputs": [],
   "source": [
    "### Author: Yuvasri Raghavan (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bad4e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-12T09:37:32.828898Z",
     "start_time": "2022-08-12T09:37:22.396724Z"
    }
   },
   "outputs": [],
   "source": [
    "# argparse for user friendly parsing of arguments\n",
    "import argparse\n",
    "\n",
    "#machine learning python framework\n",
    "import torch\n",
    "\n",
    "#PyTorch library for graph networks\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "# OGB Dataloader to load Drug Interaction Network Data\n",
    "from ogb.linkproppred import PygLinkPropPredDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaecd1",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aafb1e",
   "metadata": {},
   "source": [
    "### Saving Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22aa9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T07:53:28.310700Z",
     "start_time": "2022-07-05T07:53:28.299539Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a function to save embeddings in Node2Vec\n",
    "\n",
    "def save_embedding_todevice(model):\n",
    "    torch.save(model.embedding.weight.data.cpu(), 'embedding.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab07d7",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4bb0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T14:29:32.342264Z",
     "start_time": "2022-08-07T14:29:31.920193Z"
    }
   },
   "outputs": [],
   "source": [
    "#load OGB DDI Dataset\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "data = dataset[0]\n",
    "\n",
    "#Split the data based on a protein split\n",
    "split_edge = dataset.get_edge_split()\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccdb94",
   "metadata": {},
   "source": [
    "### Node2Vec Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0c8643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T11:32:37.076960Z",
     "start_time": "2022-07-05T07:56:11.165096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Step: 001/17, Loss: 10.0726\n",
      "Epoch: 01, Step: 002/17, Loss: 9.9564\n",
      "Epoch: 01, Step: 003/17, Loss: 9.7899\n",
      "Epoch: 01, Step: 004/17, Loss: 9.6619\n",
      "Epoch: 01, Step: 005/17, Loss: 9.5450\n",
      "Epoch: 01, Step: 006/17, Loss: 9.3609\n",
      "Epoch: 01, Step: 007/17, Loss: 9.2638\n",
      "Epoch: 01, Step: 008/17, Loss: 9.1543\n",
      "Epoch: 01, Step: 009/17, Loss: 8.9926\n",
      "Epoch: 01, Step: 010/17, Loss: 8.8368\n",
      "Epoch: 01, Step: 011/17, Loss: 8.7348\n",
      "Epoch: 01, Step: 012/17, Loss: 8.6059\n",
      "Epoch: 01, Step: 013/17, Loss: 8.4894\n",
      "Epoch: 01, Step: 014/17, Loss: 8.3420\n",
      "Epoch: 01, Step: 015/17, Loss: 8.2165\n",
      "Epoch: 01, Step: 016/17, Loss: 8.0934\n",
      "Epoch: 01, Step: 017/17, Loss: 7.9631\n",
      "Epoch: 02, Step: 001/17, Loss: 7.8535\n",
      "Epoch: 02, Step: 002/17, Loss: 7.7301\n",
      "Epoch: 02, Step: 003/17, Loss: 7.6062\n",
      "Epoch: 02, Step: 004/17, Loss: 7.4901\n",
      "Epoch: 02, Step: 005/17, Loss: 7.3756\n",
      "Epoch: 02, Step: 006/17, Loss: 7.2684\n",
      "Epoch: 02, Step: 007/17, Loss: 7.1581\n",
      "Epoch: 02, Step: 008/17, Loss: 7.0486\n",
      "Epoch: 02, Step: 009/17, Loss: 6.9217\n",
      "Epoch: 02, Step: 010/17, Loss: 6.8191\n",
      "Epoch: 02, Step: 011/17, Loss: 6.7015\n",
      "Epoch: 02, Step: 012/17, Loss: 6.5745\n",
      "Epoch: 02, Step: 013/17, Loss: 6.4852\n",
      "Epoch: 02, Step: 014/17, Loss: 6.3780\n",
      "Epoch: 02, Step: 015/17, Loss: 6.2739\n",
      "Epoch: 02, Step: 016/17, Loss: 6.1688\n",
      "Epoch: 02, Step: 017/17, Loss: 6.0750\n",
      "Epoch: 03, Step: 001/17, Loss: 5.9708\n",
      "Epoch: 03, Step: 002/17, Loss: 5.8731\n",
      "Epoch: 03, Step: 003/17, Loss: 5.7698\n",
      "Epoch: 03, Step: 004/17, Loss: 5.6862\n",
      "Epoch: 03, Step: 005/17, Loss: 5.5798\n",
      "Epoch: 03, Step: 006/17, Loss: 5.4782\n",
      "Epoch: 03, Step: 007/17, Loss: 5.3934\n",
      "Epoch: 03, Step: 008/17, Loss: 5.2993\n",
      "Epoch: 03, Step: 009/17, Loss: 5.2215\n",
      "Epoch: 03, Step: 010/17, Loss: 5.1284\n",
      "Epoch: 03, Step: 011/17, Loss: 5.0406\n",
      "Epoch: 03, Step: 012/17, Loss: 4.9429\n",
      "Epoch: 03, Step: 013/17, Loss: 4.8552\n",
      "Epoch: 03, Step: 014/17, Loss: 4.7773\n",
      "Epoch: 03, Step: 015/17, Loss: 4.6962\n",
      "Epoch: 03, Step: 016/17, Loss: 4.6035\n",
      "Epoch: 03, Step: 017/17, Loss: 4.5317\n",
      "Epoch: 04, Step: 001/17, Loss: 4.4658\n",
      "Epoch: 04, Step: 002/17, Loss: 4.3773\n",
      "Epoch: 04, Step: 003/17, Loss: 4.3038\n",
      "Epoch: 04, Step: 004/17, Loss: 4.2373\n",
      "Epoch: 04, Step: 005/17, Loss: 4.1552\n",
      "Epoch: 04, Step: 006/17, Loss: 4.0891\n",
      "Epoch: 04, Step: 007/17, Loss: 4.0137\n",
      "Epoch: 04, Step: 008/17, Loss: 3.9528\n",
      "Epoch: 04, Step: 009/17, Loss: 3.8875\n",
      "Epoch: 04, Step: 010/17, Loss: 3.8205\n",
      "Epoch: 04, Step: 011/17, Loss: 3.7533\n",
      "Epoch: 04, Step: 012/17, Loss: 3.7009\n",
      "Epoch: 04, Step: 013/17, Loss: 3.6447\n",
      "Epoch: 04, Step: 014/17, Loss: 3.5943\n",
      "Epoch: 04, Step: 015/17, Loss: 3.5436\n",
      "Epoch: 04, Step: 016/17, Loss: 3.4865\n",
      "Epoch: 04, Step: 017/17, Loss: 3.4434\n",
      "Epoch: 05, Step: 001/17, Loss: 3.3783\n",
      "Epoch: 05, Step: 002/17, Loss: 3.3355\n",
      "Epoch: 05, Step: 003/17, Loss: 3.2927\n",
      "Epoch: 05, Step: 004/17, Loss: 3.2663\n",
      "Epoch: 05, Step: 005/17, Loss: 3.2100\n",
      "Epoch: 05, Step: 006/17, Loss: 3.1910\n",
      "Epoch: 05, Step: 007/17, Loss: 3.1416\n",
      "Epoch: 05, Step: 008/17, Loss: 3.0915\n",
      "Epoch: 05, Step: 009/17, Loss: 3.0580\n",
      "Epoch: 05, Step: 010/17, Loss: 3.0087\n",
      "Epoch: 05, Step: 011/17, Loss: 2.9728\n",
      "Epoch: 05, Step: 012/17, Loss: 2.9415\n",
      "Epoch: 05, Step: 013/17, Loss: 2.9239\n",
      "Epoch: 05, Step: 014/17, Loss: 2.8810\n",
      "Epoch: 05, Step: 015/17, Loss: 2.8466\n",
      "Epoch: 05, Step: 016/17, Loss: 2.8273\n",
      "Epoch: 05, Step: 017/17, Loss: 2.7789\n",
      "Epoch: 06, Step: 001/17, Loss: 2.7617\n",
      "Epoch: 06, Step: 002/17, Loss: 2.7185\n",
      "Epoch: 06, Step: 003/17, Loss: 2.7057\n",
      "Epoch: 06, Step: 004/17, Loss: 2.6750\n",
      "Epoch: 06, Step: 005/17, Loss: 2.6358\n",
      "Epoch: 06, Step: 006/17, Loss: 2.6228\n",
      "Epoch: 06, Step: 007/17, Loss: 2.5821\n",
      "Epoch: 06, Step: 008/17, Loss: 2.5545\n",
      "Epoch: 06, Step: 009/17, Loss: 2.5308\n",
      "Epoch: 06, Step: 010/17, Loss: 2.4953\n",
      "Epoch: 06, Step: 011/17, Loss: 2.4846\n",
      "Epoch: 06, Step: 012/17, Loss: 2.4527\n",
      "Epoch: 06, Step: 013/17, Loss: 2.4302\n",
      "Epoch: 06, Step: 014/17, Loss: 2.4063\n",
      "Epoch: 06, Step: 015/17, Loss: 2.3862\n",
      "Epoch: 06, Step: 016/17, Loss: 2.3509\n",
      "Epoch: 06, Step: 017/17, Loss: 2.3317\n",
      "Epoch: 07, Step: 001/17, Loss: 2.3164\n",
      "Epoch: 07, Step: 002/17, Loss: 2.3024\n",
      "Epoch: 07, Step: 003/17, Loss: 2.2797\n",
      "Epoch: 07, Step: 004/17, Loss: 2.2544\n",
      "Epoch: 07, Step: 005/17, Loss: 2.2198\n",
      "Epoch: 07, Step: 006/17, Loss: 2.2092\n",
      "Epoch: 07, Step: 007/17, Loss: 2.1894\n",
      "Epoch: 07, Step: 008/17, Loss: 2.1736\n",
      "Epoch: 07, Step: 009/17, Loss: 2.1607\n",
      "Epoch: 07, Step: 010/17, Loss: 2.1395\n",
      "Epoch: 07, Step: 011/17, Loss: 2.1223\n",
      "Epoch: 07, Step: 012/17, Loss: 2.0960\n",
      "Epoch: 07, Step: 013/17, Loss: 2.0973\n",
      "Epoch: 07, Step: 014/17, Loss: 2.0766\n",
      "Epoch: 07, Step: 015/17, Loss: 2.0553\n",
      "Epoch: 07, Step: 016/17, Loss: 2.0347\n",
      "Epoch: 07, Step: 017/17, Loss: 2.0249\n",
      "Epoch: 08, Step: 001/17, Loss: 2.0003\n",
      "Epoch: 08, Step: 002/17, Loss: 1.9877\n",
      "Epoch: 08, Step: 003/17, Loss: 1.9760\n",
      "Epoch: 08, Step: 004/17, Loss: 1.9596\n",
      "Epoch: 08, Step: 005/17, Loss: 1.9414\n",
      "Epoch: 08, Step: 006/17, Loss: 1.9355\n",
      "Epoch: 08, Step: 007/17, Loss: 1.9213\n",
      "Epoch: 08, Step: 008/17, Loss: 1.9028\n",
      "Epoch: 08, Step: 009/17, Loss: 1.8869\n",
      "Epoch: 08, Step: 010/17, Loss: 1.8835\n",
      "Epoch: 08, Step: 011/17, Loss: 1.8608\n",
      "Epoch: 08, Step: 012/17, Loss: 1.8442\n",
      "Epoch: 08, Step: 013/17, Loss: 1.8378\n",
      "Epoch: 08, Step: 014/17, Loss: 1.8243\n",
      "Epoch: 08, Step: 015/17, Loss: 1.8131\n",
      "Epoch: 08, Step: 016/17, Loss: 1.8088\n",
      "Epoch: 08, Step: 017/17, Loss: 1.7965\n",
      "Epoch: 09, Step: 001/17, Loss: 1.7741\n",
      "Epoch: 09, Step: 002/17, Loss: 1.7640\n",
      "Epoch: 09, Step: 003/17, Loss: 1.7625\n",
      "Epoch: 09, Step: 004/17, Loss: 1.7386\n",
      "Epoch: 09, Step: 005/17, Loss: 1.7448\n",
      "Epoch: 09, Step: 006/17, Loss: 1.7234\n",
      "Epoch: 09, Step: 007/17, Loss: 1.7225\n",
      "Epoch: 09, Step: 008/17, Loss: 1.7090\n",
      "Epoch: 09, Step: 009/17, Loss: 1.7021\n",
      "Epoch: 09, Step: 010/17, Loss: 1.7006\n",
      "Epoch: 09, Step: 011/17, Loss: 1.6858\n",
      "Epoch: 09, Step: 012/17, Loss: 1.6673\n",
      "Epoch: 09, Step: 013/17, Loss: 1.6629\n",
      "Epoch: 09, Step: 014/17, Loss: 1.6506\n",
      "Epoch: 09, Step: 015/17, Loss: 1.6533\n",
      "Epoch: 09, Step: 016/17, Loss: 1.6372\n",
      "Epoch: 09, Step: 017/17, Loss: 1.6379\n",
      "Epoch: 10, Step: 001/17, Loss: 1.6221\n",
      "Epoch: 10, Step: 002/17, Loss: 1.6153\n",
      "Epoch: 10, Step: 003/17, Loss: 1.6033\n",
      "Epoch: 10, Step: 004/17, Loss: 1.6012\n",
      "Epoch: 10, Step: 005/17, Loss: 1.5905\n",
      "Epoch: 10, Step: 006/17, Loss: 1.5843\n",
      "Epoch: 10, Step: 007/17, Loss: 1.5792\n",
      "Epoch: 10, Step: 008/17, Loss: 1.5764\n",
      "Epoch: 10, Step: 009/17, Loss: 1.5691\n",
      "Epoch: 10, Step: 010/17, Loss: 1.5555\n",
      "Epoch: 10, Step: 011/17, Loss: 1.5518\n",
      "Epoch: 10, Step: 012/17, Loss: 1.5445\n",
      "Epoch: 10, Step: 013/17, Loss: 1.5432\n",
      "Epoch: 10, Step: 014/17, Loss: 1.5362\n",
      "Epoch: 10, Step: 015/17, Loss: 1.5295\n",
      "Epoch: 10, Step: 016/17, Loss: 1.5198\n",
      "Epoch: 10, Step: 017/17, Loss: 1.5170\n",
      "Epoch: 11, Step: 001/17, Loss: 1.5138\n",
      "Epoch: 11, Step: 002/17, Loss: 1.5088\n",
      "Epoch: 11, Step: 003/17, Loss: 1.5040\n",
      "Epoch: 11, Step: 004/17, Loss: 1.4981\n",
      "Epoch: 11, Step: 005/17, Loss: 1.4885\n",
      "Epoch: 11, Step: 006/17, Loss: 1.4856\n",
      "Epoch: 11, Step: 007/17, Loss: 1.4783\n",
      "Epoch: 11, Step: 008/17, Loss: 1.4753\n",
      "Epoch: 11, Step: 009/17, Loss: 1.4748\n",
      "Epoch: 11, Step: 010/17, Loss: 1.4678\n",
      "Epoch: 11, Step: 011/17, Loss: 1.4630\n",
      "Epoch: 11, Step: 012/17, Loss: 1.4595\n",
      "Epoch: 11, Step: 013/17, Loss: 1.4495\n",
      "Epoch: 11, Step: 014/17, Loss: 1.4502\n",
      "Epoch: 11, Step: 015/17, Loss: 1.4455\n",
      "Epoch: 11, Step: 016/17, Loss: 1.4436\n",
      "Epoch: 11, Step: 017/17, Loss: 1.4403\n",
      "Epoch: 12, Step: 001/17, Loss: 1.4340\n",
      "Epoch: 12, Step: 002/17, Loss: 1.4338\n",
      "Epoch: 12, Step: 003/17, Loss: 1.4215\n",
      "Epoch: 12, Step: 004/17, Loss: 1.4198\n",
      "Epoch: 12, Step: 005/17, Loss: 1.4207\n",
      "Epoch: 12, Step: 006/17, Loss: 1.4104\n",
      "Epoch: 12, Step: 007/17, Loss: 1.4152\n",
      "Epoch: 12, Step: 008/17, Loss: 1.4076\n",
      "Epoch: 12, Step: 009/17, Loss: 1.4058\n",
      "Epoch: 12, Step: 010/17, Loss: 1.4010\n",
      "Epoch: 12, Step: 011/17, Loss: 1.4005\n",
      "Epoch: 12, Step: 012/17, Loss: 1.4011\n",
      "Epoch: 12, Step: 013/17, Loss: 1.3871\n",
      "Epoch: 12, Step: 014/17, Loss: 1.3872\n",
      "Epoch: 12, Step: 015/17, Loss: 1.3923\n",
      "Epoch: 12, Step: 016/17, Loss: 1.3814\n",
      "Epoch: 12, Step: 017/17, Loss: 1.3817\n",
      "Epoch: 13, Step: 001/17, Loss: 1.3745\n",
      "Epoch: 13, Step: 002/17, Loss: 1.3702\n",
      "Epoch: 13, Step: 003/17, Loss: 1.3699\n",
      "Epoch: 13, Step: 004/17, Loss: 1.3686\n",
      "Epoch: 13, Step: 005/17, Loss: 1.3671\n",
      "Epoch: 13, Step: 006/17, Loss: 1.3686\n",
      "Epoch: 13, Step: 007/17, Loss: 1.3611\n",
      "Epoch: 13, Step: 008/17, Loss: 1.3581\n",
      "Epoch: 13, Step: 009/17, Loss: 1.3565\n",
      "Epoch: 13, Step: 010/17, Loss: 1.3582\n",
      "Epoch: 13, Step: 011/17, Loss: 1.3547\n",
      "Epoch: 13, Step: 012/17, Loss: 1.3529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Step: 013/17, Loss: 1.3503\n",
      "Epoch: 13, Step: 014/17, Loss: 1.3455\n",
      "Epoch: 13, Step: 015/17, Loss: 1.3461\n",
      "Epoch: 13, Step: 016/17, Loss: 1.3456\n",
      "Epoch: 13, Step: 017/17, Loss: 1.3376\n",
      "Epoch: 14, Step: 001/17, Loss: 1.3331\n",
      "Epoch: 14, Step: 002/17, Loss: 1.3360\n",
      "Epoch: 14, Step: 003/17, Loss: 1.3339\n",
      "Epoch: 14, Step: 004/17, Loss: 1.3318\n",
      "Epoch: 14, Step: 005/17, Loss: 1.3357\n",
      "Epoch: 14, Step: 006/17, Loss: 1.3250\n",
      "Epoch: 14, Step: 007/17, Loss: 1.3268\n",
      "Epoch: 14, Step: 008/17, Loss: 1.3165\n",
      "Epoch: 14, Step: 009/17, Loss: 1.3206\n",
      "Epoch: 14, Step: 010/17, Loss: 1.3204\n",
      "Epoch: 14, Step: 011/17, Loss: 1.3214\n",
      "Epoch: 14, Step: 012/17, Loss: 1.3209\n",
      "Epoch: 14, Step: 013/17, Loss: 1.3188\n",
      "Epoch: 14, Step: 014/17, Loss: 1.3161\n",
      "Epoch: 14, Step: 015/17, Loss: 1.3142\n",
      "Epoch: 14, Step: 016/17, Loss: 1.3171\n",
      "Epoch: 14, Step: 017/17, Loss: 1.3080\n",
      "Epoch: 15, Step: 001/17, Loss: 1.3076\n",
      "Epoch: 15, Step: 002/17, Loss: 1.3092\n",
      "Epoch: 15, Step: 003/17, Loss: 1.3071\n",
      "Epoch: 15, Step: 004/17, Loss: 1.3103\n",
      "Epoch: 15, Step: 005/17, Loss: 1.2997\n",
      "Epoch: 15, Step: 006/17, Loss: 1.3037\n",
      "Epoch: 15, Step: 007/17, Loss: 1.3017\n",
      "Epoch: 15, Step: 008/17, Loss: 1.3007\n",
      "Epoch: 15, Step: 009/17, Loss: 1.2942\n",
      "Epoch: 15, Step: 010/17, Loss: 1.2967\n",
      "Epoch: 15, Step: 011/17, Loss: 1.2950\n",
      "Epoch: 15, Step: 012/17, Loss: 1.2902\n",
      "Epoch: 15, Step: 013/17, Loss: 1.2963\n",
      "Epoch: 15, Step: 014/17, Loss: 1.2929\n",
      "Epoch: 15, Step: 015/17, Loss: 1.2878\n",
      "Epoch: 15, Step: 016/17, Loss: 1.2908\n",
      "Epoch: 15, Step: 017/17, Loss: 1.2910\n",
      "Epoch: 16, Step: 001/17, Loss: 1.2901\n",
      "Epoch: 16, Step: 002/17, Loss: 1.2861\n",
      "Epoch: 16, Step: 003/17, Loss: 1.2851\n",
      "Epoch: 16, Step: 004/17, Loss: 1.2894\n",
      "Epoch: 16, Step: 005/17, Loss: 1.2813\n",
      "Epoch: 16, Step: 006/17, Loss: 1.2838\n",
      "Epoch: 16, Step: 007/17, Loss: 1.2814\n",
      "Epoch: 16, Step: 008/17, Loss: 1.2815\n",
      "Epoch: 16, Step: 009/17, Loss: 1.2798\n",
      "Epoch: 16, Step: 010/17, Loss: 1.2813\n",
      "Epoch: 16, Step: 011/17, Loss: 1.2788\n",
      "Epoch: 16, Step: 012/17, Loss: 1.2785\n",
      "Epoch: 16, Step: 013/17, Loss: 1.2743\n",
      "Epoch: 16, Step: 014/17, Loss: 1.2750\n",
      "Epoch: 16, Step: 015/17, Loss: 1.2735\n",
      "Epoch: 16, Step: 016/17, Loss: 1.2739\n",
      "Epoch: 16, Step: 017/17, Loss: 1.2690\n",
      "Epoch: 17, Step: 001/17, Loss: 1.2712\n",
      "Epoch: 17, Step: 002/17, Loss: 1.2679\n",
      "Epoch: 17, Step: 003/17, Loss: 1.2713\n",
      "Epoch: 17, Step: 004/17, Loss: 1.2664\n",
      "Epoch: 17, Step: 005/17, Loss: 1.2681\n",
      "Epoch: 17, Step: 006/17, Loss: 1.2714\n",
      "Epoch: 17, Step: 007/17, Loss: 1.2683\n",
      "Epoch: 17, Step: 008/17, Loss: 1.2655\n",
      "Epoch: 17, Step: 009/17, Loss: 1.2677\n",
      "Epoch: 17, Step: 010/17, Loss: 1.2641\n",
      "Epoch: 17, Step: 011/17, Loss: 1.2654\n",
      "Epoch: 17, Step: 012/17, Loss: 1.2655\n",
      "Epoch: 17, Step: 013/17, Loss: 1.2598\n",
      "Epoch: 17, Step: 014/17, Loss: 1.2606\n",
      "Epoch: 17, Step: 015/17, Loss: 1.2638\n",
      "Epoch: 17, Step: 016/17, Loss: 1.2632\n",
      "Epoch: 17, Step: 017/17, Loss: 1.2626\n",
      "Epoch: 18, Step: 001/17, Loss: 1.2611\n",
      "Epoch: 18, Step: 002/17, Loss: 1.2623\n",
      "Epoch: 18, Step: 003/17, Loss: 1.2558\n",
      "Epoch: 18, Step: 004/17, Loss: 1.2574\n",
      "Epoch: 18, Step: 005/17, Loss: 1.2595\n",
      "Epoch: 18, Step: 006/17, Loss: 1.2592\n",
      "Epoch: 18, Step: 007/17, Loss: 1.2534\n",
      "Epoch: 18, Step: 008/17, Loss: 1.2549\n",
      "Epoch: 18, Step: 009/17, Loss: 1.2557\n",
      "Epoch: 18, Step: 010/17, Loss: 1.2527\n",
      "Epoch: 18, Step: 011/17, Loss: 1.2535\n",
      "Epoch: 18, Step: 012/17, Loss: 1.2539\n",
      "Epoch: 18, Step: 013/17, Loss: 1.2495\n",
      "Epoch: 18, Step: 014/17, Loss: 1.2536\n",
      "Epoch: 18, Step: 015/17, Loss: 1.2532\n",
      "Epoch: 18, Step: 016/17, Loss: 1.2500\n",
      "Epoch: 18, Step: 017/17, Loss: 1.2516\n",
      "Epoch: 19, Step: 001/17, Loss: 1.2464\n",
      "Epoch: 19, Step: 002/17, Loss: 1.2458\n",
      "Epoch: 19, Step: 003/17, Loss: 1.2504\n",
      "Epoch: 19, Step: 004/17, Loss: 1.2479\n",
      "Epoch: 19, Step: 005/17, Loss: 1.2450\n",
      "Epoch: 19, Step: 006/17, Loss: 1.2496\n",
      "Epoch: 19, Step: 007/17, Loss: 1.2468\n",
      "Epoch: 19, Step: 008/17, Loss: 1.2471\n",
      "Epoch: 19, Step: 009/17, Loss: 1.2477\n",
      "Epoch: 19, Step: 010/17, Loss: 1.2487\n",
      "Epoch: 19, Step: 011/17, Loss: 1.2470\n",
      "Epoch: 19, Step: 012/17, Loss: 1.2451\n",
      "Epoch: 19, Step: 013/17, Loss: 1.2430\n",
      "Epoch: 19, Step: 014/17, Loss: 1.2445\n",
      "Epoch: 19, Step: 015/17, Loss: 1.2454\n",
      "Epoch: 19, Step: 016/17, Loss: 1.2392\n",
      "Epoch: 19, Step: 017/17, Loss: 1.2450\n",
      "Epoch: 20, Step: 001/17, Loss: 1.2431\n",
      "Epoch: 20, Step: 002/17, Loss: 1.2425\n",
      "Epoch: 20, Step: 003/17, Loss: 1.2410\n",
      "Epoch: 20, Step: 004/17, Loss: 1.2479\n",
      "Epoch: 20, Step: 005/17, Loss: 1.2402\n",
      "Epoch: 20, Step: 006/17, Loss: 1.2390\n",
      "Epoch: 20, Step: 007/17, Loss: 1.2384\n",
      "Epoch: 20, Step: 008/17, Loss: 1.2397\n",
      "Epoch: 20, Step: 009/17, Loss: 1.2407\n",
      "Epoch: 20, Step: 010/17, Loss: 1.2389\n",
      "Epoch: 20, Step: 011/17, Loss: 1.2405\n",
      "Epoch: 20, Step: 012/17, Loss: 1.2405\n",
      "Epoch: 20, Step: 013/17, Loss: 1.2381\n",
      "Epoch: 20, Step: 014/17, Loss: 1.2361\n",
      "Epoch: 20, Step: 015/17, Loss: 1.2399\n",
      "Epoch: 20, Step: 016/17, Loss: 1.2386\n",
      "Epoch: 20, Step: 017/17, Loss: 1.2324\n",
      "Epoch: 21, Step: 001/17, Loss: 1.2340\n",
      "Epoch: 21, Step: 002/17, Loss: 1.2407\n",
      "Epoch: 21, Step: 003/17, Loss: 1.2364\n",
      "Epoch: 21, Step: 004/17, Loss: 1.2309\n",
      "Epoch: 21, Step: 005/17, Loss: 1.2347\n",
      "Epoch: 21, Step: 006/17, Loss: 1.2327\n",
      "Epoch: 21, Step: 007/17, Loss: 1.2370\n",
      "Epoch: 21, Step: 008/17, Loss: 1.2273\n",
      "Epoch: 21, Step: 009/17, Loss: 1.2357\n",
      "Epoch: 21, Step: 010/17, Loss: 1.2336\n",
      "Epoch: 21, Step: 011/17, Loss: 1.2363\n",
      "Epoch: 21, Step: 012/17, Loss: 1.2314\n",
      "Epoch: 21, Step: 013/17, Loss: 1.2343\n",
      "Epoch: 21, Step: 014/17, Loss: 1.2350\n",
      "Epoch: 21, Step: 015/17, Loss: 1.2334\n",
      "Epoch: 21, Step: 016/17, Loss: 1.2328\n",
      "Epoch: 21, Step: 017/17, Loss: 1.2336\n",
      "Epoch: 22, Step: 001/17, Loss: 1.2318\n",
      "Epoch: 22, Step: 002/17, Loss: 1.2273\n",
      "Epoch: 22, Step: 003/17, Loss: 1.2307\n",
      "Epoch: 22, Step: 004/17, Loss: 1.2303\n",
      "Epoch: 22, Step: 005/17, Loss: 1.2323\n",
      "Epoch: 22, Step: 006/17, Loss: 1.2298\n",
      "Epoch: 22, Step: 007/17, Loss: 1.2270\n",
      "Epoch: 22, Step: 008/17, Loss: 1.2289\n",
      "Epoch: 22, Step: 009/17, Loss: 1.2292\n",
      "Epoch: 22, Step: 010/17, Loss: 1.2265\n",
      "Epoch: 22, Step: 011/17, Loss: 1.2283\n",
      "Epoch: 22, Step: 012/17, Loss: 1.2322\n",
      "Epoch: 22, Step: 013/17, Loss: 1.2323\n",
      "Epoch: 22, Step: 014/17, Loss: 1.2282\n",
      "Epoch: 22, Step: 015/17, Loss: 1.2336\n",
      "Epoch: 22, Step: 016/17, Loss: 1.2262\n",
      "Epoch: 22, Step: 017/17, Loss: 1.2260\n",
      "Epoch: 23, Step: 001/17, Loss: 1.2269\n",
      "Epoch: 23, Step: 002/17, Loss: 1.2280\n",
      "Epoch: 23, Step: 003/17, Loss: 1.2270\n",
      "Epoch: 23, Step: 004/17, Loss: 1.2255\n",
      "Epoch: 23, Step: 005/17, Loss: 1.2276\n",
      "Epoch: 23, Step: 006/17, Loss: 1.2239\n",
      "Epoch: 23, Step: 007/17, Loss: 1.2239\n",
      "Epoch: 23, Step: 008/17, Loss: 1.2230\n",
      "Epoch: 23, Step: 009/17, Loss: 1.2267\n",
      "Epoch: 23, Step: 010/17, Loss: 1.2277\n",
      "Epoch: 23, Step: 011/17, Loss: 1.2268\n",
      "Epoch: 23, Step: 012/17, Loss: 1.2243\n",
      "Epoch: 23, Step: 013/17, Loss: 1.2246\n",
      "Epoch: 23, Step: 014/17, Loss: 1.2234\n",
      "Epoch: 23, Step: 015/17, Loss: 1.2225\n",
      "Epoch: 23, Step: 016/17, Loss: 1.2280\n",
      "Epoch: 23, Step: 017/17, Loss: 1.2248\n",
      "Epoch: 24, Step: 001/17, Loss: 1.2234\n",
      "Epoch: 24, Step: 002/17, Loss: 1.2255\n",
      "Epoch: 24, Step: 003/17, Loss: 1.2216\n",
      "Epoch: 24, Step: 004/17, Loss: 1.2241\n",
      "Epoch: 24, Step: 005/17, Loss: 1.2261\n",
      "Epoch: 24, Step: 006/17, Loss: 1.2253\n",
      "Epoch: 24, Step: 007/17, Loss: 1.2218\n",
      "Epoch: 24, Step: 008/17, Loss: 1.2197\n",
      "Epoch: 24, Step: 009/17, Loss: 1.2229\n",
      "Epoch: 24, Step: 010/17, Loss: 1.2217\n",
      "Epoch: 24, Step: 011/17, Loss: 1.2227\n",
      "Epoch: 24, Step: 012/17, Loss: 1.2209\n",
      "Epoch: 24, Step: 013/17, Loss: 1.2255\n",
      "Epoch: 24, Step: 014/17, Loss: 1.2231\n",
      "Epoch: 24, Step: 015/17, Loss: 1.2175\n",
      "Epoch: 24, Step: 016/17, Loss: 1.2225\n",
      "Epoch: 24, Step: 017/17, Loss: 1.2223\n",
      "Epoch: 25, Step: 001/17, Loss: 1.2221\n",
      "Epoch: 25, Step: 002/17, Loss: 1.2193\n",
      "Epoch: 25, Step: 003/17, Loss: 1.2225\n",
      "Epoch: 25, Step: 004/17, Loss: 1.2166\n",
      "Epoch: 25, Step: 005/17, Loss: 1.2232\n",
      "Epoch: 25, Step: 006/17, Loss: 1.2205\n",
      "Epoch: 25, Step: 007/17, Loss: 1.2218\n",
      "Epoch: 25, Step: 008/17, Loss: 1.2194\n",
      "Epoch: 25, Step: 009/17, Loss: 1.2191\n",
      "Epoch: 25, Step: 010/17, Loss: 1.2213\n",
      "Epoch: 25, Step: 011/17, Loss: 1.2191\n",
      "Epoch: 25, Step: 012/17, Loss: 1.2204\n",
      "Epoch: 25, Step: 013/17, Loss: 1.2217\n",
      "Epoch: 25, Step: 014/17, Loss: 1.2200\n",
      "Epoch: 25, Step: 015/17, Loss: 1.2215\n",
      "Epoch: 25, Step: 016/17, Loss: 1.2199\n",
      "Epoch: 25, Step: 017/17, Loss: 1.2172\n",
      "Epoch: 26, Step: 001/17, Loss: 1.2197\n",
      "Epoch: 26, Step: 002/17, Loss: 1.2161\n",
      "Epoch: 26, Step: 003/17, Loss: 1.2175\n",
      "Epoch: 26, Step: 004/17, Loss: 1.2151\n",
      "Epoch: 26, Step: 005/17, Loss: 1.2183\n",
      "Epoch: 26, Step: 006/17, Loss: 1.2208\n",
      "Epoch: 26, Step: 007/17, Loss: 1.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Step: 008/17, Loss: 1.2180\n",
      "Epoch: 26, Step: 009/17, Loss: 1.2195\n",
      "Epoch: 26, Step: 010/17, Loss: 1.2169\n",
      "Epoch: 26, Step: 011/17, Loss: 1.2166\n",
      "Epoch: 26, Step: 012/17, Loss: 1.2137\n",
      "Epoch: 26, Step: 013/17, Loss: 1.2198\n",
      "Epoch: 26, Step: 014/17, Loss: 1.2228\n",
      "Epoch: 26, Step: 015/17, Loss: 1.2166\n",
      "Epoch: 26, Step: 016/17, Loss: 1.2210\n",
      "Epoch: 26, Step: 017/17, Loss: 1.2192\n",
      "Epoch: 27, Step: 001/17, Loss: 1.2153\n",
      "Epoch: 27, Step: 002/17, Loss: 1.2174\n",
      "Epoch: 27, Step: 003/17, Loss: 1.2182\n",
      "Epoch: 27, Step: 004/17, Loss: 1.2180\n",
      "Epoch: 27, Step: 005/17, Loss: 1.2147\n",
      "Epoch: 27, Step: 006/17, Loss: 1.2174\n",
      "Epoch: 27, Step: 007/17, Loss: 1.2173\n",
      "Epoch: 27, Step: 008/17, Loss: 1.2163\n",
      "Epoch: 27, Step: 009/17, Loss: 1.2192\n",
      "Epoch: 27, Step: 010/17, Loss: 1.2146\n",
      "Epoch: 27, Step: 011/17, Loss: 1.2179\n",
      "Epoch: 27, Step: 012/17, Loss: 1.2157\n",
      "Epoch: 27, Step: 013/17, Loss: 1.2163\n",
      "Epoch: 27, Step: 014/17, Loss: 1.2160\n",
      "Epoch: 27, Step: 015/17, Loss: 1.2167\n",
      "Epoch: 27, Step: 016/17, Loss: 1.2151\n",
      "Epoch: 27, Step: 017/17, Loss: 1.2150\n",
      "Epoch: 28, Step: 001/17, Loss: 1.2141\n",
      "Epoch: 28, Step: 002/17, Loss: 1.2180\n",
      "Epoch: 28, Step: 003/17, Loss: 1.2123\n",
      "Epoch: 28, Step: 004/17, Loss: 1.2120\n",
      "Epoch: 28, Step: 005/17, Loss: 1.2122\n",
      "Epoch: 28, Step: 006/17, Loss: 1.2132\n",
      "Epoch: 28, Step: 007/17, Loss: 1.2174\n",
      "Epoch: 28, Step: 008/17, Loss: 1.2103\n",
      "Epoch: 28, Step: 009/17, Loss: 1.2126\n",
      "Epoch: 28, Step: 010/17, Loss: 1.2151\n",
      "Epoch: 28, Step: 011/17, Loss: 1.2132\n",
      "Epoch: 28, Step: 012/17, Loss: 1.2156\n",
      "Epoch: 28, Step: 013/17, Loss: 1.2164\n",
      "Epoch: 28, Step: 014/17, Loss: 1.2206\n",
      "Epoch: 28, Step: 015/17, Loss: 1.2149\n",
      "Epoch: 28, Step: 016/17, Loss: 1.2124\n",
      "Epoch: 28, Step: 017/17, Loss: 1.2122\n",
      "Epoch: 29, Step: 001/17, Loss: 1.2107\n",
      "Epoch: 29, Step: 002/17, Loss: 1.2128\n",
      "Epoch: 29, Step: 003/17, Loss: 1.2178\n",
      "Epoch: 29, Step: 004/17, Loss: 1.2132\n",
      "Epoch: 29, Step: 005/17, Loss: 1.2122\n",
      "Epoch: 29, Step: 006/17, Loss: 1.2141\n",
      "Epoch: 29, Step: 007/17, Loss: 1.2104\n",
      "Epoch: 29, Step: 008/17, Loss: 1.2099\n",
      "Epoch: 29, Step: 009/17, Loss: 1.2141\n",
      "Epoch: 29, Step: 010/17, Loss: 1.2167\n",
      "Epoch: 29, Step: 011/17, Loss: 1.2094\n",
      "Epoch: 29, Step: 012/17, Loss: 1.2129\n",
      "Epoch: 29, Step: 013/17, Loss: 1.2164\n",
      "Epoch: 29, Step: 014/17, Loss: 1.2133\n",
      "Epoch: 29, Step: 015/17, Loss: 1.2135\n",
      "Epoch: 29, Step: 016/17, Loss: 1.2112\n",
      "Epoch: 29, Step: 017/17, Loss: 1.2162\n",
      "Epoch: 30, Step: 001/17, Loss: 1.2117\n",
      "Epoch: 30, Step: 002/17, Loss: 1.2106\n",
      "Epoch: 30, Step: 003/17, Loss: 1.2107\n",
      "Epoch: 30, Step: 004/17, Loss: 1.2155\n",
      "Epoch: 30, Step: 005/17, Loss: 1.2122\n",
      "Epoch: 30, Step: 006/17, Loss: 1.2171\n",
      "Epoch: 30, Step: 007/17, Loss: 1.2099\n",
      "Epoch: 30, Step: 008/17, Loss: 1.2117\n",
      "Epoch: 30, Step: 009/17, Loss: 1.2129\n",
      "Epoch: 30, Step: 010/17, Loss: 1.2091\n",
      "Epoch: 30, Step: 011/17, Loss: 1.2089\n",
      "Epoch: 30, Step: 012/17, Loss: 1.2139\n",
      "Epoch: 30, Step: 013/17, Loss: 1.2113\n",
      "Epoch: 30, Step: 014/17, Loss: 1.2095\n",
      "Epoch: 30, Step: 015/17, Loss: 1.2135\n",
      "Epoch: 30, Step: 016/17, Loss: 1.2134\n",
      "Epoch: 30, Step: 017/17, Loss: 1.2090\n",
      "Epoch: 31, Step: 001/17, Loss: 1.2130\n",
      "Epoch: 31, Step: 002/17, Loss: 1.2067\n",
      "Epoch: 31, Step: 003/17, Loss: 1.2129\n",
      "Epoch: 31, Step: 004/17, Loss: 1.2127\n",
      "Epoch: 31, Step: 005/17, Loss: 1.2068\n",
      "Epoch: 31, Step: 006/17, Loss: 1.2124\n",
      "Epoch: 31, Step: 007/17, Loss: 1.2098\n",
      "Epoch: 31, Step: 008/17, Loss: 1.2143\n",
      "Epoch: 31, Step: 009/17, Loss: 1.2102\n",
      "Epoch: 31, Step: 010/17, Loss: 1.2085\n",
      "Epoch: 31, Step: 011/17, Loss: 1.2109\n",
      "Epoch: 31, Step: 012/17, Loss: 1.2118\n",
      "Epoch: 31, Step: 013/17, Loss: 1.2108\n",
      "Epoch: 31, Step: 014/17, Loss: 1.2083\n",
      "Epoch: 31, Step: 015/17, Loss: 1.2072\n",
      "Epoch: 31, Step: 016/17, Loss: 1.2060\n",
      "Epoch: 31, Step: 017/17, Loss: 1.2148\n",
      "Epoch: 32, Step: 001/17, Loss: 1.2109\n",
      "Epoch: 32, Step: 002/17, Loss: 1.2113\n",
      "Epoch: 32, Step: 003/17, Loss: 1.2091\n",
      "Epoch: 32, Step: 004/17, Loss: 1.2101\n",
      "Epoch: 32, Step: 005/17, Loss: 1.2128\n",
      "Epoch: 32, Step: 006/17, Loss: 1.2091\n",
      "Epoch: 32, Step: 007/17, Loss: 1.2096\n",
      "Epoch: 32, Step: 008/17, Loss: 1.2089\n",
      "Epoch: 32, Step: 009/17, Loss: 1.2110\n",
      "Epoch: 32, Step: 010/17, Loss: 1.2071\n",
      "Epoch: 32, Step: 011/17, Loss: 1.2084\n",
      "Epoch: 32, Step: 012/17, Loss: 1.2101\n",
      "Epoch: 32, Step: 013/17, Loss: 1.2104\n",
      "Epoch: 32, Step: 014/17, Loss: 1.2077\n",
      "Epoch: 32, Step: 015/17, Loss: 1.2079\n",
      "Epoch: 32, Step: 016/17, Loss: 1.2090\n",
      "Epoch: 32, Step: 017/17, Loss: 1.2038\n",
      "Epoch: 33, Step: 001/17, Loss: 1.2075\n",
      "Epoch: 33, Step: 002/17, Loss: 1.2066\n",
      "Epoch: 33, Step: 003/17, Loss: 1.2101\n",
      "Epoch: 33, Step: 004/17, Loss: 1.2115\n",
      "Epoch: 33, Step: 005/17, Loss: 1.2123\n",
      "Epoch: 33, Step: 006/17, Loss: 1.2107\n",
      "Epoch: 33, Step: 007/17, Loss: 1.2055\n",
      "Epoch: 33, Step: 008/17, Loss: 1.2118\n",
      "Epoch: 33, Step: 009/17, Loss: 1.2092\n",
      "Epoch: 33, Step: 010/17, Loss: 1.2087\n",
      "Epoch: 33, Step: 011/17, Loss: 1.2090\n",
      "Epoch: 33, Step: 012/17, Loss: 1.2053\n",
      "Epoch: 33, Step: 013/17, Loss: 1.2093\n",
      "Epoch: 33, Step: 014/17, Loss: 1.2089\n",
      "Epoch: 33, Step: 015/17, Loss: 1.2108\n",
      "Epoch: 33, Step: 016/17, Loss: 1.2099\n",
      "Epoch: 33, Step: 017/17, Loss: 1.2081\n",
      "Epoch: 34, Step: 001/17, Loss: 1.2057\n",
      "Epoch: 34, Step: 002/17, Loss: 1.2093\n",
      "Epoch: 34, Step: 003/17, Loss: 1.2095\n",
      "Epoch: 34, Step: 004/17, Loss: 1.2074\n",
      "Epoch: 34, Step: 005/17, Loss: 1.2110\n",
      "Epoch: 34, Step: 006/17, Loss: 1.2073\n",
      "Epoch: 34, Step: 007/17, Loss: 1.2088\n",
      "Epoch: 34, Step: 008/17, Loss: 1.2069\n",
      "Epoch: 34, Step: 009/17, Loss: 1.2076\n",
      "Epoch: 34, Step: 010/17, Loss: 1.2050\n",
      "Epoch: 34, Step: 011/17, Loss: 1.2096\n",
      "Epoch: 34, Step: 012/17, Loss: 1.2058\n",
      "Epoch: 34, Step: 013/17, Loss: 1.2076\n",
      "Epoch: 34, Step: 014/17, Loss: 1.2058\n",
      "Epoch: 34, Step: 015/17, Loss: 1.2120\n",
      "Epoch: 34, Step: 016/17, Loss: 1.2060\n",
      "Epoch: 34, Step: 017/17, Loss: 1.2095\n",
      "Epoch: 35, Step: 001/17, Loss: 1.2072\n",
      "Epoch: 35, Step: 002/17, Loss: 1.2085\n",
      "Epoch: 35, Step: 003/17, Loss: 1.2054\n",
      "Epoch: 35, Step: 004/17, Loss: 1.2079\n",
      "Epoch: 35, Step: 005/17, Loss: 1.2075\n",
      "Epoch: 35, Step: 006/17, Loss: 1.2064\n",
      "Epoch: 35, Step: 007/17, Loss: 1.2042\n",
      "Epoch: 35, Step: 008/17, Loss: 1.2083\n",
      "Epoch: 35, Step: 009/17, Loss: 1.2084\n",
      "Epoch: 35, Step: 010/17, Loss: 1.2073\n",
      "Epoch: 35, Step: 011/17, Loss: 1.2051\n",
      "Epoch: 35, Step: 012/17, Loss: 1.2113\n",
      "Epoch: 35, Step: 013/17, Loss: 1.2054\n",
      "Epoch: 35, Step: 014/17, Loss: 1.2061\n",
      "Epoch: 35, Step: 015/17, Loss: 1.2022\n",
      "Epoch: 35, Step: 016/17, Loss: 1.2064\n",
      "Epoch: 35, Step: 017/17, Loss: 1.2095\n",
      "Epoch: 36, Step: 001/17, Loss: 1.2067\n",
      "Epoch: 36, Step: 002/17, Loss: 1.2063\n",
      "Epoch: 36, Step: 003/17, Loss: 1.2068\n",
      "Epoch: 36, Step: 004/17, Loss: 1.2044\n",
      "Epoch: 36, Step: 005/17, Loss: 1.2042\n",
      "Epoch: 36, Step: 006/17, Loss: 1.2068\n",
      "Epoch: 36, Step: 007/17, Loss: 1.2079\n",
      "Epoch: 36, Step: 008/17, Loss: 1.2093\n",
      "Epoch: 36, Step: 009/17, Loss: 1.2079\n",
      "Epoch: 36, Step: 010/17, Loss: 1.2057\n",
      "Epoch: 36, Step: 011/17, Loss: 1.2095\n",
      "Epoch: 36, Step: 012/17, Loss: 1.2060\n",
      "Epoch: 36, Step: 013/17, Loss: 1.2078\n",
      "Epoch: 36, Step: 014/17, Loss: 1.2044\n",
      "Epoch: 36, Step: 015/17, Loss: 1.2048\n",
      "Epoch: 36, Step: 016/17, Loss: 1.2087\n",
      "Epoch: 36, Step: 017/17, Loss: 1.2067\n",
      "Epoch: 37, Step: 001/17, Loss: 1.2075\n",
      "Epoch: 37, Step: 002/17, Loss: 1.2054\n",
      "Epoch: 37, Step: 003/17, Loss: 1.2024\n",
      "Epoch: 37, Step: 004/17, Loss: 1.2057\n",
      "Epoch: 37, Step: 005/17, Loss: 1.2039\n",
      "Epoch: 37, Step: 006/17, Loss: 1.2101\n",
      "Epoch: 37, Step: 007/17, Loss: 1.2049\n",
      "Epoch: 37, Step: 008/17, Loss: 1.2054\n",
      "Epoch: 37, Step: 009/17, Loss: 1.2048\n",
      "Epoch: 37, Step: 010/17, Loss: 1.2056\n",
      "Epoch: 37, Step: 011/17, Loss: 1.2076\n",
      "Epoch: 37, Step: 012/17, Loss: 1.2072\n",
      "Epoch: 37, Step: 013/17, Loss: 1.2075\n",
      "Epoch: 37, Step: 014/17, Loss: 1.2015\n",
      "Epoch: 37, Step: 015/17, Loss: 1.2045\n",
      "Epoch: 37, Step: 016/17, Loss: 1.2048\n",
      "Epoch: 37, Step: 017/17, Loss: 1.2063\n",
      "Epoch: 38, Step: 001/17, Loss: 1.2052\n",
      "Epoch: 38, Step: 002/17, Loss: 1.2080\n",
      "Epoch: 38, Step: 003/17, Loss: 1.2057\n",
      "Epoch: 38, Step: 004/17, Loss: 1.2051\n",
      "Epoch: 38, Step: 005/17, Loss: 1.2064\n",
      "Epoch: 38, Step: 006/17, Loss: 1.2059\n",
      "Epoch: 38, Step: 007/17, Loss: 1.2093\n",
      "Epoch: 38, Step: 008/17, Loss: 1.2041\n",
      "Epoch: 38, Step: 009/17, Loss: 1.2054\n",
      "Epoch: 38, Step: 010/17, Loss: 1.2067\n",
      "Epoch: 38, Step: 011/17, Loss: 1.2071\n",
      "Epoch: 38, Step: 012/17, Loss: 1.2066\n",
      "Epoch: 38, Step: 013/17, Loss: 1.2067\n",
      "Epoch: 38, Step: 014/17, Loss: 1.2084\n",
      "Epoch: 38, Step: 015/17, Loss: 1.2034\n",
      "Epoch: 38, Step: 016/17, Loss: 1.2070\n",
      "Epoch: 38, Step: 017/17, Loss: 1.2052\n",
      "Epoch: 39, Step: 001/17, Loss: 1.2036\n",
      "Epoch: 39, Step: 002/17, Loss: 1.2063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Step: 003/17, Loss: 1.2044\n",
      "Epoch: 39, Step: 004/17, Loss: 1.2034\n",
      "Epoch: 39, Step: 005/17, Loss: 1.2042\n",
      "Epoch: 39, Step: 006/17, Loss: 1.2067\n",
      "Epoch: 39, Step: 007/17, Loss: 1.2083\n",
      "Epoch: 39, Step: 008/17, Loss: 1.2055\n",
      "Epoch: 39, Step: 009/17, Loss: 1.2055\n",
      "Epoch: 39, Step: 010/17, Loss: 1.2076\n",
      "Epoch: 39, Step: 011/17, Loss: 1.2072\n",
      "Epoch: 39, Step: 012/17, Loss: 1.2064\n",
      "Epoch: 39, Step: 013/17, Loss: 1.2067\n",
      "Epoch: 39, Step: 014/17, Loss: 1.2025\n",
      "Epoch: 39, Step: 015/17, Loss: 1.2076\n",
      "Epoch: 39, Step: 016/17, Loss: 1.2056\n",
      "Epoch: 39, Step: 017/17, Loss: 1.2042\n",
      "Epoch: 40, Step: 001/17, Loss: 1.2065\n",
      "Epoch: 40, Step: 002/17, Loss: 1.2071\n",
      "Epoch: 40, Step: 003/17, Loss: 1.2065\n",
      "Epoch: 40, Step: 004/17, Loss: 1.2041\n",
      "Epoch: 40, Step: 005/17, Loss: 1.2043\n",
      "Epoch: 40, Step: 006/17, Loss: 1.2030\n",
      "Epoch: 40, Step: 007/17, Loss: 1.2030\n",
      "Epoch: 40, Step: 008/17, Loss: 1.2011\n",
      "Epoch: 40, Step: 009/17, Loss: 1.2077\n",
      "Epoch: 40, Step: 010/17, Loss: 1.2029\n",
      "Epoch: 40, Step: 011/17, Loss: 1.2026\n",
      "Epoch: 40, Step: 012/17, Loss: 1.2113\n",
      "Epoch: 40, Step: 013/17, Loss: 1.2072\n",
      "Epoch: 40, Step: 014/17, Loss: 1.2055\n",
      "Epoch: 40, Step: 015/17, Loss: 1.2025\n",
      "Epoch: 40, Step: 016/17, Loss: 1.2032\n",
      "Epoch: 40, Step: 017/17, Loss: 1.2047\n",
      "Epoch: 41, Step: 001/17, Loss: 1.2024\n",
      "Epoch: 41, Step: 002/17, Loss: 1.2033\n",
      "Epoch: 41, Step: 003/17, Loss: 1.2040\n",
      "Epoch: 41, Step: 004/17, Loss: 1.2065\n",
      "Epoch: 41, Step: 005/17, Loss: 1.2073\n",
      "Epoch: 41, Step: 006/17, Loss: 1.2047\n",
      "Epoch: 41, Step: 007/17, Loss: 1.2020\n",
      "Epoch: 41, Step: 008/17, Loss: 1.2060\n",
      "Epoch: 41, Step: 009/17, Loss: 1.2083\n",
      "Epoch: 41, Step: 010/17, Loss: 1.2096\n",
      "Epoch: 41, Step: 011/17, Loss: 1.2034\n",
      "Epoch: 41, Step: 012/17, Loss: 1.2068\n",
      "Epoch: 41, Step: 013/17, Loss: 1.2067\n",
      "Epoch: 41, Step: 014/17, Loss: 1.2065\n",
      "Epoch: 41, Step: 015/17, Loss: 1.2038\n",
      "Epoch: 41, Step: 016/17, Loss: 1.2050\n",
      "Epoch: 41, Step: 017/17, Loss: 1.2103\n",
      "Epoch: 42, Step: 001/17, Loss: 1.2033\n",
      "Epoch: 42, Step: 002/17, Loss: 1.2094\n",
      "Epoch: 42, Step: 003/17, Loss: 1.2029\n",
      "Epoch: 42, Step: 004/17, Loss: 1.2021\n",
      "Epoch: 42, Step: 005/17, Loss: 1.2052\n",
      "Epoch: 42, Step: 006/17, Loss: 1.2046\n",
      "Epoch: 42, Step: 007/17, Loss: 1.2078\n",
      "Epoch: 42, Step: 008/17, Loss: 1.2061\n",
      "Epoch: 42, Step: 009/17, Loss: 1.2007\n",
      "Epoch: 42, Step: 010/17, Loss: 1.2037\n",
      "Epoch: 42, Step: 011/17, Loss: 1.2054\n",
      "Epoch: 42, Step: 012/17, Loss: 1.2019\n",
      "Epoch: 42, Step: 013/17, Loss: 1.2064\n",
      "Epoch: 42, Step: 014/17, Loss: 1.2030\n",
      "Epoch: 42, Step: 015/17, Loss: 1.2066\n",
      "Epoch: 42, Step: 016/17, Loss: 1.2075\n",
      "Epoch: 42, Step: 017/17, Loss: 1.2036\n",
      "Epoch: 43, Step: 001/17, Loss: 1.2038\n",
      "Epoch: 43, Step: 002/17, Loss: 1.2058\n",
      "Epoch: 43, Step: 003/17, Loss: 1.2024\n",
      "Epoch: 43, Step: 004/17, Loss: 1.2058\n",
      "Epoch: 43, Step: 005/17, Loss: 1.2038\n",
      "Epoch: 43, Step: 006/17, Loss: 1.2051\n",
      "Epoch: 43, Step: 007/17, Loss: 1.2033\n",
      "Epoch: 43, Step: 008/17, Loss: 1.2047\n",
      "Epoch: 43, Step: 009/17, Loss: 1.2053\n",
      "Epoch: 43, Step: 010/17, Loss: 1.2059\n",
      "Epoch: 43, Step: 011/17, Loss: 1.2044\n",
      "Epoch: 43, Step: 012/17, Loss: 1.2015\n",
      "Epoch: 43, Step: 013/17, Loss: 1.2062\n",
      "Epoch: 43, Step: 014/17, Loss: 1.2061\n",
      "Epoch: 43, Step: 015/17, Loss: 1.2034\n",
      "Epoch: 43, Step: 016/17, Loss: 1.2060\n",
      "Epoch: 43, Step: 017/17, Loss: 1.2039\n",
      "Epoch: 44, Step: 001/17, Loss: 1.2029\n",
      "Epoch: 44, Step: 002/17, Loss: 1.2028\n",
      "Epoch: 44, Step: 003/17, Loss: 1.2044\n",
      "Epoch: 44, Step: 004/17, Loss: 1.2044\n",
      "Epoch: 44, Step: 005/17, Loss: 1.2064\n",
      "Epoch: 44, Step: 006/17, Loss: 1.2021\n",
      "Epoch: 44, Step: 007/17, Loss: 1.2057\n",
      "Epoch: 44, Step: 008/17, Loss: 1.2040\n",
      "Epoch: 44, Step: 009/17, Loss: 1.1998\n",
      "Epoch: 44, Step: 010/17, Loss: 1.2044\n",
      "Epoch: 44, Step: 011/17, Loss: 1.2012\n",
      "Epoch: 44, Step: 012/17, Loss: 1.2047\n",
      "Epoch: 44, Step: 013/17, Loss: 1.2035\n",
      "Epoch: 44, Step: 014/17, Loss: 1.2043\n",
      "Epoch: 44, Step: 015/17, Loss: 1.2028\n",
      "Epoch: 44, Step: 016/17, Loss: 1.2087\n",
      "Epoch: 44, Step: 017/17, Loss: 1.2052\n",
      "Epoch: 45, Step: 001/17, Loss: 1.2016\n",
      "Epoch: 45, Step: 002/17, Loss: 1.2018\n",
      "Epoch: 45, Step: 003/17, Loss: 1.2005\n",
      "Epoch: 45, Step: 004/17, Loss: 1.2020\n",
      "Epoch: 45, Step: 005/17, Loss: 1.2039\n",
      "Epoch: 45, Step: 006/17, Loss: 1.2038\n",
      "Epoch: 45, Step: 007/17, Loss: 1.2038\n",
      "Epoch: 45, Step: 008/17, Loss: 1.2052\n",
      "Epoch: 45, Step: 009/17, Loss: 1.2028\n",
      "Epoch: 45, Step: 010/17, Loss: 1.2075\n",
      "Epoch: 45, Step: 011/17, Loss: 1.2048\n",
      "Epoch: 45, Step: 012/17, Loss: 1.2032\n",
      "Epoch: 45, Step: 013/17, Loss: 1.2024\n",
      "Epoch: 45, Step: 014/17, Loss: 1.2079\n",
      "Epoch: 45, Step: 015/17, Loss: 1.2040\n",
      "Epoch: 45, Step: 016/17, Loss: 1.2047\n",
      "Epoch: 45, Step: 017/17, Loss: 1.2024\n",
      "Epoch: 46, Step: 001/17, Loss: 1.2013\n",
      "Epoch: 46, Step: 002/17, Loss: 1.1997\n",
      "Epoch: 46, Step: 003/17, Loss: 1.2040\n",
      "Epoch: 46, Step: 004/17, Loss: 1.2090\n",
      "Epoch: 46, Step: 005/17, Loss: 1.2008\n",
      "Epoch: 46, Step: 006/17, Loss: 1.2020\n",
      "Epoch: 46, Step: 007/17, Loss: 1.2046\n",
      "Epoch: 46, Step: 008/17, Loss: 1.2028\n",
      "Epoch: 46, Step: 009/17, Loss: 1.2015\n",
      "Epoch: 46, Step: 010/17, Loss: 1.2072\n",
      "Epoch: 46, Step: 011/17, Loss: 1.2003\n",
      "Epoch: 46, Step: 012/17, Loss: 1.2052\n",
      "Epoch: 46, Step: 013/17, Loss: 1.2033\n",
      "Epoch: 46, Step: 014/17, Loss: 1.2041\n",
      "Epoch: 46, Step: 015/17, Loss: 1.2015\n",
      "Epoch: 46, Step: 016/17, Loss: 1.2044\n",
      "Epoch: 46, Step: 017/17, Loss: 1.2030\n",
      "Epoch: 47, Step: 001/17, Loss: 1.2044\n",
      "Epoch: 47, Step: 002/17, Loss: 1.2028\n",
      "Epoch: 47, Step: 003/17, Loss: 1.2031\n",
      "Epoch: 47, Step: 004/17, Loss: 1.2032\n",
      "Epoch: 47, Step: 005/17, Loss: 1.2010\n",
      "Epoch: 47, Step: 006/17, Loss: 1.2046\n",
      "Epoch: 47, Step: 007/17, Loss: 1.2056\n",
      "Epoch: 47, Step: 008/17, Loss: 1.2059\n",
      "Epoch: 47, Step: 009/17, Loss: 1.2010\n",
      "Epoch: 47, Step: 010/17, Loss: 1.2010\n",
      "Epoch: 47, Step: 011/17, Loss: 1.2041\n",
      "Epoch: 47, Step: 012/17, Loss: 1.2030\n",
      "Epoch: 47, Step: 013/17, Loss: 1.2011\n",
      "Epoch: 47, Step: 014/17, Loss: 1.2051\n",
      "Epoch: 47, Step: 015/17, Loss: 1.2020\n",
      "Epoch: 47, Step: 016/17, Loss: 1.2049\n",
      "Epoch: 47, Step: 017/17, Loss: 1.1975\n",
      "Epoch: 48, Step: 001/17, Loss: 1.2050\n",
      "Epoch: 48, Step: 002/17, Loss: 1.2010\n",
      "Epoch: 48, Step: 003/17, Loss: 1.1999\n",
      "Epoch: 48, Step: 004/17, Loss: 1.2033\n",
      "Epoch: 48, Step: 005/17, Loss: 1.2022\n",
      "Epoch: 48, Step: 006/17, Loss: 1.2034\n",
      "Epoch: 48, Step: 007/17, Loss: 1.2052\n",
      "Epoch: 48, Step: 008/17, Loss: 1.2035\n",
      "Epoch: 48, Step: 009/17, Loss: 1.1988\n",
      "Epoch: 48, Step: 010/17, Loss: 1.2006\n",
      "Epoch: 48, Step: 011/17, Loss: 1.2025\n",
      "Epoch: 48, Step: 012/17, Loss: 1.2050\n",
      "Epoch: 48, Step: 013/17, Loss: 1.2091\n",
      "Epoch: 48, Step: 014/17, Loss: 1.1999\n",
      "Epoch: 48, Step: 015/17, Loss: 1.2052\n",
      "Epoch: 48, Step: 016/17, Loss: 1.2055\n",
      "Epoch: 48, Step: 017/17, Loss: 1.2031\n",
      "Epoch: 49, Step: 001/17, Loss: 1.2030\n",
      "Epoch: 49, Step: 002/17, Loss: 1.2036\n",
      "Epoch: 49, Step: 003/17, Loss: 1.2023\n",
      "Epoch: 49, Step: 004/17, Loss: 1.2022\n",
      "Epoch: 49, Step: 005/17, Loss: 1.2003\n",
      "Epoch: 49, Step: 006/17, Loss: 1.2021\n",
      "Epoch: 49, Step: 007/17, Loss: 1.2014\n",
      "Epoch: 49, Step: 008/17, Loss: 1.2038\n",
      "Epoch: 49, Step: 009/17, Loss: 1.2044\n",
      "Epoch: 49, Step: 010/17, Loss: 1.2048\n",
      "Epoch: 49, Step: 011/17, Loss: 1.2060\n",
      "Epoch: 49, Step: 012/17, Loss: 1.2045\n",
      "Epoch: 49, Step: 013/17, Loss: 1.2036\n",
      "Epoch: 49, Step: 014/17, Loss: 1.2023\n",
      "Epoch: 49, Step: 015/17, Loss: 1.2031\n",
      "Epoch: 49, Step: 016/17, Loss: 1.2064\n",
      "Epoch: 49, Step: 017/17, Loss: 1.1990\n",
      "Epoch: 50, Step: 001/17, Loss: 1.2021\n",
      "Epoch: 50, Step: 002/17, Loss: 1.2003\n",
      "Epoch: 50, Step: 003/17, Loss: 1.1974\n",
      "Epoch: 50, Step: 004/17, Loss: 1.2056\n",
      "Epoch: 50, Step: 005/17, Loss: 1.2023\n",
      "Epoch: 50, Step: 006/17, Loss: 1.2061\n",
      "Epoch: 50, Step: 007/17, Loss: 1.2033\n",
      "Epoch: 50, Step: 008/17, Loss: 1.2008\n",
      "Epoch: 50, Step: 009/17, Loss: 1.2025\n",
      "Epoch: 50, Step: 010/17, Loss: 1.2019\n",
      "Epoch: 50, Step: 011/17, Loss: 1.2059\n",
      "Epoch: 50, Step: 012/17, Loss: 1.2061\n",
      "Epoch: 50, Step: 013/17, Loss: 1.2038\n",
      "Epoch: 50, Step: 014/17, Loss: 1.2031\n",
      "Epoch: 50, Step: 015/17, Loss: 1.2023\n",
      "Epoch: 50, Step: 016/17, Loss: 1.2029\n",
      "Epoch: 50, Step: 017/17, Loss: 1.2032\n",
      "Epoch: 51, Step: 001/17, Loss: 1.2003\n",
      "Epoch: 51, Step: 002/17, Loss: 1.2010\n",
      "Epoch: 51, Step: 003/17, Loss: 1.2006\n",
      "Epoch: 51, Step: 004/17, Loss: 1.2008\n",
      "Epoch: 51, Step: 005/17, Loss: 1.1995\n",
      "Epoch: 51, Step: 006/17, Loss: 1.2024\n",
      "Epoch: 51, Step: 007/17, Loss: 1.1984\n",
      "Epoch: 51, Step: 008/17, Loss: 1.2038\n",
      "Epoch: 51, Step: 009/17, Loss: 1.1998\n",
      "Epoch: 51, Step: 010/17, Loss: 1.1994\n",
      "Epoch: 51, Step: 011/17, Loss: 1.2064\n",
      "Epoch: 51, Step: 012/17, Loss: 1.2043\n",
      "Epoch: 51, Step: 013/17, Loss: 1.2022\n",
      "Epoch: 51, Step: 014/17, Loss: 1.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Step: 015/17, Loss: 1.2055\n",
      "Epoch: 51, Step: 016/17, Loss: 1.2019\n",
      "Epoch: 51, Step: 017/17, Loss: 1.2007\n",
      "Epoch: 52, Step: 001/17, Loss: 1.2052\n",
      "Epoch: 52, Step: 002/17, Loss: 1.2014\n",
      "Epoch: 52, Step: 003/17, Loss: 1.2012\n",
      "Epoch: 52, Step: 004/17, Loss: 1.1990\n",
      "Epoch: 52, Step: 005/17, Loss: 1.2006\n",
      "Epoch: 52, Step: 006/17, Loss: 1.2016\n",
      "Epoch: 52, Step: 007/17, Loss: 1.1996\n",
      "Epoch: 52, Step: 008/17, Loss: 1.2011\n",
      "Epoch: 52, Step: 009/17, Loss: 1.2021\n",
      "Epoch: 52, Step: 010/17, Loss: 1.2008\n",
      "Epoch: 52, Step: 011/17, Loss: 1.2013\n",
      "Epoch: 52, Step: 012/17, Loss: 1.1980\n",
      "Epoch: 52, Step: 013/17, Loss: 1.1974\n",
      "Epoch: 52, Step: 014/17, Loss: 1.2044\n",
      "Epoch: 52, Step: 015/17, Loss: 1.2006\n",
      "Epoch: 52, Step: 016/17, Loss: 1.2027\n",
      "Epoch: 52, Step: 017/17, Loss: 1.2030\n",
      "Epoch: 53, Step: 001/17, Loss: 1.2017\n",
      "Epoch: 53, Step: 002/17, Loss: 1.1986\n",
      "Epoch: 53, Step: 003/17, Loss: 1.2047\n",
      "Epoch: 53, Step: 004/17, Loss: 1.2021\n",
      "Epoch: 53, Step: 005/17, Loss: 1.2044\n",
      "Epoch: 53, Step: 006/17, Loss: 1.2036\n",
      "Epoch: 53, Step: 007/17, Loss: 1.2047\n",
      "Epoch: 53, Step: 008/17, Loss: 1.2002\n",
      "Epoch: 53, Step: 009/17, Loss: 1.2026\n",
      "Epoch: 53, Step: 010/17, Loss: 1.2010\n",
      "Epoch: 53, Step: 011/17, Loss: 1.2027\n",
      "Epoch: 53, Step: 012/17, Loss: 1.2016\n",
      "Epoch: 53, Step: 013/17, Loss: 1.2023\n",
      "Epoch: 53, Step: 014/17, Loss: 1.2011\n",
      "Epoch: 53, Step: 015/17, Loss: 1.2051\n",
      "Epoch: 53, Step: 016/17, Loss: 1.2002\n",
      "Epoch: 53, Step: 017/17, Loss: 1.2032\n",
      "Epoch: 54, Step: 001/17, Loss: 1.2025\n",
      "Epoch: 54, Step: 002/17, Loss: 1.1987\n",
      "Epoch: 54, Step: 003/17, Loss: 1.2000\n",
      "Epoch: 54, Step: 004/17, Loss: 1.2024\n",
      "Epoch: 54, Step: 005/17, Loss: 1.2006\n",
      "Epoch: 54, Step: 006/17, Loss: 1.2030\n",
      "Epoch: 54, Step: 007/17, Loss: 1.1998\n",
      "Epoch: 54, Step: 008/17, Loss: 1.2028\n",
      "Epoch: 54, Step: 009/17, Loss: 1.2019\n",
      "Epoch: 54, Step: 010/17, Loss: 1.1993\n",
      "Epoch: 54, Step: 011/17, Loss: 1.2041\n",
      "Epoch: 54, Step: 012/17, Loss: 1.2037\n",
      "Epoch: 54, Step: 013/17, Loss: 1.2049\n",
      "Epoch: 54, Step: 014/17, Loss: 1.2039\n",
      "Epoch: 54, Step: 015/17, Loss: 1.2062\n",
      "Epoch: 54, Step: 016/17, Loss: 1.2032\n",
      "Epoch: 54, Step: 017/17, Loss: 1.1992\n",
      "Epoch: 55, Step: 001/17, Loss: 1.2030\n",
      "Epoch: 55, Step: 002/17, Loss: 1.2000\n",
      "Epoch: 55, Step: 003/17, Loss: 1.2055\n",
      "Epoch: 55, Step: 004/17, Loss: 1.2029\n",
      "Epoch: 55, Step: 005/17, Loss: 1.2011\n",
      "Epoch: 55, Step: 006/17, Loss: 1.2007\n",
      "Epoch: 55, Step: 007/17, Loss: 1.2003\n",
      "Epoch: 55, Step: 008/17, Loss: 1.2003\n",
      "Epoch: 55, Step: 009/17, Loss: 1.2011\n",
      "Epoch: 55, Step: 010/17, Loss: 1.2045\n",
      "Epoch: 55, Step: 011/17, Loss: 1.2073\n",
      "Epoch: 55, Step: 012/17, Loss: 1.2004\n",
      "Epoch: 55, Step: 013/17, Loss: 1.2044\n",
      "Epoch: 55, Step: 014/17, Loss: 1.2032\n",
      "Epoch: 55, Step: 015/17, Loss: 1.2033\n",
      "Epoch: 55, Step: 016/17, Loss: 1.2026\n",
      "Epoch: 55, Step: 017/17, Loss: 1.2074\n",
      "Epoch: 56, Step: 001/17, Loss: 1.2001\n",
      "Epoch: 56, Step: 002/17, Loss: 1.2036\n",
      "Epoch: 56, Step: 003/17, Loss: 1.2021\n",
      "Epoch: 56, Step: 004/17, Loss: 1.1994\n",
      "Epoch: 56, Step: 005/17, Loss: 1.1988\n",
      "Epoch: 56, Step: 006/17, Loss: 1.2012\n",
      "Epoch: 56, Step: 007/17, Loss: 1.2020\n",
      "Epoch: 56, Step: 008/17, Loss: 1.2008\n",
      "Epoch: 56, Step: 009/17, Loss: 1.2021\n",
      "Epoch: 56, Step: 010/17, Loss: 1.2015\n",
      "Epoch: 56, Step: 011/17, Loss: 1.2067\n",
      "Epoch: 56, Step: 012/17, Loss: 1.2043\n",
      "Epoch: 56, Step: 013/17, Loss: 1.1993\n",
      "Epoch: 56, Step: 014/17, Loss: 1.1998\n",
      "Epoch: 56, Step: 015/17, Loss: 1.2041\n",
      "Epoch: 56, Step: 016/17, Loss: 1.2026\n",
      "Epoch: 56, Step: 017/17, Loss: 1.2028\n",
      "Epoch: 57, Step: 001/17, Loss: 1.2014\n",
      "Epoch: 57, Step: 002/17, Loss: 1.2009\n",
      "Epoch: 57, Step: 003/17, Loss: 1.2004\n",
      "Epoch: 57, Step: 004/17, Loss: 1.2013\n",
      "Epoch: 57, Step: 005/17, Loss: 1.2015\n",
      "Epoch: 57, Step: 006/17, Loss: 1.2028\n",
      "Epoch: 57, Step: 007/17, Loss: 1.1991\n",
      "Epoch: 57, Step: 008/17, Loss: 1.2022\n",
      "Epoch: 57, Step: 009/17, Loss: 1.2044\n",
      "Epoch: 57, Step: 010/17, Loss: 1.2011\n",
      "Epoch: 57, Step: 011/17, Loss: 1.2041\n",
      "Epoch: 57, Step: 012/17, Loss: 1.2034\n",
      "Epoch: 57, Step: 013/17, Loss: 1.1999\n",
      "Epoch: 57, Step: 014/17, Loss: 1.2052\n",
      "Epoch: 57, Step: 015/17, Loss: 1.2012\n",
      "Epoch: 57, Step: 016/17, Loss: 1.2037\n",
      "Epoch: 57, Step: 017/17, Loss: 1.1999\n",
      "Epoch: 58, Step: 001/17, Loss: 1.2034\n",
      "Epoch: 58, Step: 002/17, Loss: 1.2056\n",
      "Epoch: 58, Step: 003/17, Loss: 1.1990\n",
      "Epoch: 58, Step: 004/17, Loss: 1.1977\n",
      "Epoch: 58, Step: 005/17, Loss: 1.2025\n",
      "Epoch: 58, Step: 006/17, Loss: 1.2031\n",
      "Epoch: 58, Step: 007/17, Loss: 1.2022\n",
      "Epoch: 58, Step: 008/17, Loss: 1.2037\n",
      "Epoch: 58, Step: 009/17, Loss: 1.2029\n",
      "Epoch: 58, Step: 010/17, Loss: 1.2004\n",
      "Epoch: 58, Step: 011/17, Loss: 1.2000\n",
      "Epoch: 58, Step: 012/17, Loss: 1.2024\n",
      "Epoch: 58, Step: 013/17, Loss: 1.2019\n",
      "Epoch: 58, Step: 014/17, Loss: 1.2033\n",
      "Epoch: 58, Step: 015/17, Loss: 1.2013\n",
      "Epoch: 58, Step: 016/17, Loss: 1.2044\n",
      "Epoch: 58, Step: 017/17, Loss: 1.1988\n",
      "Epoch: 59, Step: 001/17, Loss: 1.1979\n",
      "Epoch: 59, Step: 002/17, Loss: 1.2010\n",
      "Epoch: 59, Step: 003/17, Loss: 1.2043\n",
      "Epoch: 59, Step: 004/17, Loss: 1.2014\n",
      "Epoch: 59, Step: 005/17, Loss: 1.2027\n",
      "Epoch: 59, Step: 006/17, Loss: 1.2024\n",
      "Epoch: 59, Step: 007/17, Loss: 1.2016\n",
      "Epoch: 59, Step: 008/17, Loss: 1.2010\n",
      "Epoch: 59, Step: 009/17, Loss: 1.2027\n",
      "Epoch: 59, Step: 010/17, Loss: 1.2014\n",
      "Epoch: 59, Step: 011/17, Loss: 1.2028\n",
      "Epoch: 59, Step: 012/17, Loss: 1.2026\n",
      "Epoch: 59, Step: 013/17, Loss: 1.2002\n",
      "Epoch: 59, Step: 014/17, Loss: 1.2048\n",
      "Epoch: 59, Step: 015/17, Loss: 1.2029\n",
      "Epoch: 59, Step: 016/17, Loss: 1.2036\n",
      "Epoch: 59, Step: 017/17, Loss: 1.2048\n",
      "Epoch: 60, Step: 001/17, Loss: 1.2035\n",
      "Epoch: 60, Step: 002/17, Loss: 1.1994\n",
      "Epoch: 60, Step: 003/17, Loss: 1.1985\n",
      "Epoch: 60, Step: 004/17, Loss: 1.2032\n",
      "Epoch: 60, Step: 005/17, Loss: 1.2023\n",
      "Epoch: 60, Step: 006/17, Loss: 1.2015\n",
      "Epoch: 60, Step: 007/17, Loss: 1.1993\n",
      "Epoch: 60, Step: 008/17, Loss: 1.2042\n",
      "Epoch: 60, Step: 009/17, Loss: 1.2005\n",
      "Epoch: 60, Step: 010/17, Loss: 1.2032\n",
      "Epoch: 60, Step: 011/17, Loss: 1.2006\n",
      "Epoch: 60, Step: 012/17, Loss: 1.2019\n",
      "Epoch: 60, Step: 013/17, Loss: 1.2008\n",
      "Epoch: 60, Step: 014/17, Loss: 1.2011\n",
      "Epoch: 60, Step: 015/17, Loss: 1.2017\n",
      "Epoch: 60, Step: 016/17, Loss: 1.2031\n",
      "Epoch: 60, Step: 017/17, Loss: 1.2022\n",
      "Epoch: 61, Step: 001/17, Loss: 1.1989\n",
      "Epoch: 61, Step: 002/17, Loss: 1.1996\n",
      "Epoch: 61, Step: 003/17, Loss: 1.2025\n",
      "Epoch: 61, Step: 004/17, Loss: 1.2052\n",
      "Epoch: 61, Step: 005/17, Loss: 1.2029\n",
      "Epoch: 61, Step: 006/17, Loss: 1.2016\n",
      "Epoch: 61, Step: 007/17, Loss: 1.2046\n",
      "Epoch: 61, Step: 008/17, Loss: 1.1998\n",
      "Epoch: 61, Step: 009/17, Loss: 1.2052\n",
      "Epoch: 61, Step: 010/17, Loss: 1.2011\n",
      "Epoch: 61, Step: 011/17, Loss: 1.2017\n",
      "Epoch: 61, Step: 012/17, Loss: 1.1984\n",
      "Epoch: 61, Step: 013/17, Loss: 1.2010\n",
      "Epoch: 61, Step: 014/17, Loss: 1.2007\n",
      "Epoch: 61, Step: 015/17, Loss: 1.2017\n",
      "Epoch: 61, Step: 016/17, Loss: 1.2023\n",
      "Epoch: 61, Step: 017/17, Loss: 1.1969\n",
      "Epoch: 62, Step: 001/17, Loss: 1.2020\n",
      "Epoch: 62, Step: 002/17, Loss: 1.1984\n",
      "Epoch: 62, Step: 003/17, Loss: 1.1975\n",
      "Epoch: 62, Step: 004/17, Loss: 1.2025\n",
      "Epoch: 62, Step: 005/17, Loss: 1.1985\n",
      "Epoch: 62, Step: 006/17, Loss: 1.2077\n",
      "Epoch: 62, Step: 007/17, Loss: 1.1992\n",
      "Epoch: 62, Step: 008/17, Loss: 1.2037\n",
      "Epoch: 62, Step: 009/17, Loss: 1.1983\n",
      "Epoch: 62, Step: 010/17, Loss: 1.2010\n",
      "Epoch: 62, Step: 011/17, Loss: 1.1999\n",
      "Epoch: 62, Step: 012/17, Loss: 1.2032\n",
      "Epoch: 62, Step: 013/17, Loss: 1.1994\n",
      "Epoch: 62, Step: 014/17, Loss: 1.2010\n",
      "Epoch: 62, Step: 015/17, Loss: 1.1999\n",
      "Epoch: 62, Step: 016/17, Loss: 1.1999\n",
      "Epoch: 62, Step: 017/17, Loss: 1.2017\n",
      "Epoch: 63, Step: 001/17, Loss: 1.2007\n",
      "Epoch: 63, Step: 002/17, Loss: 1.2019\n",
      "Epoch: 63, Step: 003/17, Loss: 1.1990\n",
      "Epoch: 63, Step: 004/17, Loss: 1.2048\n",
      "Epoch: 63, Step: 005/17, Loss: 1.2022\n",
      "Epoch: 63, Step: 006/17, Loss: 1.1983\n",
      "Epoch: 63, Step: 007/17, Loss: 1.2029\n",
      "Epoch: 63, Step: 008/17, Loss: 1.1993\n",
      "Epoch: 63, Step: 009/17, Loss: 1.1985\n",
      "Epoch: 63, Step: 010/17, Loss: 1.2012\n",
      "Epoch: 63, Step: 011/17, Loss: 1.2006\n",
      "Epoch: 63, Step: 012/17, Loss: 1.2011\n",
      "Epoch: 63, Step: 013/17, Loss: 1.1987\n",
      "Epoch: 63, Step: 014/17, Loss: 1.2006\n",
      "Epoch: 63, Step: 015/17, Loss: 1.2015\n",
      "Epoch: 63, Step: 016/17, Loss: 1.2007\n",
      "Epoch: 63, Step: 017/17, Loss: 1.2033\n",
      "Epoch: 64, Step: 001/17, Loss: 1.1980\n",
      "Epoch: 64, Step: 002/17, Loss: 1.2000\n",
      "Epoch: 64, Step: 003/17, Loss: 1.2021\n",
      "Epoch: 64, Step: 004/17, Loss: 1.2010\n",
      "Epoch: 64, Step: 005/17, Loss: 1.2017\n",
      "Epoch: 64, Step: 006/17, Loss: 1.2034\n",
      "Epoch: 64, Step: 007/17, Loss: 1.1977\n",
      "Epoch: 64, Step: 008/17, Loss: 1.2020\n",
      "Epoch: 64, Step: 009/17, Loss: 1.1994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Step: 010/17, Loss: 1.2012\n",
      "Epoch: 64, Step: 011/17, Loss: 1.2049\n",
      "Epoch: 64, Step: 012/17, Loss: 1.1998\n",
      "Epoch: 64, Step: 013/17, Loss: 1.2035\n",
      "Epoch: 64, Step: 014/17, Loss: 1.2003\n",
      "Epoch: 64, Step: 015/17, Loss: 1.2022\n",
      "Epoch: 64, Step: 016/17, Loss: 1.2021\n",
      "Epoch: 64, Step: 017/17, Loss: 1.2053\n",
      "Epoch: 65, Step: 001/17, Loss: 1.1999\n",
      "Epoch: 65, Step: 002/17, Loss: 1.2006\n",
      "Epoch: 65, Step: 003/17, Loss: 1.2007\n",
      "Epoch: 65, Step: 004/17, Loss: 1.2000\n",
      "Epoch: 65, Step: 005/17, Loss: 1.2041\n",
      "Epoch: 65, Step: 006/17, Loss: 1.1987\n",
      "Epoch: 65, Step: 007/17, Loss: 1.2006\n",
      "Epoch: 65, Step: 008/17, Loss: 1.2019\n",
      "Epoch: 65, Step: 009/17, Loss: 1.2006\n",
      "Epoch: 65, Step: 010/17, Loss: 1.1985\n",
      "Epoch: 65, Step: 011/17, Loss: 1.1984\n",
      "Epoch: 65, Step: 012/17, Loss: 1.2002\n",
      "Epoch: 65, Step: 013/17, Loss: 1.2011\n",
      "Epoch: 65, Step: 014/17, Loss: 1.2016\n",
      "Epoch: 65, Step: 015/17, Loss: 1.2029\n",
      "Epoch: 65, Step: 016/17, Loss: 1.2015\n",
      "Epoch: 65, Step: 017/17, Loss: 1.2019\n",
      "Epoch: 66, Step: 001/17, Loss: 1.2003\n",
      "Epoch: 66, Step: 002/17, Loss: 1.2017\n",
      "Epoch: 66, Step: 003/17, Loss: 1.1995\n",
      "Epoch: 66, Step: 004/17, Loss: 1.2017\n",
      "Epoch: 66, Step: 005/17, Loss: 1.1994\n",
      "Epoch: 66, Step: 006/17, Loss: 1.2030\n",
      "Epoch: 66, Step: 007/17, Loss: 1.1986\n",
      "Epoch: 66, Step: 008/17, Loss: 1.2035\n",
      "Epoch: 66, Step: 009/17, Loss: 1.1983\n",
      "Epoch: 66, Step: 010/17, Loss: 1.2021\n",
      "Epoch: 66, Step: 011/17, Loss: 1.1988\n",
      "Epoch: 66, Step: 012/17, Loss: 1.2028\n",
      "Epoch: 66, Step: 013/17, Loss: 1.2022\n",
      "Epoch: 66, Step: 014/17, Loss: 1.2029\n",
      "Epoch: 66, Step: 015/17, Loss: 1.2005\n",
      "Epoch: 66, Step: 016/17, Loss: 1.1977\n",
      "Epoch: 66, Step: 017/17, Loss: 1.2031\n",
      "Epoch: 67, Step: 001/17, Loss: 1.1987\n",
      "Epoch: 67, Step: 002/17, Loss: 1.2015\n",
      "Epoch: 67, Step: 003/17, Loss: 1.2005\n",
      "Epoch: 67, Step: 004/17, Loss: 1.2011\n",
      "Epoch: 67, Step: 005/17, Loss: 1.2027\n",
      "Epoch: 67, Step: 006/17, Loss: 1.2000\n",
      "Epoch: 67, Step: 007/17, Loss: 1.2008\n",
      "Epoch: 67, Step: 008/17, Loss: 1.2028\n",
      "Epoch: 67, Step: 009/17, Loss: 1.2010\n",
      "Epoch: 67, Step: 010/17, Loss: 1.2044\n",
      "Epoch: 67, Step: 011/17, Loss: 1.2022\n",
      "Epoch: 67, Step: 012/17, Loss: 1.2016\n",
      "Epoch: 67, Step: 013/17, Loss: 1.1967\n",
      "Epoch: 67, Step: 014/17, Loss: 1.1994\n",
      "Epoch: 67, Step: 015/17, Loss: 1.2008\n",
      "Epoch: 67, Step: 016/17, Loss: 1.1995\n",
      "Epoch: 67, Step: 017/17, Loss: 1.2060\n",
      "Epoch: 68, Step: 001/17, Loss: 1.1975\n",
      "Epoch: 68, Step: 002/17, Loss: 1.2033\n",
      "Epoch: 68, Step: 003/17, Loss: 1.2011\n",
      "Epoch: 68, Step: 004/17, Loss: 1.2013\n",
      "Epoch: 68, Step: 005/17, Loss: 1.1987\n",
      "Epoch: 68, Step: 006/17, Loss: 1.2035\n",
      "Epoch: 68, Step: 007/17, Loss: 1.2010\n",
      "Epoch: 68, Step: 008/17, Loss: 1.1997\n",
      "Epoch: 68, Step: 009/17, Loss: 1.2017\n",
      "Epoch: 68, Step: 010/17, Loss: 1.2023\n",
      "Epoch: 68, Step: 011/17, Loss: 1.2015\n",
      "Epoch: 68, Step: 012/17, Loss: 1.1991\n",
      "Epoch: 68, Step: 013/17, Loss: 1.2006\n",
      "Epoch: 68, Step: 014/17, Loss: 1.2064\n",
      "Epoch: 68, Step: 015/17, Loss: 1.2028\n",
      "Epoch: 68, Step: 016/17, Loss: 1.2014\n",
      "Epoch: 68, Step: 017/17, Loss: 1.1983\n",
      "Epoch: 69, Step: 001/17, Loss: 1.2035\n",
      "Epoch: 69, Step: 002/17, Loss: 1.2002\n",
      "Epoch: 69, Step: 003/17, Loss: 1.1997\n",
      "Epoch: 69, Step: 004/17, Loss: 1.2023\n",
      "Epoch: 69, Step: 005/17, Loss: 1.1978\n",
      "Epoch: 69, Step: 006/17, Loss: 1.2017\n",
      "Epoch: 69, Step: 007/17, Loss: 1.1999\n",
      "Epoch: 69, Step: 008/17, Loss: 1.2037\n",
      "Epoch: 69, Step: 009/17, Loss: 1.2024\n",
      "Epoch: 69, Step: 010/17, Loss: 1.2013\n",
      "Epoch: 69, Step: 011/17, Loss: 1.1975\n",
      "Epoch: 69, Step: 012/17, Loss: 1.2040\n",
      "Epoch: 69, Step: 013/17, Loss: 1.2019\n",
      "Epoch: 69, Step: 014/17, Loss: 1.1987\n",
      "Epoch: 69, Step: 015/17, Loss: 1.1976\n",
      "Epoch: 69, Step: 016/17, Loss: 1.2027\n",
      "Epoch: 69, Step: 017/17, Loss: 1.1986\n",
      "Epoch: 70, Step: 001/17, Loss: 1.2022\n",
      "Epoch: 70, Step: 002/17, Loss: 1.2005\n",
      "Epoch: 70, Step: 003/17, Loss: 1.1998\n",
      "Epoch: 70, Step: 004/17, Loss: 1.1960\n",
      "Epoch: 70, Step: 005/17, Loss: 1.2027\n",
      "Epoch: 70, Step: 006/17, Loss: 1.2020\n",
      "Epoch: 70, Step: 007/17, Loss: 1.2033\n",
      "Epoch: 70, Step: 008/17, Loss: 1.1987\n",
      "Epoch: 70, Step: 009/17, Loss: 1.2046\n",
      "Epoch: 70, Step: 010/17, Loss: 1.2014\n",
      "Epoch: 70, Step: 011/17, Loss: 1.2024\n",
      "Epoch: 70, Step: 012/17, Loss: 1.1988\n",
      "Epoch: 70, Step: 013/17, Loss: 1.2030\n",
      "Epoch: 70, Step: 014/17, Loss: 1.2001\n",
      "Epoch: 70, Step: 015/17, Loss: 1.2029\n",
      "Epoch: 70, Step: 016/17, Loss: 1.2030\n",
      "Epoch: 70, Step: 017/17, Loss: 1.1958\n",
      "Epoch: 71, Step: 001/17, Loss: 1.2019\n",
      "Epoch: 71, Step: 002/17, Loss: 1.2019\n",
      "Epoch: 71, Step: 003/17, Loss: 1.2032\n",
      "Epoch: 71, Step: 004/17, Loss: 1.2027\n",
      "Epoch: 71, Step: 005/17, Loss: 1.1983\n",
      "Epoch: 71, Step: 006/17, Loss: 1.2042\n",
      "Epoch: 71, Step: 007/17, Loss: 1.2035\n",
      "Epoch: 71, Step: 008/17, Loss: 1.2029\n",
      "Epoch: 71, Step: 009/17, Loss: 1.1975\n",
      "Epoch: 71, Step: 010/17, Loss: 1.2003\n",
      "Epoch: 71, Step: 011/17, Loss: 1.2007\n",
      "Epoch: 71, Step: 012/17, Loss: 1.1990\n",
      "Epoch: 71, Step: 013/17, Loss: 1.2006\n",
      "Epoch: 71, Step: 014/17, Loss: 1.2005\n",
      "Epoch: 71, Step: 015/17, Loss: 1.2005\n",
      "Epoch: 71, Step: 016/17, Loss: 1.2017\n",
      "Epoch: 71, Step: 017/17, Loss: 1.2041\n",
      "Epoch: 72, Step: 001/17, Loss: 1.2033\n",
      "Epoch: 72, Step: 002/17, Loss: 1.2007\n",
      "Epoch: 72, Step: 003/17, Loss: 1.2008\n",
      "Epoch: 72, Step: 004/17, Loss: 1.1988\n",
      "Epoch: 72, Step: 005/17, Loss: 1.1962\n",
      "Epoch: 72, Step: 006/17, Loss: 1.2002\n",
      "Epoch: 72, Step: 007/17, Loss: 1.2033\n",
      "Epoch: 72, Step: 008/17, Loss: 1.1998\n",
      "Epoch: 72, Step: 009/17, Loss: 1.2008\n",
      "Epoch: 72, Step: 010/17, Loss: 1.2033\n",
      "Epoch: 72, Step: 011/17, Loss: 1.1998\n",
      "Epoch: 72, Step: 012/17, Loss: 1.2030\n",
      "Epoch: 72, Step: 013/17, Loss: 1.1998\n",
      "Epoch: 72, Step: 014/17, Loss: 1.1993\n",
      "Epoch: 72, Step: 015/17, Loss: 1.2048\n",
      "Epoch: 72, Step: 016/17, Loss: 1.2001\n",
      "Epoch: 72, Step: 017/17, Loss: 1.1991\n",
      "Epoch: 73, Step: 001/17, Loss: 1.2035\n",
      "Epoch: 73, Step: 002/17, Loss: 1.2058\n",
      "Epoch: 73, Step: 003/17, Loss: 1.2023\n",
      "Epoch: 73, Step: 004/17, Loss: 1.2005\n",
      "Epoch: 73, Step: 005/17, Loss: 1.1981\n",
      "Epoch: 73, Step: 006/17, Loss: 1.2022\n",
      "Epoch: 73, Step: 007/17, Loss: 1.1996\n",
      "Epoch: 73, Step: 008/17, Loss: 1.1996\n",
      "Epoch: 73, Step: 009/17, Loss: 1.1989\n",
      "Epoch: 73, Step: 010/17, Loss: 1.2018\n",
      "Epoch: 73, Step: 011/17, Loss: 1.2005\n",
      "Epoch: 73, Step: 012/17, Loss: 1.2002\n",
      "Epoch: 73, Step: 013/17, Loss: 1.1981\n",
      "Epoch: 73, Step: 014/17, Loss: 1.2052\n",
      "Epoch: 73, Step: 015/17, Loss: 1.1990\n",
      "Epoch: 73, Step: 016/17, Loss: 1.2046\n",
      "Epoch: 73, Step: 017/17, Loss: 1.2019\n",
      "Epoch: 74, Step: 001/17, Loss: 1.1995\n",
      "Epoch: 74, Step: 002/17, Loss: 1.1971\n",
      "Epoch: 74, Step: 003/17, Loss: 1.1987\n",
      "Epoch: 74, Step: 004/17, Loss: 1.1994\n",
      "Epoch: 74, Step: 005/17, Loss: 1.2002\n",
      "Epoch: 74, Step: 006/17, Loss: 1.2017\n",
      "Epoch: 74, Step: 007/17, Loss: 1.2000\n",
      "Epoch: 74, Step: 008/17, Loss: 1.2005\n",
      "Epoch: 74, Step: 009/17, Loss: 1.2000\n",
      "Epoch: 74, Step: 010/17, Loss: 1.2053\n",
      "Epoch: 74, Step: 011/17, Loss: 1.2007\n",
      "Epoch: 74, Step: 012/17, Loss: 1.2012\n",
      "Epoch: 74, Step: 013/17, Loss: 1.2031\n",
      "Epoch: 74, Step: 014/17, Loss: 1.2001\n",
      "Epoch: 74, Step: 015/17, Loss: 1.2001\n",
      "Epoch: 74, Step: 016/17, Loss: 1.2008\n",
      "Epoch: 74, Step: 017/17, Loss: 1.2014\n",
      "Epoch: 75, Step: 001/17, Loss: 1.2002\n",
      "Epoch: 75, Step: 002/17, Loss: 1.2006\n",
      "Epoch: 75, Step: 003/17, Loss: 1.2007\n",
      "Epoch: 75, Step: 004/17, Loss: 1.2018\n",
      "Epoch: 75, Step: 005/17, Loss: 1.2017\n",
      "Epoch: 75, Step: 006/17, Loss: 1.2001\n",
      "Epoch: 75, Step: 007/17, Loss: 1.1988\n",
      "Epoch: 75, Step: 008/17, Loss: 1.2008\n",
      "Epoch: 75, Step: 009/17, Loss: 1.2024\n",
      "Epoch: 75, Step: 010/17, Loss: 1.1994\n",
      "Epoch: 75, Step: 011/17, Loss: 1.2024\n",
      "Epoch: 75, Step: 012/17, Loss: 1.2009\n",
      "Epoch: 75, Step: 013/17, Loss: 1.1999\n",
      "Epoch: 75, Step: 014/17, Loss: 1.2029\n",
      "Epoch: 75, Step: 015/17, Loss: 1.2032\n",
      "Epoch: 75, Step: 016/17, Loss: 1.2053\n",
      "Epoch: 75, Step: 017/17, Loss: 1.2007\n",
      "Epoch: 76, Step: 001/17, Loss: 1.1980\n",
      "Epoch: 76, Step: 002/17, Loss: 1.2015\n",
      "Epoch: 76, Step: 003/17, Loss: 1.1986\n",
      "Epoch: 76, Step: 004/17, Loss: 1.2020\n",
      "Epoch: 76, Step: 005/17, Loss: 1.2022\n",
      "Epoch: 76, Step: 006/17, Loss: 1.1997\n",
      "Epoch: 76, Step: 007/17, Loss: 1.1981\n",
      "Epoch: 76, Step: 008/17, Loss: 1.1995\n",
      "Epoch: 76, Step: 009/17, Loss: 1.2017\n",
      "Epoch: 76, Step: 010/17, Loss: 1.2031\n",
      "Epoch: 76, Step: 011/17, Loss: 1.1960\n",
      "Epoch: 76, Step: 012/17, Loss: 1.2009\n",
      "Epoch: 76, Step: 013/17, Loss: 1.2030\n",
      "Epoch: 76, Step: 014/17, Loss: 1.2037\n",
      "Epoch: 76, Step: 015/17, Loss: 1.2017\n",
      "Epoch: 76, Step: 016/17, Loss: 1.2028\n",
      "Epoch: 76, Step: 017/17, Loss: 1.2037\n",
      "Epoch: 77, Step: 001/17, Loss: 1.2013\n",
      "Epoch: 77, Step: 002/17, Loss: 1.2046\n",
      "Epoch: 77, Step: 003/17, Loss: 1.2015\n",
      "Epoch: 77, Step: 004/17, Loss: 1.2036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Step: 005/17, Loss: 1.2015\n",
      "Epoch: 77, Step: 006/17, Loss: 1.1978\n",
      "Epoch: 77, Step: 007/17, Loss: 1.2018\n",
      "Epoch: 77, Step: 008/17, Loss: 1.1968\n",
      "Epoch: 77, Step: 009/17, Loss: 1.2040\n",
      "Epoch: 77, Step: 010/17, Loss: 1.2045\n",
      "Epoch: 77, Step: 011/17, Loss: 1.2017\n",
      "Epoch: 77, Step: 012/17, Loss: 1.2001\n",
      "Epoch: 77, Step: 013/17, Loss: 1.1980\n",
      "Epoch: 77, Step: 014/17, Loss: 1.1992\n",
      "Epoch: 77, Step: 015/17, Loss: 1.2006\n",
      "Epoch: 77, Step: 016/17, Loss: 1.2006\n",
      "Epoch: 77, Step: 017/17, Loss: 1.2023\n",
      "Epoch: 78, Step: 001/17, Loss: 1.1993\n",
      "Epoch: 78, Step: 002/17, Loss: 1.1966\n",
      "Epoch: 78, Step: 003/17, Loss: 1.1973\n",
      "Epoch: 78, Step: 004/17, Loss: 1.2020\n",
      "Epoch: 78, Step: 005/17, Loss: 1.2020\n",
      "Epoch: 78, Step: 006/17, Loss: 1.1976\n",
      "Epoch: 78, Step: 007/17, Loss: 1.2021\n",
      "Epoch: 78, Step: 008/17, Loss: 1.2017\n",
      "Epoch: 78, Step: 009/17, Loss: 1.1992\n",
      "Epoch: 78, Step: 010/17, Loss: 1.2044\n",
      "Epoch: 78, Step: 011/17, Loss: 1.2013\n",
      "Epoch: 78, Step: 012/17, Loss: 1.1999\n",
      "Epoch: 78, Step: 013/17, Loss: 1.1979\n",
      "Epoch: 78, Step: 014/17, Loss: 1.1984\n",
      "Epoch: 78, Step: 015/17, Loss: 1.2020\n",
      "Epoch: 78, Step: 016/17, Loss: 1.2034\n",
      "Epoch: 78, Step: 017/17, Loss: 1.2009\n",
      "Epoch: 79, Step: 001/17, Loss: 1.1978\n",
      "Epoch: 79, Step: 002/17, Loss: 1.1994\n",
      "Epoch: 79, Step: 003/17, Loss: 1.2015\n",
      "Epoch: 79, Step: 004/17, Loss: 1.2007\n",
      "Epoch: 79, Step: 005/17, Loss: 1.1989\n",
      "Epoch: 79, Step: 006/17, Loss: 1.1982\n",
      "Epoch: 79, Step: 007/17, Loss: 1.2024\n",
      "Epoch: 79, Step: 008/17, Loss: 1.2012\n",
      "Epoch: 79, Step: 009/17, Loss: 1.2013\n",
      "Epoch: 79, Step: 010/17, Loss: 1.1974\n",
      "Epoch: 79, Step: 011/17, Loss: 1.2001\n",
      "Epoch: 79, Step: 012/17, Loss: 1.1993\n",
      "Epoch: 79, Step: 013/17, Loss: 1.2017\n",
      "Epoch: 79, Step: 014/17, Loss: 1.1987\n",
      "Epoch: 79, Step: 015/17, Loss: 1.1994\n",
      "Epoch: 79, Step: 016/17, Loss: 1.2056\n",
      "Epoch: 79, Step: 017/17, Loss: 1.2023\n",
      "Epoch: 80, Step: 001/17, Loss: 1.2002\n",
      "Epoch: 80, Step: 002/17, Loss: 1.1986\n",
      "Epoch: 80, Step: 003/17, Loss: 1.1984\n",
      "Epoch: 80, Step: 004/17, Loss: 1.1988\n",
      "Epoch: 80, Step: 005/17, Loss: 1.1990\n",
      "Epoch: 80, Step: 006/17, Loss: 1.2006\n",
      "Epoch: 80, Step: 007/17, Loss: 1.1995\n",
      "Epoch: 80, Step: 008/17, Loss: 1.2010\n",
      "Epoch: 80, Step: 009/17, Loss: 1.2005\n",
      "Epoch: 80, Step: 010/17, Loss: 1.2029\n",
      "Epoch: 80, Step: 011/17, Loss: 1.1978\n",
      "Epoch: 80, Step: 012/17, Loss: 1.2024\n",
      "Epoch: 80, Step: 013/17, Loss: 1.2011\n",
      "Epoch: 80, Step: 014/17, Loss: 1.2029\n",
      "Epoch: 80, Step: 015/17, Loss: 1.2024\n",
      "Epoch: 80, Step: 016/17, Loss: 1.2043\n",
      "Epoch: 80, Step: 017/17, Loss: 1.2010\n",
      "Epoch: 81, Step: 001/17, Loss: 1.2001\n",
      "Epoch: 81, Step: 002/17, Loss: 1.2013\n",
      "Epoch: 81, Step: 003/17, Loss: 1.1973\n",
      "Epoch: 81, Step: 004/17, Loss: 1.2016\n",
      "Epoch: 81, Step: 005/17, Loss: 1.2022\n",
      "Epoch: 81, Step: 006/17, Loss: 1.2034\n",
      "Epoch: 81, Step: 007/17, Loss: 1.2013\n",
      "Epoch: 81, Step: 008/17, Loss: 1.1999\n",
      "Epoch: 81, Step: 009/17, Loss: 1.2041\n",
      "Epoch: 81, Step: 010/17, Loss: 1.2005\n",
      "Epoch: 81, Step: 011/17, Loss: 1.2028\n",
      "Epoch: 81, Step: 012/17, Loss: 1.1984\n",
      "Epoch: 81, Step: 013/17, Loss: 1.2046\n",
      "Epoch: 81, Step: 014/17, Loss: 1.2008\n",
      "Epoch: 81, Step: 015/17, Loss: 1.2020\n",
      "Epoch: 81, Step: 016/17, Loss: 1.2034\n",
      "Epoch: 81, Step: 017/17, Loss: 1.1996\n",
      "Epoch: 82, Step: 001/17, Loss: 1.2004\n",
      "Epoch: 82, Step: 002/17, Loss: 1.1983\n",
      "Epoch: 82, Step: 003/17, Loss: 1.1976\n",
      "Epoch: 82, Step: 004/17, Loss: 1.2004\n",
      "Epoch: 82, Step: 005/17, Loss: 1.2016\n",
      "Epoch: 82, Step: 006/17, Loss: 1.2026\n",
      "Epoch: 82, Step: 007/17, Loss: 1.2052\n",
      "Epoch: 82, Step: 008/17, Loss: 1.1998\n",
      "Epoch: 82, Step: 009/17, Loss: 1.2034\n",
      "Epoch: 82, Step: 010/17, Loss: 1.2014\n",
      "Epoch: 82, Step: 011/17, Loss: 1.2006\n",
      "Epoch: 82, Step: 012/17, Loss: 1.1988\n",
      "Epoch: 82, Step: 013/17, Loss: 1.1999\n",
      "Epoch: 82, Step: 014/17, Loss: 1.2004\n",
      "Epoch: 82, Step: 015/17, Loss: 1.2001\n",
      "Epoch: 82, Step: 016/17, Loss: 1.2013\n",
      "Epoch: 82, Step: 017/17, Loss: 1.2022\n",
      "Epoch: 83, Step: 001/17, Loss: 1.2034\n",
      "Epoch: 83, Step: 002/17, Loss: 1.1962\n",
      "Epoch: 83, Step: 003/17, Loss: 1.2015\n",
      "Epoch: 83, Step: 004/17, Loss: 1.2033\n",
      "Epoch: 83, Step: 005/17, Loss: 1.2006\n",
      "Epoch: 83, Step: 006/17, Loss: 1.2007\n",
      "Epoch: 83, Step: 007/17, Loss: 1.1995\n",
      "Epoch: 83, Step: 008/17, Loss: 1.1991\n",
      "Epoch: 83, Step: 009/17, Loss: 1.2022\n",
      "Epoch: 83, Step: 010/17, Loss: 1.2015\n",
      "Epoch: 83, Step: 011/17, Loss: 1.2040\n",
      "Epoch: 83, Step: 012/17, Loss: 1.2009\n",
      "Epoch: 83, Step: 013/17, Loss: 1.2025\n",
      "Epoch: 83, Step: 014/17, Loss: 1.1991\n",
      "Epoch: 83, Step: 015/17, Loss: 1.2009\n",
      "Epoch: 83, Step: 016/17, Loss: 1.2014\n",
      "Epoch: 83, Step: 017/17, Loss: 1.2002\n",
      "Epoch: 84, Step: 001/17, Loss: 1.2005\n",
      "Epoch: 84, Step: 002/17, Loss: 1.1983\n",
      "Epoch: 84, Step: 003/17, Loss: 1.2005\n",
      "Epoch: 84, Step: 004/17, Loss: 1.1997\n",
      "Epoch: 84, Step: 005/17, Loss: 1.1992\n",
      "Epoch: 84, Step: 006/17, Loss: 1.2002\n",
      "Epoch: 84, Step: 007/17, Loss: 1.2021\n",
      "Epoch: 84, Step: 008/17, Loss: 1.1973\n",
      "Epoch: 84, Step: 009/17, Loss: 1.2023\n",
      "Epoch: 84, Step: 010/17, Loss: 1.2018\n",
      "Epoch: 84, Step: 011/17, Loss: 1.2008\n",
      "Epoch: 84, Step: 012/17, Loss: 1.2033\n",
      "Epoch: 84, Step: 013/17, Loss: 1.2012\n",
      "Epoch: 84, Step: 014/17, Loss: 1.1985\n",
      "Epoch: 84, Step: 015/17, Loss: 1.2010\n",
      "Epoch: 84, Step: 016/17, Loss: 1.1990\n",
      "Epoch: 84, Step: 017/17, Loss: 1.2000\n",
      "Epoch: 85, Step: 001/17, Loss: 1.2008\n",
      "Epoch: 85, Step: 002/17, Loss: 1.2013\n",
      "Epoch: 85, Step: 003/17, Loss: 1.2030\n",
      "Epoch: 85, Step: 004/17, Loss: 1.1995\n",
      "Epoch: 85, Step: 005/17, Loss: 1.2001\n",
      "Epoch: 85, Step: 006/17, Loss: 1.2032\n",
      "Epoch: 85, Step: 007/17, Loss: 1.2009\n",
      "Epoch: 85, Step: 008/17, Loss: 1.2009\n",
      "Epoch: 85, Step: 009/17, Loss: 1.2021\n",
      "Epoch: 85, Step: 010/17, Loss: 1.2028\n",
      "Epoch: 85, Step: 011/17, Loss: 1.2043\n",
      "Epoch: 85, Step: 012/17, Loss: 1.1979\n",
      "Epoch: 85, Step: 013/17, Loss: 1.2006\n",
      "Epoch: 85, Step: 014/17, Loss: 1.2002\n",
      "Epoch: 85, Step: 015/17, Loss: 1.2007\n",
      "Epoch: 85, Step: 016/17, Loss: 1.2014\n",
      "Epoch: 85, Step: 017/17, Loss: 1.1982\n",
      "Epoch: 86, Step: 001/17, Loss: 1.2008\n",
      "Epoch: 86, Step: 002/17, Loss: 1.1980\n",
      "Epoch: 86, Step: 003/17, Loss: 1.1978\n",
      "Epoch: 86, Step: 004/17, Loss: 1.2014\n",
      "Epoch: 86, Step: 005/17, Loss: 1.1980\n",
      "Epoch: 86, Step: 006/17, Loss: 1.2003\n",
      "Epoch: 86, Step: 007/17, Loss: 1.1991\n",
      "Epoch: 86, Step: 008/17, Loss: 1.2013\n",
      "Epoch: 86, Step: 009/17, Loss: 1.2022\n",
      "Epoch: 86, Step: 010/17, Loss: 1.1993\n",
      "Epoch: 86, Step: 011/17, Loss: 1.2047\n",
      "Epoch: 86, Step: 012/17, Loss: 1.2042\n",
      "Epoch: 86, Step: 013/17, Loss: 1.2007\n",
      "Epoch: 86, Step: 014/17, Loss: 1.2037\n",
      "Epoch: 86, Step: 015/17, Loss: 1.1988\n",
      "Epoch: 86, Step: 016/17, Loss: 1.2009\n",
      "Epoch: 86, Step: 017/17, Loss: 1.2034\n",
      "Epoch: 87, Step: 001/17, Loss: 1.2007\n",
      "Epoch: 87, Step: 002/17, Loss: 1.2001\n",
      "Epoch: 87, Step: 003/17, Loss: 1.1963\n",
      "Epoch: 87, Step: 004/17, Loss: 1.2036\n",
      "Epoch: 87, Step: 005/17, Loss: 1.2009\n",
      "Epoch: 87, Step: 006/17, Loss: 1.1981\n",
      "Epoch: 87, Step: 007/17, Loss: 1.2006\n",
      "Epoch: 87, Step: 008/17, Loss: 1.2021\n",
      "Epoch: 87, Step: 009/17, Loss: 1.1997\n",
      "Epoch: 87, Step: 010/17, Loss: 1.2011\n",
      "Epoch: 87, Step: 011/17, Loss: 1.1975\n",
      "Epoch: 87, Step: 012/17, Loss: 1.2019\n",
      "Epoch: 87, Step: 013/17, Loss: 1.2008\n",
      "Epoch: 87, Step: 014/17, Loss: 1.1989\n",
      "Epoch: 87, Step: 015/17, Loss: 1.2001\n",
      "Epoch: 87, Step: 016/17, Loss: 1.2010\n",
      "Epoch: 87, Step: 017/17, Loss: 1.2053\n",
      "Epoch: 88, Step: 001/17, Loss: 1.1989\n",
      "Epoch: 88, Step: 002/17, Loss: 1.1981\n",
      "Epoch: 88, Step: 003/17, Loss: 1.1971\n",
      "Epoch: 88, Step: 004/17, Loss: 1.2010\n",
      "Epoch: 88, Step: 005/17, Loss: 1.1990\n",
      "Epoch: 88, Step: 006/17, Loss: 1.2029\n",
      "Epoch: 88, Step: 007/17, Loss: 1.2038\n",
      "Epoch: 88, Step: 008/17, Loss: 1.1950\n",
      "Epoch: 88, Step: 009/17, Loss: 1.1997\n",
      "Epoch: 88, Step: 010/17, Loss: 1.2056\n",
      "Epoch: 88, Step: 011/17, Loss: 1.2002\n",
      "Epoch: 88, Step: 012/17, Loss: 1.2035\n",
      "Epoch: 88, Step: 013/17, Loss: 1.2029\n",
      "Epoch: 88, Step: 014/17, Loss: 1.2000\n",
      "Epoch: 88, Step: 015/17, Loss: 1.2018\n",
      "Epoch: 88, Step: 016/17, Loss: 1.2014\n",
      "Epoch: 88, Step: 017/17, Loss: 1.1990\n",
      "Epoch: 89, Step: 001/17, Loss: 1.1981\n",
      "Epoch: 89, Step: 002/17, Loss: 1.2009\n",
      "Epoch: 89, Step: 003/17, Loss: 1.2003\n",
      "Epoch: 89, Step: 004/17, Loss: 1.2025\n",
      "Epoch: 89, Step: 005/17, Loss: 1.2007\n",
      "Epoch: 89, Step: 006/17, Loss: 1.1987\n",
      "Epoch: 89, Step: 007/17, Loss: 1.2006\n",
      "Epoch: 89, Step: 008/17, Loss: 1.1990\n",
      "Epoch: 89, Step: 009/17, Loss: 1.2004\n",
      "Epoch: 89, Step: 010/17, Loss: 1.2012\n",
      "Epoch: 89, Step: 011/17, Loss: 1.1995\n",
      "Epoch: 89, Step: 012/17, Loss: 1.1998\n",
      "Epoch: 89, Step: 013/17, Loss: 1.2045\n",
      "Epoch: 89, Step: 014/17, Loss: 1.2000\n",
      "Epoch: 89, Step: 015/17, Loss: 1.2003\n",
      "Epoch: 89, Step: 016/17, Loss: 1.2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, Step: 017/17, Loss: 1.2035\n",
      "Epoch: 90, Step: 001/17, Loss: 1.2008\n",
      "Epoch: 90, Step: 002/17, Loss: 1.2016\n",
      "Epoch: 90, Step: 003/17, Loss: 1.1990\n",
      "Epoch: 90, Step: 004/17, Loss: 1.2006\n",
      "Epoch: 90, Step: 005/17, Loss: 1.1977\n",
      "Epoch: 90, Step: 006/17, Loss: 1.1999\n",
      "Epoch: 90, Step: 007/17, Loss: 1.2030\n",
      "Epoch: 90, Step: 008/17, Loss: 1.2028\n",
      "Epoch: 90, Step: 009/17, Loss: 1.2013\n",
      "Epoch: 90, Step: 010/17, Loss: 1.2031\n",
      "Epoch: 90, Step: 011/17, Loss: 1.2011\n",
      "Epoch: 90, Step: 012/17, Loss: 1.1994\n",
      "Epoch: 90, Step: 013/17, Loss: 1.1976\n",
      "Epoch: 90, Step: 014/17, Loss: 1.2010\n",
      "Epoch: 90, Step: 015/17, Loss: 1.1986\n",
      "Epoch: 90, Step: 016/17, Loss: 1.2034\n",
      "Epoch: 90, Step: 017/17, Loss: 1.2003\n",
      "Epoch: 91, Step: 001/17, Loss: 1.1981\n",
      "Epoch: 91, Step: 002/17, Loss: 1.2006\n",
      "Epoch: 91, Step: 003/17, Loss: 1.2002\n",
      "Epoch: 91, Step: 004/17, Loss: 1.1991\n",
      "Epoch: 91, Step: 005/17, Loss: 1.2002\n",
      "Epoch: 91, Step: 006/17, Loss: 1.1992\n",
      "Epoch: 91, Step: 007/17, Loss: 1.2014\n",
      "Epoch: 91, Step: 008/17, Loss: 1.1991\n",
      "Epoch: 91, Step: 009/17, Loss: 1.2013\n",
      "Epoch: 91, Step: 010/17, Loss: 1.1986\n",
      "Epoch: 91, Step: 011/17, Loss: 1.2039\n",
      "Epoch: 91, Step: 012/17, Loss: 1.1985\n",
      "Epoch: 91, Step: 013/17, Loss: 1.2037\n",
      "Epoch: 91, Step: 014/17, Loss: 1.2012\n",
      "Epoch: 91, Step: 015/17, Loss: 1.1999\n",
      "Epoch: 91, Step: 016/17, Loss: 1.1996\n",
      "Epoch: 91, Step: 017/17, Loss: 1.2043\n",
      "Epoch: 92, Step: 001/17, Loss: 1.2015\n",
      "Epoch: 92, Step: 002/17, Loss: 1.2029\n",
      "Epoch: 92, Step: 003/17, Loss: 1.1977\n",
      "Epoch: 92, Step: 004/17, Loss: 1.2037\n",
      "Epoch: 92, Step: 005/17, Loss: 1.2011\n",
      "Epoch: 92, Step: 006/17, Loss: 1.1969\n",
      "Epoch: 92, Step: 007/17, Loss: 1.1993\n",
      "Epoch: 92, Step: 008/17, Loss: 1.2003\n",
      "Epoch: 92, Step: 009/17, Loss: 1.1994\n",
      "Epoch: 92, Step: 010/17, Loss: 1.1997\n",
      "Epoch: 92, Step: 011/17, Loss: 1.2037\n",
      "Epoch: 92, Step: 012/17, Loss: 1.2009\n",
      "Epoch: 92, Step: 013/17, Loss: 1.2016\n",
      "Epoch: 92, Step: 014/17, Loss: 1.1991\n",
      "Epoch: 92, Step: 015/17, Loss: 1.1999\n",
      "Epoch: 92, Step: 016/17, Loss: 1.2035\n",
      "Epoch: 92, Step: 017/17, Loss: 1.2009\n",
      "Epoch: 93, Step: 001/17, Loss: 1.2006\n",
      "Epoch: 93, Step: 002/17, Loss: 1.2000\n",
      "Epoch: 93, Step: 003/17, Loss: 1.2015\n",
      "Epoch: 93, Step: 004/17, Loss: 1.1996\n",
      "Epoch: 93, Step: 005/17, Loss: 1.1991\n",
      "Epoch: 93, Step: 006/17, Loss: 1.1988\n",
      "Epoch: 93, Step: 007/17, Loss: 1.2013\n",
      "Epoch: 93, Step: 008/17, Loss: 1.2048\n",
      "Epoch: 93, Step: 009/17, Loss: 1.2011\n",
      "Epoch: 93, Step: 010/17, Loss: 1.1999\n",
      "Epoch: 93, Step: 011/17, Loss: 1.2022\n",
      "Epoch: 93, Step: 012/17, Loss: 1.2032\n",
      "Epoch: 93, Step: 013/17, Loss: 1.2016\n",
      "Epoch: 93, Step: 014/17, Loss: 1.1999\n",
      "Epoch: 93, Step: 015/17, Loss: 1.2029\n",
      "Epoch: 93, Step: 016/17, Loss: 1.2014\n",
      "Epoch: 93, Step: 017/17, Loss: 1.2036\n",
      "Epoch: 94, Step: 001/17, Loss: 1.2026\n",
      "Epoch: 94, Step: 002/17, Loss: 1.2035\n",
      "Epoch: 94, Step: 003/17, Loss: 1.2002\n",
      "Epoch: 94, Step: 004/17, Loss: 1.2025\n",
      "Epoch: 94, Step: 005/17, Loss: 1.2009\n",
      "Epoch: 94, Step: 006/17, Loss: 1.2001\n",
      "Epoch: 94, Step: 007/17, Loss: 1.2014\n",
      "Epoch: 94, Step: 008/17, Loss: 1.2035\n",
      "Epoch: 94, Step: 009/17, Loss: 1.1982\n",
      "Epoch: 94, Step: 010/17, Loss: 1.1989\n",
      "Epoch: 94, Step: 011/17, Loss: 1.2016\n",
      "Epoch: 94, Step: 012/17, Loss: 1.1987\n",
      "Epoch: 94, Step: 013/17, Loss: 1.2036\n",
      "Epoch: 94, Step: 014/17, Loss: 1.2004\n",
      "Epoch: 94, Step: 015/17, Loss: 1.1993\n",
      "Epoch: 94, Step: 016/17, Loss: 1.2006\n",
      "Epoch: 94, Step: 017/17, Loss: 1.2032\n",
      "Epoch: 95, Step: 001/17, Loss: 1.1999\n",
      "Epoch: 95, Step: 002/17, Loss: 1.1999\n",
      "Epoch: 95, Step: 003/17, Loss: 1.2011\n",
      "Epoch: 95, Step: 004/17, Loss: 1.2006\n",
      "Epoch: 95, Step: 005/17, Loss: 1.1995\n",
      "Epoch: 95, Step: 006/17, Loss: 1.2038\n",
      "Epoch: 95, Step: 007/17, Loss: 1.2008\n",
      "Epoch: 95, Step: 008/17, Loss: 1.1998\n",
      "Epoch: 95, Step: 009/17, Loss: 1.2006\n",
      "Epoch: 95, Step: 010/17, Loss: 1.1976\n",
      "Epoch: 95, Step: 011/17, Loss: 1.2029\n",
      "Epoch: 95, Step: 012/17, Loss: 1.1996\n",
      "Epoch: 95, Step: 013/17, Loss: 1.2008\n",
      "Epoch: 95, Step: 014/17, Loss: 1.2017\n",
      "Epoch: 95, Step: 015/17, Loss: 1.1976\n",
      "Epoch: 95, Step: 016/17, Loss: 1.1984\n",
      "Epoch: 95, Step: 017/17, Loss: 1.2025\n",
      "Epoch: 96, Step: 001/17, Loss: 1.2010\n",
      "Epoch: 96, Step: 002/17, Loss: 1.1994\n",
      "Epoch: 96, Step: 003/17, Loss: 1.2004\n",
      "Epoch: 96, Step: 004/17, Loss: 1.2025\n",
      "Epoch: 96, Step: 005/17, Loss: 1.1998\n",
      "Epoch: 96, Step: 006/17, Loss: 1.1983\n",
      "Epoch: 96, Step: 007/17, Loss: 1.1977\n",
      "Epoch: 96, Step: 008/17, Loss: 1.1991\n",
      "Epoch: 96, Step: 009/17, Loss: 1.2005\n",
      "Epoch: 96, Step: 010/17, Loss: 1.2003\n",
      "Epoch: 96, Step: 011/17, Loss: 1.2019\n",
      "Epoch: 96, Step: 012/17, Loss: 1.2006\n",
      "Epoch: 96, Step: 013/17, Loss: 1.1976\n",
      "Epoch: 96, Step: 014/17, Loss: 1.1979\n",
      "Epoch: 96, Step: 015/17, Loss: 1.1982\n",
      "Epoch: 96, Step: 016/17, Loss: 1.2052\n",
      "Epoch: 96, Step: 017/17, Loss: 1.2043\n",
      "Epoch: 97, Step: 001/17, Loss: 1.1975\n",
      "Epoch: 97, Step: 002/17, Loss: 1.1989\n",
      "Epoch: 97, Step: 003/17, Loss: 1.1995\n",
      "Epoch: 97, Step: 004/17, Loss: 1.1998\n",
      "Epoch: 97, Step: 005/17, Loss: 1.1990\n",
      "Epoch: 97, Step: 006/17, Loss: 1.1950\n",
      "Epoch: 97, Step: 007/17, Loss: 1.2016\n",
      "Epoch: 97, Step: 008/17, Loss: 1.1988\n",
      "Epoch: 97, Step: 009/17, Loss: 1.2020\n",
      "Epoch: 97, Step: 010/17, Loss: 1.2010\n",
      "Epoch: 97, Step: 011/17, Loss: 1.1981\n",
      "Epoch: 97, Step: 012/17, Loss: 1.2036\n",
      "Epoch: 97, Step: 013/17, Loss: 1.2005\n",
      "Epoch: 97, Step: 014/17, Loss: 1.1999\n",
      "Epoch: 97, Step: 015/17, Loss: 1.1997\n",
      "Epoch: 97, Step: 016/17, Loss: 1.2039\n",
      "Epoch: 97, Step: 017/17, Loss: 1.2044\n",
      "Epoch: 98, Step: 001/17, Loss: 1.1987\n",
      "Epoch: 98, Step: 002/17, Loss: 1.2017\n",
      "Epoch: 98, Step: 003/17, Loss: 1.2005\n",
      "Epoch: 98, Step: 004/17, Loss: 1.1994\n",
      "Epoch: 98, Step: 005/17, Loss: 1.1986\n",
      "Epoch: 98, Step: 006/17, Loss: 1.1994\n",
      "Epoch: 98, Step: 007/17, Loss: 1.1964\n",
      "Epoch: 98, Step: 008/17, Loss: 1.1993\n",
      "Epoch: 98, Step: 009/17, Loss: 1.2023\n",
      "Epoch: 98, Step: 010/17, Loss: 1.1989\n",
      "Epoch: 98, Step: 011/17, Loss: 1.2031\n",
      "Epoch: 98, Step: 012/17, Loss: 1.2007\n",
      "Epoch: 98, Step: 013/17, Loss: 1.2025\n",
      "Epoch: 98, Step: 014/17, Loss: 1.2029\n",
      "Epoch: 98, Step: 015/17, Loss: 1.2010\n",
      "Epoch: 98, Step: 016/17, Loss: 1.2000\n",
      "Epoch: 98, Step: 017/17, Loss: 1.2003\n",
      "Epoch: 99, Step: 001/17, Loss: 1.2023\n",
      "Epoch: 99, Step: 002/17, Loss: 1.2018\n",
      "Epoch: 99, Step: 003/17, Loss: 1.1987\n",
      "Epoch: 99, Step: 004/17, Loss: 1.2026\n",
      "Epoch: 99, Step: 005/17, Loss: 1.1969\n",
      "Epoch: 99, Step: 006/17, Loss: 1.2037\n",
      "Epoch: 99, Step: 007/17, Loss: 1.2017\n",
      "Epoch: 99, Step: 008/17, Loss: 1.2013\n",
      "Epoch: 99, Step: 009/17, Loss: 1.2026\n",
      "Epoch: 99, Step: 010/17, Loss: 1.1998\n",
      "Epoch: 99, Step: 011/17, Loss: 1.2015\n",
      "Epoch: 99, Step: 012/17, Loss: 1.2004\n",
      "Epoch: 99, Step: 013/17, Loss: 1.2021\n",
      "Epoch: 99, Step: 014/17, Loss: 1.2016\n",
      "Epoch: 99, Step: 015/17, Loss: 1.1988\n",
      "Epoch: 99, Step: 016/17, Loss: 1.2001\n",
      "Epoch: 99, Step: 017/17, Loss: 1.1941\n",
      "Epoch: 100, Step: 001/17, Loss: 1.2009\n",
      "Epoch: 100, Step: 002/17, Loss: 1.1989\n",
      "Epoch: 100, Step: 003/17, Loss: 1.2023\n",
      "Epoch: 100, Step: 004/17, Loss: 1.1977\n",
      "Epoch: 100, Step: 005/17, Loss: 1.1999\n",
      "Epoch: 100, Step: 006/17, Loss: 1.1983\n",
      "Epoch: 100, Step: 007/17, Loss: 1.2005\n",
      "Epoch: 100, Step: 008/17, Loss: 1.1994\n",
      "Epoch: 100, Step: 009/17, Loss: 1.1993\n",
      "Epoch: 100, Step: 010/17, Loss: 1.2032\n",
      "Epoch: 100, Step: 011/17, Loss: 1.2030\n",
      "Epoch: 100, Step: 012/17, Loss: 1.2041\n",
      "Epoch: 100, Step: 013/17, Loss: 1.1993\n",
      "Epoch: 100, Step: 014/17, Loss: 1.1991\n",
      "Epoch: 100, Step: 015/17, Loss: 1.2002\n",
      "Epoch: 100, Step: 016/17, Loss: 1.2046\n",
      "Epoch: 100, Step: 017/17, Loss: 1.2014\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #Parser for arguments for Node2Vec\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (Node2Vec)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--embedding_dim', type=int, default=128)\n",
    "    parser.add_argument('--walk_length', type=int, default=40)\n",
    "    parser.add_argument('--context_size', type=int, default=20)\n",
    "    parser.add_argument('--walks_per_node', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=256)\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--epochs', type=int, default=100)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #Use GPU if available\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    #load OGB DDI Dataset\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "    data = dataset[0]\n",
    "\n",
    "    #Defining the Node@Vec Model\n",
    "    model = Node2Vec(data.edge_index, args.embedding_dim, args.walk_length,\n",
    "                     args.context_size, args.walks_per_node,\n",
    "                     sparse=True).to(device)\n",
    "\n",
    "    loader = model.loader(batch_size=args.batch_size, shuffle=True,\n",
    "                          num_workers=4)\n",
    "    \n",
    "    # Using SparseAdam optimizer for parameterization\n",
    "    optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=args.lr)\n",
    "\n",
    "    #Train Node2Vec model\n",
    "    model.train()\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % args.log_steps == 0:\n",
    "                print(f'Epoch: {epoch:02d}, Step: {i+1:03d}/{len(loader)}, '\n",
    "                      f'Loss: {loss:.4f}')\n",
    "\n",
    "            if (i + 1) % 100 == 0:  # Save model every 100 steps.\n",
    "                save_embedding_todevice(model)\n",
    "        save_embedding_todevice(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5dc95f",
   "metadata": {},
   "source": [
    "## Tracker Function to Record Run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger Code referred from: https://github.com/snap-stanford/ogb/blob/master/examples/linkproppred/ddi/logger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbd084f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T08:37:43.163387Z",
     "start_time": "2022-07-14T08:37:43.128473Z"
    }
   },
   "outputs": [],
   "source": [
    "class Logger_Models(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f}  {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f}  {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f}  {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f}  {r.std():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4960d9",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386dc375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T11:37:42.342960Z",
     "start_time": "2022-07-05T11:37:42.319925Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021c01d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T14:56:03.711224Z",
     "start_time": "2022-08-07T14:55:57.375801Z"
    }
   },
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model, title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff30337d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-06T05:05:12.471903Z",
     "start_time": "2022-07-05T11:37:44.998735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(f='C:\\\\Users\\\\b04753yr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-30e704de-a8cc-40a4-8675-f15ec8e16fa1.json', device=0, log_steps=1, num_layers=3, hidden_channels=256, dropout=0.5, batch_size=65536, lr=0.01, epochs=200, eval_steps=5, runs=10)\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.4626, Train: 9.03%, Valid: 7.82%, Test: 2.86%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.4626, Train: 11.33%, Valid: 9.77%, Test: 8.22%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.4626, Train: 14.72%, Valid: 12.75%, Test: 13.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 10, Loss: 0.4281, Train: 9.99%, Valid: 8.56%, Test: 7.90%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 10, Loss: 0.4281, Train: 15.64%, Valid: 13.61%, Test: 10.38%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 10, Loss: 0.4281, Train: 20.27%, Valid: 17.76%, Test: 17.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 15, Loss: 0.4102, Train: 13.14%, Valid: 11.15%, Test: 11.13%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 15, Loss: 0.4102, Train: 19.22%, Valid: 16.61%, Test: 15.90%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 15, Loss: 0.4102, Train: 22.94%, Valid: 19.93%, Test: 20.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 20, Loss: 0.4010, Train: 14.09%, Valid: 12.07%, Test: 10.09%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 20, Loss: 0.4010, Train: 20.77%, Valid: 17.92%, Test: 15.91%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 20, Loss: 0.4010, Train: 22.62%, Valid: 19.65%, Test: 18.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 25, Loss: 0.3949, Train: 15.83%, Valid: 13.54%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 25, Loss: 0.3949, Train: 22.29%, Valid: 19.25%, Test: 15.00%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 25, Loss: 0.3949, Train: 27.89%, Valid: 24.40%, Test: 20.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 30, Loss: 0.3899, Train: 17.35%, Valid: 14.83%, Test: 11.25%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 30, Loss: 0.3899, Train: 22.42%, Valid: 19.34%, Test: 15.69%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 30, Loss: 0.3899, Train: 26.09%, Valid: 22.70%, Test: 22.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 35, Loss: 0.3888, Train: 14.65%, Valid: 12.48%, Test: 10.57%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 35, Loss: 0.3888, Train: 20.87%, Valid: 17.85%, Test: 17.05%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 35, Loss: 0.3888, Train: 24.94%, Valid: 21.60%, Test: 21.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 40, Loss: 0.3853, Train: 15.61%, Valid: 13.21%, Test: 11.74%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 40, Loss: 0.3853, Train: 22.47%, Valid: 19.41%, Test: 16.78%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 40, Loss: 0.3853, Train: 26.22%, Valid: 22.83%, Test: 23.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 45, Loss: 0.3831, Train: 16.29%, Valid: 13.68%, Test: 11.42%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 45, Loss: 0.3831, Train: 23.49%, Valid: 20.22%, Test: 17.50%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 45, Loss: 0.3831, Train: 27.32%, Valid: 23.72%, Test: 21.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 50, Loss: 0.3829, Train: 15.23%, Valid: 12.79%, Test: 10.82%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 50, Loss: 0.3829, Train: 21.78%, Valid: 18.65%, Test: 14.83%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 50, Loss: 0.3829, Train: 27.78%, Valid: 24.13%, Test: 20.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 55, Loss: 0.3800, Train: 13.51%, Valid: 11.33%, Test: 11.92%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 55, Loss: 0.3800, Train: 20.32%, Valid: 17.37%, Test: 15.61%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 55, Loss: 0.3800, Train: 26.37%, Valid: 22.73%, Test: 22.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 60, Loss: 0.3794, Train: 15.45%, Valid: 13.12%, Test: 13.20%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 60, Loss: 0.3794, Train: 20.82%, Valid: 17.77%, Test: 17.90%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 60, Loss: 0.3794, Train: 29.27%, Valid: 25.41%, Test: 21.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 65, Loss: 0.3784, Train: 15.16%, Valid: 12.73%, Test: 10.77%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 65, Loss: 0.3784, Train: 21.82%, Valid: 18.62%, Test: 16.35%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 65, Loss: 0.3784, Train: 26.89%, Valid: 23.30%, Test: 18.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 70, Loss: 0.3792, Train: 15.86%, Valid: 13.37%, Test: 11.76%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 70, Loss: 0.3792, Train: 24.59%, Valid: 21.21%, Test: 17.10%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 70, Loss: 0.3792, Train: 28.62%, Valid: 24.83%, Test: 22.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 75, Loss: 0.3778, Train: 10.34%, Valid: 8.60%, Test: 11.14%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 75, Loss: 0.3778, Train: 19.89%, Valid: 16.86%, Test: 17.15%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 75, Loss: 0.3778, Train: 25.36%, Valid: 21.74%, Test: 21.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 80, Loss: 0.3766, Train: 13.14%, Valid: 11.06%, Test: 10.65%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 80, Loss: 0.3766, Train: 23.14%, Valid: 19.84%, Test: 16.25%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 80, Loss: 0.3766, Train: 26.89%, Valid: 23.24%, Test: 21.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 85, Loss: 0.3764, Train: 15.06%, Valid: 12.58%, Test: 10.90%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 85, Loss: 0.3764, Train: 26.83%, Valid: 23.07%, Test: 18.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 85, Loss: 0.3764, Train: 30.67%, Valid: 26.68%, Test: 22.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 90, Loss: 0.3748, Train: 15.22%, Valid: 12.74%, Test: 10.63%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 90, Loss: 0.3748, Train: 19.55%, Valid: 16.55%, Test: 14.65%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 90, Loss: 0.3748, Train: 28.11%, Valid: 24.32%, Test: 17.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 95, Loss: 0.3762, Train: 13.60%, Valid: 11.31%, Test: 10.75%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.3762, Train: 23.29%, Valid: 19.98%, Test: 16.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 95, Loss: 0.3762, Train: 30.63%, Valid: 26.72%, Test: 22.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 100, Loss: 0.3760, Train: 14.98%, Valid: 12.63%, Test: 9.02%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.3760, Train: 20.03%, Valid: 17.02%, Test: 14.46%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 100, Loss: 0.3760, Train: 26.15%, Valid: 22.53%, Test: 20.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 105, Loss: 0.3751, Train: 16.14%, Valid: 13.61%, Test: 9.60%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.3751, Train: 23.92%, Valid: 20.40%, Test: 17.21%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 105, Loss: 0.3751, Train: 27.88%, Valid: 24.09%, Test: 19.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 110, Loss: 0.3753, Train: 12.78%, Valid: 10.57%, Test: 10.53%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.3753, Train: 22.89%, Valid: 19.48%, Test: 15.76%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 110, Loss: 0.3753, Train: 26.26%, Valid: 22.54%, Test: 21.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 115, Loss: 0.3740, Train: 16.08%, Valid: 13.54%, Test: 11.97%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.3740, Train: 22.11%, Valid: 18.78%, Test: 16.04%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 115, Loss: 0.3740, Train: 27.27%, Valid: 23.51%, Test: 20.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 120, Loss: 0.3744, Train: 11.14%, Valid: 9.22%, Test: 7.68%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.3744, Train: 21.95%, Valid: 18.62%, Test: 14.32%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 120, Loss: 0.3744, Train: 26.62%, Valid: 22.93%, Test: 19.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 125, Loss: 0.3747, Train: 11.72%, Valid: 9.76%, Test: 8.67%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.3747, Train: 23.09%, Valid: 19.61%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 125, Loss: 0.3747, Train: 25.27%, Valid: 21.67%, Test: 18.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 130, Loss: 0.3736, Train: 13.10%, Valid: 10.91%, Test: 10.74%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.3736, Train: 20.50%, Valid: 17.33%, Test: 13.53%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 130, Loss: 0.3736, Train: 27.27%, Valid: 23.52%, Test: 16.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 135, Loss: 0.3725, Train: 15.72%, Valid: 13.20%, Test: 8.58%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.3725, Train: 26.08%, Valid: 22.48%, Test: 15.71%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 135, Loss: 0.3725, Train: 30.22%, Valid: 26.32%, Test: 21.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 140, Loss: 0.3748, Train: 13.12%, Valid: 10.94%, Test: 9.59%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.3748, Train: 21.55%, Valid: 18.36%, Test: 15.16%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 140, Loss: 0.3748, Train: 23.92%, Valid: 20.51%, Test: 19.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 145, Loss: 0.3721, Train: 16.68%, Valid: 14.02%, Test: 10.64%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.3721, Train: 25.30%, Valid: 21.71%, Test: 14.47%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 145, Loss: 0.3721, Train: 28.40%, Valid: 24.63%, Test: 19.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 150, Loss: 0.3726, Train: 11.84%, Valid: 9.88%, Test: 8.38%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.3726, Train: 22.83%, Valid: 19.39%, Test: 15.21%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 150, Loss: 0.3726, Train: 26.65%, Valid: 22.87%, Test: 18.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 155, Loss: 0.3728, Train: 12.89%, Valid: 10.67%, Test: 8.56%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.3728, Train: 24.96%, Valid: 21.34%, Test: 15.54%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 155, Loss: 0.3728, Train: 29.51%, Valid: 25.54%, Test: 18.45%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 01, Epoch: 160, Loss: 0.3728, Train: 15.83%, Valid: 13.27%, Test: 8.06%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.3728, Train: 23.93%, Valid: 20.44%, Test: 14.56%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 160, Loss: 0.3728, Train: 29.84%, Valid: 25.82%, Test: 19.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 165, Loss: 0.3722, Train: 15.81%, Valid: 13.24%, Test: 10.28%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.3722, Train: 20.96%, Valid: 17.78%, Test: 14.20%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 165, Loss: 0.3722, Train: 26.89%, Valid: 23.17%, Test: 19.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 170, Loss: 0.3712, Train: 15.64%, Valid: 13.11%, Test: 10.53%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.3712, Train: 24.32%, Valid: 20.75%, Test: 14.31%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 170, Loss: 0.3712, Train: 26.66%, Valid: 22.88%, Test: 19.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 175, Loss: 0.3729, Train: 8.22%, Valid: 6.78%, Test: 9.27%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.3729, Train: 19.55%, Valid: 16.42%, Test: 15.31%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 175, Loss: 0.3729, Train: 23.77%, Valid: 20.16%, Test: 18.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 180, Loss: 0.3727, Train: 11.73%, Valid: 9.73%, Test: 9.03%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.3727, Train: 21.79%, Valid: 18.39%, Test: 15.43%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 180, Loss: 0.3727, Train: 25.67%, Valid: 21.92%, Test: 19.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 185, Loss: 0.3721, Train: 12.92%, Valid: 10.79%, Test: 10.74%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.3721, Train: 21.79%, Valid: 18.51%, Test: 14.32%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 185, Loss: 0.3721, Train: 27.34%, Valid: 23.55%, Test: 16.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 190, Loss: 0.3707, Train: 10.00%, Valid: 8.29%, Test: 8.63%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.3707, Train: 21.37%, Valid: 18.12%, Test: 16.15%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 190, Loss: 0.3707, Train: 27.16%, Valid: 23.34%, Test: 19.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 195, Loss: 0.3712, Train: 13.54%, Valid: 11.28%, Test: 9.39%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.3712, Train: 23.91%, Valid: 20.38%, Test: 15.72%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 195, Loss: 0.3712, Train: 27.03%, Valid: 23.25%, Test: 18.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 200, Loss: 0.3707, Train: 11.73%, Valid: 9.73%, Test: 9.87%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.3707, Train: 22.64%, Valid: 19.33%, Test: 13.01%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 200, Loss: 0.3707, Train: 25.37%, Valid: 21.75%, Test: 18.22%\n",
      "---\n",
      "Hits@10\n",
      "Run 01:\n",
      "Highest Train: 17.35\n",
      "Highest Valid: 14.83\n",
      "  Final Train: 17.35\n",
      "   Final Test: 11.25\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Train: 26.83\n",
      "Highest Valid: 23.07\n",
      "  Final Train: 26.83\n",
      "   Final Test: 18.49\n",
      "Hits@30\n",
      "Run 01:\n",
      "Highest Train: 30.67\n",
      "Highest Valid: 26.72\n",
      "  Final Train: 30.63\n",
      "   Final Test: 22.09\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.4635, Train: 8.49%, Valid: 7.34%, Test: 3.74%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.4635, Train: 11.57%, Valid: 9.99%, Test: 7.28%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.4635, Train: 15.92%, Valid: 13.85%, Test: 12.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 10, Loss: 0.4306, Train: 12.73%, Valid: 11.00%, Test: 6.28%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.4306, Train: 15.28%, Valid: 13.24%, Test: 9.15%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 10, Loss: 0.4306, Train: 18.53%, Valid: 16.18%, Test: 16.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 15, Loss: 0.4118, Train: 13.75%, Valid: 11.64%, Test: 10.89%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.4118, Train: 18.47%, Valid: 15.94%, Test: 16.57%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 15, Loss: 0.4118, Train: 22.55%, Valid: 19.66%, Test: 22.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 20, Loss: 0.4031, Train: 14.32%, Valid: 12.19%, Test: 11.60%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.4031, Train: 21.64%, Valid: 18.64%, Test: 19.10%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 20, Loss: 0.4031, Train: 26.00%, Valid: 22.55%, Test: 23.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 25, Loss: 0.3946, Train: 13.86%, Valid: 11.72%, Test: 12.24%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.3946, Train: 18.73%, Valid: 15.99%, Test: 16.02%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 25, Loss: 0.3946, Train: 22.17%, Valid: 19.17%, Test: 20.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 30, Loss: 0.3910, Train: 14.30%, Valid: 11.98%, Test: 12.42%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.3910, Train: 20.26%, Valid: 17.48%, Test: 17.79%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 30, Loss: 0.3910, Train: 23.60%, Valid: 20.42%, Test: 21.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 35, Loss: 0.3870, Train: 11.03%, Valid: 9.12%, Test: 13.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.3870, Train: 17.76%, Valid: 15.01%, Test: 16.83%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 35, Loss: 0.3870, Train: 21.60%, Valid: 18.46%, Test: 21.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 40, Loss: 0.3839, Train: 10.76%, Valid: 8.94%, Test: 11.19%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.3839, Train: 18.54%, Valid: 15.63%, Test: 16.90%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 40, Loss: 0.3839, Train: 22.48%, Valid: 19.23%, Test: 21.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 45, Loss: 0.3839, Train: 12.03%, Valid: 10.02%, Test: 12.83%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.3839, Train: 16.08%, Valid: 13.55%, Test: 15.85%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 45, Loss: 0.3839, Train: 21.90%, Valid: 18.64%, Test: 19.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 50, Loss: 0.3814, Train: 13.31%, Valid: 11.08%, Test: 10.63%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.3814, Train: 16.93%, Valid: 14.23%, Test: 14.99%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 50, Loss: 0.3814, Train: 20.62%, Valid: 17.60%, Test: 20.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 55, Loss: 0.3802, Train: 16.95%, Valid: 14.28%, Test: 10.62%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.3802, Train: 19.27%, Valid: 16.33%, Test: 16.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 55, Loss: 0.3802, Train: 24.65%, Valid: 21.22%, Test: 19.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 60, Loss: 0.3796, Train: 15.89%, Valid: 13.32%, Test: 10.87%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.3796, Train: 20.11%, Valid: 17.09%, Test: 14.52%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 60, Loss: 0.3796, Train: 25.18%, Valid: 21.66%, Test: 18.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 65, Loss: 0.3779, Train: 14.62%, Valid: 12.25%, Test: 10.93%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.3779, Train: 19.35%, Valid: 16.47%, Test: 16.06%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 65, Loss: 0.3779, Train: 24.87%, Valid: 21.31%, Test: 18.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 70, Loss: 0.3782, Train: 11.52%, Valid: 9.55%, Test: 10.58%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.3782, Train: 17.46%, Valid: 14.75%, Test: 13.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 70, Loss: 0.3782, Train: 20.24%, Valid: 17.21%, Test: 18.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 75, Loss: 0.3772, Train: 15.07%, Valid: 12.66%, Test: 10.04%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.3772, Train: 19.97%, Valid: 16.89%, Test: 13.88%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 75, Loss: 0.3772, Train: 23.75%, Valid: 20.36%, Test: 17.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 80, Loss: 0.3757, Train: 17.18%, Valid: 14.62%, Test: 7.84%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.3757, Train: 23.56%, Valid: 20.20%, Test: 12.30%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 80, Loss: 0.3757, Train: 25.60%, Valid: 22.07%, Test: 17.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 85, Loss: 0.3750, Train: 12.43%, Valid: 10.29%, Test: 8.64%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.3750, Train: 16.16%, Valid: 13.54%, Test: 13.63%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 85, Loss: 0.3750, Train: 20.28%, Valid: 17.17%, Test: 17.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 90, Loss: 0.3747, Train: 11.90%, Valid: 9.94%, Test: 10.33%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.3747, Train: 17.81%, Valid: 15.02%, Test: 13.72%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 90, Loss: 0.3747, Train: 22.03%, Valid: 18.75%, Test: 17.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 95, Loss: 0.3742, Train: 9.42%, Valid: 7.79%, Test: 8.48%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.3742, Train: 16.92%, Valid: 14.23%, Test: 13.62%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 95, Loss: 0.3742, Train: 20.57%, Valid: 17.52%, Test: 18.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 100, Loss: 0.3744, Train: 14.53%, Valid: 12.16%, Test: 11.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.3744, Train: 18.56%, Valid: 15.64%, Test: 15.07%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 100, Loss: 0.3744, Train: 23.76%, Valid: 20.26%, Test: 19.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 105, Loss: 0.3745, Train: 14.14%, Valid: 11.79%, Test: 10.15%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.3745, Train: 19.49%, Valid: 16.53%, Test: 12.64%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 105, Loss: 0.3745, Train: 23.25%, Valid: 19.75%, Test: 15.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 110, Loss: 0.3730, Train: 13.98%, Valid: 11.71%, Test: 10.15%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.3730, Train: 19.07%, Valid: 16.12%, Test: 13.37%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 110, Loss: 0.3730, Train: 25.45%, Valid: 21.81%, Test: 17.26%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 02, Epoch: 115, Loss: 0.3733, Train: 14.22%, Valid: 11.92%, Test: 9.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.3733, Train: 21.89%, Valid: 18.60%, Test: 13.09%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 115, Loss: 0.3733, Train: 23.92%, Valid: 20.49%, Test: 15.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 120, Loss: 0.3723, Train: 15.90%, Valid: 13.36%, Test: 9.77%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.3723, Train: 21.83%, Valid: 18.58%, Test: 13.97%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 120, Loss: 0.3723, Train: 27.30%, Valid: 23.55%, Test: 17.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 125, Loss: 0.3726, Train: 14.46%, Valid: 12.09%, Test: 9.50%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.3726, Train: 21.27%, Valid: 17.94%, Test: 13.62%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 125, Loss: 0.3726, Train: 25.23%, Valid: 21.52%, Test: 17.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 130, Loss: 0.3725, Train: 16.56%, Valid: 13.94%, Test: 9.57%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.3725, Train: 20.11%, Valid: 17.06%, Test: 11.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 130, Loss: 0.3725, Train: 22.64%, Valid: 19.24%, Test: 14.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 135, Loss: 0.3730, Train: 13.13%, Valid: 10.93%, Test: 7.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.3730, Train: 19.19%, Valid: 16.28%, Test: 11.63%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 135, Loss: 0.3730, Train: 23.34%, Valid: 19.91%, Test: 15.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 140, Loss: 0.3725, Train: 11.41%, Valid: 9.48%, Test: 9.11%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.3725, Train: 19.09%, Valid: 16.17%, Test: 12.04%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 140, Loss: 0.3725, Train: 23.41%, Valid: 19.99%, Test: 17.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 145, Loss: 0.3715, Train: 13.90%, Valid: 11.58%, Test: 9.86%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.3715, Train: 17.78%, Valid: 15.03%, Test: 13.84%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 145, Loss: 0.3715, Train: 24.15%, Valid: 20.60%, Test: 17.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 150, Loss: 0.3715, Train: 11.44%, Valid: 9.41%, Test: 8.30%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.3715, Train: 16.56%, Valid: 14.00%, Test: 11.76%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 150, Loss: 0.3715, Train: 22.30%, Valid: 19.01%, Test: 15.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 155, Loss: 0.3711, Train: 13.85%, Valid: 11.51%, Test: 9.07%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.3711, Train: 18.37%, Valid: 15.41%, Test: 11.92%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 155, Loss: 0.3711, Train: 21.72%, Valid: 18.40%, Test: 15.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 160, Loss: 0.3704, Train: 15.08%, Valid: 12.56%, Test: 10.31%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.3704, Train: 19.45%, Valid: 16.51%, Test: 14.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 160, Loss: 0.3704, Train: 23.23%, Valid: 19.81%, Test: 17.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 165, Loss: 0.3702, Train: 12.48%, Valid: 10.39%, Test: 10.35%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.3702, Train: 18.34%, Valid: 15.54%, Test: 14.71%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 165, Loss: 0.3702, Train: 25.35%, Valid: 21.73%, Test: 18.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 170, Loss: 0.3718, Train: 12.33%, Valid: 10.22%, Test: 9.31%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.3718, Train: 19.99%, Valid: 17.04%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 170, Loss: 0.3718, Train: 25.26%, Valid: 21.73%, Test: 17.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 175, Loss: 0.3703, Train: 14.04%, Valid: 11.68%, Test: 10.30%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.3703, Train: 20.27%, Valid: 17.29%, Test: 14.15%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 175, Loss: 0.3703, Train: 23.80%, Valid: 20.36%, Test: 16.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 180, Loss: 0.3708, Train: 10.41%, Valid: 8.47%, Test: 11.42%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.3708, Train: 17.69%, Valid: 14.86%, Test: 13.10%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 180, Loss: 0.3708, Train: 21.45%, Valid: 18.09%, Test: 17.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 185, Loss: 0.3709, Train: 13.77%, Valid: 11.40%, Test: 8.06%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.3709, Train: 18.73%, Valid: 15.80%, Test: 11.78%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 185, Loss: 0.3709, Train: 23.39%, Valid: 19.91%, Test: 15.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 190, Loss: 0.3711, Train: 12.22%, Valid: 10.10%, Test: 10.14%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.3711, Train: 17.32%, Valid: 14.66%, Test: 12.93%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 190, Loss: 0.3711, Train: 20.85%, Valid: 17.72%, Test: 16.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 195, Loss: 0.3707, Train: 14.44%, Valid: 12.05%, Test: 9.43%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.3707, Train: 19.62%, Valid: 16.58%, Test: 14.17%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 195, Loss: 0.3707, Train: 23.65%, Valid: 20.14%, Test: 16.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 200, Loss: 0.3697, Train: 12.03%, Valid: 9.99%, Test: 10.30%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.3697, Train: 18.66%, Valid: 15.77%, Test: 13.32%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 200, Loss: 0.3697, Train: 22.79%, Valid: 19.41%, Test: 16.62%\n",
      "---\n",
      "Hits@10\n",
      "Run 02:\n",
      "Highest Train: 17.18\n",
      "Highest Valid: 14.62\n",
      "  Final Train: 17.18\n",
      "   Final Test: 7.84\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Train: 23.56\n",
      "Highest Valid: 20.20\n",
      "  Final Train: 23.56\n",
      "   Final Test: 12.30\n",
      "Hits@30\n",
      "Run 02:\n",
      "Highest Train: 27.30\n",
      "Highest Valid: 23.55\n",
      "  Final Train: 27.30\n",
      "   Final Test: 17.13\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.4626, Train: 8.23%, Valid: 7.11%, Test: 3.76%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.4626, Train: 13.06%, Valid: 11.40%, Test: 7.66%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.4626, Train: 17.66%, Valid: 15.48%, Test: 13.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 10, Loss: 0.4313, Train: 10.50%, Valid: 9.09%, Test: 8.34%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 10, Loss: 0.4313, Train: 16.80%, Valid: 14.56%, Test: 14.66%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 10, Loss: 0.4313, Train: 21.94%, Valid: 19.20%, Test: 18.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 15, Loss: 0.4121, Train: 12.18%, Valid: 10.34%, Test: 14.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 15, Loss: 0.4121, Train: 21.98%, Valid: 19.13%, Test: 19.00%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 15, Loss: 0.4121, Train: 25.08%, Valid: 21.90%, Test: 22.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 20, Loss: 0.4025, Train: 14.56%, Valid: 12.49%, Test: 12.34%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 20, Loss: 0.4025, Train: 21.84%, Valid: 18.95%, Test: 18.34%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 20, Loss: 0.4025, Train: 27.37%, Valid: 23.98%, Test: 22.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 25, Loss: 0.3945, Train: 14.64%, Valid: 12.56%, Test: 13.30%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 25, Loss: 0.3945, Train: 23.07%, Valid: 20.07%, Test: 16.95%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 25, Loss: 0.3945, Train: 26.08%, Valid: 22.82%, Test: 21.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 30, Loss: 0.3902, Train: 15.45%, Valid: 13.18%, Test: 12.42%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 30, Loss: 0.3902, Train: 24.48%, Valid: 21.27%, Test: 19.85%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 30, Loss: 0.3902, Train: 27.48%, Valid: 24.00%, Test: 23.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 35, Loss: 0.3878, Train: 17.14%, Valid: 14.58%, Test: 12.52%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 35, Loss: 0.3878, Train: 23.20%, Valid: 20.02%, Test: 15.65%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 35, Loss: 0.3878, Train: 27.60%, Valid: 24.10%, Test: 22.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 40, Loss: 0.3857, Train: 15.05%, Valid: 12.69%, Test: 11.50%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 40, Loss: 0.3857, Train: 19.94%, Valid: 17.16%, Test: 16.94%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 40, Loss: 0.3857, Train: 24.86%, Valid: 21.48%, Test: 21.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 45, Loss: 0.3837, Train: 18.24%, Valid: 15.54%, Test: 11.10%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 45, Loss: 0.3837, Train: 21.85%, Valid: 18.74%, Test: 15.10%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 45, Loss: 0.3837, Train: 27.74%, Valid: 24.15%, Test: 21.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 50, Loss: 0.3812, Train: 17.03%, Valid: 14.48%, Test: 12.12%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 50, Loss: 0.3812, Train: 22.92%, Valid: 19.85%, Test: 17.28%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 50, Loss: 0.3812, Train: 28.47%, Valid: 24.73%, Test: 24.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 55, Loss: 0.3815, Train: 13.64%, Valid: 11.38%, Test: 11.55%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 55, Loss: 0.3815, Train: 20.38%, Valid: 17.46%, Test: 18.30%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 55, Loss: 0.3815, Train: 24.92%, Valid: 21.43%, Test: 22.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 60, Loss: 0.3799, Train: 14.55%, Valid: 12.22%, Test: 13.28%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 60, Loss: 0.3799, Train: 22.91%, Valid: 19.60%, Test: 18.14%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 60, Loss: 0.3799, Train: 28.03%, Valid: 24.33%, Test: 23.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 65, Loss: 0.3787, Train: 18.06%, Valid: 15.27%, Test: 11.44%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 65, Loss: 0.3787, Train: 22.56%, Valid: 19.25%, Test: 17.73%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 65, Loss: 0.3787, Train: 29.43%, Valid: 25.64%, Test: 23.04%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 03, Epoch: 70, Loss: 0.3777, Train: 16.93%, Valid: 14.34%, Test: 11.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 70, Loss: 0.3777, Train: 24.79%, Valid: 21.31%, Test: 16.15%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 70, Loss: 0.3777, Train: 30.10%, Valid: 26.23%, Test: 20.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 75, Loss: 0.3769, Train: 15.57%, Valid: 13.11%, Test: 9.96%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 75, Loss: 0.3769, Train: 24.67%, Valid: 21.26%, Test: 16.31%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 75, Loss: 0.3769, Train: 30.95%, Valid: 27.00%, Test: 21.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 80, Loss: 0.3773, Train: 15.84%, Valid: 13.32%, Test: 10.18%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 80, Loss: 0.3773, Train: 24.18%, Valid: 20.77%, Test: 16.17%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 80, Loss: 0.3773, Train: 28.03%, Valid: 24.22%, Test: 19.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 85, Loss: 0.3774, Train: 14.26%, Valid: 11.97%, Test: 11.22%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 85, Loss: 0.3774, Train: 22.78%, Valid: 19.46%, Test: 15.04%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 85, Loss: 0.3774, Train: 26.94%, Valid: 23.28%, Test: 18.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 90, Loss: 0.3754, Train: 15.68%, Valid: 13.14%, Test: 10.73%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 90, Loss: 0.3754, Train: 22.05%, Valid: 18.85%, Test: 15.86%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 90, Loss: 0.3754, Train: 27.34%, Valid: 23.74%, Test: 21.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 95, Loss: 0.3769, Train: 15.93%, Valid: 13.38%, Test: 10.28%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 95, Loss: 0.3769, Train: 22.65%, Valid: 19.30%, Test: 14.77%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 95, Loss: 0.3769, Train: 26.87%, Valid: 23.27%, Test: 19.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 100, Loss: 0.3748, Train: 13.80%, Valid: 11.58%, Test: 10.60%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 100, Loss: 0.3748, Train: 20.71%, Valid: 17.68%, Test: 13.59%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 100, Loss: 0.3748, Train: 23.61%, Valid: 20.30%, Test: 18.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 105, Loss: 0.3751, Train: 13.65%, Valid: 11.36%, Test: 10.42%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 105, Loss: 0.3751, Train: 21.63%, Valid: 18.41%, Test: 14.29%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 105, Loss: 0.3751, Train: 28.71%, Valid: 24.91%, Test: 20.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 110, Loss: 0.3747, Train: 17.16%, Valid: 14.37%, Test: 7.40%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 110, Loss: 0.3747, Train: 22.25%, Valid: 18.94%, Test: 13.28%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 110, Loss: 0.3747, Train: 25.55%, Valid: 21.95%, Test: 17.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 115, Loss: 0.3743, Train: 14.57%, Valid: 12.14%, Test: 10.70%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 115, Loss: 0.3743, Train: 21.53%, Valid: 18.28%, Test: 14.48%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 115, Loss: 0.3743, Train: 27.20%, Valid: 23.47%, Test: 17.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 120, Loss: 0.3742, Train: 14.79%, Valid: 12.26%, Test: 9.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 120, Loss: 0.3742, Train: 21.45%, Valid: 18.17%, Test: 15.69%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 120, Loss: 0.3742, Train: 25.56%, Valid: 21.97%, Test: 19.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 125, Loss: 0.3738, Train: 13.08%, Valid: 10.90%, Test: 8.78%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 125, Loss: 0.3738, Train: 18.16%, Valid: 15.31%, Test: 14.30%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 125, Loss: 0.3738, Train: 23.92%, Valid: 20.51%, Test: 20.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 130, Loss: 0.3735, Train: 12.34%, Valid: 10.16%, Test: 8.77%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 130, Loss: 0.3735, Train: 22.87%, Valid: 19.46%, Test: 13.66%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 130, Loss: 0.3735, Train: 26.56%, Valid: 22.84%, Test: 17.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 135, Loss: 0.3730, Train: 12.72%, Valid: 10.52%, Test: 9.11%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 135, Loss: 0.3730, Train: 16.88%, Valid: 14.13%, Test: 13.92%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 135, Loss: 0.3730, Train: 21.84%, Valid: 18.52%, Test: 16.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 140, Loss: 0.3722, Train: 13.29%, Valid: 10.94%, Test: 8.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 140, Loss: 0.3722, Train: 19.66%, Valid: 16.49%, Test: 15.34%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 140, Loss: 0.3722, Train: 24.61%, Valid: 20.97%, Test: 18.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 145, Loss: 0.3720, Train: 14.01%, Valid: 11.54%, Test: 9.20%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 145, Loss: 0.3720, Train: 20.03%, Valid: 16.87%, Test: 12.98%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 145, Loss: 0.3720, Train: 25.33%, Valid: 21.68%, Test: 16.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 150, Loss: 0.3726, Train: 13.73%, Valid: 11.39%, Test: 7.15%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 150, Loss: 0.3726, Train: 20.16%, Valid: 17.05%, Test: 15.08%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 150, Loss: 0.3726, Train: 25.41%, Valid: 21.70%, Test: 18.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 155, Loss: 0.3716, Train: 13.43%, Valid: 11.13%, Test: 6.81%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 155, Loss: 0.3716, Train: 20.09%, Valid: 16.93%, Test: 14.75%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 155, Loss: 0.3716, Train: 23.42%, Valid: 19.93%, Test: 18.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 160, Loss: 0.3723, Train: 13.81%, Valid: 11.39%, Test: 8.40%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 160, Loss: 0.3723, Train: 20.19%, Valid: 17.05%, Test: 12.94%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 160, Loss: 0.3723, Train: 24.26%, Valid: 20.61%, Test: 18.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 165, Loss: 0.3717, Train: 14.83%, Valid: 12.27%, Test: 7.81%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 165, Loss: 0.3717, Train: 19.01%, Valid: 15.90%, Test: 12.98%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 165, Loss: 0.3717, Train: 26.04%, Valid: 22.28%, Test: 16.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 170, Loss: 0.3713, Train: 10.08%, Valid: 8.21%, Test: 8.89%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 170, Loss: 0.3713, Train: 16.90%, Valid: 14.14%, Test: 13.39%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 170, Loss: 0.3713, Train: 24.53%, Valid: 20.93%, Test: 16.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 175, Loss: 0.3720, Train: 14.39%, Valid: 12.01%, Test: 7.36%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 175, Loss: 0.3720, Train: 20.33%, Valid: 17.26%, Test: 12.47%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 175, Loss: 0.3720, Train: 25.32%, Valid: 21.64%, Test: 17.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 180, Loss: 0.3711, Train: 11.68%, Valid: 9.68%, Test: 9.82%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 180, Loss: 0.3711, Train: 19.43%, Valid: 16.41%, Test: 14.00%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 180, Loss: 0.3711, Train: 26.47%, Valid: 22.69%, Test: 17.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 185, Loss: 0.3703, Train: 14.90%, Valid: 12.32%, Test: 9.40%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 185, Loss: 0.3703, Train: 19.43%, Valid: 16.27%, Test: 13.90%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 185, Loss: 0.3703, Train: 25.78%, Valid: 22.05%, Test: 18.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 190, Loss: 0.3712, Train: 14.62%, Valid: 12.21%, Test: 8.90%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 190, Loss: 0.3712, Train: 19.18%, Valid: 16.06%, Test: 13.49%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 190, Loss: 0.3712, Train: 26.70%, Valid: 22.79%, Test: 18.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 195, Loss: 0.3698, Train: 14.44%, Valid: 11.93%, Test: 7.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 195, Loss: 0.3698, Train: 22.47%, Valid: 18.95%, Test: 14.31%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 195, Loss: 0.3698, Train: 26.81%, Valid: 22.89%, Test: 17.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 200, Loss: 0.3709, Train: 17.72%, Valid: 14.83%, Test: 8.47%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 200, Loss: 0.3709, Train: 24.54%, Valid: 20.77%, Test: 15.53%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 200, Loss: 0.3709, Train: 28.42%, Valid: 24.34%, Test: 18.97%\n",
      "---\n",
      "Hits@10\n",
      "Run 03:\n",
      "Highest Train: 18.24\n",
      "Highest Valid: 15.54\n",
      "  Final Train: 18.24\n",
      "   Final Test: 11.10\n",
      "Hits@20\n",
      "Run 03:\n",
      "Highest Train: 24.79\n",
      "Highest Valid: 21.31\n",
      "  Final Train: 24.79\n",
      "   Final Test: 16.15\n",
      "Hits@30\n",
      "Run 03:\n",
      "Highest Train: 30.95\n",
      "Highest Valid: 27.00\n",
      "  Final Train: 30.95\n",
      "   Final Test: 21.59\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.4658, Train: 7.76%, Valid: 6.71%, Test: 3.11%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.4658, Train: 10.70%, Valid: 9.20%, Test: 7.47%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.4658, Train: 13.62%, Valid: 11.75%, Test: 13.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 10, Loss: 0.4314, Train: 11.88%, Valid: 10.28%, Test: 7.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 10, Loss: 0.4314, Train: 15.00%, Valid: 12.94%, Test: 11.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 10, Loss: 0.4314, Train: 19.34%, Valid: 16.79%, Test: 16.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 15, Loss: 0.4139, Train: 13.53%, Valid: 11.61%, Test: 9.09%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 15, Loss: 0.4139, Train: 18.18%, Valid: 15.74%, Test: 14.57%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 15, Loss: 0.4139, Train: 21.96%, Valid: 19.09%, Test: 19.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 20, Loss: 0.4029, Train: 16.40%, Valid: 14.04%, Test: 10.12%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 20, Loss: 0.4029, Train: 20.76%, Valid: 17.89%, Test: 16.09%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 20, Loss: 0.4029, Train: 24.78%, Valid: 21.44%, Test: 20.81%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 25, Loss: 0.3964, Train: 12.78%, Valid: 10.82%, Test: 14.05%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 25, Loss: 0.3964, Train: 21.86%, Valid: 18.82%, Test: 17.86%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 25, Loss: 0.3964, Train: 26.93%, Valid: 23.45%, Test: 22.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 30, Loss: 0.3932, Train: 14.04%, Valid: 11.84%, Test: 10.88%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 30, Loss: 0.3932, Train: 20.52%, Valid: 17.69%, Test: 16.42%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 30, Loss: 0.3932, Train: 23.91%, Valid: 20.74%, Test: 20.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 35, Loss: 0.3896, Train: 12.22%, Valid: 10.33%, Test: 10.12%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 35, Loss: 0.3896, Train: 19.36%, Valid: 16.62%, Test: 18.03%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 35, Loss: 0.3896, Train: 23.44%, Valid: 20.26%, Test: 21.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 40, Loss: 0.3870, Train: 13.79%, Valid: 11.60%, Test: 12.09%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 40, Loss: 0.3870, Train: 21.39%, Valid: 18.38%, Test: 16.81%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 40, Loss: 0.3870, Train: 25.25%, Valid: 21.83%, Test: 19.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 45, Loss: 0.3851, Train: 11.72%, Valid: 9.79%, Test: 11.91%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 45, Loss: 0.3851, Train: 20.12%, Valid: 17.11%, Test: 16.95%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 45, Loss: 0.3851, Train: 22.97%, Valid: 19.67%, Test: 20.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 50, Loss: 0.3845, Train: 9.51%, Valid: 7.85%, Test: 12.08%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 50, Loss: 0.3845, Train: 17.04%, Valid: 14.39%, Test: 16.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 50, Loss: 0.3845, Train: 24.54%, Valid: 21.05%, Test: 21.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 55, Loss: 0.3833, Train: 14.02%, Valid: 11.79%, Test: 10.83%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 55, Loss: 0.3833, Train: 17.89%, Valid: 15.10%, Test: 16.43%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 55, Loss: 0.3833, Train: 21.28%, Valid: 18.16%, Test: 21.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 60, Loss: 0.3828, Train: 10.50%, Valid: 8.62%, Test: 12.37%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 60, Loss: 0.3828, Train: 17.32%, Valid: 14.71%, Test: 16.62%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 60, Loss: 0.3828, Train: 22.63%, Valid: 19.37%, Test: 21.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 65, Loss: 0.3806, Train: 11.25%, Valid: 9.29%, Test: 9.83%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 65, Loss: 0.3806, Train: 18.11%, Valid: 15.30%, Test: 17.29%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 65, Loss: 0.3806, Train: 21.20%, Valid: 18.02%, Test: 21.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 70, Loss: 0.3804, Train: 12.89%, Valid: 10.79%, Test: 11.88%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 70, Loss: 0.3804, Train: 18.07%, Valid: 15.34%, Test: 17.10%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 70, Loss: 0.3804, Train: 23.06%, Valid: 19.75%, Test: 21.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 75, Loss: 0.3784, Train: 11.70%, Valid: 9.71%, Test: 11.40%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 75, Loss: 0.3784, Train: 18.94%, Valid: 16.00%, Test: 15.71%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 75, Loss: 0.3784, Train: 23.70%, Valid: 20.35%, Test: 20.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 80, Loss: 0.3787, Train: 12.63%, Valid: 10.55%, Test: 11.81%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 80, Loss: 0.3787, Train: 19.28%, Valid: 16.40%, Test: 14.55%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 80, Loss: 0.3787, Train: 24.01%, Valid: 20.59%, Test: 19.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 85, Loss: 0.3788, Train: 10.65%, Valid: 8.87%, Test: 12.35%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 85, Loss: 0.3788, Train: 19.73%, Valid: 16.79%, Test: 15.20%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 85, Loss: 0.3788, Train: 23.87%, Valid: 20.45%, Test: 19.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 90, Loss: 0.3780, Train: 13.86%, Valid: 11.63%, Test: 12.90%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 90, Loss: 0.3780, Train: 21.98%, Valid: 18.75%, Test: 15.51%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 90, Loss: 0.3780, Train: 25.03%, Valid: 21.53%, Test: 19.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 95, Loss: 0.3783, Train: 13.79%, Valid: 11.52%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 95, Loss: 0.3783, Train: 20.96%, Valid: 17.84%, Test: 15.57%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 95, Loss: 0.3783, Train: 26.59%, Valid: 22.96%, Test: 19.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 100, Loss: 0.3773, Train: 10.58%, Valid: 8.76%, Test: 10.41%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 100, Loss: 0.3773, Train: 17.13%, Valid: 14.43%, Test: 16.18%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 100, Loss: 0.3773, Train: 22.83%, Valid: 19.40%, Test: 18.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 105, Loss: 0.3780, Train: 9.45%, Valid: 7.78%, Test: 11.29%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 105, Loss: 0.3780, Train: 17.77%, Valid: 14.92%, Test: 16.15%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 105, Loss: 0.3780, Train: 21.54%, Valid: 18.32%, Test: 19.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 110, Loss: 0.3767, Train: 13.12%, Valid: 10.93%, Test: 10.21%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 110, Loss: 0.3767, Train: 16.48%, Valid: 13.83%, Test: 14.80%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 110, Loss: 0.3767, Train: 24.74%, Valid: 21.11%, Test: 20.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 115, Loss: 0.3763, Train: 11.63%, Valid: 9.54%, Test: 12.47%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 115, Loss: 0.3763, Train: 22.84%, Valid: 19.39%, Test: 14.82%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 115, Loss: 0.3763, Train: 24.54%, Valid: 20.98%, Test: 19.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 120, Loss: 0.3752, Train: 12.44%, Valid: 10.27%, Test: 10.43%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 120, Loss: 0.3752, Train: 17.46%, Valid: 14.60%, Test: 17.66%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 120, Loss: 0.3752, Train: 25.35%, Valid: 21.68%, Test: 21.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 125, Loss: 0.3750, Train: 13.02%, Valid: 10.83%, Test: 11.06%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 125, Loss: 0.3750, Train: 19.43%, Valid: 16.41%, Test: 15.55%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 125, Loss: 0.3750, Train: 23.79%, Valid: 20.26%, Test: 18.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 130, Loss: 0.3744, Train: 10.99%, Valid: 9.00%, Test: 10.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 130, Loss: 0.3744, Train: 19.43%, Valid: 16.46%, Test: 18.39%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 130, Loss: 0.3744, Train: 26.12%, Valid: 22.41%, Test: 20.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 135, Loss: 0.3743, Train: 15.00%, Valid: 12.44%, Test: 11.06%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 135, Loss: 0.3743, Train: 20.82%, Valid: 17.66%, Test: 17.90%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 135, Loss: 0.3743, Train: 26.18%, Valid: 22.51%, Test: 20.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 140, Loss: 0.3735, Train: 12.63%, Valid: 10.29%, Test: 9.62%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 140, Loss: 0.3735, Train: 21.10%, Valid: 17.87%, Test: 16.73%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 140, Loss: 0.3735, Train: 27.38%, Valid: 23.60%, Test: 20.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 145, Loss: 0.3742, Train: 8.80%, Valid: 7.13%, Test: 8.51%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 145, Loss: 0.3742, Train: 21.08%, Valid: 17.79%, Test: 14.82%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 145, Loss: 0.3742, Train: 25.74%, Valid: 22.04%, Test: 19.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 150, Loss: 0.3746, Train: 14.43%, Valid: 11.93%, Test: 9.67%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 150, Loss: 0.3746, Train: 22.39%, Valid: 18.99%, Test: 15.12%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 150, Loss: 0.3746, Train: 27.26%, Valid: 23.40%, Test: 18.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 155, Loss: 0.3739, Train: 11.92%, Valid: 9.87%, Test: 11.79%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 155, Loss: 0.3739, Train: 19.22%, Valid: 16.19%, Test: 14.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 155, Loss: 0.3739, Train: 24.89%, Valid: 21.32%, Test: 19.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 160, Loss: 0.3744, Train: 14.52%, Valid: 12.02%, Test: 11.20%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 160, Loss: 0.3744, Train: 21.51%, Valid: 18.20%, Test: 13.33%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 160, Loss: 0.3744, Train: 25.20%, Valid: 21.58%, Test: 17.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 165, Loss: 0.3746, Train: 14.60%, Valid: 12.15%, Test: 10.61%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 165, Loss: 0.3746, Train: 20.20%, Valid: 17.02%, Test: 14.92%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 165, Loss: 0.3746, Train: 25.06%, Valid: 21.43%, Test: 18.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 170, Loss: 0.3736, Train: 13.16%, Valid: 10.96%, Test: 9.73%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 170, Loss: 0.3736, Train: 18.48%, Valid: 15.40%, Test: 13.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 170, Loss: 0.3736, Train: 22.99%, Valid: 19.50%, Test: 17.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 175, Loss: 0.3737, Train: 15.73%, Valid: 13.14%, Test: 10.90%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 175, Loss: 0.3737, Train: 23.31%, Valid: 19.87%, Test: 14.66%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 175, Loss: 0.3737, Train: 29.01%, Valid: 25.00%, Test: 18.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 180, Loss: 0.3730, Train: 16.55%, Valid: 13.84%, Test: 11.19%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 180, Loss: 0.3730, Train: 25.91%, Valid: 22.19%, Test: 13.93%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 180, Loss: 0.3730, Train: 27.77%, Valid: 23.88%, Test: 16.63%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 185, Loss: 0.3727, Train: 14.85%, Valid: 12.38%, Test: 10.09%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 185, Loss: 0.3727, Train: 20.57%, Valid: 17.30%, Test: 13.47%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 185, Loss: 0.3727, Train: 25.16%, Valid: 21.48%, Test: 17.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 190, Loss: 0.3718, Train: 18.58%, Valid: 15.67%, Test: 9.59%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 190, Loss: 0.3718, Train: 23.01%, Valid: 19.58%, Test: 13.56%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 190, Loss: 0.3718, Train: 26.83%, Valid: 23.06%, Test: 16.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 195, Loss: 0.3731, Train: 15.84%, Valid: 13.18%, Test: 10.27%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 195, Loss: 0.3731, Train: 21.34%, Valid: 18.00%, Test: 15.51%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 195, Loss: 0.3731, Train: 25.30%, Valid: 21.61%, Test: 17.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 200, Loss: 0.3723, Train: 13.19%, Valid: 10.98%, Test: 9.75%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 200, Loss: 0.3723, Train: 21.36%, Valid: 18.06%, Test: 14.69%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 200, Loss: 0.3723, Train: 25.86%, Valid: 22.12%, Test: 18.04%\n",
      "---\n",
      "Hits@10\n",
      "Run 04:\n",
      "Highest Train: 18.58\n",
      "Highest Valid: 15.67\n",
      "  Final Train: 18.58\n",
      "   Final Test: 9.59\n",
      "Hits@20\n",
      "Run 04:\n",
      "Highest Train: 25.91\n",
      "Highest Valid: 22.19\n",
      "  Final Train: 25.91\n",
      "   Final Test: 13.93\n",
      "Hits@30\n",
      "Run 04:\n",
      "Highest Train: 29.01\n",
      "Highest Valid: 25.00\n",
      "  Final Train: 29.01\n",
      "   Final Test: 18.65\n",
      "Hits@10\n",
      "Run: 05, Epoch: 05, Loss: 0.4639, Train: 8.30%, Valid: 7.14%, Test: 4.17%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 05, Loss: 0.4639, Train: 12.71%, Valid: 10.95%, Test: 8.25%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 05, Loss: 0.4639, Train: 15.60%, Valid: 13.55%, Test: 13.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 10, Loss: 0.4351, Train: 13.90%, Valid: 11.96%, Test: 7.61%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 10, Loss: 0.4351, Train: 17.11%, Valid: 14.73%, Test: 11.18%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 10, Loss: 0.4351, Train: 20.41%, Valid: 17.70%, Test: 15.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 15, Loss: 0.4169, Train: 11.96%, Valid: 10.19%, Test: 9.45%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 15, Loss: 0.4169, Train: 19.22%, Valid: 16.55%, Test: 16.26%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 15, Loss: 0.4169, Train: 21.89%, Valid: 19.01%, Test: 19.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 20, Loss: 0.4053, Train: 11.12%, Valid: 9.41%, Test: 11.84%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 20, Loss: 0.4053, Train: 20.56%, Valid: 17.73%, Test: 17.53%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 20, Loss: 0.4053, Train: 25.01%, Valid: 21.87%, Test: 21.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 25, Loss: 0.3974, Train: 14.87%, Valid: 12.63%, Test: 10.43%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 25, Loss: 0.3974, Train: 20.69%, Valid: 17.81%, Test: 15.94%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 25, Loss: 0.3974, Train: 24.72%, Valid: 21.46%, Test: 19.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 30, Loss: 0.3919, Train: 16.01%, Valid: 13.59%, Test: 13.21%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 30, Loss: 0.3919, Train: 21.83%, Valid: 18.81%, Test: 18.75%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 30, Loss: 0.3919, Train: 26.90%, Valid: 23.45%, Test: 22.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 35, Loss: 0.3902, Train: 16.65%, Valid: 14.18%, Test: 11.21%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 35, Loss: 0.3902, Train: 21.66%, Valid: 18.69%, Test: 17.52%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 35, Loss: 0.3902, Train: 25.38%, Valid: 22.08%, Test: 23.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 40, Loss: 0.3857, Train: 17.80%, Valid: 15.18%, Test: 13.06%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 40, Loss: 0.3857, Train: 22.38%, Valid: 19.41%, Test: 20.48%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 40, Loss: 0.3857, Train: 26.91%, Valid: 23.44%, Test: 26.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 45, Loss: 0.3846, Train: 16.17%, Valid: 13.64%, Test: 13.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 45, Loss: 0.3846, Train: 20.29%, Valid: 17.37%, Test: 19.11%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 45, Loss: 0.3846, Train: 26.12%, Valid: 22.62%, Test: 22.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 50, Loss: 0.3820, Train: 16.36%, Valid: 13.90%, Test: 14.12%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 50, Loss: 0.3820, Train: 22.04%, Valid: 18.95%, Test: 18.11%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 50, Loss: 0.3820, Train: 26.70%, Valid: 23.25%, Test: 23.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 55, Loss: 0.3814, Train: 15.61%, Valid: 13.21%, Test: 13.62%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 55, Loss: 0.3814, Train: 20.57%, Valid: 17.57%, Test: 21.16%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 55, Loss: 0.3814, Train: 28.62%, Valid: 24.88%, Test: 25.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 60, Loss: 0.3807, Train: 17.66%, Valid: 15.04%, Test: 12.23%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 60, Loss: 0.3807, Train: 23.41%, Valid: 20.23%, Test: 17.36%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 60, Loss: 0.3807, Train: 27.54%, Valid: 24.01%, Test: 23.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 65, Loss: 0.3800, Train: 17.09%, Valid: 14.52%, Test: 13.07%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 65, Loss: 0.3800, Train: 22.48%, Valid: 19.38%, Test: 18.87%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 65, Loss: 0.3800, Train: 26.75%, Valid: 23.31%, Test: 22.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 70, Loss: 0.3795, Train: 14.97%, Valid: 12.53%, Test: 11.79%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 70, Loss: 0.3795, Train: 22.41%, Valid: 19.13%, Test: 17.64%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 70, Loss: 0.3795, Train: 28.42%, Valid: 24.80%, Test: 22.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 75, Loss: 0.3793, Train: 17.53%, Valid: 14.83%, Test: 13.29%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 75, Loss: 0.3793, Train: 23.05%, Valid: 19.87%, Test: 18.33%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 75, Loss: 0.3793, Train: 28.96%, Valid: 25.39%, Test: 25.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 80, Loss: 0.3782, Train: 15.32%, Valid: 12.87%, Test: 10.45%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 80, Loss: 0.3782, Train: 20.78%, Valid: 17.68%, Test: 17.56%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 80, Loss: 0.3782, Train: 26.31%, Valid: 22.81%, Test: 22.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 85, Loss: 0.3782, Train: 11.48%, Valid: 9.54%, Test: 11.99%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 85, Loss: 0.3782, Train: 18.73%, Valid: 15.76%, Test: 18.79%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 85, Loss: 0.3782, Train: 23.61%, Valid: 20.24%, Test: 22.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 90, Loss: 0.3770, Train: 13.87%, Valid: 11.68%, Test: 11.26%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 90, Loss: 0.3770, Train: 22.76%, Valid: 19.47%, Test: 19.09%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 90, Loss: 0.3770, Train: 26.10%, Valid: 22.58%, Test: 22.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 95, Loss: 0.3763, Train: 14.63%, Valid: 12.27%, Test: 12.45%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 95, Loss: 0.3763, Train: 23.72%, Valid: 20.46%, Test: 18.06%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 95, Loss: 0.3763, Train: 28.32%, Valid: 24.66%, Test: 21.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 100, Loss: 0.3764, Train: 13.48%, Valid: 11.31%, Test: 11.96%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 100, Loss: 0.3764, Train: 17.90%, Valid: 15.25%, Test: 16.42%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 100, Loss: 0.3764, Train: 23.02%, Valid: 19.83%, Test: 23.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 105, Loss: 0.3747, Train: 18.25%, Valid: 15.50%, Test: 12.55%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 105, Loss: 0.3747, Train: 24.43%, Valid: 21.12%, Test: 17.57%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 105, Loss: 0.3747, Train: 30.61%, Valid: 26.77%, Test: 23.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 110, Loss: 0.3736, Train: 14.53%, Valid: 12.22%, Test: 10.26%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 110, Loss: 0.3736, Train: 18.90%, Valid: 16.12%, Test: 15.58%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 110, Loss: 0.3736, Train: 25.95%, Valid: 22.40%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 115, Loss: 0.3743, Train: 14.32%, Valid: 11.92%, Test: 12.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 115, Loss: 0.3743, Train: 21.08%, Valid: 17.93%, Test: 16.87%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 115, Loss: 0.3743, Train: 27.41%, Valid: 23.79%, Test: 20.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 120, Loss: 0.3746, Train: 13.37%, Valid: 11.10%, Test: 11.57%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 120, Loss: 0.3746, Train: 20.30%, Valid: 17.28%, Test: 16.54%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 120, Loss: 0.3746, Train: 28.02%, Valid: 24.30%, Test: 21.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 125, Loss: 0.3735, Train: 16.22%, Valid: 13.74%, Test: 13.21%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 125, Loss: 0.3735, Train: 21.07%, Valid: 17.92%, Test: 18.74%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 125, Loss: 0.3735, Train: 28.35%, Valid: 24.64%, Test: 21.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 130, Loss: 0.3734, Train: 14.89%, Valid: 12.43%, Test: 10.52%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 130, Loss: 0.3734, Train: 21.01%, Valid: 17.85%, Test: 15.92%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 130, Loss: 0.3734, Train: 27.46%, Valid: 23.78%, Test: 18.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 135, Loss: 0.3726, Train: 17.58%, Valid: 14.78%, Test: 12.90%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 135, Loss: 0.3726, Train: 26.44%, Valid: 22.76%, Test: 15.81%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 135, Loss: 0.3726, Train: 30.51%, Valid: 26.57%, Test: 19.15%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 05, Epoch: 140, Loss: 0.3724, Train: 15.76%, Valid: 13.07%, Test: 12.43%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 140, Loss: 0.3724, Train: 22.98%, Valid: 19.57%, Test: 16.26%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 140, Loss: 0.3724, Train: 27.23%, Valid: 23.43%, Test: 19.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 145, Loss: 0.3717, Train: 17.50%, Valid: 14.83%, Test: 12.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 145, Loss: 0.3717, Train: 23.58%, Valid: 20.20%, Test: 18.02%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 145, Loss: 0.3717, Train: 27.32%, Valid: 23.66%, Test: 20.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 150, Loss: 0.3731, Train: 13.05%, Valid: 10.95%, Test: 10.76%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 150, Loss: 0.3731, Train: 20.36%, Valid: 17.16%, Test: 15.48%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 150, Loss: 0.3731, Train: 26.59%, Valid: 22.81%, Test: 17.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 155, Loss: 0.3727, Train: 15.12%, Valid: 12.62%, Test: 11.54%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 155, Loss: 0.3727, Train: 22.81%, Valid: 19.52%, Test: 17.02%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 155, Loss: 0.3727, Train: 27.63%, Valid: 23.82%, Test: 19.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 160, Loss: 0.3708, Train: 17.26%, Valid: 14.46%, Test: 11.10%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 160, Loss: 0.3708, Train: 23.11%, Valid: 19.77%, Test: 16.28%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 160, Loss: 0.3708, Train: 28.39%, Valid: 24.65%, Test: 19.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 165, Loss: 0.3726, Train: 17.73%, Valid: 14.84%, Test: 9.82%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 165, Loss: 0.3726, Train: 22.21%, Valid: 18.87%, Test: 13.52%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 165, Loss: 0.3726, Train: 25.76%, Valid: 22.10%, Test: 17.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 170, Loss: 0.3716, Train: 15.50%, Valid: 12.94%, Test: 10.14%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 170, Loss: 0.3716, Train: 23.09%, Valid: 19.78%, Test: 15.12%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 170, Loss: 0.3716, Train: 25.58%, Valid: 21.96%, Test: 18.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 175, Loss: 0.3707, Train: 17.90%, Valid: 15.00%, Test: 12.35%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 175, Loss: 0.3707, Train: 22.98%, Valid: 19.52%, Test: 16.44%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 175, Loss: 0.3707, Train: 26.56%, Valid: 22.85%, Test: 19.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 180, Loss: 0.3698, Train: 13.32%, Valid: 10.99%, Test: 9.25%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 180, Loss: 0.3698, Train: 20.44%, Valid: 17.26%, Test: 14.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 180, Loss: 0.3698, Train: 24.89%, Valid: 21.33%, Test: 18.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 185, Loss: 0.3704, Train: 15.77%, Valid: 13.31%, Test: 9.28%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 185, Loss: 0.3704, Train: 23.04%, Valid: 19.75%, Test: 14.62%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 185, Loss: 0.3704, Train: 26.31%, Valid: 22.68%, Test: 17.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 190, Loss: 0.3707, Train: 16.43%, Valid: 13.80%, Test: 10.53%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 190, Loss: 0.3707, Train: 24.27%, Valid: 20.81%, Test: 14.05%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 190, Loss: 0.3707, Train: 30.04%, Valid: 26.13%, Test: 18.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 195, Loss: 0.3689, Train: 12.09%, Valid: 10.01%, Test: 10.02%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 195, Loss: 0.3689, Train: 20.54%, Valid: 17.31%, Test: 14.64%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 195, Loss: 0.3689, Train: 25.23%, Valid: 21.62%, Test: 17.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 200, Loss: 0.3707, Train: 12.83%, Valid: 10.59%, Test: 8.85%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 200, Loss: 0.3707, Train: 21.75%, Valid: 18.39%, Test: 13.94%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 200, Loss: 0.3707, Train: 25.52%, Valid: 21.94%, Test: 18.74%\n",
      "---\n",
      "Hits@10\n",
      "Run 05:\n",
      "Highest Train: 18.25\n",
      "Highest Valid: 15.50\n",
      "  Final Train: 18.25\n",
      "   Final Test: 12.55\n",
      "Hits@20\n",
      "Run 05:\n",
      "Highest Train: 26.44\n",
      "Highest Valid: 22.76\n",
      "  Final Train: 26.44\n",
      "   Final Test: 15.81\n",
      "Hits@30\n",
      "Run 05:\n",
      "Highest Train: 30.61\n",
      "Highest Valid: 26.77\n",
      "  Final Train: 30.61\n",
      "   Final Test: 23.15\n",
      "Hits@10\n",
      "Run: 06, Epoch: 05, Loss: 0.4648, Train: 7.38%, Valid: 6.40%, Test: 3.42%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 05, Loss: 0.4648, Train: 11.15%, Valid: 9.68%, Test: 7.68%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 05, Loss: 0.4648, Train: 14.20%, Valid: 12.32%, Test: 12.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 10, Loss: 0.4312, Train: 10.28%, Valid: 8.80%, Test: 6.73%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 10, Loss: 0.4312, Train: 15.54%, Valid: 13.47%, Test: 9.96%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 10, Loss: 0.4312, Train: 19.67%, Valid: 17.03%, Test: 17.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 15, Loss: 0.4136, Train: 12.57%, Valid: 10.78%, Test: 9.94%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 15, Loss: 0.4136, Train: 19.33%, Valid: 16.64%, Test: 17.21%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 15, Loss: 0.4136, Train: 23.08%, Valid: 20.14%, Test: 22.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 20, Loss: 0.4028, Train: 11.12%, Valid: 9.45%, Test: 11.58%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 20, Loss: 0.4028, Train: 17.58%, Valid: 15.16%, Test: 17.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 20, Loss: 0.4028, Train: 21.39%, Valid: 18.48%, Test: 20.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 25, Loss: 0.3957, Train: 14.55%, Valid: 12.30%, Test: 12.52%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 25, Loss: 0.3957, Train: 20.00%, Valid: 17.11%, Test: 18.79%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 25, Loss: 0.3957, Train: 27.39%, Valid: 23.82%, Test: 21.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 30, Loss: 0.3902, Train: 12.10%, Valid: 10.20%, Test: 10.61%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 30, Loss: 0.3902, Train: 19.95%, Valid: 17.10%, Test: 16.80%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 30, Loss: 0.3902, Train: 24.38%, Valid: 21.15%, Test: 19.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 35, Loss: 0.3869, Train: 12.53%, Valid: 10.62%, Test: 15.08%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 35, Loss: 0.3869, Train: 22.66%, Valid: 19.50%, Test: 20.66%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 35, Loss: 0.3869, Train: 26.01%, Valid: 22.57%, Test: 23.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 40, Loss: 0.3851, Train: 15.07%, Valid: 12.73%, Test: 13.04%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 40, Loss: 0.3851, Train: 20.34%, Valid: 17.33%, Test: 18.66%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 40, Loss: 0.3851, Train: 22.67%, Valid: 19.42%, Test: 21.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 45, Loss: 0.3839, Train: 15.80%, Valid: 13.27%, Test: 13.08%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 45, Loss: 0.3839, Train: 22.03%, Valid: 18.79%, Test: 19.32%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 45, Loss: 0.3839, Train: 27.01%, Valid: 23.32%, Test: 22.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 50, Loss: 0.3813, Train: 15.81%, Valid: 13.35%, Test: 13.91%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 50, Loss: 0.3813, Train: 19.11%, Valid: 16.30%, Test: 17.35%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 50, Loss: 0.3813, Train: 24.99%, Valid: 21.52%, Test: 21.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 55, Loss: 0.3806, Train: 13.34%, Valid: 11.15%, Test: 13.36%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 55, Loss: 0.3806, Train: 19.09%, Valid: 16.24%, Test: 18.36%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 55, Loss: 0.3806, Train: 23.93%, Valid: 20.56%, Test: 21.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 60, Loss: 0.3792, Train: 15.85%, Valid: 13.31%, Test: 16.35%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 60, Loss: 0.3792, Train: 22.38%, Valid: 19.22%, Test: 19.68%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 60, Loss: 0.3792, Train: 26.61%, Valid: 23.07%, Test: 23.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 65, Loss: 0.3788, Train: 14.78%, Valid: 12.33%, Test: 13.86%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 65, Loss: 0.3788, Train: 18.79%, Valid: 15.88%, Test: 17.31%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 65, Loss: 0.3788, Train: 21.85%, Valid: 18.59%, Test: 20.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 70, Loss: 0.3785, Train: 17.36%, Valid: 14.76%, Test: 15.42%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 70, Loss: 0.3785, Train: 21.88%, Valid: 18.70%, Test: 18.91%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 70, Loss: 0.3785, Train: 26.35%, Valid: 22.83%, Test: 22.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 75, Loss: 0.3774, Train: 15.87%, Valid: 13.37%, Test: 14.15%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 75, Loss: 0.3774, Train: 22.63%, Valid: 19.45%, Test: 16.38%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 75, Loss: 0.3774, Train: 24.96%, Valid: 21.56%, Test: 24.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 80, Loss: 0.3770, Train: 14.14%, Valid: 11.85%, Test: 13.38%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 80, Loss: 0.3770, Train: 18.62%, Valid: 15.75%, Test: 17.08%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 80, Loss: 0.3770, Train: 26.99%, Valid: 23.46%, Test: 19.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 85, Loss: 0.3749, Train: 17.08%, Valid: 14.47%, Test: 13.63%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 85, Loss: 0.3749, Train: 23.13%, Valid: 19.88%, Test: 18.61%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 85, Loss: 0.3749, Train: 27.73%, Valid: 24.12%, Test: 22.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 90, Loss: 0.3748, Train: 16.62%, Valid: 14.05%, Test: 15.95%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 90, Loss: 0.3748, Train: 23.50%, Valid: 20.17%, Test: 19.69%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 90, Loss: 0.3748, Train: 26.67%, Valid: 23.16%, Test: 24.02%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 06, Epoch: 95, Loss: 0.3759, Train: 15.47%, Valid: 12.93%, Test: 11.95%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 95, Loss: 0.3759, Train: 23.06%, Valid: 19.79%, Test: 17.16%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 95, Loss: 0.3759, Train: 27.87%, Valid: 24.19%, Test: 19.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 100, Loss: 0.3744, Train: 15.03%, Valid: 12.65%, Test: 12.18%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 100, Loss: 0.3744, Train: 20.61%, Valid: 17.53%, Test: 17.90%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 100, Loss: 0.3744, Train: 25.52%, Valid: 21.98%, Test: 20.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 105, Loss: 0.3742, Train: 18.05%, Valid: 15.40%, Test: 14.03%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 105, Loss: 0.3742, Train: 22.79%, Valid: 19.70%, Test: 18.02%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 105, Loss: 0.3742, Train: 26.30%, Valid: 22.87%, Test: 23.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 110, Loss: 0.3739, Train: 16.86%, Valid: 14.15%, Test: 14.61%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 110, Loss: 0.3739, Train: 22.24%, Valid: 19.03%, Test: 16.26%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 110, Loss: 0.3739, Train: 25.23%, Valid: 21.71%, Test: 19.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 115, Loss: 0.3742, Train: 16.51%, Valid: 13.94%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 115, Loss: 0.3742, Train: 22.88%, Valid: 19.56%, Test: 18.41%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 115, Loss: 0.3742, Train: 29.20%, Valid: 25.35%, Test: 22.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 120, Loss: 0.3744, Train: 17.57%, Valid: 14.84%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 120, Loss: 0.3744, Train: 25.25%, Valid: 21.73%, Test: 17.16%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 120, Loss: 0.3744, Train: 30.11%, Valid: 26.28%, Test: 19.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 125, Loss: 0.3734, Train: 13.63%, Valid: 11.39%, Test: 13.99%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 125, Loss: 0.3734, Train: 21.16%, Valid: 18.04%, Test: 19.30%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 125, Loss: 0.3734, Train: 25.80%, Valid: 22.35%, Test: 22.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 130, Loss: 0.3727, Train: 13.65%, Valid: 11.37%, Test: 13.44%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 130, Loss: 0.3727, Train: 19.69%, Valid: 16.76%, Test: 17.64%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 130, Loss: 0.3727, Train: 24.59%, Valid: 21.13%, Test: 21.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 135, Loss: 0.3724, Train: 11.31%, Valid: 9.42%, Test: 12.73%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 135, Loss: 0.3724, Train: 18.28%, Valid: 15.44%, Test: 17.07%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 135, Loss: 0.3724, Train: 24.48%, Valid: 20.99%, Test: 21.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 140, Loss: 0.3719, Train: 14.60%, Valid: 12.18%, Test: 12.38%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 140, Loss: 0.3719, Train: 23.52%, Valid: 20.07%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 140, Loss: 0.3719, Train: 25.66%, Valid: 21.95%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 145, Loss: 0.3716, Train: 16.20%, Valid: 13.67%, Test: 11.74%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 145, Loss: 0.3716, Train: 24.94%, Valid: 21.49%, Test: 16.44%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 145, Loss: 0.3716, Train: 28.44%, Valid: 24.60%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 150, Loss: 0.3714, Train: 14.89%, Valid: 12.43%, Test: 13.11%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 150, Loss: 0.3714, Train: 21.41%, Valid: 18.15%, Test: 15.93%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 150, Loss: 0.3714, Train: 26.31%, Valid: 22.64%, Test: 19.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 155, Loss: 0.3710, Train: 20.08%, Valid: 16.99%, Test: 13.03%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 155, Loss: 0.3710, Train: 24.56%, Valid: 21.01%, Test: 16.14%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 155, Loss: 0.3710, Train: 29.99%, Valid: 26.03%, Test: 20.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 160, Loss: 0.3717, Train: 15.10%, Valid: 12.64%, Test: 12.26%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 160, Loss: 0.3717, Train: 20.18%, Valid: 17.01%, Test: 15.34%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 160, Loss: 0.3717, Train: 24.12%, Valid: 20.65%, Test: 18.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 165, Loss: 0.3723, Train: 16.31%, Valid: 13.71%, Test: 9.49%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 165, Loss: 0.3723, Train: 21.84%, Valid: 18.54%, Test: 14.82%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 165, Loss: 0.3723, Train: 24.65%, Valid: 20.91%, Test: 18.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 170, Loss: 0.3711, Train: 17.14%, Valid: 14.45%, Test: 11.94%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 170, Loss: 0.3711, Train: 21.87%, Valid: 18.60%, Test: 16.30%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 170, Loss: 0.3711, Train: 27.22%, Valid: 23.47%, Test: 20.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 175, Loss: 0.3705, Train: 14.32%, Valid: 11.99%, Test: 11.15%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 175, Loss: 0.3705, Train: 23.73%, Valid: 20.32%, Test: 15.58%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 175, Loss: 0.3705, Train: 28.93%, Valid: 24.96%, Test: 18.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 180, Loss: 0.3725, Train: 13.20%, Valid: 11.08%, Test: 9.94%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 180, Loss: 0.3725, Train: 20.51%, Valid: 17.38%, Test: 14.66%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 180, Loss: 0.3725, Train: 25.66%, Valid: 21.94%, Test: 16.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 185, Loss: 0.3708, Train: 17.35%, Valid: 14.56%, Test: 11.24%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 185, Loss: 0.3708, Train: 23.36%, Valid: 19.98%, Test: 15.48%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 185, Loss: 0.3708, Train: 26.42%, Valid: 22.69%, Test: 18.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 190, Loss: 0.3709, Train: 17.30%, Valid: 14.50%, Test: 10.80%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 190, Loss: 0.3709, Train: 23.40%, Valid: 19.90%, Test: 14.94%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 190, Loss: 0.3709, Train: 28.35%, Valid: 24.50%, Test: 18.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 195, Loss: 0.3693, Train: 18.79%, Valid: 15.83%, Test: 11.29%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 195, Loss: 0.3693, Train: 23.88%, Valid: 20.27%, Test: 16.46%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 195, Loss: 0.3693, Train: 29.08%, Valid: 25.14%, Test: 20.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 200, Loss: 0.3710, Train: 15.58%, Valid: 13.07%, Test: 12.43%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 200, Loss: 0.3710, Train: 23.11%, Valid: 19.67%, Test: 15.89%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 200, Loss: 0.3710, Train: 27.40%, Valid: 23.37%, Test: 18.53%\n",
      "---\n",
      "Hits@10\n",
      "Run 06:\n",
      "Highest Train: 20.08\n",
      "Highest Valid: 16.99\n",
      "  Final Train: 20.08\n",
      "   Final Test: 13.03\n",
      "Hits@20\n",
      "Run 06:\n",
      "Highest Train: 25.25\n",
      "Highest Valid: 21.73\n",
      "  Final Train: 25.25\n",
      "   Final Test: 17.16\n",
      "Hits@30\n",
      "Run 06:\n",
      "Highest Train: 30.11\n",
      "Highest Valid: 26.28\n",
      "  Final Train: 30.11\n",
      "   Final Test: 19.57\n",
      "Hits@10\n",
      "Run: 07, Epoch: 05, Loss: 0.4636, Train: 8.64%, Valid: 7.47%, Test: 3.39%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 05, Loss: 0.4636, Train: 10.38%, Valid: 8.98%, Test: 7.83%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 05, Loss: 0.4636, Train: 14.79%, Valid: 12.90%, Test: 12.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 10, Loss: 0.4334, Train: 12.09%, Valid: 10.43%, Test: 8.45%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 10, Loss: 0.4334, Train: 15.16%, Valid: 13.10%, Test: 11.56%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 10, Loss: 0.4334, Train: 19.48%, Valid: 16.95%, Test: 16.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 15, Loss: 0.4163, Train: 10.77%, Valid: 9.27%, Test: 8.43%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 15, Loss: 0.4163, Train: 20.14%, Valid: 17.43%, Test: 15.37%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 15, Loss: 0.4163, Train: 22.80%, Valid: 19.84%, Test: 18.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 20, Loss: 0.4039, Train: 14.27%, Valid: 12.13%, Test: 10.70%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 20, Loss: 0.4039, Train: 21.65%, Valid: 18.68%, Test: 17.07%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 20, Loss: 0.4039, Train: 24.52%, Valid: 21.40%, Test: 20.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 25, Loss: 0.3978, Train: 17.37%, Valid: 14.91%, Test: 11.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 25, Loss: 0.3978, Train: 22.64%, Valid: 19.57%, Test: 19.01%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 25, Loss: 0.3978, Train: 26.41%, Valid: 23.05%, Test: 22.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 30, Loss: 0.3945, Train: 18.01%, Valid: 15.46%, Test: 11.04%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 30, Loss: 0.3945, Train: 20.67%, Valid: 17.80%, Test: 16.58%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 30, Loss: 0.3945, Train: 23.03%, Valid: 19.86%, Test: 19.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 35, Loss: 0.3897, Train: 15.93%, Valid: 13.59%, Test: 11.25%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 35, Loss: 0.3897, Train: 20.73%, Valid: 17.81%, Test: 17.22%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 35, Loss: 0.3897, Train: 25.19%, Valid: 21.82%, Test: 22.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 40, Loss: 0.3894, Train: 14.67%, Valid: 12.39%, Test: 12.00%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 40, Loss: 0.3894, Train: 21.81%, Valid: 18.78%, Test: 15.83%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 40, Loss: 0.3894, Train: 26.83%, Valid: 23.30%, Test: 20.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 45, Loss: 0.3868, Train: 17.01%, Valid: 14.56%, Test: 10.94%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 45, Loss: 0.3868, Train: 24.75%, Valid: 21.47%, Test: 17.23%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 45, Loss: 0.3868, Train: 27.72%, Valid: 24.08%, Test: 21.94%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 07, Epoch: 50, Loss: 0.3845, Train: 17.12%, Valid: 14.59%, Test: 11.68%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 50, Loss: 0.3845, Train: 23.68%, Valid: 20.37%, Test: 17.60%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 50, Loss: 0.3845, Train: 27.66%, Valid: 23.99%, Test: 19.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 55, Loss: 0.3836, Train: 19.54%, Valid: 16.61%, Test: 13.66%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 55, Loss: 0.3836, Train: 23.82%, Valid: 20.58%, Test: 16.83%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 55, Loss: 0.3836, Train: 28.19%, Valid: 24.54%, Test: 24.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 60, Loss: 0.3818, Train: 16.25%, Valid: 13.87%, Test: 9.79%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 60, Loss: 0.3818, Train: 21.12%, Valid: 18.19%, Test: 14.18%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 60, Loss: 0.3818, Train: 25.92%, Valid: 22.49%, Test: 20.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 65, Loss: 0.3815, Train: 14.66%, Valid: 12.43%, Test: 10.45%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 65, Loss: 0.3815, Train: 20.98%, Valid: 17.90%, Test: 16.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 65, Loss: 0.3815, Train: 26.31%, Valid: 22.80%, Test: 19.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 70, Loss: 0.3807, Train: 15.02%, Valid: 12.58%, Test: 11.19%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 70, Loss: 0.3807, Train: 21.63%, Valid: 18.52%, Test: 13.57%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 70, Loss: 0.3807, Train: 25.26%, Valid: 21.70%, Test: 20.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 75, Loss: 0.3793, Train: 14.12%, Valid: 11.89%, Test: 11.98%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 75, Loss: 0.3793, Train: 20.09%, Valid: 17.02%, Test: 14.41%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 75, Loss: 0.3793, Train: 23.98%, Valid: 20.52%, Test: 18.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 80, Loss: 0.3793, Train: 17.84%, Valid: 15.14%, Test: 10.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 80, Loss: 0.3793, Train: 26.84%, Valid: 23.14%, Test: 15.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 80, Loss: 0.3793, Train: 29.62%, Valid: 25.75%, Test: 18.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 85, Loss: 0.3792, Train: 14.29%, Valid: 11.90%, Test: 12.68%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 85, Loss: 0.3792, Train: 21.75%, Valid: 18.49%, Test: 14.31%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 85, Loss: 0.3792, Train: 25.53%, Valid: 22.04%, Test: 19.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 90, Loss: 0.3789, Train: 17.17%, Valid: 14.48%, Test: 11.93%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 90, Loss: 0.3789, Train: 23.80%, Valid: 20.48%, Test: 14.47%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 90, Loss: 0.3789, Train: 29.00%, Valid: 25.21%, Test: 19.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 95, Loss: 0.3776, Train: 18.68%, Valid: 15.88%, Test: 11.52%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 95, Loss: 0.3776, Train: 25.06%, Valid: 21.59%, Test: 16.80%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 95, Loss: 0.3776, Train: 28.37%, Valid: 24.66%, Test: 19.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 100, Loss: 0.3758, Train: 16.39%, Valid: 13.82%, Test: 9.65%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 100, Loss: 0.3758, Train: 23.56%, Valid: 20.19%, Test: 14.05%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 100, Loss: 0.3758, Train: 26.43%, Valid: 22.89%, Test: 16.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 105, Loss: 0.3784, Train: 17.05%, Valid: 14.30%, Test: 10.62%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 105, Loss: 0.3784, Train: 22.30%, Valid: 18.98%, Test: 13.60%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 105, Loss: 0.3784, Train: 28.22%, Valid: 24.46%, Test: 16.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 110, Loss: 0.3764, Train: 15.29%, Valid: 12.86%, Test: 9.67%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 110, Loss: 0.3764, Train: 22.64%, Valid: 19.30%, Test: 13.45%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 110, Loss: 0.3764, Train: 27.76%, Valid: 24.05%, Test: 17.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 115, Loss: 0.3760, Train: 12.63%, Valid: 10.46%, Test: 8.07%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 115, Loss: 0.3760, Train: 22.16%, Valid: 18.89%, Test: 10.94%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 115, Loss: 0.3760, Train: 25.94%, Valid: 22.35%, Test: 16.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 120, Loss: 0.3768, Train: 14.30%, Valid: 11.95%, Test: 8.56%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 120, Loss: 0.3768, Train: 21.72%, Valid: 18.65%, Test: 14.19%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 120, Loss: 0.3768, Train: 27.35%, Valid: 23.72%, Test: 17.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 125, Loss: 0.3753, Train: 13.28%, Valid: 11.09%, Test: 9.86%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 125, Loss: 0.3753, Train: 22.90%, Valid: 19.56%, Test: 13.29%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 125, Loss: 0.3753, Train: 27.99%, Valid: 24.26%, Test: 16.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 130, Loss: 0.3755, Train: 13.35%, Valid: 11.11%, Test: 9.18%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 130, Loss: 0.3755, Train: 18.87%, Valid: 15.94%, Test: 13.78%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 130, Loss: 0.3755, Train: 25.46%, Valid: 21.92%, Test: 17.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 135, Loss: 0.3735, Train: 12.06%, Valid: 10.02%, Test: 8.94%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 135, Loss: 0.3735, Train: 19.90%, Valid: 16.72%, Test: 13.98%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 135, Loss: 0.3735, Train: 23.95%, Valid: 20.36%, Test: 16.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 140, Loss: 0.3752, Train: 14.53%, Valid: 12.20%, Test: 9.48%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 140, Loss: 0.3752, Train: 17.56%, Valid: 14.89%, Test: 11.94%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 140, Loss: 0.3752, Train: 26.28%, Valid: 22.66%, Test: 15.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 145, Loss: 0.3744, Train: 14.60%, Valid: 12.18%, Test: 9.16%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 145, Loss: 0.3744, Train: 18.11%, Valid: 15.22%, Test: 11.78%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 145, Loss: 0.3744, Train: 22.66%, Valid: 19.25%, Test: 16.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 150, Loss: 0.3743, Train: 12.11%, Valid: 9.99%, Test: 9.90%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 150, Loss: 0.3743, Train: 21.84%, Valid: 18.57%, Test: 11.15%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 150, Loss: 0.3743, Train: 28.18%, Valid: 24.36%, Test: 14.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 155, Loss: 0.3742, Train: 15.75%, Valid: 13.21%, Test: 9.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 155, Loss: 0.3742, Train: 22.95%, Valid: 19.65%, Test: 12.57%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 155, Loss: 0.3742, Train: 25.70%, Valid: 22.15%, Test: 16.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 160, Loss: 0.3737, Train: 14.34%, Valid: 11.85%, Test: 9.69%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 160, Loss: 0.3737, Train: 20.85%, Valid: 17.67%, Test: 11.95%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 160, Loss: 0.3737, Train: 24.80%, Valid: 21.21%, Test: 16.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 165, Loss: 0.3740, Train: 13.89%, Valid: 11.52%, Test: 9.44%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 165, Loss: 0.3740, Train: 19.36%, Valid: 16.33%, Test: 11.87%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 165, Loss: 0.3740, Train: 23.23%, Valid: 19.80%, Test: 15.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 170, Loss: 0.3729, Train: 16.54%, Valid: 13.77%, Test: 8.43%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 170, Loss: 0.3729, Train: 21.74%, Valid: 18.35%, Test: 12.91%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 170, Loss: 0.3729, Train: 25.02%, Valid: 21.31%, Test: 15.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 175, Loss: 0.3740, Train: 13.36%, Valid: 11.26%, Test: 9.90%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 175, Loss: 0.3740, Train: 21.79%, Valid: 18.43%, Test: 13.14%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 175, Loss: 0.3740, Train: 26.39%, Valid: 22.66%, Test: 15.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 180, Loss: 0.3729, Train: 12.01%, Valid: 9.94%, Test: 8.25%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 180, Loss: 0.3729, Train: 20.17%, Valid: 17.01%, Test: 11.87%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 180, Loss: 0.3729, Train: 24.34%, Valid: 20.79%, Test: 15.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 185, Loss: 0.3726, Train: 13.57%, Valid: 11.30%, Test: 9.45%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 185, Loss: 0.3726, Train: 24.34%, Valid: 20.78%, Test: 12.48%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 185, Loss: 0.3726, Train: 26.29%, Valid: 22.50%, Test: 16.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 190, Loss: 0.3727, Train: 10.68%, Valid: 8.83%, Test: 7.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 190, Loss: 0.3727, Train: 17.45%, Valid: 14.64%, Test: 11.63%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 190, Loss: 0.3727, Train: 23.24%, Valid: 19.71%, Test: 15.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 195, Loss: 0.3732, Train: 11.60%, Valid: 9.63%, Test: 9.15%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 195, Loss: 0.3732, Train: 19.23%, Valid: 16.13%, Test: 11.90%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 195, Loss: 0.3732, Train: 25.80%, Valid: 22.07%, Test: 15.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 200, Loss: 0.3713, Train: 14.35%, Valid: 11.93%, Test: 8.81%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 200, Loss: 0.3713, Train: 18.32%, Valid: 15.30%, Test: 12.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 200, Loss: 0.3713, Train: 21.48%, Valid: 18.15%, Test: 16.58%\n",
      "---\n",
      "Hits@10\n",
      "Run 07:\n",
      "Highest Train: 19.54\n",
      "Highest Valid: 16.61\n",
      "  Final Train: 19.54\n",
      "   Final Test: 13.66\n",
      "Hits@20\n",
      "Run 07:\n",
      "Highest Train: 26.84\n",
      "Highest Valid: 23.14\n",
      "  Final Train: 26.84\n",
      "   Final Test: 15.59\n",
      "Hits@30\n",
      "Run 07:\n",
      "Highest Train: 29.62\n",
      "Highest Valid: 25.75\n",
      "  Final Train: 29.62\n",
      "   Final Test: 18.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 05, Loss: 0.4641, Train: 8.31%, Valid: 7.20%, Test: 2.51%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 05, Loss: 0.4641, Train: 11.75%, Valid: 10.18%, Test: 7.90%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 05, Loss: 0.4641, Train: 14.17%, Valid: 12.33%, Test: 11.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 10, Loss: 0.4306, Train: 10.03%, Valid: 8.64%, Test: 8.80%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 10, Loss: 0.4306, Train: 15.12%, Valid: 13.12%, Test: 12.77%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 10, Loss: 0.4306, Train: 19.86%, Valid: 17.34%, Test: 17.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 15, Loss: 0.4140, Train: 14.17%, Valid: 12.18%, Test: 10.85%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 15, Loss: 0.4140, Train: 20.52%, Valid: 17.76%, Test: 16.13%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 15, Loss: 0.4140, Train: 23.58%, Valid: 20.46%, Test: 19.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 20, Loss: 0.4041, Train: 13.50%, Valid: 11.54%, Test: 9.10%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 20, Loss: 0.4041, Train: 17.46%, Valid: 14.91%, Test: 13.07%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 20, Loss: 0.4041, Train: 22.25%, Valid: 19.26%, Test: 20.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 25, Loss: 0.3970, Train: 9.12%, Valid: 7.70%, Test: 9.53%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 25, Loss: 0.3970, Train: 18.96%, Valid: 16.15%, Test: 15.73%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 25, Loss: 0.3970, Train: 22.81%, Valid: 19.60%, Test: 22.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 30, Loss: 0.3929, Train: 11.57%, Valid: 9.81%, Test: 9.94%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 30, Loss: 0.3929, Train: 17.78%, Valid: 15.23%, Test: 16.63%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 30, Loss: 0.3929, Train: 20.97%, Valid: 18.05%, Test: 21.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 35, Loss: 0.3899, Train: 15.02%, Valid: 12.71%, Test: 11.69%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 35, Loss: 0.3899, Train: 22.70%, Valid: 19.51%, Test: 19.81%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 35, Loss: 0.3899, Train: 25.58%, Valid: 22.16%, Test: 22.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 40, Loss: 0.3862, Train: 9.90%, Valid: 8.09%, Test: 10.58%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 40, Loss: 0.3862, Train: 19.16%, Valid: 16.31%, Test: 17.24%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 40, Loss: 0.3862, Train: 22.58%, Valid: 19.39%, Test: 20.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 45, Loss: 0.3868, Train: 9.81%, Valid: 8.01%, Test: 12.28%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 45, Loss: 0.3868, Train: 18.49%, Valid: 15.67%, Test: 15.57%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 45, Loss: 0.3868, Train: 24.95%, Valid: 21.42%, Test: 23.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 50, Loss: 0.3852, Train: 12.56%, Valid: 10.53%, Test: 9.47%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 50, Loss: 0.3852, Train: 20.35%, Valid: 17.36%, Test: 17.43%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 50, Loss: 0.3852, Train: 23.12%, Valid: 19.86%, Test: 22.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 55, Loss: 0.3837, Train: 11.85%, Valid: 9.92%, Test: 10.67%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 55, Loss: 0.3837, Train: 18.36%, Valid: 15.59%, Test: 14.89%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 55, Loss: 0.3837, Train: 22.13%, Valid: 18.98%, Test: 20.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 60, Loss: 0.3827, Train: 8.79%, Valid: 7.23%, Test: 10.39%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 60, Loss: 0.3827, Train: 17.90%, Valid: 15.15%, Test: 13.68%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 60, Loss: 0.3827, Train: 22.04%, Valid: 18.93%, Test: 19.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 65, Loss: 0.3822, Train: 10.60%, Valid: 8.74%, Test: 10.77%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 65, Loss: 0.3822, Train: 18.87%, Valid: 16.02%, Test: 14.62%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 65, Loss: 0.3822, Train: 23.36%, Valid: 20.02%, Test: 19.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 70, Loss: 0.3807, Train: 11.54%, Valid: 9.66%, Test: 10.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 70, Loss: 0.3807, Train: 20.10%, Valid: 17.09%, Test: 14.95%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 70, Loss: 0.3807, Train: 23.95%, Valid: 20.55%, Test: 20.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 75, Loss: 0.3786, Train: 12.80%, Valid: 10.68%, Test: 10.90%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 75, Loss: 0.3786, Train: 20.46%, Valid: 17.43%, Test: 13.68%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 75, Loss: 0.3786, Train: 23.07%, Valid: 19.78%, Test: 17.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 80, Loss: 0.3795, Train: 11.86%, Valid: 9.87%, Test: 10.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 80, Loss: 0.3795, Train: 19.05%, Valid: 16.31%, Test: 14.33%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 80, Loss: 0.3795, Train: 23.64%, Valid: 20.36%, Test: 19.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 85, Loss: 0.3785, Train: 12.03%, Valid: 9.96%, Test: 9.07%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 85, Loss: 0.3785, Train: 17.97%, Valid: 15.20%, Test: 13.69%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 85, Loss: 0.3785, Train: 21.53%, Valid: 18.33%, Test: 17.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 90, Loss: 0.3781, Train: 15.60%, Valid: 13.07%, Test: 10.84%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 90, Loss: 0.3781, Train: 23.61%, Valid: 20.24%, Test: 15.38%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 90, Loss: 0.3781, Train: 26.83%, Valid: 23.20%, Test: 20.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 95, Loss: 0.3785, Train: 14.24%, Valid: 11.91%, Test: 10.47%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 95, Loss: 0.3785, Train: 23.47%, Valid: 20.06%, Test: 15.85%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 95, Loss: 0.3785, Train: 26.46%, Valid: 22.76%, Test: 19.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 100, Loss: 0.3776, Train: 11.89%, Valid: 9.89%, Test: 9.89%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 100, Loss: 0.3776, Train: 19.05%, Valid: 16.24%, Test: 14.62%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 100, Loss: 0.3776, Train: 22.23%, Valid: 19.16%, Test: 16.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 105, Loss: 0.3773, Train: 11.14%, Valid: 9.21%, Test: 10.54%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 105, Loss: 0.3773, Train: 17.74%, Valid: 15.03%, Test: 13.71%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 105, Loss: 0.3773, Train: 22.14%, Valid: 18.89%, Test: 16.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 110, Loss: 0.3776, Train: 14.83%, Valid: 12.39%, Test: 11.16%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 110, Loss: 0.3776, Train: 20.79%, Valid: 17.59%, Test: 16.33%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 110, Loss: 0.3776, Train: 23.22%, Valid: 19.79%, Test: 19.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 115, Loss: 0.3761, Train: 11.97%, Valid: 9.98%, Test: 10.13%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 115, Loss: 0.3761, Train: 17.15%, Valid: 14.45%, Test: 14.37%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 115, Loss: 0.3761, Train: 20.78%, Valid: 17.79%, Test: 18.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 120, Loss: 0.3756, Train: 15.29%, Valid: 12.85%, Test: 11.57%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 120, Loss: 0.3756, Train: 20.16%, Valid: 17.20%, Test: 14.70%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 120, Loss: 0.3756, Train: 23.84%, Valid: 20.42%, Test: 17.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 125, Loss: 0.3761, Train: 13.09%, Valid: 10.95%, Test: 12.32%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 125, Loss: 0.3761, Train: 19.60%, Valid: 16.57%, Test: 15.05%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 125, Loss: 0.3761, Train: 23.38%, Valid: 19.88%, Test: 19.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 130, Loss: 0.3757, Train: 12.73%, Valid: 10.62%, Test: 11.06%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 130, Loss: 0.3757, Train: 18.23%, Valid: 15.35%, Test: 14.65%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 130, Loss: 0.3757, Train: 24.44%, Valid: 20.89%, Test: 16.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 135, Loss: 0.3768, Train: 15.88%, Valid: 13.41%, Test: 11.55%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 135, Loss: 0.3768, Train: 22.99%, Valid: 19.64%, Test: 15.00%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 135, Loss: 0.3768, Train: 27.49%, Valid: 23.74%, Test: 18.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 140, Loss: 0.3754, Train: 11.00%, Valid: 9.09%, Test: 9.14%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 140, Loss: 0.3754, Train: 20.42%, Valid: 17.31%, Test: 13.80%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 140, Loss: 0.3754, Train: 25.69%, Valid: 22.02%, Test: 16.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 145, Loss: 0.3759, Train: 14.03%, Valid: 11.69%, Test: 9.99%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 145, Loss: 0.3759, Train: 22.52%, Valid: 19.21%, Test: 14.52%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 145, Loss: 0.3759, Train: 26.11%, Valid: 22.37%, Test: 17.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 150, Loss: 0.3745, Train: 10.84%, Valid: 8.92%, Test: 8.72%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 150, Loss: 0.3745, Train: 16.68%, Valid: 13.92%, Test: 12.90%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 150, Loss: 0.3745, Train: 22.34%, Valid: 18.98%, Test: 17.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 155, Loss: 0.3726, Train: 14.02%, Valid: 11.63%, Test: 9.06%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 155, Loss: 0.3726, Train: 18.64%, Valid: 15.66%, Test: 13.24%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 155, Loss: 0.3726, Train: 26.07%, Valid: 22.28%, Test: 16.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 160, Loss: 0.3741, Train: 13.52%, Valid: 11.29%, Test: 10.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 160, Loss: 0.3741, Train: 20.93%, Valid: 17.70%, Test: 15.88%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 160, Loss: 0.3741, Train: 24.02%, Valid: 20.43%, Test: 18.26%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 165, Loss: 0.3729, Train: 13.18%, Valid: 10.98%, Test: 9.48%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 165, Loss: 0.3729, Train: 19.59%, Valid: 16.56%, Test: 13.37%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 165, Loss: 0.3729, Train: 23.57%, Valid: 20.10%, Test: 16.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 170, Loss: 0.3749, Train: 12.67%, Valid: 10.49%, Test: 9.73%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 170, Loss: 0.3749, Train: 19.63%, Valid: 16.64%, Test: 12.62%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 170, Loss: 0.3749, Train: 23.50%, Valid: 19.98%, Test: 14.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 175, Loss: 0.3730, Train: 14.77%, Valid: 12.42%, Test: 11.13%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 175, Loss: 0.3730, Train: 21.45%, Valid: 18.16%, Test: 13.13%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 175, Loss: 0.3730, Train: 26.38%, Valid: 22.66%, Test: 18.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 180, Loss: 0.3728, Train: 15.16%, Valid: 12.68%, Test: 9.52%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 180, Loss: 0.3728, Train: 19.17%, Valid: 16.18%, Test: 12.75%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 180, Loss: 0.3728, Train: 24.02%, Valid: 20.46%, Test: 16.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 185, Loss: 0.3746, Train: 12.21%, Valid: 10.08%, Test: 9.37%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 185, Loss: 0.3746, Train: 20.32%, Valid: 17.30%, Test: 12.92%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 185, Loss: 0.3746, Train: 23.32%, Valid: 19.95%, Test: 16.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 190, Loss: 0.3733, Train: 14.40%, Valid: 12.09%, Test: 10.12%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 190, Loss: 0.3733, Train: 17.96%, Valid: 15.07%, Test: 13.30%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 190, Loss: 0.3733, Train: 21.98%, Valid: 18.60%, Test: 16.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 195, Loss: 0.3728, Train: 14.79%, Valid: 12.32%, Test: 10.37%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 195, Loss: 0.3728, Train: 21.16%, Valid: 17.97%, Test: 14.23%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 195, Loss: 0.3728, Train: 25.95%, Valid: 22.23%, Test: 16.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 200, Loss: 0.3732, Train: 14.23%, Valid: 11.89%, Test: 11.07%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 200, Loss: 0.3732, Train: 21.88%, Valid: 18.56%, Test: 15.33%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 200, Loss: 0.3732, Train: 27.85%, Valid: 24.03%, Test: 18.52%\n",
      "---\n",
      "Hits@10\n",
      "Run 08:\n",
      "Highest Train: 15.88\n",
      "Highest Valid: 13.41\n",
      "  Final Train: 15.88\n",
      "   Final Test: 11.55\n",
      "Hits@20\n",
      "Run 08:\n",
      "Highest Train: 23.61\n",
      "Highest Valid: 20.24\n",
      "  Final Train: 23.61\n",
      "   Final Test: 15.38\n",
      "Hits@30\n",
      "Run 08:\n",
      "Highest Train: 27.85\n",
      "Highest Valid: 24.03\n",
      "  Final Train: 27.85\n",
      "   Final Test: 18.52\n",
      "Hits@10\n",
      "Run: 09, Epoch: 05, Loss: 0.4649, Train: 8.07%, Valid: 6.97%, Test: 2.51%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 05, Loss: 0.4649, Train: 11.73%, Valid: 10.11%, Test: 8.08%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 05, Loss: 0.4649, Train: 14.64%, Valid: 12.74%, Test: 11.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 10, Loss: 0.4329, Train: 11.07%, Valid: 9.46%, Test: 5.52%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 10, Loss: 0.4329, Train: 16.06%, Valid: 13.94%, Test: 9.76%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 10, Loss: 0.4329, Train: 17.93%, Valid: 15.58%, Test: 16.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 15, Loss: 0.4153, Train: 13.91%, Valid: 11.94%, Test: 9.55%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 15, Loss: 0.4153, Train: 20.19%, Valid: 17.56%, Test: 15.81%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 15, Loss: 0.4153, Train: 23.45%, Valid: 20.40%, Test: 19.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 20, Loss: 0.4032, Train: 16.61%, Valid: 14.23%, Test: 9.51%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 20, Loss: 0.4032, Train: 22.97%, Valid: 19.91%, Test: 15.89%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 20, Loss: 0.4032, Train: 25.93%, Valid: 22.65%, Test: 21.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 25, Loss: 0.3977, Train: 13.15%, Valid: 11.27%, Test: 11.18%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 25, Loss: 0.3977, Train: 18.73%, Valid: 16.16%, Test: 16.08%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 25, Loss: 0.3977, Train: 22.09%, Valid: 19.14%, Test: 18.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 30, Loss: 0.3917, Train: 17.78%, Valid: 15.26%, Test: 9.57%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 30, Loss: 0.3917, Train: 22.62%, Valid: 19.55%, Test: 15.30%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 30, Loss: 0.3917, Train: 25.16%, Valid: 21.83%, Test: 19.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 35, Loss: 0.3884, Train: 17.04%, Valid: 14.54%, Test: 13.00%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 35, Loss: 0.3884, Train: 19.94%, Valid: 17.08%, Test: 16.24%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 35, Loss: 0.3884, Train: 23.50%, Valid: 20.34%, Test: 20.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 40, Loss: 0.3865, Train: 16.95%, Valid: 14.43%, Test: 12.42%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 40, Loss: 0.3865, Train: 20.87%, Valid: 17.88%, Test: 17.87%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 40, Loss: 0.3865, Train: 24.26%, Valid: 21.05%, Test: 20.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 45, Loss: 0.3840, Train: 16.33%, Valid: 13.81%, Test: 12.76%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 45, Loss: 0.3840, Train: 20.83%, Valid: 17.86%, Test: 17.23%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 45, Loss: 0.3840, Train: 24.96%, Valid: 21.59%, Test: 21.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 50, Loss: 0.3832, Train: 14.08%, Valid: 11.92%, Test: 10.82%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 50, Loss: 0.3832, Train: 20.44%, Valid: 17.47%, Test: 17.02%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 50, Loss: 0.3832, Train: 23.41%, Valid: 20.13%, Test: 21.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 55, Loss: 0.3822, Train: 15.33%, Valid: 12.98%, Test: 12.27%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 55, Loss: 0.3822, Train: 25.24%, Valid: 21.81%, Test: 17.01%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 55, Loss: 0.3822, Train: 27.63%, Valid: 24.03%, Test: 23.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 60, Loss: 0.3803, Train: 16.94%, Valid: 14.32%, Test: 13.26%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 60, Loss: 0.3803, Train: 25.12%, Valid: 21.67%, Test: 16.77%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 60, Loss: 0.3803, Train: 28.26%, Valid: 24.53%, Test: 20.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 65, Loss: 0.3799, Train: 16.68%, Valid: 14.14%, Test: 9.33%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 65, Loss: 0.3799, Train: 22.18%, Valid: 19.08%, Test: 17.40%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 65, Loss: 0.3799, Train: 27.02%, Valid: 23.40%, Test: 21.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 70, Loss: 0.3807, Train: 18.67%, Valid: 15.88%, Test: 12.08%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 70, Loss: 0.3807, Train: 22.54%, Valid: 19.42%, Test: 17.23%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 70, Loss: 0.3807, Train: 28.82%, Valid: 25.14%, Test: 20.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 75, Loss: 0.3785, Train: 16.47%, Valid: 14.00%, Test: 10.72%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 75, Loss: 0.3785, Train: 22.63%, Valid: 19.45%, Test: 16.30%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 75, Loss: 0.3785, Train: 27.83%, Valid: 24.03%, Test: 21.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 80, Loss: 0.3783, Train: 19.04%, Valid: 16.23%, Test: 9.24%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 80, Loss: 0.3783, Train: 25.07%, Valid: 21.57%, Test: 18.57%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 80, Loss: 0.3783, Train: 29.69%, Valid: 25.82%, Test: 21.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 85, Loss: 0.3787, Train: 14.97%, Valid: 12.58%, Test: 9.66%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 85, Loss: 0.3787, Train: 26.15%, Valid: 22.51%, Test: 15.40%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 85, Loss: 0.3787, Train: 28.82%, Valid: 24.88%, Test: 18.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 90, Loss: 0.3755, Train: 11.97%, Valid: 10.04%, Test: 8.25%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 90, Loss: 0.3755, Train: 20.59%, Valid: 17.65%, Test: 16.60%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 90, Loss: 0.3755, Train: 27.99%, Valid: 24.22%, Test: 19.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 95, Loss: 0.3761, Train: 19.38%, Valid: 16.51%, Test: 10.58%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 95, Loss: 0.3761, Train: 25.86%, Valid: 22.31%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 95, Loss: 0.3761, Train: 27.87%, Valid: 24.27%, Test: 19.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 100, Loss: 0.3761, Train: 17.31%, Valid: 14.64%, Test: 10.77%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 100, Loss: 0.3761, Train: 25.21%, Valid: 21.65%, Test: 14.19%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 100, Loss: 0.3761, Train: 30.60%, Valid: 26.59%, Test: 18.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 105, Loss: 0.3761, Train: 19.40%, Valid: 16.47%, Test: 7.49%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 105, Loss: 0.3761, Train: 28.06%, Valid: 24.25%, Test: 15.35%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 105, Loss: 0.3761, Train: 32.02%, Valid: 28.03%, Test: 20.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 110, Loss: 0.3743, Train: 17.13%, Valid: 14.47%, Test: 7.82%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 110, Loss: 0.3743, Train: 27.03%, Valid: 23.28%, Test: 14.02%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 110, Loss: 0.3743, Train: 30.27%, Valid: 26.22%, Test: 16.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 115, Loss: 0.3748, Train: 16.00%, Valid: 13.46%, Test: 9.34%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 115, Loss: 0.3748, Train: 24.59%, Valid: 21.05%, Test: 15.47%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 115, Loss: 0.3748, Train: 27.81%, Valid: 24.06%, Test: 19.07%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 09, Epoch: 120, Loss: 0.3759, Train: 17.23%, Valid: 14.59%, Test: 10.73%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 120, Loss: 0.3759, Train: 23.74%, Valid: 20.36%, Test: 14.39%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 120, Loss: 0.3759, Train: 27.05%, Valid: 23.33%, Test: 17.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 125, Loss: 0.3743, Train: 15.81%, Valid: 13.31%, Test: 9.56%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 125, Loss: 0.3743, Train: 24.49%, Valid: 21.14%, Test: 14.37%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 125, Loss: 0.3743, Train: 29.23%, Valid: 25.46%, Test: 17.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 130, Loss: 0.3742, Train: 17.69%, Valid: 14.94%, Test: 10.34%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 130, Loss: 0.3742, Train: 24.72%, Valid: 21.12%, Test: 14.82%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 130, Loss: 0.3742, Train: 26.85%, Valid: 23.06%, Test: 18.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 135, Loss: 0.3729, Train: 16.73%, Valid: 14.05%, Test: 10.22%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 135, Loss: 0.3729, Train: 24.27%, Valid: 20.83%, Test: 17.45%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 135, Loss: 0.3729, Train: 30.65%, Valid: 26.65%, Test: 23.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 140, Loss: 0.3731, Train: 19.38%, Valid: 16.56%, Test: 11.77%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 140, Loss: 0.3731, Train: 26.75%, Valid: 23.10%, Test: 16.41%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 140, Loss: 0.3731, Train: 33.65%, Valid: 29.60%, Test: 19.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 145, Loss: 0.3732, Train: 19.31%, Valid: 16.35%, Test: 10.51%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 145, Loss: 0.3732, Train: 26.95%, Valid: 23.22%, Test: 14.80%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 145, Loss: 0.3732, Train: 31.84%, Valid: 27.79%, Test: 19.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 150, Loss: 0.3741, Train: 17.82%, Valid: 15.07%, Test: 9.87%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 150, Loss: 0.3741, Train: 23.72%, Valid: 20.32%, Test: 13.78%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 150, Loss: 0.3741, Train: 27.56%, Valid: 23.86%, Test: 18.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 155, Loss: 0.3729, Train: 18.87%, Valid: 16.02%, Test: 9.27%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 155, Loss: 0.3729, Train: 24.37%, Valid: 20.83%, Test: 14.77%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 155, Loss: 0.3729, Train: 29.00%, Valid: 24.97%, Test: 18.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 160, Loss: 0.3721, Train: 17.53%, Valid: 14.79%, Test: 9.60%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 160, Loss: 0.3721, Train: 25.10%, Valid: 21.50%, Test: 15.31%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 160, Loss: 0.3721, Train: 29.77%, Valid: 25.83%, Test: 19.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 165, Loss: 0.3732, Train: 19.82%, Valid: 16.87%, Test: 9.75%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 165, Loss: 0.3732, Train: 25.97%, Valid: 22.39%, Test: 14.17%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 165, Loss: 0.3732, Train: 30.79%, Valid: 26.77%, Test: 18.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 170, Loss: 0.3722, Train: 17.44%, Valid: 14.74%, Test: 9.08%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 170, Loss: 0.3722, Train: 23.34%, Valid: 19.96%, Test: 15.81%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 170, Loss: 0.3722, Train: 26.93%, Valid: 23.19%, Test: 18.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 175, Loss: 0.3728, Train: 16.64%, Valid: 14.00%, Test: 10.14%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 175, Loss: 0.3728, Train: 26.28%, Valid: 22.68%, Test: 14.56%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 175, Loss: 0.3728, Train: 29.35%, Valid: 25.53%, Test: 19.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 180, Loss: 0.3728, Train: 17.40%, Valid: 14.61%, Test: 8.08%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 180, Loss: 0.3728, Train: 25.95%, Valid: 22.39%, Test: 14.68%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 180, Loss: 0.3728, Train: 30.88%, Valid: 26.94%, Test: 18.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 185, Loss: 0.3719, Train: 15.81%, Valid: 13.24%, Test: 9.78%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 185, Loss: 0.3719, Train: 25.15%, Valid: 21.55%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 185, Loss: 0.3719, Train: 32.62%, Valid: 28.45%, Test: 18.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 190, Loss: 0.3721, Train: 21.06%, Valid: 17.93%, Test: 8.96%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 190, Loss: 0.3721, Train: 26.57%, Valid: 22.91%, Test: 14.73%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 190, Loss: 0.3721, Train: 31.36%, Valid: 27.37%, Test: 18.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 195, Loss: 0.3703, Train: 16.94%, Valid: 14.19%, Test: 8.44%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 195, Loss: 0.3703, Train: 23.17%, Valid: 19.79%, Test: 12.25%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 195, Loss: 0.3703, Train: 32.00%, Valid: 27.92%, Test: 17.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 200, Loss: 0.3719, Train: 19.68%, Valid: 16.76%, Test: 8.24%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 200, Loss: 0.3719, Train: 24.59%, Valid: 21.14%, Test: 13.87%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 200, Loss: 0.3719, Train: 27.64%, Valid: 23.87%, Test: 17.46%\n",
      "---\n",
      "Hits@10\n",
      "Run 09:\n",
      "Highest Train: 21.06\n",
      "Highest Valid: 17.93\n",
      "  Final Train: 21.06\n",
      "   Final Test: 8.96\n",
      "Hits@20\n",
      "Run 09:\n",
      "Highest Train: 28.06\n",
      "Highest Valid: 24.25\n",
      "  Final Train: 28.06\n",
      "   Final Test: 15.35\n",
      "Hits@30\n",
      "Run 09:\n",
      "Highest Train: 33.65\n",
      "Highest Valid: 29.60\n",
      "  Final Train: 33.65\n",
      "   Final Test: 19.03\n",
      "Hits@10\n",
      "Run: 10, Epoch: 05, Loss: 0.4666, Train: 7.22%, Valid: 6.26%, Test: 3.73%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 05, Loss: 0.4666, Train: 10.68%, Valid: 9.26%, Test: 8.83%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 05, Loss: 0.4666, Train: 13.68%, Valid: 11.91%, Test: 12.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 10, Loss: 0.4341, Train: 8.01%, Valid: 6.88%, Test: 6.62%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 10, Loss: 0.4341, Train: 14.69%, Valid: 12.74%, Test: 10.22%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 10, Loss: 0.4341, Train: 20.62%, Valid: 17.92%, Test: 15.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 15, Loss: 0.4136, Train: 10.12%, Valid: 8.71%, Test: 8.99%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 15, Loss: 0.4136, Train: 17.71%, Valid: 15.28%, Test: 16.26%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 15, Loss: 0.4136, Train: 23.71%, Valid: 20.68%, Test: 19.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 20, Loss: 0.4049, Train: 16.11%, Valid: 13.89%, Test: 10.28%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 20, Loss: 0.4049, Train: 21.10%, Valid: 18.29%, Test: 18.18%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 20, Loss: 0.4049, Train: 24.79%, Valid: 21.72%, Test: 21.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 25, Loss: 0.3965, Train: 16.24%, Valid: 13.87%, Test: 10.98%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 25, Loss: 0.3965, Train: 23.03%, Valid: 19.99%, Test: 17.79%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 25, Loss: 0.3965, Train: 26.57%, Valid: 23.20%, Test: 22.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 30, Loss: 0.3915, Train: 15.02%, Valid: 12.89%, Test: 11.84%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 30, Loss: 0.3915, Train: 22.40%, Valid: 19.43%, Test: 21.36%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 30, Loss: 0.3915, Train: 26.65%, Valid: 23.30%, Test: 24.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 35, Loss: 0.3886, Train: 17.20%, Valid: 14.75%, Test: 12.32%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 35, Loss: 0.3886, Train: 25.02%, Valid: 21.84%, Test: 17.32%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 35, Loss: 0.3886, Train: 26.87%, Valid: 23.58%, Test: 21.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 40, Loss: 0.3885, Train: 17.32%, Valid: 14.83%, Test: 12.40%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 40, Loss: 0.3885, Train: 22.73%, Valid: 19.69%, Test: 18.80%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 40, Loss: 0.3885, Train: 27.95%, Valid: 24.49%, Test: 23.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 45, Loss: 0.3854, Train: 18.28%, Valid: 15.58%, Test: 14.03%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 45, Loss: 0.3854, Train: 24.17%, Valid: 21.04%, Test: 21.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 45, Loss: 0.3854, Train: 29.67%, Valid: 26.05%, Test: 24.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 50, Loss: 0.3843, Train: 19.54%, Valid: 16.83%, Test: 14.45%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 50, Loss: 0.3843, Train: 25.14%, Valid: 21.83%, Test: 20.33%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 50, Loss: 0.3843, Train: 30.40%, Valid: 26.71%, Test: 24.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 55, Loss: 0.3819, Train: 18.01%, Valid: 15.41%, Test: 15.35%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 55, Loss: 0.3819, Train: 24.82%, Valid: 21.57%, Test: 19.45%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 55, Loss: 0.3819, Train: 29.69%, Valid: 26.06%, Test: 23.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 60, Loss: 0.3820, Train: 17.93%, Valid: 15.40%, Test: 15.11%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 60, Loss: 0.3820, Train: 30.14%, Valid: 26.38%, Test: 19.49%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 60, Loss: 0.3820, Train: 32.08%, Valid: 28.15%, Test: 24.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 65, Loss: 0.3804, Train: 20.75%, Valid: 17.84%, Test: 13.72%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 65, Loss: 0.3804, Train: 25.68%, Valid: 22.34%, Test: 19.30%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 65, Loss: 0.3804, Train: 32.41%, Valid: 28.55%, Test: 25.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 70, Loss: 0.3791, Train: 19.39%, Valid: 16.54%, Test: 13.88%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 70, Loss: 0.3791, Train: 23.88%, Valid: 20.67%, Test: 17.59%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 70, Loss: 0.3791, Train: 31.54%, Valid: 27.70%, Test: 22.30%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 10, Epoch: 75, Loss: 0.3794, Train: 17.66%, Valid: 15.07%, Test: 12.80%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 75, Loss: 0.3794, Train: 23.12%, Valid: 19.91%, Test: 17.94%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 75, Loss: 0.3794, Train: 29.27%, Valid: 25.52%, Test: 21.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 80, Loss: 0.3785, Train: 16.52%, Valid: 13.98%, Test: 12.65%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 80, Loss: 0.3785, Train: 28.41%, Valid: 24.68%, Test: 17.03%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 80, Loss: 0.3785, Train: 30.82%, Valid: 26.96%, Test: 22.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 85, Loss: 0.3786, Train: 15.52%, Valid: 13.11%, Test: 12.30%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 85, Loss: 0.3786, Train: 24.95%, Valid: 21.52%, Test: 15.69%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 85, Loss: 0.3786, Train: 31.19%, Valid: 27.21%, Test: 20.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 90, Loss: 0.3797, Train: 14.71%, Valid: 12.41%, Test: 13.87%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 90, Loss: 0.3797, Train: 22.81%, Valid: 19.63%, Test: 19.10%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 90, Loss: 0.3797, Train: 29.75%, Valid: 25.96%, Test: 22.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 95, Loss: 0.3755, Train: 15.85%, Valid: 13.42%, Test: 12.27%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 95, Loss: 0.3755, Train: 24.62%, Valid: 21.20%, Test: 16.21%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 95, Loss: 0.3755, Train: 29.85%, Valid: 26.11%, Test: 20.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 100, Loss: 0.3769, Train: 13.86%, Valid: 11.62%, Test: 10.68%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 100, Loss: 0.3769, Train: 21.00%, Valid: 17.90%, Test: 17.96%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 100, Loss: 0.3769, Train: 27.30%, Valid: 23.71%, Test: 22.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 105, Loss: 0.3768, Train: 18.77%, Valid: 15.88%, Test: 12.61%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 105, Loss: 0.3768, Train: 25.17%, Valid: 21.67%, Test: 17.00%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 105, Loss: 0.3768, Train: 31.27%, Valid: 27.35%, Test: 21.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 110, Loss: 0.3765, Train: 18.57%, Valid: 15.70%, Test: 12.82%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 110, Loss: 0.3765, Train: 24.33%, Valid: 20.91%, Test: 17.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 110, Loss: 0.3765, Train: 30.12%, Valid: 26.27%, Test: 21.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 115, Loss: 0.3754, Train: 17.13%, Valid: 14.48%, Test: 12.52%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 115, Loss: 0.3754, Train: 24.85%, Valid: 21.28%, Test: 17.64%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 115, Loss: 0.3754, Train: 29.13%, Valid: 25.43%, Test: 19.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 120, Loss: 0.3755, Train: 16.22%, Valid: 13.68%, Test: 11.53%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 120, Loss: 0.3755, Train: 24.03%, Valid: 20.74%, Test: 15.44%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 120, Loss: 0.3755, Train: 27.92%, Valid: 24.29%, Test: 18.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 125, Loss: 0.3768, Train: 15.98%, Valid: 13.43%, Test: 12.14%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 125, Loss: 0.3768, Train: 22.92%, Valid: 19.64%, Test: 16.23%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 125, Loss: 0.3768, Train: 26.20%, Valid: 22.63%, Test: 20.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 130, Loss: 0.3750, Train: 16.13%, Valid: 13.49%, Test: 12.97%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 130, Loss: 0.3750, Train: 24.35%, Valid: 20.88%, Test: 16.45%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 130, Loss: 0.3750, Train: 29.71%, Valid: 25.93%, Test: 20.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 135, Loss: 0.3745, Train: 18.29%, Valid: 15.57%, Test: 11.54%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 135, Loss: 0.3745, Train: 26.65%, Valid: 23.15%, Test: 15.84%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 135, Loss: 0.3745, Train: 31.65%, Valid: 27.80%, Test: 19.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 140, Loss: 0.3749, Train: 14.43%, Valid: 12.06%, Test: 13.47%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 140, Loss: 0.3749, Train: 24.81%, Valid: 21.50%, Test: 18.20%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 140, Loss: 0.3749, Train: 29.29%, Valid: 25.74%, Test: 21.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 145, Loss: 0.3740, Train: 16.82%, Valid: 14.20%, Test: 11.44%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 145, Loss: 0.3740, Train: 24.75%, Valid: 21.29%, Test: 15.12%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 145, Loss: 0.3740, Train: 30.25%, Valid: 26.41%, Test: 18.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 150, Loss: 0.3744, Train: 18.47%, Valid: 15.62%, Test: 12.36%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 150, Loss: 0.3744, Train: 24.27%, Valid: 20.84%, Test: 15.87%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 150, Loss: 0.3744, Train: 28.55%, Valid: 24.75%, Test: 20.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 155, Loss: 0.3738, Train: 16.58%, Valid: 13.93%, Test: 12.49%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 155, Loss: 0.3738, Train: 23.47%, Valid: 20.04%, Test: 16.64%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 155, Loss: 0.3738, Train: 30.69%, Valid: 26.81%, Test: 19.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 160, Loss: 0.3745, Train: 11.13%, Valid: 9.23%, Test: 11.98%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 160, Loss: 0.3745, Train: 22.30%, Valid: 18.93%, Test: 16.09%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 160, Loss: 0.3745, Train: 28.97%, Valid: 25.04%, Test: 19.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 165, Loss: 0.3740, Train: 19.40%, Valid: 16.40%, Test: 13.26%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 165, Loss: 0.3740, Train: 28.69%, Valid: 24.72%, Test: 17.29%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 165, Loss: 0.3740, Train: 32.98%, Valid: 28.85%, Test: 20.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 170, Loss: 0.3742, Train: 13.22%, Valid: 11.00%, Test: 11.80%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 170, Loss: 0.3742, Train: 25.07%, Valid: 21.47%, Test: 16.86%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 170, Loss: 0.3742, Train: 29.70%, Valid: 25.75%, Test: 20.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 175, Loss: 0.3727, Train: 18.04%, Valid: 15.16%, Test: 12.18%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 175, Loss: 0.3727, Train: 24.08%, Valid: 20.57%, Test: 16.23%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 175, Loss: 0.3727, Train: 31.21%, Valid: 27.27%, Test: 20.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 180, Loss: 0.3738, Train: 18.99%, Valid: 16.04%, Test: 12.13%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 180, Loss: 0.3738, Train: 26.93%, Valid: 23.29%, Test: 17.13%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 180, Loss: 0.3738, Train: 31.22%, Valid: 27.33%, Test: 22.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 185, Loss: 0.3723, Train: 14.00%, Valid: 11.57%, Test: 12.75%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 185, Loss: 0.3723, Train: 26.76%, Valid: 23.00%, Test: 16.38%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 185, Loss: 0.3723, Train: 30.51%, Valid: 26.49%, Test: 20.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 190, Loss: 0.3728, Train: 15.51%, Valid: 12.85%, Test: 11.16%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 190, Loss: 0.3728, Train: 21.18%, Valid: 17.96%, Test: 15.12%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 190, Loss: 0.3728, Train: 27.00%, Valid: 23.32%, Test: 19.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 195, Loss: 0.3719, Train: 14.60%, Valid: 12.09%, Test: 12.12%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 195, Loss: 0.3719, Train: 24.63%, Valid: 21.04%, Test: 14.84%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 195, Loss: 0.3719, Train: 30.48%, Valid: 26.35%, Test: 17.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 200, Loss: 0.3715, Train: 16.23%, Valid: 13.53%, Test: 13.00%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 200, Loss: 0.3715, Train: 24.73%, Valid: 21.06%, Test: 15.98%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 200, Loss: 0.3715, Train: 29.66%, Valid: 25.67%, Test: 19.87%\n",
      "---\n",
      "Hits@10\n",
      "Run 10:\n",
      "Highest Train: 20.75\n",
      "Highest Valid: 17.84\n",
      "  Final Train: 20.75\n",
      "   Final Test: 13.72\n",
      "Hits@20\n",
      "Run 10:\n",
      "Highest Train: 30.14\n",
      "Highest Valid: 26.38\n",
      "  Final Train: 30.14\n",
      "   Final Test: 19.49\n",
      "Hits@30\n",
      "Run 10:\n",
      "Highest Train: 32.98\n",
      "Highest Valid: 28.85\n",
      "  Final Train: 32.98\n",
      "   Final Test: 20.18\n",
      "Hits@10\n",
      "All runs:\n",
      "Highest Train: 18.69  1.66\n",
      "Highest Valid: 15.89  1.45\n",
      "  Final Train: 18.69  1.66\n",
      "   Final Test: 11.33  2.01\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Train: 26.14  2.01\n",
      "Highest Valid: 22.53  1.87\n",
      "  Final Train: 26.14  2.01\n",
      "   Final Test: 15.97  2.07\n",
      "Hits@30\n",
      "All runs:\n",
      "Highest Train: 30.27  2.01\n",
      "Highest Valid: 26.35  1.91\n",
      "  Final Train: 30.27  2.01\n",
      "   Final Test: 19.88  1.86\n"
     ]
    }
   ],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def train(predictor, x, edge_index, split_edge, optimizer, batch_size):\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(x[edge[0]], x[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(x[edge[0]], x[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(predictor, x, split_edge, evaluator, batch_size):\n",
    "    predictor.eval()\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (MLP)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    parser.add_argument('--num_layers', type=int, default=3)\n",
    "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--epochs', type=int, default=200)\n",
    "    parser.add_argument('--eval_steps', type=int, default=5)\n",
    "    parser.add_argument('--runs', type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "    data = dataset[0]\n",
    "    split_edge = dataset.get_edge_split()\n",
    "\n",
    "    # We randomly pick some training samples that we want to evaluate on:\n",
    "    torch.manual_seed(12345)\n",
    "    idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "    idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "    split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "    x = torch.load('embedding.pt', map_location='cpu').to(device)\n",
    "\n",
    "    predictor = LinkPredictor(x.size(-1), args.hidden_channels, 1,\n",
    "                              args.num_layers, args.dropout).to(device)\n",
    "\n",
    "    evaluator = Evaluator(name='ogbl-ddi')\n",
    "    Logger_Models_Models = {\n",
    "        'Hits@10': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@20': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@30': Logger_Models_Model(args.runs, args),\n",
    "    }\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        predictor.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(predictor.parameters(), lr=args.lr)\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(predictor, x, data.edge_index, split_edge, optimizer,\n",
    "                         args.batch_size)\n",
    "\n",
    "            if epoch % args.eval_steps == 0:\n",
    "                results = test(predictor, x, split_edge, evaluator,\n",
    "                               args.batch_size)\n",
    "                for key, result in results.items():\n",
    "                    Logger_Models_Models[key].add_result(run, result)\n",
    "\n",
    "                if epoch % args.log_steps == 0:\n",
    "                    for key, result in results.items():\n",
    "                        train_hits, valid_hits, test_hits = result\n",
    "                        print(key)\n",
    "                        print(f'Run: {run + 1:02d}, '\n",
    "                              f'Epoch: {epoch:02d}, '\n",
    "                              f'Loss: {loss:.4f}, '\n",
    "                              f'Train: {100 * train_hits:.2f}%, '\n",
    "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                              f'Test: {100 * test_hits:.2f}%')\n",
    "                    print('---')\n",
    "\n",
    "        for key in Logger_Models_Models.keys():\n",
    "            print(key)\n",
    "            Logger_Models_Models[key].print_statistics(run)\n",
    "\n",
    "    for key in Logger_Models_Models.keys():\n",
    "        print(key)\n",
    "        Logger_Models_Models[key].print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e0432",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6385d258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-06T05:48:34.970792Z",
     "start_time": "2022-07-06T05:48:34.952874Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a69fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T04:12:06.706543Z",
     "start_time": "2022-07-06T05:48:37.827914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(f='C:\\\\Users\\\\b04753yr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-30e704de-a8cc-40a4-8675-f15ec8e16fa1.json', device=0, log_steps=1, num_layers=3, hidden_channels=256, dropout=0.5, batch_size=65536, lr=0.01, epochs=200, eval_steps=5, runs=10)\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 1.3863, Train: 0.02%, Valid: 0.01%, Test: 0.01%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 1.3863, Train: 0.04%, Valid: 0.03%, Test: 0.02%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 1.3863, Train: 0.05%, Valid: 0.04%, Test: 0.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 10, Loss: 1.0024, Train: 0.68%, Valid: 0.61%, Test: 0.65%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 10, Loss: 1.0024, Train: 1.16%, Valid: 1.01%, Test: 1.26%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 10, Loss: 1.0024, Train: 1.47%, Valid: 1.32%, Test: 1.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 15, Loss: 0.7196, Train: 2.61%, Valid: 2.24%, Test: 2.44%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 15, Loss: 0.7196, Train: 3.30%, Valid: 2.91%, Test: 3.67%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 15, Loss: 0.7196, Train: 4.07%, Valid: 3.58%, Test: 4.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 20, Loss: 0.3725, Train: 15.34%, Valid: 13.37%, Test: 11.27%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 20, Loss: 0.3725, Train: 20.12%, Valid: 17.69%, Test: 14.63%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 20, Loss: 0.3725, Train: 24.81%, Valid: 21.87%, Test: 17.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 25, Loss: 0.2604, Train: 20.81%, Valid: 17.54%, Test: 13.39%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 25, Loss: 0.2604, Train: 27.60%, Valid: 23.46%, Test: 17.64%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 25, Loss: 0.2604, Train: 30.96%, Valid: 26.41%, Test: 20.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 30, Loss: 0.2137, Train: 23.30%, Valid: 18.76%, Test: 11.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 30, Loss: 0.2137, Train: 34.52%, Valid: 28.38%, Test: 16.54%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 30, Loss: 0.2137, Train: 39.98%, Valid: 33.15%, Test: 20.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 35, Loss: 0.1899, Train: 33.39%, Valid: 26.16%, Test: 12.55%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 35, Loss: 0.1899, Train: 38.36%, Valid: 30.35%, Test: 17.95%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 35, Loss: 0.1899, Train: 45.37%, Valid: 36.46%, Test: 23.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 40, Loss: 0.1735, Train: 41.83%, Valid: 31.80%, Test: 10.17%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 40, Loss: 0.1735, Train: 46.19%, Valid: 35.64%, Test: 19.19%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 40, Loss: 0.1735, Train: 52.25%, Valid: 41.03%, Test: 26.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 45, Loss: 0.1631, Train: 38.47%, Valid: 27.69%, Test: 9.28%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 45, Loss: 0.1631, Train: 49.50%, Valid: 37.00%, Test: 15.84%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 45, Loss: 0.1631, Train: 53.97%, Valid: 41.08%, Test: 22.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 50, Loss: 0.1531, Train: 45.55%, Valid: 31.65%, Test: 4.96%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 50, Loss: 0.1531, Train: 54.97%, Valid: 40.00%, Test: 12.51%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 50, Loss: 0.1531, Train: 57.09%, Valid: 41.92%, Test: 17.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 55, Loss: 0.1448, Train: 44.93%, Valid: 29.25%, Test: 5.77%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 55, Loss: 0.1448, Train: 54.75%, Valid: 37.83%, Test: 11.87%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 55, Loss: 0.1448, Train: 60.79%, Valid: 43.39%, Test: 16.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 60, Loss: 0.1397, Train: 39.22%, Valid: 23.11%, Test: 8.60%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 60, Loss: 0.1397, Train: 55.32%, Valid: 36.26%, Test: 12.16%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 60, Loss: 0.1397, Train: 59.73%, Valid: 40.28%, Test: 17.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 65, Loss: 0.1346, Train: 40.63%, Valid: 22.58%, Test: 3.53%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 65, Loss: 0.1346, Train: 57.32%, Valid: 36.22%, Test: 9.13%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 65, Loss: 0.1346, Train: 64.94%, Valid: 43.32%, Test: 16.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 70, Loss: 0.1298, Train: 46.90%, Valid: 26.07%, Test: 3.04%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 70, Loss: 0.1298, Train: 58.96%, Valid: 36.28%, Test: 7.51%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 70, Loss: 0.1298, Train: 66.85%, Valid: 43.96%, Test: 13.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 75, Loss: 0.1279, Train: 47.83%, Valid: 25.48%, Test: 2.80%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 75, Loss: 0.1279, Train: 58.46%, Valid: 34.18%, Test: 5.95%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 75, Loss: 0.1279, Train: 64.32%, Valid: 39.58%, Test: 13.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 80, Loss: 0.1250, Train: 47.94%, Valid: 23.91%, Test: 3.18%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 80, Loss: 0.1250, Train: 56.95%, Valid: 31.06%, Test: 6.70%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 80, Loss: 0.1250, Train: 64.78%, Valid: 38.06%, Test: 12.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 85, Loss: 0.1212, Train: 39.13%, Valid: 16.81%, Test: 3.88%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 85, Loss: 0.1212, Train: 60.67%, Valid: 32.77%, Test: 9.60%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 85, Loss: 0.1212, Train: 67.01%, Valid: 38.87%, Test: 16.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 90, Loss: 0.1195, Train: 45.44%, Valid: 19.94%, Test: 4.86%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 90, Loss: 0.1195, Train: 60.19%, Valid: 31.09%, Test: 7.39%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 90, Loss: 0.1195, Train: 67.79%, Valid: 38.28%, Test: 13.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 95, Loss: 0.1176, Train: 47.18%, Valid: 19.91%, Test: 4.57%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.1176, Train: 57.80%, Valid: 27.76%, Test: 10.55%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 95, Loss: 0.1176, Train: 65.97%, Valid: 34.89%, Test: 15.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 100, Loss: 0.1168, Train: 42.24%, Valid: 16.01%, Test: 3.33%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.1168, Train: 58.58%, Valid: 27.17%, Test: 12.38%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 100, Loss: 0.1168, Train: 65.50%, Valid: 33.13%, Test: 17.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 105, Loss: 0.1127, Train: 46.09%, Valid: 17.15%, Test: 3.87%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.1127, Train: 57.48%, Valid: 25.02%, Test: 10.62%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 105, Loss: 0.1127, Train: 64.90%, Valid: 31.31%, Test: 16.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 110, Loss: 0.1108, Train: 43.57%, Valid: 14.78%, Test: 4.88%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.1108, Train: 57.71%, Valid: 23.96%, Test: 13.48%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 110, Loss: 0.1108, Train: 67.40%, Valid: 32.30%, Test: 19.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 115, Loss: 0.1087, Train: 45.56%, Valid: 15.23%, Test: 3.16%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.1087, Train: 57.41%, Valid: 22.73%, Test: 9.46%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 115, Loss: 0.1087, Train: 69.19%, Valid: 32.78%, Test: 16.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 120, Loss: 0.1076, Train: 51.45%, Valid: 17.68%, Test: 4.07%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.1076, Train: 64.49%, Valid: 27.21%, Test: 14.63%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 120, Loss: 0.1076, Train: 72.50%, Valid: 34.79%, Test: 21.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 125, Loss: 0.1052, Train: 52.97%, Valid: 17.63%, Test: 4.23%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.1052, Train: 65.84%, Valid: 26.90%, Test: 6.87%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 125, Loss: 0.1052, Train: 75.52%, Valid: 36.62%, Test: 12.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 130, Loss: 0.1036, Train: 46.84%, Valid: 13.36%, Test: 1.69%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.1036, Train: 64.70%, Valid: 24.90%, Test: 9.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 130, Loss: 0.1036, Train: 75.85%, Valid: 35.94%, Test: 18.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 135, Loss: 0.1027, Train: 46.46%, Valid: 12.24%, Test: 2.37%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.1027, Train: 58.13%, Valid: 18.82%, Test: 7.68%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 135, Loss: 0.1027, Train: 69.21%, Valid: 27.56%, Test: 15.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 140, Loss: 0.1018, Train: 55.05%, Valid: 16.18%, Test: 7.22%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.1018, Train: 67.07%, Valid: 24.66%, Test: 14.26%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 140, Loss: 0.1018, Train: 73.70%, Valid: 30.82%, Test: 27.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 145, Loss: 0.0989, Train: 41.14%, Valid: 8.73%, Test: 3.17%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.0989, Train: 62.24%, Valid: 20.11%, Test: 10.78%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 145, Loss: 0.0989, Train: 69.86%, Valid: 26.27%, Test: 17.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 150, Loss: 0.0987, Train: 53.03%, Valid: 13.32%, Test: 4.48%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.0987, Train: 66.45%, Valid: 22.00%, Test: 10.59%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 150, Loss: 0.0987, Train: 74.96%, Valid: 29.88%, Test: 17.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 155, Loss: 0.0972, Train: 44.40%, Valid: 8.95%, Test: 2.26%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.0972, Train: 67.34%, Valid: 22.04%, Test: 7.37%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 155, Loss: 0.0972, Train: 75.90%, Valid: 30.15%, Test: 14.96%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 01, Epoch: 160, Loss: 0.0948, Train: 53.38%, Valid: 12.26%, Test: 4.75%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.0948, Train: 60.75%, Valid: 16.45%, Test: 9.24%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 160, Loss: 0.0948, Train: 75.59%, Valid: 28.59%, Test: 13.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 165, Loss: 0.0946, Train: 48.11%, Valid: 9.35%, Test: 7.44%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.0946, Train: 64.66%, Valid: 18.23%, Test: 12.03%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 165, Loss: 0.0946, Train: 75.46%, Valid: 27.47%, Test: 31.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 170, Loss: 0.0933, Train: 37.55%, Valid: 5.38%, Test: 3.87%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.0933, Train: 63.98%, Valid: 17.23%, Test: 11.39%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 170, Loss: 0.0933, Train: 75.81%, Valid: 27.16%, Test: 18.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 175, Loss: 0.0909, Train: 46.96%, Valid: 8.14%, Test: 4.70%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.0909, Train: 70.01%, Valid: 20.89%, Test: 10.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 175, Loss: 0.0909, Train: 79.46%, Valid: 30.49%, Test: 26.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 180, Loss: 0.0909, Train: 49.77%, Valid: 8.68%, Test: 4.99%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.0909, Train: 76.32%, Valid: 25.90%, Test: 10.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 180, Loss: 0.0909, Train: 83.01%, Valid: 34.58%, Test: 24.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 185, Loss: 0.0895, Train: 66.46%, Valid: 16.23%, Test: 5.69%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.0895, Train: 81.02%, Valid: 29.83%, Test: 9.65%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 185, Loss: 0.0895, Train: 84.57%, Valid: 35.25%, Test: 26.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 190, Loss: 0.0888, Train: 54.20%, Valid: 9.37%, Test: 3.44%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.0888, Train: 68.29%, Valid: 17.02%, Test: 10.38%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 190, Loss: 0.0888, Train: 77.24%, Valid: 24.60%, Test: 23.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 195, Loss: 0.0873, Train: 49.61%, Valid: 7.07%, Test: 5.70%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.0873, Train: 70.69%, Valid: 17.85%, Test: 13.44%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 195, Loss: 0.0873, Train: 76.68%, Valid: 22.96%, Test: 25.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 200, Loss: 0.0856, Train: 48.82%, Valid: 6.39%, Test: 2.40%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.0856, Train: 70.56%, Valid: 17.05%, Test: 7.79%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 200, Loss: 0.0856, Train: 80.28%, Valid: 26.22%, Test: 12.81%\n",
      "---\n",
      "Hits@10\n",
      "Run 01:\n",
      "Highest Train: 66.46\n",
      "Highest Valid: 31.80\n",
      "  Final Train: 41.83\n",
      "   Final Test: 10.17\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Train: 81.02\n",
      "Highest Valid: 40.00\n",
      "  Final Train: 54.97\n",
      "   Final Test: 12.51\n",
      "Hits@30\n",
      "Run 01:\n",
      "Highest Train: 84.57\n",
      "Highest Valid: 43.96\n",
      "  Final Train: 66.85\n",
      "   Final Test: 13.26\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 1.2252, Train: 0.06%, Valid: 0.07%, Test: 0.06%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 1.2252, Train: 0.13%, Valid: 0.12%, Test: 0.12%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 1.2252, Train: 0.17%, Valid: 0.18%, Test: 0.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 10, Loss: 0.8804, Train: 1.90%, Valid: 1.65%, Test: 1.46%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.8804, Train: 2.45%, Valid: 2.12%, Test: 1.95%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 10, Loss: 0.8804, Train: 3.15%, Valid: 2.76%, Test: 2.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 15, Loss: 0.5314, Train: 14.92%, Valid: 12.76%, Test: 9.72%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.5314, Train: 19.54%, Valid: 16.93%, Test: 13.10%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 15, Loss: 0.5314, Train: 23.51%, Valid: 20.44%, Test: 15.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 20, Loss: 0.3404, Train: 23.89%, Valid: 20.27%, Test: 9.79%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.3404, Train: 28.53%, Valid: 24.39%, Test: 14.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 20, Loss: 0.3404, Train: 31.62%, Valid: 27.16%, Test: 19.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 25, Loss: 0.2560, Train: 25.04%, Valid: 20.57%, Test: 9.38%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.2560, Train: 27.33%, Valid: 22.64%, Test: 15.54%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 25, Loss: 0.2560, Train: 31.25%, Valid: 25.94%, Test: 19.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 30, Loss: 0.2133, Train: 24.88%, Valid: 19.65%, Test: 6.93%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.2133, Train: 35.70%, Valid: 28.64%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 30, Loss: 0.2133, Train: 38.73%, Valid: 31.19%, Test: 18.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 35, Loss: 0.1886, Train: 28.19%, Valid: 21.51%, Test: 12.52%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.1886, Train: 37.29%, Valid: 29.02%, Test: 16.07%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 35, Loss: 0.1886, Train: 43.08%, Valid: 33.79%, Test: 19.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 40, Loss: 0.1714, Train: 29.51%, Valid: 21.78%, Test: 11.34%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.1714, Train: 41.86%, Valid: 31.57%, Test: 17.96%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 40, Loss: 0.1714, Train: 45.88%, Valid: 34.96%, Test: 20.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 45, Loss: 0.1600, Train: 31.93%, Valid: 22.94%, Test: 11.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.1600, Train: 44.90%, Valid: 33.17%, Test: 16.07%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 45, Loss: 0.1600, Train: 49.29%, Valid: 36.63%, Test: 20.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 50, Loss: 0.1516, Train: 39.94%, Valid: 27.99%, Test: 10.71%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.1516, Train: 46.50%, Valid: 33.26%, Test: 17.55%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 50, Loss: 0.1516, Train: 53.92%, Valid: 39.15%, Test: 20.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 55, Loss: 0.1443, Train: 38.75%, Valid: 26.11%, Test: 8.71%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.1443, Train: 45.45%, Valid: 31.18%, Test: 16.43%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 55, Loss: 0.1443, Train: 53.70%, Valid: 37.70%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 60, Loss: 0.1376, Train: 41.35%, Valid: 27.07%, Test: 9.65%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.1376, Train: 52.49%, Valid: 35.59%, Test: 15.90%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 60, Loss: 0.1376, Train: 58.42%, Valid: 40.31%, Test: 19.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 65, Loss: 0.1328, Train: 38.32%, Valid: 23.32%, Test: 4.74%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.1328, Train: 49.92%, Valid: 31.89%, Test: 13.72%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 65, Loss: 0.1328, Train: 57.34%, Valid: 37.64%, Test: 17.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 70, Loss: 0.1277, Train: 31.36%, Valid: 17.51%, Test: 6.46%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.1277, Train: 52.45%, Valid: 32.29%, Test: 14.64%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 70, Loss: 0.1277, Train: 58.65%, Valid: 37.09%, Test: 18.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 75, Loss: 0.1235, Train: 30.18%, Valid: 15.95%, Test: 7.60%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.1235, Train: 42.77%, Valid: 24.11%, Test: 11.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 75, Loss: 0.1235, Train: 60.63%, Valid: 37.50%, Test: 19.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 80, Loss: 0.1196, Train: 25.95%, Valid: 12.56%, Test: 6.01%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.1196, Train: 42.93%, Valid: 23.27%, Test: 13.04%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 80, Loss: 0.1196, Train: 59.99%, Valid: 35.76%, Test: 21.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 85, Loss: 0.1154, Train: 29.30%, Valid: 13.64%, Test: 6.92%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.1154, Train: 39.93%, Valid: 20.33%, Test: 11.98%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 85, Loss: 0.1154, Train: 58.29%, Valid: 33.11%, Test: 21.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 90, Loss: 0.1131, Train: 25.99%, Valid: 11.18%, Test: 9.73%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.1131, Train: 41.11%, Valid: 20.22%, Test: 14.29%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 90, Loss: 0.1131, Train: 56.75%, Valid: 31.08%, Test: 23.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 95, Loss: 0.1093, Train: 27.20%, Valid: 11.08%, Test: 8.35%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.1093, Train: 40.98%, Valid: 18.88%, Test: 15.45%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 95, Loss: 0.1093, Train: 50.39%, Valid: 25.00%, Test: 23.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 100, Loss: 0.1057, Train: 27.20%, Valid: 10.70%, Test: 8.36%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.1057, Train: 42.61%, Valid: 19.39%, Test: 19.15%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 100, Loss: 0.1057, Train: 62.65%, Valid: 32.81%, Test: 28.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 105, Loss: 0.1023, Train: 32.69%, Valid: 13.18%, Test: 7.66%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.1023, Train: 45.64%, Valid: 20.56%, Test: 17.85%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 105, Loss: 0.1023, Train: 65.17%, Valid: 33.86%, Test: 26.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 110, Loss: 0.1007, Train: 29.25%, Valid: 10.79%, Test: 10.61%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.1007, Train: 49.31%, Valid: 22.08%, Test: 21.56%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 110, Loss: 0.1007, Train: 64.16%, Valid: 32.24%, Test: 29.43%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 02, Epoch: 115, Loss: 0.0998, Train: 42.15%, Valid: 17.26%, Test: 7.13%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.0998, Train: 55.56%, Valid: 25.50%, Test: 18.76%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 115, Loss: 0.0998, Train: 64.17%, Valid: 31.52%, Test: 28.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 120, Loss: 0.0968, Train: 34.40%, Valid: 12.24%, Test: 7.50%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.0968, Train: 49.57%, Valid: 20.77%, Test: 22.76%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 120, Loss: 0.0968, Train: 62.55%, Valid: 29.29%, Test: 29.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 125, Loss: 0.0944, Train: 34.42%, Valid: 11.72%, Test: 4.28%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.0944, Train: 53.76%, Valid: 22.63%, Test: 14.18%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 125, Loss: 0.0944, Train: 63.94%, Valid: 29.51%, Test: 29.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 130, Loss: 0.0921, Train: 30.60%, Valid: 9.44%, Test: 6.73%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.0921, Train: 51.80%, Valid: 20.73%, Test: 19.45%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 130, Loss: 0.0921, Train: 64.80%, Valid: 29.17%, Test: 30.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 135, Loss: 0.0910, Train: 32.60%, Valid: 10.01%, Test: 7.13%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.0910, Train: 48.42%, Valid: 18.18%, Test: 24.47%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 135, Loss: 0.0910, Train: 66.03%, Valid: 29.85%, Test: 32.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 140, Loss: 0.0887, Train: 34.82%, Valid: 10.89%, Test: 5.44%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.0887, Train: 53.65%, Valid: 20.94%, Test: 16.38%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 140, Loss: 0.0887, Train: 69.59%, Valid: 31.73%, Test: 27.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 145, Loss: 0.0867, Train: 33.67%, Valid: 9.80%, Test: 8.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.0867, Train: 55.69%, Valid: 21.46%, Test: 22.95%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 145, Loss: 0.0867, Train: 71.10%, Valid: 32.00%, Test: 31.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 150, Loss: 0.0856, Train: 43.68%, Valid: 14.36%, Test: 6.25%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.0856, Train: 59.23%, Valid: 23.31%, Test: 18.22%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 150, Loss: 0.0856, Train: 71.22%, Valid: 31.73%, Test: 28.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 155, Loss: 0.0842, Train: 51.60%, Valid: 18.42%, Test: 7.00%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.0842, Train: 61.79%, Valid: 24.66%, Test: 19.78%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 155, Loss: 0.0842, Train: 74.90%, Valid: 34.24%, Test: 27.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 160, Loss: 0.0830, Train: 36.17%, Valid: 10.15%, Test: 10.14%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.0830, Train: 57.78%, Valid: 21.36%, Test: 26.16%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 160, Loss: 0.0830, Train: 71.91%, Valid: 31.12%, Test: 30.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 165, Loss: 0.0812, Train: 38.03%, Valid: 10.66%, Test: 5.43%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.0812, Train: 57.87%, Valid: 21.03%, Test: 19.99%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 165, Loss: 0.0812, Train: 73.30%, Valid: 31.71%, Test: 28.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 170, Loss: 0.0802, Train: 35.82%, Valid: 9.21%, Test: 5.91%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.0802, Train: 49.19%, Valid: 15.66%, Test: 23.57%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 170, Loss: 0.0802, Train: 70.14%, Valid: 28.84%, Test: 28.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 175, Loss: 0.0787, Train: 32.94%, Valid: 7.77%, Test: 4.93%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.0787, Train: 62.65%, Valid: 22.99%, Test: 21.85%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 175, Loss: 0.0787, Train: 74.90%, Valid: 31.72%, Test: 29.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 180, Loss: 0.0788, Train: 44.08%, Valid: 12.21%, Test: 7.63%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.0788, Train: 56.19%, Valid: 18.54%, Test: 22.68%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 180, Loss: 0.0788, Train: 69.57%, Valid: 27.29%, Test: 28.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 185, Loss: 0.0768, Train: 34.40%, Valid: 7.84%, Test: 9.13%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.0768, Train: 61.73%, Valid: 21.45%, Test: 21.64%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 185, Loss: 0.0768, Train: 66.87%, Valid: 24.79%, Test: 27.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 190, Loss: 0.0751, Train: 36.81%, Valid: 8.62%, Test: 9.41%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.0751, Train: 53.88%, Valid: 16.53%, Test: 25.32%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 190, Loss: 0.0751, Train: 64.72%, Valid: 22.99%, Test: 27.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 195, Loss: 0.0752, Train: 47.28%, Valid: 12.86%, Test: 8.12%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.0752, Train: 61.67%, Valid: 20.53%, Test: 18.88%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 195, Loss: 0.0752, Train: 70.18%, Valid: 26.21%, Test: 27.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 200, Loss: 0.0745, Train: 45.32%, Valid: 11.67%, Test: 11.34%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.0745, Train: 63.22%, Valid: 21.37%, Test: 25.84%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 200, Loss: 0.0745, Train: 74.95%, Valid: 29.61%, Test: 27.65%\n",
      "---\n",
      "Hits@10\n",
      "Run 02:\n",
      "Highest Train: 51.60\n",
      "Highest Valid: 27.99\n",
      "  Final Train: 39.94\n",
      "   Final Test: 10.71\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Train: 63.22\n",
      "Highest Valid: 35.59\n",
      "  Final Train: 52.49\n",
      "   Final Test: 15.90\n",
      "Hits@30\n",
      "Run 02:\n",
      "Highest Train: 74.95\n",
      "Highest Valid: 40.31\n",
      "  Final Train: 58.42\n",
      "   Final Test: 19.86\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 1.3070, Train: 0.03%, Valid: 0.05%, Test: 0.04%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 1.3070, Train: 0.07%, Valid: 0.08%, Test: 0.07%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 1.3070, Train: 0.10%, Valid: 0.12%, Test: 0.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 10, Loss: 0.8616, Train: 1.49%, Valid: 1.26%, Test: 2.43%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 10, Loss: 0.8616, Train: 2.11%, Valid: 1.84%, Test: 3.23%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 10, Loss: 0.8616, Train: 2.95%, Valid: 2.59%, Test: 3.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 15, Loss: 0.4718, Train: 13.90%, Valid: 11.85%, Test: 7.48%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 15, Loss: 0.4718, Train: 18.20%, Valid: 15.72%, Test: 13.87%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 15, Loss: 0.4718, Train: 22.77%, Valid: 20.04%, Test: 17.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 20, Loss: 0.2987, Train: 16.52%, Valid: 13.87%, Test: 7.45%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 20, Loss: 0.2987, Train: 25.21%, Valid: 21.42%, Test: 18.85%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 20, Loss: 0.2987, Train: 28.90%, Valid: 24.85%, Test: 22.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 25, Loss: 0.2295, Train: 14.81%, Valid: 11.90%, Test: 9.61%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 25, Loss: 0.2295, Train: 24.44%, Valid: 19.99%, Test: 17.77%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 25, Loss: 0.2295, Train: 31.68%, Valid: 26.20%, Test: 22.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 30, Loss: 0.1962, Train: 19.04%, Valid: 14.88%, Test: 8.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 30, Loss: 0.1962, Train: 29.36%, Valid: 23.15%, Test: 17.15%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 30, Loss: 0.1962, Train: 35.11%, Valid: 27.90%, Test: 20.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 35, Loss: 0.1760, Train: 20.62%, Valid: 15.44%, Test: 10.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 35, Loss: 0.1760, Train: 35.51%, Valid: 27.14%, Test: 18.14%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 35, Loss: 0.1760, Train: 42.50%, Valid: 32.79%, Test: 21.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 40, Loss: 0.1618, Train: 30.54%, Valid: 22.08%, Test: 9.54%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 40, Loss: 0.1618, Train: 38.05%, Valid: 27.89%, Test: 13.99%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 40, Loss: 0.1618, Train: 47.06%, Valid: 35.22%, Test: 19.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 45, Loss: 0.1521, Train: 32.34%, Valid: 22.16%, Test: 6.72%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 45, Loss: 0.1521, Train: 48.28%, Valid: 34.75%, Test: 11.34%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 45, Loss: 0.1521, Train: 57.13%, Valid: 42.22%, Test: 19.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 50, Loss: 0.1440, Train: 32.18%, Valid: 20.57%, Test: 5.10%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 50, Loss: 0.1440, Train: 45.95%, Valid: 31.27%, Test: 11.13%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 50, Loss: 0.1440, Train: 54.98%, Valid: 38.80%, Test: 18.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 55, Loss: 0.1365, Train: 33.43%, Valid: 20.01%, Test: 4.76%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 55, Loss: 0.1365, Train: 47.00%, Valid: 30.30%, Test: 11.20%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 55, Loss: 0.1365, Train: 57.96%, Valid: 39.62%, Test: 15.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 60, Loss: 0.1318, Train: 40.90%, Valid: 24.14%, Test: 4.45%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 60, Loss: 0.1318, Train: 52.02%, Valid: 32.96%, Test: 11.86%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 60, Loss: 0.1318, Train: 61.16%, Valid: 40.84%, Test: 18.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 65, Loss: 0.1269, Train: 45.66%, Valid: 26.30%, Test: 2.70%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 65, Loss: 0.1269, Train: 54.53%, Valid: 33.34%, Test: 6.82%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 65, Loss: 0.1269, Train: 61.50%, Valid: 39.30%, Test: 17.96%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 03, Epoch: 70, Loss: 0.1236, Train: 35.16%, Valid: 17.64%, Test: 3.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 70, Loss: 0.1236, Train: 50.99%, Valid: 28.96%, Test: 12.65%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 70, Loss: 0.1236, Train: 59.92%, Valid: 36.22%, Test: 19.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 75, Loss: 0.1191, Train: 40.00%, Valid: 19.66%, Test: 6.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 75, Loss: 0.1191, Train: 50.57%, Valid: 27.31%, Test: 15.68%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 75, Loss: 0.1191, Train: 60.08%, Valid: 34.98%, Test: 25.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 80, Loss: 0.1162, Train: 44.45%, Valid: 21.57%, Test: 5.62%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 80, Loss: 0.1162, Train: 53.76%, Valid: 28.37%, Test: 13.07%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 80, Loss: 0.1162, Train: 57.66%, Valid: 31.47%, Test: 21.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 85, Loss: 0.1130, Train: 48.00%, Valid: 23.06%, Test: 6.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 85, Loss: 0.1130, Train: 58.78%, Valid: 31.27%, Test: 13.39%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 85, Loss: 0.1130, Train: 63.91%, Valid: 35.66%, Test: 26.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 90, Loss: 0.1098, Train: 38.53%, Valid: 15.86%, Test: 6.18%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 90, Loss: 0.1098, Train: 52.46%, Valid: 24.98%, Test: 13.65%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 90, Loss: 0.1098, Train: 60.86%, Valid: 31.62%, Test: 21.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 95, Loss: 0.1079, Train: 46.18%, Valid: 19.58%, Test: 4.83%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 95, Loss: 0.1079, Train: 56.61%, Valid: 26.71%, Test: 9.75%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 95, Loss: 0.1079, Train: 65.50%, Valid: 34.07%, Test: 18.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 100, Loss: 0.1037, Train: 41.98%, Valid: 16.15%, Test: 6.89%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 100, Loss: 0.1037, Train: 52.22%, Valid: 22.61%, Test: 13.08%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 100, Loss: 0.1037, Train: 64.29%, Valid: 31.85%, Test: 23.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 105, Loss: 0.1029, Train: 35.99%, Valid: 12.12%, Test: 8.16%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 105, Loss: 0.1029, Train: 50.42%, Valid: 20.31%, Test: 14.32%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 105, Loss: 0.1029, Train: 59.30%, Valid: 26.51%, Test: 23.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 110, Loss: 0.1012, Train: 39.46%, Valid: 13.16%, Test: 9.15%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 110, Loss: 0.1012, Train: 55.47%, Valid: 22.74%, Test: 14.47%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 110, Loss: 0.1012, Train: 67.14%, Valid: 32.13%, Test: 35.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 115, Loss: 0.0988, Train: 38.08%, Valid: 11.88%, Test: 8.55%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 115, Loss: 0.0988, Train: 52.87%, Valid: 20.36%, Test: 14.68%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 115, Loss: 0.0988, Train: 68.03%, Valid: 31.89%, Test: 27.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 120, Loss: 0.0977, Train: 37.00%, Valid: 10.80%, Test: 5.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 120, Loss: 0.0977, Train: 53.68%, Valid: 20.10%, Test: 16.31%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 120, Loss: 0.0977, Train: 61.81%, Valid: 25.91%, Test: 27.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 125, Loss: 0.0961, Train: 40.88%, Valid: 12.00%, Test: 8.10%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 125, Loss: 0.0961, Train: 58.97%, Valid: 22.90%, Test: 18.40%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 125, Loss: 0.0961, Train: 66.48%, Valid: 28.79%, Test: 30.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 130, Loss: 0.0940, Train: 40.06%, Valid: 11.16%, Test: 7.23%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 130, Loss: 0.0940, Train: 58.71%, Valid: 22.06%, Test: 15.85%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 130, Loss: 0.0940, Train: 69.54%, Valid: 30.54%, Test: 33.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 135, Loss: 0.0924, Train: 42.49%, Valid: 11.79%, Test: 5.26%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 135, Loss: 0.0924, Train: 56.83%, Valid: 20.02%, Test: 15.15%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 135, Loss: 0.0924, Train: 65.24%, Valid: 26.20%, Test: 27.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 140, Loss: 0.0911, Train: 43.52%, Valid: 11.94%, Test: 11.38%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 140, Loss: 0.0911, Train: 61.13%, Valid: 22.30%, Test: 25.24%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 140, Loss: 0.0911, Train: 67.70%, Valid: 27.35%, Test: 37.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 145, Loss: 0.0892, Train: 42.63%, Valid: 11.00%, Test: 15.14%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 145, Loss: 0.0892, Train: 60.09%, Valid: 20.92%, Test: 26.97%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 145, Loss: 0.0892, Train: 70.55%, Valid: 29.05%, Test: 36.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 150, Loss: 0.0893, Train: 43.04%, Valid: 10.61%, Test: 9.51%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 150, Loss: 0.0893, Train: 55.90%, Valid: 17.53%, Test: 30.31%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 150, Loss: 0.0893, Train: 67.33%, Valid: 25.53%, Test: 39.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 155, Loss: 0.0876, Train: 38.45%, Valid: 8.29%, Test: 13.05%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 155, Loss: 0.0876, Train: 57.25%, Valid: 17.84%, Test: 30.61%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 155, Loss: 0.0876, Train: 69.53%, Valid: 26.78%, Test: 34.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 160, Loss: 0.0854, Train: 37.73%, Valid: 7.62%, Test: 12.32%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 160, Loss: 0.0854, Train: 60.28%, Valid: 19.20%, Test: 27.37%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 160, Loss: 0.0854, Train: 68.96%, Valid: 25.69%, Test: 36.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 165, Loss: 0.0845, Train: 40.13%, Valid: 8.29%, Test: 12.24%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 165, Loss: 0.0845, Train: 56.78%, Valid: 16.38%, Test: 25.71%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 165, Loss: 0.0845, Train: 68.37%, Valid: 24.57%, Test: 32.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 170, Loss: 0.0834, Train: 45.22%, Valid: 10.17%, Test: 8.65%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 170, Loss: 0.0834, Train: 61.11%, Valid: 18.70%, Test: 22.54%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 170, Loss: 0.0834, Train: 71.96%, Valid: 26.89%, Test: 31.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 175, Loss: 0.0834, Train: 39.21%, Valid: 7.38%, Test: 7.62%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 175, Loss: 0.0834, Train: 60.80%, Valid: 18.23%, Test: 21.69%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 175, Loss: 0.0834, Train: 70.98%, Valid: 25.84%, Test: 31.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 180, Loss: 0.0810, Train: 48.95%, Valid: 11.13%, Test: 10.59%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 180, Loss: 0.0810, Train: 64.95%, Valid: 20.51%, Test: 20.80%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 180, Loss: 0.0810, Train: 72.74%, Valid: 26.68%, Test: 30.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 185, Loss: 0.0808, Train: 51.70%, Valid: 12.24%, Test: 8.29%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 185, Loss: 0.0808, Train: 65.60%, Valid: 20.63%, Test: 22.12%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 185, Loss: 0.0808, Train: 75.25%, Valid: 28.44%, Test: 31.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 190, Loss: 0.0792, Train: 52.36%, Valid: 12.20%, Test: 7.51%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 190, Loss: 0.0792, Train: 63.66%, Valid: 18.82%, Test: 16.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 190, Loss: 0.0792, Train: 71.44%, Valid: 24.61%, Test: 24.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 195, Loss: 0.0787, Train: 46.88%, Valid: 9.65%, Test: 9.17%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 195, Loss: 0.0787, Train: 69.97%, Valid: 23.29%, Test: 19.62%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 195, Loss: 0.0787, Train: 77.45%, Valid: 29.62%, Test: 28.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 200, Loss: 0.0772, Train: 51.72%, Valid: 11.53%, Test: 11.22%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 200, Loss: 0.0772, Train: 66.93%, Valid: 20.43%, Test: 20.59%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 200, Loss: 0.0772, Train: 78.26%, Valid: 29.70%, Test: 28.12%\n",
      "---\n",
      "Hits@10\n",
      "Run 03:\n",
      "Highest Train: 52.36\n",
      "Highest Valid: 26.30\n",
      "  Final Train: 45.66\n",
      "   Final Test: 2.70\n",
      "Hits@20\n",
      "Run 03:\n",
      "Highest Train: 69.97\n",
      "Highest Valid: 34.75\n",
      "  Final Train: 48.28\n",
      "   Final Test: 11.34\n",
      "Hits@30\n",
      "Run 03:\n",
      "Highest Train: 78.26\n",
      "Highest Valid: 42.22\n",
      "  Final Train: 57.13\n",
      "   Final Test: 19.03\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 1.3439, Train: 0.31%, Valid: 0.24%, Test: 0.25%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 1.3439, Train: 0.53%, Valid: 0.43%, Test: 0.40%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 1.3439, Train: 0.70%, Valid: 0.57%, Test: 0.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 10, Loss: 0.9156, Train: 1.76%, Valid: 1.53%, Test: 2.61%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 10, Loss: 0.9156, Train: 2.40%, Valid: 2.11%, Test: 3.67%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 10, Loss: 0.9156, Train: 2.87%, Valid: 2.50%, Test: 4.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 15, Loss: 0.5770, Train: 11.55%, Valid: 9.88%, Test: 9.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 15, Loss: 0.5770, Train: 17.13%, Valid: 14.79%, Test: 14.61%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 15, Loss: 0.5770, Train: 20.65%, Valid: 17.93%, Test: 17.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 20, Loss: 0.3600, Train: 15.21%, Valid: 12.75%, Test: 6.64%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 20, Loss: 0.3600, Train: 21.13%, Valid: 18.01%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 20, Loss: 0.3600, Train: 27.75%, Valid: 23.92%, Test: 19.96%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 25, Loss: 0.2694, Train: 12.44%, Valid: 9.99%, Test: 8.12%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 25, Loss: 0.2694, Train: 22.24%, Valid: 18.33%, Test: 18.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 25, Loss: 0.2694, Train: 30.77%, Valid: 25.91%, Test: 23.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 30, Loss: 0.2238, Train: 17.11%, Valid: 13.28%, Test: 7.33%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 30, Loss: 0.2238, Train: 28.80%, Valid: 22.93%, Test: 19.29%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 30, Loss: 0.2238, Train: 36.88%, Valid: 29.82%, Test: 22.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 35, Loss: 0.1939, Train: 25.12%, Valid: 18.71%, Test: 10.54%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 35, Loss: 0.1939, Train: 33.93%, Valid: 25.94%, Test: 21.63%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 35, Loss: 0.1939, Train: 46.83%, Valid: 36.93%, Test: 25.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 40, Loss: 0.1762, Train: 24.79%, Valid: 16.93%, Test: 7.52%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 40, Loss: 0.1762, Train: 37.32%, Valid: 26.90%, Test: 13.61%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 40, Loss: 0.1762, Train: 42.01%, Valid: 30.78%, Test: 17.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 45, Loss: 0.1625, Train: 25.15%, Valid: 15.81%, Test: 5.46%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 45, Loss: 0.1625, Train: 38.43%, Valid: 26.03%, Test: 9.66%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 45, Loss: 0.1625, Train: 45.42%, Valid: 31.81%, Test: 14.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 50, Loss: 0.1535, Train: 28.56%, Valid: 16.80%, Test: 3.75%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 50, Loss: 0.1535, Train: 39.90%, Valid: 25.31%, Test: 8.65%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 50, Loss: 0.1535, Train: 47.94%, Valid: 32.06%, Test: 10.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 55, Loss: 0.1461, Train: 30.04%, Valid: 16.53%, Test: 4.54%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 55, Loss: 0.1461, Train: 45.45%, Valid: 27.98%, Test: 7.49%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 55, Loss: 0.1461, Train: 54.82%, Valid: 36.05%, Test: 10.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 60, Loss: 0.1410, Train: 34.45%, Valid: 18.14%, Test: 3.06%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 60, Loss: 0.1410, Train: 49.55%, Valid: 29.30%, Test: 6.50%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 60, Loss: 0.1410, Train: 56.46%, Valid: 35.47%, Test: 9.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 65, Loss: 0.1369, Train: 32.55%, Valid: 15.62%, Test: 3.64%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 65, Loss: 0.1369, Train: 48.08%, Valid: 26.55%, Test: 6.26%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 65, Loss: 0.1369, Train: 53.15%, Valid: 30.59%, Test: 11.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 70, Loss: 0.1320, Train: 28.99%, Valid: 12.34%, Test: 3.48%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 70, Loss: 0.1320, Train: 43.26%, Valid: 21.38%, Test: 8.31%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 70, Loss: 0.1320, Train: 54.99%, Valid: 30.36%, Test: 16.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 75, Loss: 0.1281, Train: 27.68%, Valid: 10.57%, Test: 2.27%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 75, Loss: 0.1281, Train: 41.54%, Valid: 18.71%, Test: 9.18%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 75, Loss: 0.1281, Train: 56.08%, Valid: 29.18%, Test: 17.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 80, Loss: 0.1250, Train: 31.97%, Valid: 11.73%, Test: 3.66%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 80, Loss: 0.1250, Train: 44.17%, Valid: 18.86%, Test: 8.45%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 80, Loss: 0.1250, Train: 54.05%, Valid: 25.76%, Test: 23.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 85, Loss: 0.1217, Train: 28.38%, Valid: 9.13%, Test: 2.73%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 85, Loss: 0.1217, Train: 43.44%, Valid: 17.24%, Test: 11.21%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 85, Loss: 0.1217, Train: 56.15%, Valid: 25.96%, Test: 20.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 90, Loss: 0.1188, Train: 24.70%, Valid: 6.78%, Test: 2.65%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 90, Loss: 0.1188, Train: 45.80%, Valid: 17.33%, Test: 11.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 90, Loss: 0.1188, Train: 58.31%, Valid: 25.98%, Test: 18.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 95, Loss: 0.1163, Train: 30.91%, Valid: 8.60%, Test: 8.23%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 95, Loss: 0.1163, Train: 47.15%, Valid: 16.86%, Test: 18.49%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 95, Loss: 0.1163, Train: 54.30%, Valid: 21.57%, Test: 22.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 100, Loss: 0.1136, Train: 33.19%, Valid: 8.72%, Test: 7.90%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 100, Loss: 0.1136, Train: 49.18%, Valid: 16.64%, Test: 15.09%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 100, Loss: 0.1136, Train: 61.71%, Valid: 25.52%, Test: 22.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 105, Loss: 0.1122, Train: 30.33%, Valid: 6.86%, Test: 5.05%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 105, Loss: 0.1122, Train: 47.23%, Valid: 14.50%, Test: 20.24%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 105, Loss: 0.1122, Train: 62.37%, Valid: 24.42%, Test: 39.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 110, Loss: 0.1094, Train: 34.11%, Valid: 7.74%, Test: 5.15%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 110, Loss: 0.1094, Train: 51.21%, Valid: 15.74%, Test: 14.55%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 110, Loss: 0.1094, Train: 65.78%, Valid: 26.18%, Test: 29.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 115, Loss: 0.1077, Train: 40.05%, Valid: 9.43%, Test: 7.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 115, Loss: 0.1077, Train: 56.30%, Valid: 17.87%, Test: 22.77%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 115, Loss: 0.1077, Train: 66.83%, Valid: 25.93%, Test: 32.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 120, Loss: 0.1049, Train: 33.46%, Valid: 6.32%, Test: 5.94%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 120, Loss: 0.1049, Train: 60.82%, Valid: 19.70%, Test: 18.63%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 120, Loss: 0.1049, Train: 65.65%, Valid: 23.44%, Test: 25.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 125, Loss: 0.1041, Train: 29.90%, Valid: 4.73%, Test: 5.71%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 125, Loss: 0.1041, Train: 54.78%, Valid: 14.80%, Test: 14.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 125, Loss: 0.1041, Train: 68.88%, Valid: 25.25%, Test: 25.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 130, Loss: 0.1016, Train: 35.38%, Valid: 5.82%, Test: 3.99%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 130, Loss: 0.1016, Train: 51.02%, Valid: 11.94%, Test: 9.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 130, Loss: 0.1016, Train: 62.55%, Valid: 18.71%, Test: 21.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 135, Loss: 0.1000, Train: 37.92%, Valid: 6.13%, Test: 5.40%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 135, Loss: 0.1000, Train: 55.62%, Valid: 13.57%, Test: 13.18%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 135, Loss: 0.1000, Train: 68.26%, Valid: 22.28%, Test: 21.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 140, Loss: 0.0983, Train: 40.14%, Valid: 6.41%, Test: 6.31%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 140, Loss: 0.0983, Train: 54.12%, Valid: 12.03%, Test: 12.85%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 140, Loss: 0.0983, Train: 65.84%, Valid: 19.39%, Test: 25.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 145, Loss: 0.0967, Train: 39.93%, Valid: 5.89%, Test: 3.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 145, Loss: 0.0967, Train: 55.77%, Valid: 12.01%, Test: 9.86%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 145, Loss: 0.0967, Train: 67.11%, Valid: 19.35%, Test: 16.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 150, Loss: 0.0959, Train: 39.62%, Valid: 5.27%, Test: 3.56%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 150, Loss: 0.0959, Train: 55.62%, Valid: 11.20%, Test: 7.92%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 150, Loss: 0.0959, Train: 71.66%, Valid: 22.51%, Test: 11.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 155, Loss: 0.0931, Train: 45.88%, Valid: 6.78%, Test: 3.81%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 155, Loss: 0.0931, Train: 56.40%, Valid: 11.04%, Test: 9.86%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 155, Loss: 0.0931, Train: 73.33%, Valid: 23.36%, Test: 15.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 160, Loss: 0.0911, Train: 40.39%, Valid: 4.83%, Test: 6.13%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 160, Loss: 0.0911, Train: 62.01%, Valid: 13.62%, Test: 11.57%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 160, Loss: 0.0911, Train: 73.52%, Valid: 22.66%, Test: 17.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 165, Loss: 0.0905, Train: 41.58%, Valid: 4.84%, Test: 7.67%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 165, Loss: 0.0905, Train: 64.93%, Valid: 14.65%, Test: 11.69%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 165, Loss: 0.0905, Train: 71.78%, Valid: 20.04%, Test: 20.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 170, Loss: 0.0888, Train: 57.89%, Valid: 10.13%, Test: 7.18%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 170, Loss: 0.0888, Train: 71.04%, Valid: 18.59%, Test: 12.30%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 170, Loss: 0.0888, Train: 79.62%, Valid: 28.44%, Test: 28.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 175, Loss: 0.0866, Train: 50.83%, Valid: 6.82%, Test: 7.22%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 175, Loss: 0.0866, Train: 70.58%, Valid: 17.47%, Test: 12.84%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 175, Loss: 0.0866, Train: 78.72%, Valid: 26.31%, Test: 27.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 180, Loss: 0.0863, Train: 53.88%, Valid: 7.61%, Test: 9.65%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 180, Loss: 0.0863, Train: 74.24%, Valid: 20.41%, Test: 20.21%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 180, Loss: 0.0863, Train: 82.34%, Valid: 31.34%, Test: 40.35%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 185, Loss: 0.0852, Train: 55.30%, Valid: 7.73%, Test: 6.98%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 185, Loss: 0.0852, Train: 72.18%, Valid: 17.63%, Test: 16.01%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 185, Loss: 0.0852, Train: 80.21%, Valid: 26.99%, Test: 21.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 190, Loss: 0.0834, Train: 54.48%, Valid: 7.01%, Test: 7.38%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 190, Loss: 0.0834, Train: 73.02%, Valid: 17.68%, Test: 13.75%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 190, Loss: 0.0834, Train: 79.63%, Valid: 25.16%, Test: 32.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 195, Loss: 0.0826, Train: 53.09%, Valid: 6.29%, Test: 10.85%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 195, Loss: 0.0826, Train: 73.94%, Valid: 18.20%, Test: 18.54%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 195, Loss: 0.0826, Train: 78.46%, Valid: 23.24%, Test: 36.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 200, Loss: 0.0815, Train: 53.95%, Valid: 6.14%, Test: 11.25%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 200, Loss: 0.0815, Train: 74.14%, Valid: 17.51%, Test: 20.91%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 200, Loss: 0.0815, Train: 82.12%, Valid: 27.33%, Test: 37.62%\n",
      "---\n",
      "Hits@10\n",
      "Run 04:\n",
      "Highest Train: 57.89\n",
      "Highest Valid: 18.71\n",
      "  Final Train: 25.12\n",
      "   Final Test: 10.54\n",
      "Hits@20\n",
      "Run 04:\n",
      "Highest Train: 74.24\n",
      "Highest Valid: 29.30\n",
      "  Final Train: 49.55\n",
      "   Final Test: 6.50\n",
      "Hits@30\n",
      "Run 04:\n",
      "Highest Train: 82.34\n",
      "Highest Valid: 36.93\n",
      "  Final Train: 46.83\n",
      "   Final Test: 25.96\n",
      "Hits@10\n",
      "Run: 05, Epoch: 05, Loss: 1.2328, Train: 0.05%, Valid: 0.04%, Test: 0.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 05, Loss: 1.2328, Train: 0.08%, Valid: 0.07%, Test: 0.05%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 05, Loss: 1.2328, Train: 0.11%, Valid: 0.10%, Test: 0.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 10, Loss: 0.8684, Train: 1.85%, Valid: 1.61%, Test: 2.69%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 10, Loss: 0.8684, Train: 2.39%, Valid: 2.12%, Test: 3.73%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 10, Loss: 0.8684, Train: 2.98%, Valid: 2.62%, Test: 4.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 15, Loss: 0.5429, Train: 13.63%, Valid: 11.49%, Test: 8.62%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 15, Loss: 0.5429, Train: 17.75%, Valid: 15.18%, Test: 15.58%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 15, Loss: 0.5429, Train: 20.19%, Valid: 17.51%, Test: 17.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 20, Loss: 0.3320, Train: 21.31%, Valid: 18.16%, Test: 8.56%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 20, Loss: 0.3320, Train: 27.72%, Valid: 24.09%, Test: 17.47%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 20, Loss: 0.3320, Train: 30.39%, Valid: 26.43%, Test: 22.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 25, Loss: 0.2477, Train: 22.47%, Valid: 18.64%, Test: 8.48%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 25, Loss: 0.2477, Train: 28.58%, Valid: 23.83%, Test: 12.54%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 25, Loss: 0.2477, Train: 33.11%, Valid: 27.82%, Test: 16.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 30, Loss: 0.2063, Train: 23.55%, Valid: 18.81%, Test: 7.97%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 30, Loss: 0.2063, Train: 33.72%, Valid: 27.25%, Test: 11.34%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 30, Loss: 0.2063, Train: 36.45%, Valid: 29.49%, Test: 14.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 35, Loss: 0.1839, Train: 28.57%, Valid: 22.12%, Test: 7.43%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 35, Loss: 0.1839, Train: 35.82%, Valid: 27.95%, Test: 11.39%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 35, Loss: 0.1839, Train: 42.59%, Valid: 33.49%, Test: 15.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 40, Loss: 0.1692, Train: 30.90%, Valid: 23.14%, Test: 6.46%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 40, Loss: 0.1692, Train: 40.04%, Valid: 30.34%, Test: 10.55%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 40, Loss: 0.1692, Train: 43.09%, Valid: 32.79%, Test: 14.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 45, Loss: 0.1584, Train: 35.97%, Valid: 26.12%, Test: 6.90%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 45, Loss: 0.1584, Train: 42.18%, Valid: 30.86%, Test: 11.51%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 45, Loss: 0.1584, Train: 45.44%, Valid: 33.52%, Test: 14.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 50, Loss: 0.1490, Train: 36.58%, Valid: 25.61%, Test: 5.63%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 50, Loss: 0.1490, Train: 46.25%, Valid: 32.96%, Test: 10.80%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 50, Loss: 0.1490, Train: 52.99%, Valid: 38.12%, Test: 14.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 55, Loss: 0.1426, Train: 33.63%, Valid: 21.89%, Test: 2.24%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 55, Loss: 0.1426, Train: 45.70%, Valid: 30.80%, Test: 6.56%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 55, Loss: 0.1426, Train: 50.79%, Valid: 34.68%, Test: 11.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 60, Loss: 0.1360, Train: 35.38%, Valid: 21.30%, Test: 2.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 60, Loss: 0.1360, Train: 45.99%, Valid: 29.04%, Test: 8.26%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 60, Loss: 0.1360, Train: 52.58%, Valid: 34.14%, Test: 12.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 65, Loss: 0.1313, Train: 39.15%, Valid: 22.89%, Test: 3.04%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 65, Loss: 0.1313, Train: 47.77%, Valid: 29.21%, Test: 8.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 65, Loss: 0.1313, Train: 54.16%, Valid: 34.07%, Test: 14.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 70, Loss: 0.1255, Train: 41.08%, Valid: 22.67%, Test: 5.79%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 70, Loss: 0.1255, Train: 50.09%, Valid: 29.11%, Test: 9.32%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 70, Loss: 0.1255, Train: 57.62%, Valid: 34.96%, Test: 16.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 75, Loss: 0.1207, Train: 31.68%, Valid: 15.18%, Test: 6.61%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 75, Loss: 0.1207, Train: 41.21%, Valid: 21.25%, Test: 11.48%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 75, Loss: 0.1207, Train: 49.11%, Valid: 26.84%, Test: 19.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 80, Loss: 0.1188, Train: 37.09%, Valid: 17.50%, Test: 5.17%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 80, Loss: 0.1188, Train: 49.89%, Valid: 26.00%, Test: 13.06%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 80, Loss: 0.1188, Train: 58.74%, Valid: 32.59%, Test: 22.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 85, Loss: 0.1146, Train: 31.70%, Valid: 13.86%, Test: 3.22%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 85, Loss: 0.1146, Train: 49.77%, Valid: 25.26%, Test: 12.67%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 85, Loss: 0.1146, Train: 60.23%, Valid: 33.16%, Test: 27.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 90, Loss: 0.1119, Train: 33.89%, Valid: 14.27%, Test: 3.70%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 90, Loss: 0.1119, Train: 50.25%, Valid: 24.71%, Test: 10.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 90, Loss: 0.1119, Train: 56.69%, Valid: 29.18%, Test: 17.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 95, Loss: 0.1092, Train: 30.80%, Valid: 11.87%, Test: 4.58%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 95, Loss: 0.1092, Train: 46.52%, Valid: 20.90%, Test: 14.03%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 95, Loss: 0.1092, Train: 56.21%, Valid: 27.49%, Test: 26.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 100, Loss: 0.1064, Train: 31.51%, Valid: 11.57%, Test: 3.67%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 100, Loss: 0.1064, Train: 50.18%, Valid: 22.39%, Test: 9.10%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 100, Loss: 0.1064, Train: 57.28%, Valid: 27.39%, Test: 21.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 105, Loss: 0.1032, Train: 38.92%, Valid: 15.49%, Test: 5.24%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 105, Loss: 0.1032, Train: 57.59%, Valid: 27.34%, Test: 12.11%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 105, Loss: 0.1032, Train: 66.58%, Valid: 34.02%, Test: 29.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 110, Loss: 0.1008, Train: 43.18%, Valid: 16.98%, Test: 5.08%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 110, Loss: 0.1008, Train: 56.08%, Valid: 24.88%, Test: 9.20%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 110, Loss: 0.1008, Train: 69.07%, Valid: 34.52%, Test: 18.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 115, Loss: 0.0982, Train: 39.97%, Valid: 14.98%, Test: 4.37%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 115, Loss: 0.0982, Train: 53.12%, Valid: 22.84%, Test: 12.13%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 115, Loss: 0.0982, Train: 64.11%, Valid: 30.33%, Test: 22.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 120, Loss: 0.0965, Train: 30.78%, Valid: 9.67%, Test: 8.80%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 120, Loss: 0.0965, Train: 59.55%, Valid: 25.85%, Test: 13.00%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 120, Loss: 0.0965, Train: 67.57%, Valid: 31.72%, Test: 20.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 125, Loss: 0.0948, Train: 33.24%, Valid: 10.32%, Test: 7.45%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 125, Loss: 0.0948, Train: 53.27%, Valid: 21.12%, Test: 12.44%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 125, Loss: 0.0948, Train: 65.26%, Valid: 29.09%, Test: 25.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 130, Loss: 0.0928, Train: 30.86%, Valid: 8.69%, Test: 5.59%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 130, Loss: 0.0928, Train: 52.03%, Valid: 19.50%, Test: 23.74%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 130, Loss: 0.0928, Train: 67.51%, Valid: 29.89%, Test: 35.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 135, Loss: 0.0901, Train: 31.87%, Valid: 9.13%, Test: 6.17%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 135, Loss: 0.0901, Train: 61.29%, Valid: 25.15%, Test: 13.60%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 135, Loss: 0.0901, Train: 73.38%, Valid: 33.97%, Test: 20.93%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 05, Epoch: 140, Loss: 0.0894, Train: 31.01%, Valid: 8.07%, Test: 5.30%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 140, Loss: 0.0894, Train: 53.15%, Valid: 18.97%, Test: 12.52%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 140, Loss: 0.0894, Train: 67.95%, Valid: 28.72%, Test: 29.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 145, Loss: 0.0878, Train: 38.53%, Valid: 11.43%, Test: 5.28%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 145, Loss: 0.0878, Train: 57.28%, Valid: 21.46%, Test: 10.51%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 145, Loss: 0.0878, Train: 72.88%, Valid: 32.25%, Test: 26.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 150, Loss: 0.0856, Train: 28.18%, Valid: 6.38%, Test: 4.38%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 150, Loss: 0.0856, Train: 50.40%, Valid: 16.53%, Test: 11.67%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 150, Loss: 0.0856, Train: 69.02%, Valid: 28.36%, Test: 20.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 155, Loss: 0.0852, Train: 36.52%, Valid: 10.16%, Test: 4.33%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 155, Loss: 0.0852, Train: 58.66%, Valid: 21.57%, Test: 12.06%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 155, Loss: 0.0852, Train: 71.01%, Valid: 29.84%, Test: 31.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 160, Loss: 0.0831, Train: 36.62%, Valid: 9.84%, Test: 7.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 160, Loss: 0.0831, Train: 67.33%, Valid: 26.61%, Test: 18.25%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 160, Loss: 0.0831, Train: 72.38%, Valid: 30.18%, Test: 31.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 165, Loss: 0.0819, Train: 42.56%, Valid: 11.84%, Test: 6.90%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 165, Loss: 0.0819, Train: 66.02%, Valid: 25.13%, Test: 24.92%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 165, Loss: 0.0819, Train: 75.00%, Valid: 31.61%, Test: 32.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 170, Loss: 0.0795, Train: 32.68%, Valid: 7.21%, Test: 5.33%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 170, Loss: 0.0795, Train: 62.79%, Valid: 22.37%, Test: 16.27%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 170, Loss: 0.0795, Train: 71.13%, Valid: 28.01%, Test: 28.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 175, Loss: 0.0797, Train: 42.51%, Valid: 10.99%, Test: 8.72%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 175, Loss: 0.0797, Train: 63.74%, Valid: 22.46%, Test: 19.13%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 175, Loss: 0.0797, Train: 78.11%, Valid: 32.88%, Test: 31.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 180, Loss: 0.0774, Train: 31.48%, Valid: 6.46%, Test: 3.60%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 180, Loss: 0.0774, Train: 63.74%, Valid: 22.09%, Test: 12.71%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 180, Loss: 0.0774, Train: 77.32%, Valid: 31.65%, Test: 25.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 185, Loss: 0.0779, Train: 39.49%, Valid: 9.46%, Test: 7.39%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 185, Loss: 0.0779, Train: 59.64%, Valid: 19.57%, Test: 21.01%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 185, Loss: 0.0779, Train: 74.70%, Valid: 29.45%, Test: 30.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 190, Loss: 0.0759, Train: 36.74%, Valid: 8.12%, Test: 8.13%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 190, Loss: 0.0759, Train: 58.33%, Valid: 18.18%, Test: 24.95%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 190, Loss: 0.0759, Train: 72.39%, Valid: 27.09%, Test: 30.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 195, Loss: 0.0747, Train: 34.74%, Valid: 6.94%, Test: 5.63%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 195, Loss: 0.0747, Train: 57.72%, Valid: 17.23%, Test: 15.20%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 195, Loss: 0.0747, Train: 78.96%, Valid: 31.36%, Test: 27.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 200, Loss: 0.0734, Train: 52.52%, Valid: 14.89%, Test: 5.75%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 200, Loss: 0.0734, Train: 71.03%, Valid: 25.63%, Test: 11.72%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 200, Loss: 0.0734, Train: 79.23%, Valid: 31.79%, Test: 24.87%\n",
      "---\n",
      "Hits@10\n",
      "Run 05:\n",
      "Highest Train: 52.52\n",
      "Highest Valid: 26.12\n",
      "  Final Train: 35.97\n",
      "   Final Test: 6.90\n",
      "Hits@20\n",
      "Run 05:\n",
      "Highest Train: 71.03\n",
      "Highest Valid: 32.96\n",
      "  Final Train: 46.25\n",
      "   Final Test: 10.80\n",
      "Hits@30\n",
      "Run 05:\n",
      "Highest Train: 79.23\n",
      "Highest Valid: 38.12\n",
      "  Final Train: 52.99\n",
      "   Final Test: 14.89\n",
      "Hits@10\n",
      "Run: 06, Epoch: 05, Loss: 1.3717, Train: 0.09%, Valid: 0.08%, Test: 0.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 05, Loss: 1.3717, Train: 0.18%, Valid: 0.16%, Test: 0.21%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 05, Loss: 1.3717, Train: 0.24%, Valid: 0.21%, Test: 0.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 10, Loss: 0.8373, Train: 1.29%, Valid: 1.12%, Test: 1.84%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 10, Loss: 0.8373, Train: 2.26%, Valid: 1.97%, Test: 3.13%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 10, Loss: 0.8373, Train: 2.96%, Valid: 2.63%, Test: 3.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 15, Loss: 0.4631, Train: 14.89%, Valid: 12.77%, Test: 12.67%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 15, Loss: 0.4631, Train: 18.11%, Valid: 15.60%, Test: 18.03%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 15, Loss: 0.4631, Train: 23.51%, Valid: 20.65%, Test: 20.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 20, Loss: 0.3010, Train: 15.80%, Valid: 13.09%, Test: 11.27%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 20, Loss: 0.3010, Train: 22.71%, Valid: 19.24%, Test: 19.46%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 20, Loss: 0.3010, Train: 28.24%, Valid: 24.03%, Test: 21.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 25, Loss: 0.2273, Train: 20.11%, Valid: 15.96%, Test: 7.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 25, Loss: 0.2273, Train: 31.91%, Valid: 25.82%, Test: 15.67%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 25, Loss: 0.2273, Train: 34.30%, Valid: 27.97%, Test: 21.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 30, Loss: 0.1905, Train: 23.79%, Valid: 17.71%, Test: 9.42%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 30, Loss: 0.1905, Train: 35.65%, Valid: 27.39%, Test: 18.72%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 30, Loss: 0.1905, Train: 41.48%, Valid: 32.34%, Test: 23.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 35, Loss: 0.1688, Train: 22.45%, Valid: 15.63%, Test: 13.89%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 35, Loss: 0.1688, Train: 37.60%, Valid: 27.46%, Test: 20.59%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 35, Loss: 0.1688, Train: 44.02%, Valid: 32.73%, Test: 27.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 40, Loss: 0.1566, Train: 27.76%, Valid: 17.73%, Test: 10.87%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 40, Loss: 0.1566, Train: 38.88%, Valid: 26.04%, Test: 15.76%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 40, Loss: 0.1566, Train: 48.40%, Valid: 33.67%, Test: 22.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 45, Loss: 0.1446, Train: 28.93%, Valid: 16.60%, Test: 6.22%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 45, Loss: 0.1446, Train: 41.39%, Valid: 25.53%, Test: 15.01%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 45, Loss: 0.1446, Train: 51.86%, Valid: 33.94%, Test: 18.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 50, Loss: 0.1361, Train: 32.23%, Valid: 17.31%, Test: 4.69%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 50, Loss: 0.1361, Train: 45.76%, Valid: 26.81%, Test: 11.52%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 50, Loss: 0.1361, Train: 53.25%, Valid: 32.75%, Test: 16.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 55, Loss: 0.1297, Train: 35.50%, Valid: 17.72%, Test: 3.07%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 55, Loss: 0.1297, Train: 48.66%, Valid: 26.94%, Test: 10.21%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 55, Loss: 0.1297, Train: 57.39%, Valid: 33.92%, Test: 18.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 60, Loss: 0.1248, Train: 40.80%, Valid: 19.79%, Test: 4.04%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 60, Loss: 0.1248, Train: 48.74%, Valid: 25.23%, Test: 13.29%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 60, Loss: 0.1248, Train: 59.26%, Valid: 33.41%, Test: 19.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 65, Loss: 0.1208, Train: 38.05%, Valid: 16.55%, Test: 5.34%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 65, Loss: 0.1208, Train: 50.50%, Valid: 24.74%, Test: 12.11%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 65, Loss: 0.1208, Train: 57.58%, Valid: 30.13%, Test: 16.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 70, Loss: 0.1152, Train: 39.88%, Valid: 16.40%, Test: 5.17%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 70, Loss: 0.1152, Train: 51.58%, Valid: 24.02%, Test: 15.94%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 70, Loss: 0.1152, Train: 61.98%, Valid: 32.09%, Test: 20.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 75, Loss: 0.1132, Train: 39.74%, Valid: 15.15%, Test: 6.10%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 75, Loss: 0.1132, Train: 46.98%, Valid: 19.60%, Test: 11.86%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 75, Loss: 0.1132, Train: 60.56%, Valid: 29.33%, Test: 19.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 80, Loss: 0.1088, Train: 46.09%, Valid: 17.81%, Test: 7.54%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 80, Loss: 0.1088, Train: 56.98%, Valid: 25.20%, Test: 13.16%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 80, Loss: 0.1088, Train: 64.77%, Valid: 31.23%, Test: 20.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 85, Loss: 0.1067, Train: 42.38%, Valid: 14.61%, Test: 5.69%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 85, Loss: 0.1067, Train: 57.59%, Valid: 24.10%, Test: 13.53%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 85, Loss: 0.1067, Train: 65.10%, Valid: 29.98%, Test: 22.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 90, Loss: 0.1044, Train: 44.48%, Valid: 14.80%, Test: 7.44%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 90, Loss: 0.1044, Train: 61.00%, Valid: 25.24%, Test: 13.78%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 90, Loss: 0.1044, Train: 68.56%, Valid: 31.38%, Test: 25.87%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 06, Epoch: 95, Loss: 0.1013, Train: 51.27%, Valid: 17.63%, Test: 5.55%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 95, Loss: 0.1013, Train: 60.79%, Valid: 23.85%, Test: 14.86%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 95, Loss: 0.1013, Train: 68.94%, Valid: 30.54%, Test: 21.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 100, Loss: 0.0986, Train: 52.81%, Valid: 17.67%, Test: 6.10%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 100, Loss: 0.0986, Train: 61.16%, Valid: 23.26%, Test: 17.36%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 100, Loss: 0.0986, Train: 70.52%, Valid: 30.88%, Test: 25.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 105, Loss: 0.0975, Train: 50.73%, Valid: 15.48%, Test: 7.11%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 105, Loss: 0.0975, Train: 63.37%, Valid: 23.57%, Test: 15.70%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 105, Loss: 0.0975, Train: 70.06%, Valid: 29.10%, Test: 26.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 110, Loss: 0.0948, Train: 53.53%, Valid: 16.27%, Test: 6.98%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 110, Loss: 0.0948, Train: 68.26%, Valid: 26.35%, Test: 18.53%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 110, Loss: 0.0948, Train: 75.24%, Valid: 32.81%, Test: 32.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 115, Loss: 0.0927, Train: 47.64%, Valid: 12.26%, Test: 10.76%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 115, Loss: 0.0927, Train: 67.21%, Valid: 24.31%, Test: 21.71%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 115, Loss: 0.0927, Train: 77.04%, Valid: 33.45%, Test: 36.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 120, Loss: 0.0914, Train: 47.04%, Valid: 11.37%, Test: 9.88%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 120, Loss: 0.0914, Train: 69.65%, Valid: 25.40%, Test: 20.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 120, Loss: 0.0914, Train: 79.72%, Valid: 35.20%, Test: 31.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 125, Loss: 0.0896, Train: 52.48%, Valid: 13.15%, Test: 12.37%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 125, Loss: 0.0896, Train: 74.71%, Valid: 28.83%, Test: 20.69%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 125, Loss: 0.0896, Train: 81.73%, Valid: 36.50%, Test: 34.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 130, Loss: 0.0876, Train: 57.03%, Valid: 15.06%, Test: 10.16%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 130, Loss: 0.0876, Train: 67.04%, Valid: 21.33%, Test: 21.10%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 130, Loss: 0.0876, Train: 79.17%, Valid: 32.12%, Test: 30.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 135, Loss: 0.0865, Train: 55.88%, Valid: 13.74%, Test: 9.32%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 135, Loss: 0.0865, Train: 69.52%, Valid: 22.37%, Test: 18.14%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 135, Loss: 0.0865, Train: 80.28%, Valid: 32.41%, Test: 31.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 140, Loss: 0.0845, Train: 59.74%, Valid: 15.12%, Test: 12.03%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 140, Loss: 0.0845, Train: 72.30%, Valid: 23.78%, Test: 26.15%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 140, Loss: 0.0845, Train: 78.03%, Valid: 28.96%, Test: 32.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 145, Loss: 0.0827, Train: 62.53%, Valid: 16.16%, Test: 6.99%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 145, Loss: 0.0827, Train: 74.97%, Valid: 25.11%, Test: 17.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 145, Loss: 0.0827, Train: 85.34%, Valid: 36.27%, Test: 34.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 150, Loss: 0.0820, Train: 63.67%, Valid: 16.10%, Test: 8.93%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 150, Loss: 0.0820, Train: 75.90%, Valid: 25.06%, Test: 19.38%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 150, Loss: 0.0820, Train: 83.30%, Valid: 32.67%, Test: 29.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 155, Loss: 0.0796, Train: 56.16%, Valid: 11.56%, Test: 12.00%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 155, Loss: 0.0796, Train: 70.93%, Valid: 20.39%, Test: 19.26%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 155, Loss: 0.0796, Train: 82.08%, Valid: 30.55%, Test: 31.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 160, Loss: 0.0786, Train: 60.90%, Valid: 13.44%, Test: 9.67%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 160, Loss: 0.0786, Train: 67.12%, Valid: 17.03%, Test: 18.59%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 160, Loss: 0.0786, Train: 75.13%, Valid: 23.01%, Test: 31.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 165, Loss: 0.0773, Train: 61.59%, Valid: 13.08%, Test: 6.90%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 165, Loss: 0.0773, Train: 70.44%, Valid: 18.43%, Test: 13.87%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 165, Loss: 0.0773, Train: 85.49%, Valid: 32.70%, Test: 28.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 170, Loss: 0.0751, Train: 59.39%, Valid: 11.71%, Test: 7.75%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 170, Loss: 0.0751, Train: 70.68%, Valid: 18.16%, Test: 20.12%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 170, Loss: 0.0751, Train: 80.73%, Valid: 26.69%, Test: 31.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 175, Loss: 0.0748, Train: 62.13%, Valid: 12.52%, Test: 10.31%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 175, Loss: 0.0748, Train: 76.92%, Valid: 22.66%, Test: 26.75%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 175, Loss: 0.0748, Train: 89.95%, Valid: 36.88%, Test: 32.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 180, Loss: 0.0741, Train: 66.99%, Valid: 14.60%, Test: 9.24%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 180, Loss: 0.0741, Train: 79.31%, Valid: 23.76%, Test: 21.94%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 180, Loss: 0.0741, Train: 92.17%, Valid: 38.90%, Test: 28.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 185, Loss: 0.0724, Train: 69.30%, Valid: 15.83%, Test: 10.98%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 185, Loss: 0.0724, Train: 79.03%, Valid: 23.14%, Test: 24.31%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 185, Loss: 0.0724, Train: 88.04%, Valid: 32.79%, Test: 30.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 190, Loss: 0.0714, Train: 67.41%, Valid: 14.02%, Test: 9.46%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 190, Loss: 0.0714, Train: 81.90%, Valid: 25.09%, Test: 25.68%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 190, Loss: 0.0714, Train: 93.16%, Valid: 38.27%, Test: 30.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 195, Loss: 0.0694, Train: 62.44%, Valid: 11.05%, Test: 9.67%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 195, Loss: 0.0694, Train: 83.66%, Valid: 26.50%, Test: 21.34%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 195, Loss: 0.0694, Train: 94.02%, Valid: 38.42%, Test: 28.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 200, Loss: 0.0696, Train: 62.65%, Valid: 10.84%, Test: 9.26%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 200, Loss: 0.0696, Train: 82.20%, Valid: 24.46%, Test: 18.44%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 200, Loss: 0.0696, Train: 92.38%, Valid: 35.94%, Test: 24.82%\n",
      "---\n",
      "Hits@10\n",
      "Run 06:\n",
      "Highest Train: 69.30\n",
      "Highest Valid: 19.79\n",
      "  Final Train: 40.80\n",
      "   Final Test: 4.04\n",
      "Hits@20\n",
      "Run 06:\n",
      "Highest Train: 83.66\n",
      "Highest Valid: 28.83\n",
      "  Final Train: 74.71\n",
      "   Final Test: 20.69\n",
      "Hits@30\n",
      "Run 06:\n",
      "Highest Train: 94.02\n",
      "Highest Valid: 38.90\n",
      "  Final Train: 92.17\n",
      "   Final Test: 28.26\n",
      "Hits@10\n",
      "Run: 07, Epoch: 05, Loss: 1.3089, Train: 0.51%, Valid: 0.42%, Test: 0.31%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 05, Loss: 1.3089, Train: 0.81%, Valid: 0.69%, Test: 0.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 05, Loss: 1.3089, Train: 1.03%, Valid: 0.88%, Test: 0.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 10, Loss: 0.8424, Train: 1.83%, Valid: 1.59%, Test: 1.74%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 10, Loss: 0.8424, Train: 2.38%, Valid: 2.11%, Test: 3.33%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 10, Loss: 0.8424, Train: 3.16%, Valid: 2.79%, Test: 4.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 15, Loss: 0.4762, Train: 17.58%, Valid: 15.35%, Test: 9.65%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 15, Loss: 0.4762, Train: 21.51%, Valid: 18.93%, Test: 16.60%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 15, Loss: 0.4762, Train: 24.96%, Valid: 22.12%, Test: 18.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 20, Loss: 0.3131, Train: 16.81%, Valid: 14.15%, Test: 5.92%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 20, Loss: 0.3131, Train: 21.59%, Valid: 18.35%, Test: 13.92%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 20, Loss: 0.3131, Train: 30.09%, Valid: 26.03%, Test: 19.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 25, Loss: 0.2399, Train: 20.10%, Valid: 16.08%, Test: 7.62%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 25, Loss: 0.2399, Train: 26.71%, Valid: 21.63%, Test: 14.44%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 25, Loss: 0.2399, Train: 33.18%, Valid: 27.18%, Test: 20.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 30, Loss: 0.2006, Train: 19.73%, Valid: 14.81%, Test: 6.89%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 30, Loss: 0.2006, Train: 32.12%, Valid: 24.75%, Test: 12.22%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 30, Loss: 0.2006, Train: 38.84%, Valid: 30.30%, Test: 20.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 35, Loss: 0.1771, Train: 28.18%, Valid: 19.73%, Test: 6.20%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 35, Loss: 0.1771, Train: 41.44%, Valid: 30.22%, Test: 10.31%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 35, Loss: 0.1771, Train: 47.54%, Valid: 35.16%, Test: 14.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 40, Loss: 0.1613, Train: 34.12%, Valid: 21.97%, Test: 3.36%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 40, Loss: 0.1613, Train: 43.91%, Valid: 29.56%, Test: 5.92%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 40, Loss: 0.1613, Train: 53.15%, Valid: 37.31%, Test: 9.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 45, Loss: 0.1499, Train: 38.38%, Valid: 22.64%, Test: 2.79%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 45, Loss: 0.1499, Train: 51.06%, Valid: 32.68%, Test: 6.13%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 45, Loss: 0.1499, Train: 56.17%, Valid: 37.10%, Test: 9.26%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 07, Epoch: 50, Loss: 0.1418, Train: 45.47%, Valid: 25.95%, Test: 2.98%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 50, Loss: 0.1418, Train: 54.91%, Valid: 33.60%, Test: 8.37%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 50, Loss: 0.1418, Train: 60.97%, Valid: 39.10%, Test: 10.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 55, Loss: 0.1355, Train: 39.35%, Valid: 19.46%, Test: 1.61%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 55, Loss: 0.1355, Train: 55.58%, Valid: 31.87%, Test: 7.45%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 55, Loss: 0.1355, Train: 63.77%, Valid: 39.37%, Test: 13.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 60, Loss: 0.1313, Train: 47.04%, Valid: 23.13%, Test: 2.26%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 60, Loss: 0.1313, Train: 56.84%, Valid: 30.74%, Test: 9.46%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 60, Loss: 0.1313, Train: 65.48%, Valid: 38.70%, Test: 19.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 65, Loss: 0.1264, Train: 42.31%, Valid: 18.37%, Test: 1.82%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 65, Loss: 0.1264, Train: 55.48%, Valid: 27.76%, Test: 6.74%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 65, Loss: 0.1264, Train: 67.18%, Valid: 38.33%, Test: 19.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 70, Loss: 0.1234, Train: 47.25%, Valid: 19.68%, Test: 1.58%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 70, Loss: 0.1234, Train: 62.34%, Valid: 31.31%, Test: 6.44%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 70, Loss: 0.1234, Train: 67.32%, Valid: 36.12%, Test: 14.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 75, Loss: 0.1192, Train: 44.62%, Valid: 16.79%, Test: 2.29%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 75, Loss: 0.1192, Train: 57.15%, Valid: 25.23%, Test: 8.06%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 75, Loss: 0.1192, Train: 65.45%, Valid: 32.18%, Test: 15.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 80, Loss: 0.1155, Train: 45.06%, Valid: 15.79%, Test: 2.89%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 80, Loss: 0.1155, Train: 60.37%, Valid: 26.07%, Test: 10.42%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 80, Loss: 0.1155, Train: 69.71%, Valid: 34.55%, Test: 14.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 85, Loss: 0.1119, Train: 52.66%, Valid: 18.81%, Test: 2.28%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 85, Loss: 0.1119, Train: 66.35%, Valid: 29.26%, Test: 12.38%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 85, Loss: 0.1119, Train: 70.49%, Valid: 33.23%, Test: 18.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 90, Loss: 0.1103, Train: 42.34%, Valid: 12.04%, Test: 2.86%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 90, Loss: 0.1103, Train: 59.61%, Valid: 22.25%, Test: 10.27%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 90, Loss: 0.1103, Train: 71.19%, Valid: 32.13%, Test: 15.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 95, Loss: 0.1075, Train: 47.63%, Valid: 13.72%, Test: 1.06%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 95, Loss: 0.1075, Train: 59.80%, Valid: 21.14%, Test: 5.57%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 95, Loss: 0.1075, Train: 72.17%, Valid: 31.60%, Test: 12.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 100, Loss: 0.1046, Train: 56.57%, Valid: 17.32%, Test: 2.61%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 100, Loss: 0.1046, Train: 67.54%, Valid: 25.29%, Test: 9.77%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 100, Loss: 0.1046, Train: 77.25%, Valid: 35.34%, Test: 23.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 105, Loss: 0.1022, Train: 57.86%, Valid: 17.03%, Test: 2.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 105, Loss: 0.1022, Train: 68.02%, Valid: 24.38%, Test: 9.71%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 105, Loss: 0.1022, Train: 74.43%, Valid: 30.64%, Test: 20.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 110, Loss: 0.0998, Train: 56.62%, Valid: 15.35%, Test: 5.04%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 110, Loss: 0.0998, Train: 70.74%, Valid: 25.79%, Test: 14.39%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 110, Loss: 0.0998, Train: 75.33%, Valid: 30.39%, Test: 23.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 115, Loss: 0.0985, Train: 63.47%, Valid: 18.51%, Test: 2.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 115, Loss: 0.0985, Train: 70.85%, Valid: 24.45%, Test: 11.51%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 115, Loss: 0.0985, Train: 75.39%, Valid: 28.87%, Test: 19.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 120, Loss: 0.0957, Train: 60.46%, Valid: 15.66%, Test: 2.01%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 120, Loss: 0.0957, Train: 74.53%, Valid: 26.72%, Test: 8.87%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 120, Loss: 0.0957, Train: 81.73%, Valid: 35.74%, Test: 19.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 125, Loss: 0.0939, Train: 62.69%, Valid: 16.11%, Test: 9.81%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 125, Loss: 0.0939, Train: 73.58%, Valid: 24.55%, Test: 18.19%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 125, Loss: 0.0939, Train: 80.87%, Valid: 32.80%, Test: 33.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 130, Loss: 0.0919, Train: 56.92%, Valid: 11.98%, Test: 3.30%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 130, Loss: 0.0919, Train: 72.08%, Valid: 21.95%, Test: 13.13%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 130, Loss: 0.0919, Train: 79.04%, Valid: 29.21%, Test: 33.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 135, Loss: 0.0900, Train: 67.56%, Valid: 17.36%, Test: 5.92%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 135, Loss: 0.0900, Train: 76.96%, Valid: 25.76%, Test: 13.46%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 135, Loss: 0.0900, Train: 81.32%, Valid: 31.06%, Test: 27.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 140, Loss: 0.0892, Train: 70.88%, Valid: 19.06%, Test: 9.48%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 140, Loss: 0.0892, Train: 77.77%, Valid: 25.58%, Test: 15.15%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 140, Loss: 0.0892, Train: 83.34%, Valid: 32.76%, Test: 24.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 145, Loss: 0.0872, Train: 65.80%, Valid: 14.43%, Test: 8.32%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 145, Loss: 0.0872, Train: 77.57%, Valid: 24.00%, Test: 16.98%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 145, Loss: 0.0872, Train: 82.45%, Valid: 30.10%, Test: 24.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 150, Loss: 0.0848, Train: 71.90%, Valid: 18.19%, Test: 4.54%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 150, Loss: 0.0848, Train: 77.44%, Valid: 23.39%, Test: 15.79%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 150, Loss: 0.0848, Train: 83.99%, Valid: 31.74%, Test: 27.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 155, Loss: 0.0832, Train: 70.69%, Valid: 16.31%, Test: 7.60%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 155, Loss: 0.0832, Train: 79.59%, Valid: 24.58%, Test: 18.69%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 155, Loss: 0.0832, Train: 84.61%, Valid: 31.33%, Test: 34.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 160, Loss: 0.0815, Train: 70.69%, Valid: 15.43%, Test: 2.81%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 160, Loss: 0.0815, Train: 79.65%, Valid: 23.46%, Test: 13.74%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 160, Loss: 0.0815, Train: 84.71%, Valid: 30.09%, Test: 28.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 165, Loss: 0.0806, Train: 68.41%, Valid: 13.15%, Test: 8.89%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 165, Loss: 0.0806, Train: 80.94%, Valid: 24.09%, Test: 19.88%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 165, Loss: 0.0806, Train: 86.42%, Valid: 31.48%, Test: 35.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 170, Loss: 0.0800, Train: 72.50%, Valid: 15.46%, Test: 14.83%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 170, Loss: 0.0800, Train: 82.69%, Valid: 25.48%, Test: 31.65%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 170, Loss: 0.0800, Train: 88.24%, Valid: 33.67%, Test: 36.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 175, Loss: 0.0785, Train: 70.51%, Valid: 13.53%, Test: 4.50%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 175, Loss: 0.0785, Train: 83.44%, Valid: 25.85%, Test: 13.08%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 175, Loss: 0.0785, Train: 87.16%, Valid: 31.27%, Test: 26.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 180, Loss: 0.0769, Train: 74.89%, Valid: 16.18%, Test: 7.53%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 180, Loss: 0.0769, Train: 81.92%, Valid: 23.26%, Test: 14.31%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 180, Loss: 0.0769, Train: 87.48%, Valid: 31.20%, Test: 32.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 185, Loss: 0.0753, Train: 68.59%, Valid: 11.19%, Test: 7.55%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 185, Loss: 0.0753, Train: 83.44%, Valid: 24.14%, Test: 19.22%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 185, Loss: 0.0753, Train: 88.06%, Valid: 31.01%, Test: 32.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 190, Loss: 0.0743, Train: 70.70%, Valid: 12.05%, Test: 15.12%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 190, Loss: 0.0743, Train: 79.17%, Valid: 18.73%, Test: 30.52%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 190, Loss: 0.0743, Train: 85.93%, Valid: 27.04%, Test: 35.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 195, Loss: 0.0725, Train: 77.17%, Valid: 16.42%, Test: 6.13%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 195, Loss: 0.0725, Train: 84.21%, Valid: 24.08%, Test: 21.00%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 195, Loss: 0.0725, Train: 90.01%, Valid: 32.67%, Test: 32.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 200, Loss: 0.0722, Train: 75.48%, Valid: 14.27%, Test: 7.07%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 200, Loss: 0.0722, Train: 86.86%, Valid: 26.30%, Test: 27.96%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 200, Loss: 0.0722, Train: 90.73%, Valid: 32.36%, Test: 34.47%\n",
      "---\n",
      "Hits@10\n",
      "Run 07:\n",
      "Highest Train: 77.17\n",
      "Highest Valid: 25.95\n",
      "  Final Train: 45.47\n",
      "   Final Test: 2.98\n",
      "Hits@20\n",
      "Run 07:\n",
      "Highest Train: 86.86\n",
      "Highest Valid: 33.60\n",
      "  Final Train: 54.91\n",
      "   Final Test: 8.37\n",
      "Hits@30\n",
      "Run 07:\n",
      "Highest Train: 90.73\n",
      "Highest Valid: 39.37\n",
      "  Final Train: 63.77\n",
      "   Final Test: 13.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 05, Loss: 1.1602, Train: 0.12%, Valid: 0.12%, Test: 0.09%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 05, Loss: 1.1602, Train: 0.19%, Valid: 0.20%, Test: 0.19%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 05, Loss: 1.1602, Train: 0.27%, Valid: 0.27%, Test: 0.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 10, Loss: 0.8390, Train: 1.49%, Valid: 1.33%, Test: 2.67%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 10, Loss: 0.8390, Train: 2.30%, Valid: 2.03%, Test: 3.51%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 10, Loss: 0.8390, Train: 2.62%, Valid: 2.32%, Test: 4.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 15, Loss: 0.4829, Train: 14.17%, Valid: 12.29%, Test: 9.61%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 15, Loss: 0.4829, Train: 20.05%, Valid: 17.57%, Test: 13.92%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 15, Loss: 0.4829, Train: 22.62%, Valid: 20.03%, Test: 16.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 20, Loss: 0.3295, Train: 13.67%, Valid: 11.42%, Test: 9.16%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 20, Loss: 0.3295, Train: 21.93%, Valid: 18.47%, Test: 15.34%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 20, Loss: 0.3295, Train: 25.81%, Valid: 21.94%, Test: 19.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 25, Loss: 0.2510, Train: 19.62%, Valid: 15.79%, Test: 9.30%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 25, Loss: 0.2510, Train: 25.62%, Valid: 20.84%, Test: 13.71%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 25, Loss: 0.2510, Train: 32.00%, Valid: 26.31%, Test: 18.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 30, Loss: 0.2096, Train: 25.17%, Valid: 19.42%, Test: 8.48%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 30, Loss: 0.2096, Train: 34.79%, Valid: 27.44%, Test: 14.68%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 30, Loss: 0.2096, Train: 39.89%, Valid: 31.79%, Test: 17.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 35, Loss: 0.1851, Train: 29.58%, Valid: 22.08%, Test: 7.32%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 35, Loss: 0.1851, Train: 39.50%, Valid: 30.33%, Test: 13.15%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 35, Loss: 0.1851, Train: 43.61%, Valid: 33.79%, Test: 16.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 40, Loss: 0.1681, Train: 27.47%, Valid: 19.42%, Test: 7.88%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 40, Loss: 0.1681, Train: 46.23%, Valid: 34.51%, Test: 13.23%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 40, Loss: 0.1681, Train: 50.76%, Valid: 38.25%, Test: 18.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 45, Loss: 0.1570, Train: 29.27%, Valid: 19.59%, Test: 10.14%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 45, Loss: 0.1570, Train: 48.52%, Valid: 34.85%, Test: 17.36%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 45, Loss: 0.1570, Train: 56.59%, Valid: 41.60%, Test: 20.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 50, Loss: 0.1473, Train: 30.12%, Valid: 18.71%, Test: 7.43%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 50, Loss: 0.1473, Train: 45.27%, Valid: 30.31%, Test: 13.26%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 50, Loss: 0.1473, Train: 54.54%, Valid: 37.98%, Test: 17.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 55, Loss: 0.1388, Train: 33.47%, Valid: 19.73%, Test: 4.17%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 55, Loss: 0.1388, Train: 45.19%, Valid: 28.67%, Test: 8.74%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 55, Loss: 0.1388, Train: 57.28%, Valid: 38.44%, Test: 12.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 60, Loss: 0.1329, Train: 38.85%, Valid: 22.65%, Test: 3.41%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 60, Loss: 0.1329, Train: 49.70%, Valid: 30.98%, Test: 11.18%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 60, Loss: 0.1329, Train: 61.05%, Valid: 40.41%, Test: 16.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 65, Loss: 0.1271, Train: 33.75%, Valid: 17.63%, Test: 4.67%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 65, Loss: 0.1271, Train: 47.11%, Valid: 27.29%, Test: 12.07%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 65, Loss: 0.1271, Train: 59.25%, Valid: 36.96%, Test: 18.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 70, Loss: 0.1228, Train: 35.12%, Valid: 17.67%, Test: 3.22%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 70, Loss: 0.1228, Train: 51.59%, Valid: 29.27%, Test: 9.35%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 70, Loss: 0.1228, Train: 57.81%, Valid: 34.41%, Test: 17.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 75, Loss: 0.1188, Train: 38.59%, Valid: 18.85%, Test: 4.25%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 75, Loss: 0.1188, Train: 50.37%, Valid: 27.17%, Test: 9.31%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 75, Loss: 0.1188, Train: 57.22%, Valid: 32.49%, Test: 19.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 80, Loss: 0.1157, Train: 32.02%, Valid: 13.88%, Test: 6.93%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 80, Loss: 0.1157, Train: 45.07%, Valid: 22.26%, Test: 20.31%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 80, Loss: 0.1157, Train: 56.40%, Valid: 30.58%, Test: 25.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 85, Loss: 0.1122, Train: 31.30%, Valid: 12.74%, Test: 5.93%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 85, Loss: 0.1122, Train: 50.59%, Valid: 24.86%, Test: 16.48%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 85, Loss: 0.1122, Train: 60.28%, Valid: 32.45%, Test: 26.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 90, Loss: 0.1094, Train: 36.93%, Valid: 15.16%, Test: 7.76%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 90, Loss: 0.1094, Train: 52.57%, Valid: 25.30%, Test: 15.25%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 90, Loss: 0.1094, Train: 63.27%, Valid: 33.55%, Test: 24.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 95, Loss: 0.1065, Train: 40.48%, Valid: 16.55%, Test: 7.50%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 95, Loss: 0.1065, Train: 50.69%, Valid: 23.16%, Test: 13.14%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 95, Loss: 0.1065, Train: 65.60%, Valid: 34.53%, Test: 26.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 100, Loss: 0.1048, Train: 33.60%, Valid: 11.90%, Test: 8.81%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 100, Loss: 0.1048, Train: 50.12%, Valid: 21.68%, Test: 15.42%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 100, Loss: 0.1048, Train: 62.05%, Valid: 30.34%, Test: 24.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 105, Loss: 0.1011, Train: 36.37%, Valid: 12.83%, Test: 8.05%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 105, Loss: 0.1011, Train: 46.72%, Valid: 18.87%, Test: 15.77%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 105, Loss: 0.1011, Train: 59.08%, Valid: 27.03%, Test: 20.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 110, Loss: 0.1005, Train: 27.91%, Valid: 8.18%, Test: 6.27%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 110, Loss: 0.1005, Train: 45.01%, Valid: 16.91%, Test: 17.65%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 110, Loss: 0.1005, Train: 56.13%, Valid: 23.90%, Test: 25.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 115, Loss: 0.0970, Train: 38.76%, Valid: 12.57%, Test: 10.75%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 115, Loss: 0.0970, Train: 47.50%, Valid: 17.49%, Test: 19.84%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 115, Loss: 0.0970, Train: 65.02%, Valid: 29.49%, Test: 34.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 120, Loss: 0.0960, Train: 36.61%, Valid: 11.08%, Test: 9.53%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 120, Loss: 0.0960, Train: 52.73%, Valid: 19.95%, Test: 18.69%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 120, Loss: 0.0960, Train: 61.67%, Valid: 26.06%, Test: 25.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 125, Loss: 0.0939, Train: 37.97%, Valid: 11.23%, Test: 8.13%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 125, Loss: 0.0939, Train: 51.79%, Valid: 18.69%, Test: 17.87%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 125, Loss: 0.0939, Train: 64.94%, Valid: 27.70%, Test: 27.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 130, Loss: 0.0931, Train: 40.87%, Valid: 12.07%, Test: 12.16%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 130, Loss: 0.0931, Train: 54.93%, Valid: 19.83%, Test: 19.01%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 130, Loss: 0.0931, Train: 69.17%, Valid: 30.41%, Test: 29.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 135, Loss: 0.0902, Train: 41.25%, Valid: 11.70%, Test: 12.36%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 135, Loss: 0.0902, Train: 55.47%, Valid: 19.46%, Test: 25.73%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 135, Loss: 0.0902, Train: 69.91%, Valid: 30.00%, Test: 34.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 140, Loss: 0.0886, Train: 38.19%, Valid: 9.59%, Test: 9.62%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 140, Loss: 0.0886, Train: 50.83%, Valid: 15.83%, Test: 25.20%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 140, Loss: 0.0886, Train: 69.12%, Valid: 28.26%, Test: 34.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 145, Loss: 0.0874, Train: 35.78%, Valid: 8.31%, Test: 7.98%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 145, Loss: 0.0874, Train: 56.27%, Valid: 18.61%, Test: 20.43%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 145, Loss: 0.0874, Train: 70.65%, Valid: 29.06%, Test: 35.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 150, Loss: 0.0861, Train: 41.57%, Valid: 10.26%, Test: 8.46%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 150, Loss: 0.0861, Train: 54.45%, Valid: 16.70%, Test: 17.82%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 150, Loss: 0.0861, Train: 72.98%, Valid: 30.02%, Test: 31.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 155, Loss: 0.0860, Train: 45.74%, Valid: 11.54%, Test: 7.15%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 155, Loss: 0.0860, Train: 56.93%, Valid: 17.48%, Test: 20.70%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 155, Loss: 0.0860, Train: 71.17%, Valid: 27.61%, Test: 33.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 160, Loss: 0.0842, Train: 38.73%, Valid: 8.00%, Test: 9.91%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 160, Loss: 0.0842, Train: 57.00%, Valid: 16.78%, Test: 26.44%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 160, Loss: 0.0842, Train: 63.76%, Valid: 21.07%, Test: 37.15%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 165, Loss: 0.0821, Train: 47.60%, Valid: 11.36%, Test: 11.38%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 165, Loss: 0.0821, Train: 58.99%, Valid: 17.37%, Test: 26.95%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 165, Loss: 0.0821, Train: 67.55%, Valid: 23.01%, Test: 33.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 170, Loss: 0.0816, Train: 42.90%, Valid: 9.11%, Test: 6.82%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 170, Loss: 0.0816, Train: 62.45%, Valid: 19.09%, Test: 21.82%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 170, Loss: 0.0816, Train: 72.29%, Valid: 26.33%, Test: 30.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 175, Loss: 0.0793, Train: 48.44%, Valid: 11.02%, Test: 10.39%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 175, Loss: 0.0793, Train: 62.81%, Valid: 18.88%, Test: 24.59%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 175, Loss: 0.0793, Train: 75.90%, Valid: 28.84%, Test: 34.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 180, Loss: 0.0789, Train: 44.61%, Valid: 8.91%, Test: 9.97%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 180, Loss: 0.0789, Train: 65.36%, Valid: 19.59%, Test: 18.03%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 180, Loss: 0.0789, Train: 75.75%, Valid: 27.65%, Test: 29.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 185, Loss: 0.0779, Train: 53.90%, Valid: 12.50%, Test: 11.80%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 185, Loss: 0.0779, Train: 69.18%, Valid: 21.78%, Test: 20.94%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 185, Loss: 0.0779, Train: 80.40%, Valid: 31.43%, Test: 24.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 190, Loss: 0.0771, Train: 53.09%, Valid: 11.87%, Test: 6.65%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 190, Loss: 0.0771, Train: 64.38%, Valid: 18.04%, Test: 21.62%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 190, Loss: 0.0771, Train: 77.37%, Valid: 27.93%, Test: 30.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 195, Loss: 0.0756, Train: 56.73%, Valid: 13.40%, Test: 6.24%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 195, Loss: 0.0756, Train: 70.01%, Valid: 21.53%, Test: 21.28%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 195, Loss: 0.0756, Train: 81.64%, Valid: 31.57%, Test: 32.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 200, Loss: 0.0748, Train: 55.04%, Valid: 12.00%, Test: 11.21%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 200, Loss: 0.0748, Train: 71.43%, Valid: 21.78%, Test: 25.25%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 200, Loss: 0.0748, Train: 82.01%, Valid: 30.89%, Test: 31.94%\n",
      "---\n",
      "Hits@10\n",
      "Run 08:\n",
      "Highest Train: 56.73\n",
      "Highest Valid: 22.65\n",
      "  Final Train: 38.85\n",
      "   Final Test: 3.41\n",
      "Hits@20\n",
      "Run 08:\n",
      "Highest Train: 71.43\n",
      "Highest Valid: 34.85\n",
      "  Final Train: 48.52\n",
      "   Final Test: 17.36\n",
      "Hits@30\n",
      "Run 08:\n",
      "Highest Train: 82.01\n",
      "Highest Valid: 41.60\n",
      "  Final Train: 56.59\n",
      "   Final Test: 20.49\n",
      "Hits@10\n",
      "Run: 09, Epoch: 05, Loss: 1.1402, Train: 0.09%, Valid: 0.10%, Test: 0.07%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 05, Loss: 1.1402, Train: 0.16%, Valid: 0.14%, Test: 0.16%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 05, Loss: 1.1402, Train: 0.23%, Valid: 0.21%, Test: 0.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 10, Loss: 0.8538, Train: 1.60%, Valid: 1.43%, Test: 2.47%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 10, Loss: 0.8538, Train: 2.41%, Valid: 2.15%, Test: 3.33%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 10, Loss: 0.8538, Train: 3.20%, Valid: 2.81%, Test: 3.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 15, Loss: 0.5074, Train: 14.01%, Valid: 11.92%, Test: 12.24%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 15, Loss: 0.5074, Train: 20.61%, Valid: 17.72%, Test: 16.50%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 15, Loss: 0.5074, Train: 23.14%, Valid: 19.97%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 20, Loss: 0.3326, Train: 22.79%, Valid: 19.39%, Test: 14.90%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 20, Loss: 0.3326, Train: 28.52%, Valid: 24.64%, Test: 18.50%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 20, Loss: 0.3326, Train: 32.34%, Valid: 28.14%, Test: 22.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 25, Loss: 0.2526, Train: 22.20%, Valid: 18.47%, Test: 10.45%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 25, Loss: 0.2526, Train: 30.54%, Valid: 25.54%, Test: 13.94%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 25, Loss: 0.2526, Train: 34.14%, Valid: 28.64%, Test: 18.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 30, Loss: 0.2100, Train: 18.26%, Valid: 14.46%, Test: 6.76%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 30, Loss: 0.2100, Train: 30.21%, Valid: 24.34%, Test: 13.25%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 30, Loss: 0.2100, Train: 38.23%, Valid: 30.94%, Test: 18.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 35, Loss: 0.1866, Train: 26.81%, Valid: 20.83%, Test: 6.69%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 35, Loss: 0.1866, Train: 33.16%, Valid: 26.06%, Test: 11.81%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 35, Loss: 0.1866, Train: 37.29%, Valid: 29.42%, Test: 15.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 40, Loss: 0.1692, Train: 29.23%, Valid: 21.98%, Test: 4.93%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 40, Loss: 0.1692, Train: 39.24%, Valid: 29.88%, Test: 9.51%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 40, Loss: 0.1692, Train: 45.33%, Valid: 34.80%, Test: 13.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 45, Loss: 0.1596, Train: 38.41%, Valid: 28.14%, Test: 4.32%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 45, Loss: 0.1596, Train: 44.99%, Valid: 33.34%, Test: 10.63%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 45, Loss: 0.1596, Train: 49.30%, Valid: 36.89%, Test: 14.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 50, Loss: 0.1502, Train: 36.56%, Valid: 25.38%, Test: 5.88%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 50, Loss: 0.1502, Train: 49.13%, Valid: 35.25%, Test: 11.08%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 50, Loss: 0.1502, Train: 54.52%, Valid: 39.75%, Test: 14.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 55, Loss: 0.1423, Train: 31.54%, Valid: 19.99%, Test: 3.45%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 55, Loss: 0.1423, Train: 45.54%, Valid: 30.52%, Test: 8.70%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 55, Loss: 0.1423, Train: 53.76%, Valid: 36.95%, Test: 11.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 60, Loss: 0.1382, Train: 31.83%, Valid: 19.00%, Test: 3.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 60, Loss: 0.1382, Train: 46.26%, Valid: 29.38%, Test: 8.19%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 60, Loss: 0.1382, Train: 52.98%, Valid: 34.65%, Test: 13.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 65, Loss: 0.1318, Train: 37.37%, Valid: 21.97%, Test: 3.33%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 65, Loss: 0.1318, Train: 51.25%, Valid: 32.18%, Test: 5.61%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 65, Loss: 0.1318, Train: 59.50%, Valid: 38.79%, Test: 12.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 70, Loss: 0.1280, Train: 33.50%, Valid: 18.08%, Test: 2.68%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 70, Loss: 0.1280, Train: 49.14%, Valid: 29.01%, Test: 8.56%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 70, Loss: 0.1280, Train: 57.15%, Valid: 35.06%, Test: 14.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 75, Loss: 0.1232, Train: 30.25%, Valid: 14.81%, Test: 2.63%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 75, Loss: 0.1232, Train: 46.37%, Valid: 25.48%, Test: 8.66%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 75, Loss: 0.1232, Train: 55.00%, Valid: 31.75%, Test: 19.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 80, Loss: 0.1186, Train: 41.18%, Valid: 21.42%, Test: 2.45%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 80, Loss: 0.1186, Train: 50.40%, Valid: 27.75%, Test: 12.51%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 80, Loss: 0.1186, Train: 58.91%, Valid: 34.23%, Test: 21.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 85, Loss: 0.1152, Train: 41.99%, Valid: 21.05%, Test: 6.55%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 85, Loss: 0.1152, Train: 54.45%, Valid: 29.36%, Test: 13.95%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 85, Loss: 0.1152, Train: 61.15%, Valid: 34.65%, Test: 20.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 90, Loss: 0.1131, Train: 40.40%, Valid: 19.22%, Test: 5.49%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 90, Loss: 0.1131, Train: 54.26%, Valid: 28.33%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 90, Loss: 0.1131, Train: 59.23%, Valid: 31.96%, Test: 24.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 95, Loss: 0.1089, Train: 35.44%, Valid: 15.41%, Test: 5.48%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 95, Loss: 0.1089, Train: 55.15%, Valid: 27.87%, Test: 14.50%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 95, Loss: 0.1089, Train: 65.25%, Valid: 35.41%, Test: 25.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 100, Loss: 0.1058, Train: 39.65%, Valid: 17.49%, Test: 6.35%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 100, Loss: 0.1058, Train: 57.14%, Valid: 28.71%, Test: 14.10%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 100, Loss: 0.1058, Train: 63.76%, Valid: 33.49%, Test: 25.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 105, Loss: 0.1040, Train: 42.79%, Valid: 18.02%, Test: 4.15%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 105, Loss: 0.1040, Train: 54.03%, Valid: 25.07%, Test: 12.82%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 105, Loss: 0.1040, Train: 63.62%, Valid: 31.84%, Test: 21.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 110, Loss: 0.1016, Train: 48.24%, Valid: 20.77%, Test: 5.68%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 110, Loss: 0.1016, Train: 58.70%, Valid: 27.38%, Test: 16.18%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 110, Loss: 0.1016, Train: 64.81%, Valid: 31.78%, Test: 22.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 115, Loss: 0.0994, Train: 40.95%, Valid: 15.98%, Test: 6.59%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 115, Loss: 0.0994, Train: 54.22%, Valid: 23.84%, Test: 14.35%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 115, Loss: 0.0994, Train: 66.05%, Valid: 32.02%, Test: 20.82%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 09, Epoch: 120, Loss: 0.0957, Train: 40.74%, Valid: 15.25%, Test: 4.71%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 120, Loss: 0.0957, Train: 58.50%, Valid: 25.82%, Test: 10.97%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 120, Loss: 0.0957, Train: 66.44%, Valid: 31.47%, Test: 19.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 125, Loss: 0.0949, Train: 45.64%, Valid: 17.63%, Test: 5.03%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 125, Loss: 0.0949, Train: 58.11%, Valid: 25.26%, Test: 11.67%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 125, Loss: 0.0949, Train: 66.75%, Valid: 31.40%, Test: 24.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 130, Loss: 0.0932, Train: 46.21%, Valid: 17.25%, Test: 5.68%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 130, Loss: 0.0932, Train: 62.89%, Valid: 27.68%, Test: 15.06%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 130, Loss: 0.0932, Train: 68.99%, Valid: 32.18%, Test: 24.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 135, Loss: 0.0908, Train: 37.75%, Valid: 12.14%, Test: 3.48%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 135, Loss: 0.0908, Train: 59.22%, Valid: 24.23%, Test: 13.03%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 135, Loss: 0.0908, Train: 68.00%, Valid: 30.49%, Test: 20.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 140, Loss: 0.0888, Train: 40.20%, Valid: 13.19%, Test: 3.69%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 140, Loss: 0.0888, Train: 61.85%, Valid: 25.67%, Test: 14.43%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 140, Loss: 0.0888, Train: 69.58%, Valid: 31.11%, Test: 21.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 145, Loss: 0.0876, Train: 39.70%, Valid: 12.33%, Test: 6.13%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 145, Loss: 0.0876, Train: 60.84%, Valid: 24.20%, Test: 12.85%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 145, Loss: 0.0876, Train: 69.82%, Valid: 30.54%, Test: 20.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 150, Loss: 0.0858, Train: 42.06%, Valid: 13.50%, Test: 6.35%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 150, Loss: 0.0858, Train: 61.01%, Valid: 24.13%, Test: 14.36%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 150, Loss: 0.0858, Train: 70.16%, Valid: 30.35%, Test: 24.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 155, Loss: 0.0841, Train: 37.89%, Valid: 10.79%, Test: 4.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 155, Loss: 0.0841, Train: 58.98%, Valid: 21.99%, Test: 15.78%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 155, Loss: 0.0841, Train: 72.40%, Valid: 31.20%, Test: 27.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 160, Loss: 0.0833, Train: 46.01%, Valid: 14.18%, Test: 6.84%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 160, Loss: 0.0833, Train: 61.73%, Valid: 22.92%, Test: 17.94%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 160, Loss: 0.0833, Train: 73.78%, Valid: 31.60%, Test: 25.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 165, Loss: 0.0826, Train: 48.73%, Valid: 15.26%, Test: 7.13%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 165, Loss: 0.0826, Train: 65.19%, Valid: 24.88%, Test: 17.66%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 165, Loss: 0.0826, Train: 74.39%, Valid: 31.49%, Test: 28.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 170, Loss: 0.0806, Train: 47.91%, Valid: 14.72%, Test: 6.02%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 170, Loss: 0.0806, Train: 63.77%, Valid: 23.71%, Test: 15.88%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 170, Loss: 0.0806, Train: 76.12%, Valid: 32.34%, Test: 24.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 175, Loss: 0.0799, Train: 46.51%, Valid: 13.31%, Test: 6.59%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 175, Loss: 0.0799, Train: 65.61%, Valid: 23.99%, Test: 17.53%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 175, Loss: 0.0799, Train: 77.43%, Valid: 32.63%, Test: 27.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 180, Loss: 0.0789, Train: 51.79%, Valid: 15.55%, Test: 7.00%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 180, Loss: 0.0789, Train: 67.64%, Valid: 24.81%, Test: 15.98%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 180, Loss: 0.0789, Train: 74.71%, Valid: 29.97%, Test: 23.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 185, Loss: 0.0775, Train: 45.04%, Valid: 11.89%, Test: 9.56%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 185, Loss: 0.0775, Train: 67.89%, Valid: 24.39%, Test: 19.96%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 185, Loss: 0.0775, Train: 77.46%, Valid: 31.44%, Test: 26.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 190, Loss: 0.0770, Train: 41.71%, Valid: 10.09%, Test: 5.98%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 190, Loss: 0.0770, Train: 66.72%, Valid: 23.07%, Test: 15.63%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 190, Loss: 0.0770, Train: 73.97%, Valid: 28.26%, Test: 25.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 195, Loss: 0.0766, Train: 41.43%, Valid: 9.81%, Test: 7.22%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 195, Loss: 0.0766, Train: 70.29%, Valid: 25.18%, Test: 17.97%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 195, Loss: 0.0766, Train: 80.58%, Valid: 32.93%, Test: 29.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 200, Loss: 0.0758, Train: 49.99%, Valid: 13.13%, Test: 7.04%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 200, Loss: 0.0758, Train: 70.56%, Valid: 24.87%, Test: 17.06%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 200, Loss: 0.0758, Train: 75.39%, Valid: 28.40%, Test: 28.50%\n",
      "---\n",
      "Hits@10\n",
      "Run 09:\n",
      "Highest Train: 51.79\n",
      "Highest Valid: 28.14\n",
      "  Final Train: 38.41\n",
      "   Final Test: 4.32\n",
      "Hits@20\n",
      "Run 09:\n",
      "Highest Train: 70.56\n",
      "Highest Valid: 35.25\n",
      "  Final Train: 49.13\n",
      "   Final Test: 11.08\n",
      "Hits@30\n",
      "Run 09:\n",
      "Highest Train: 80.58\n",
      "Highest Valid: 39.75\n",
      "  Final Train: 54.52\n",
      "   Final Test: 14.99\n",
      "Hits@10\n",
      "Run: 10, Epoch: 05, Loss: 1.3309, Train: 0.17%, Valid: 0.19%, Test: 0.23%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 05, Loss: 1.3309, Train: 0.47%, Valid: 0.46%, Test: 0.60%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 05, Loss: 1.3309, Train: 0.85%, Valid: 0.82%, Test: 0.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 10, Loss: 0.8593, Train: 1.64%, Valid: 1.46%, Test: 2.37%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 10, Loss: 0.8593, Train: 2.34%, Valid: 2.10%, Test: 3.68%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 10, Loss: 0.8593, Train: 3.03%, Valid: 2.71%, Test: 4.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 15, Loss: 0.4881, Train: 14.97%, Valid: 12.94%, Test: 13.34%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 15, Loss: 0.4881, Train: 20.07%, Valid: 17.47%, Test: 17.77%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 15, Loss: 0.4881, Train: 23.63%, Valid: 20.75%, Test: 19.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 20, Loss: 0.3113, Train: 15.93%, Valid: 13.40%, Test: 14.40%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 20, Loss: 0.3113, Train: 20.68%, Valid: 17.51%, Test: 19.54%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 20, Loss: 0.3113, Train: 26.03%, Valid: 22.33%, Test: 23.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 25, Loss: 0.2354, Train: 15.09%, Valid: 12.06%, Test: 17.54%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 25, Loss: 0.2354, Train: 25.30%, Valid: 20.58%, Test: 24.42%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 25, Loss: 0.2354, Train: 31.16%, Valid: 25.57%, Test: 27.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 30, Loss: 0.1995, Train: 21.32%, Valid: 16.15%, Test: 17.42%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 30, Loss: 0.1995, Train: 37.05%, Valid: 29.22%, Test: 25.89%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 30, Loss: 0.1995, Train: 42.71%, Valid: 34.05%, Test: 28.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 35, Loss: 0.1771, Train: 29.82%, Valid: 21.76%, Test: 17.10%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 35, Loss: 0.1771, Train: 46.15%, Valid: 35.12%, Test: 21.70%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 35, Loss: 0.1771, Train: 49.86%, Valid: 38.33%, Test: 26.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 40, Loss: 0.1630, Train: 37.88%, Valid: 26.29%, Test: 11.60%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 40, Loss: 0.1630, Train: 42.76%, Valid: 30.14%, Test: 18.30%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 40, Loss: 0.1630, Train: 50.58%, Valid: 36.73%, Test: 21.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 45, Loss: 0.1509, Train: 38.06%, Valid: 23.91%, Test: 7.26%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 45, Loss: 0.1509, Train: 51.52%, Valid: 34.87%, Test: 13.28%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 45, Loss: 0.1509, Train: 55.76%, Valid: 38.62%, Test: 18.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 50, Loss: 0.1421, Train: 46.86%, Valid: 28.26%, Test: 6.71%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 50, Loss: 0.1421, Train: 52.60%, Valid: 32.99%, Test: 12.40%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 50, Loss: 0.1421, Train: 57.52%, Valid: 37.40%, Test: 17.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 55, Loss: 0.1361, Train: 48.00%, Valid: 27.06%, Test: 3.50%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 55, Loss: 0.1361, Train: 54.78%, Valid: 32.61%, Test: 9.63%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 55, Loss: 0.1361, Train: 59.91%, Valid: 37.25%, Test: 15.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 60, Loss: 0.1308, Train: 46.92%, Valid: 24.27%, Test: 4.54%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 60, Loss: 0.1308, Train: 57.06%, Valid: 32.40%, Test: 13.36%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 60, Loss: 0.1308, Train: 60.80%, Valid: 35.86%, Test: 18.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 65, Loss: 0.1262, Train: 38.17%, Valid: 16.59%, Test: 3.61%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 65, Loss: 0.1262, Train: 51.14%, Valid: 25.38%, Test: 14.44%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 65, Loss: 0.1262, Train: 62.41%, Valid: 34.84%, Test: 18.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 70, Loss: 0.1219, Train: 40.02%, Valid: 16.40%, Test: 8.62%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 70, Loss: 0.1219, Train: 55.79%, Valid: 27.39%, Test: 20.92%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 70, Loss: 0.1219, Train: 60.40%, Valid: 31.12%, Test: 27.86%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 10, Epoch: 75, Loss: 0.1182, Train: 35.87%, Valid: 12.91%, Test: 4.06%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 75, Loss: 0.1182, Train: 54.68%, Valid: 24.80%, Test: 18.79%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 75, Loss: 0.1182, Train: 62.86%, Valid: 31.55%, Test: 25.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 80, Loss: 0.1160, Train: 43.20%, Valid: 15.65%, Test: 6.51%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 80, Loss: 0.1160, Train: 59.24%, Valid: 26.58%, Test: 18.98%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 80, Loss: 0.1160, Train: 65.25%, Valid: 31.80%, Test: 26.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 85, Loss: 0.1134, Train: 38.07%, Valid: 11.87%, Test: 5.27%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 85, Loss: 0.1134, Train: 58.40%, Valid: 24.49%, Test: 15.29%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 85, Loss: 0.1134, Train: 64.12%, Valid: 29.24%, Test: 21.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 90, Loss: 0.1099, Train: 38.29%, Valid: 10.98%, Test: 9.26%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 90, Loss: 0.1099, Train: 56.79%, Valid: 21.88%, Test: 15.50%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 90, Loss: 0.1099, Train: 66.54%, Valid: 30.00%, Test: 26.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 95, Loss: 0.1081, Train: 38.29%, Valid: 10.13%, Test: 10.97%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 95, Loss: 0.1081, Train: 55.07%, Valid: 19.35%, Test: 23.01%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 95, Loss: 0.1081, Train: 64.53%, Valid: 26.66%, Test: 28.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 100, Loss: 0.1047, Train: 46.04%, Valid: 13.08%, Test: 11.32%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 100, Loss: 0.1047, Train: 62.55%, Valid: 23.59%, Test: 20.02%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 100, Loss: 0.1047, Train: 70.83%, Valid: 31.08%, Test: 34.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 105, Loss: 0.1035, Train: 45.66%, Valid: 11.98%, Test: 12.84%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 105, Loss: 0.1035, Train: 59.69%, Valid: 20.29%, Test: 20.13%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 105, Loss: 0.1035, Train: 69.52%, Valid: 28.46%, Test: 28.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 110, Loss: 0.1009, Train: 53.42%, Valid: 15.18%, Test: 11.14%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 110, Loss: 0.1009, Train: 64.83%, Valid: 23.14%, Test: 21.88%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 110, Loss: 0.1009, Train: 72.43%, Valid: 29.94%, Test: 28.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 115, Loss: 0.0989, Train: 55.97%, Valid: 15.71%, Test: 7.45%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 115, Loss: 0.0989, Train: 68.71%, Valid: 25.17%, Test: 17.72%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 115, Loss: 0.0989, Train: 75.57%, Valid: 32.24%, Test: 26.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 120, Loss: 0.0972, Train: 54.07%, Valid: 13.81%, Test: 11.35%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 120, Loss: 0.0972, Train: 69.71%, Valid: 24.74%, Test: 22.91%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 120, Loss: 0.0972, Train: 76.28%, Valid: 31.54%, Test: 38.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 125, Loss: 0.0964, Train: 57.44%, Valid: 14.99%, Test: 7.90%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 125, Loss: 0.0964, Train: 68.15%, Valid: 22.53%, Test: 16.09%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 125, Loss: 0.0964, Train: 76.85%, Valid: 31.32%, Test: 26.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 130, Loss: 0.0935, Train: 56.76%, Valid: 13.65%, Test: 9.16%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 130, Loss: 0.0935, Train: 63.56%, Valid: 17.76%, Test: 16.71%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 130, Loss: 0.0935, Train: 73.61%, Valid: 26.18%, Test: 30.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 135, Loss: 0.0927, Train: 60.26%, Valid: 14.89%, Test: 7.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 135, Loss: 0.0927, Train: 67.42%, Valid: 19.69%, Test: 16.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 135, Loss: 0.0927, Train: 73.77%, Valid: 25.41%, Test: 26.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 140, Loss: 0.0910, Train: 57.63%, Valid: 12.62%, Test: 9.77%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 140, Loss: 0.0910, Train: 71.86%, Valid: 22.58%, Test: 19.68%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 140, Loss: 0.0910, Train: 78.01%, Valid: 29.19%, Test: 33.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 145, Loss: 0.0897, Train: 61.14%, Valid: 13.85%, Test: 7.43%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 145, Loss: 0.0897, Train: 70.65%, Valid: 20.50%, Test: 12.98%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 145, Loss: 0.0897, Train: 76.52%, Valid: 26.22%, Test: 28.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 150, Loss: 0.0881, Train: 56.80%, Valid: 10.96%, Test: 8.52%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 150, Loss: 0.0881, Train: 71.14%, Valid: 20.09%, Test: 18.34%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 150, Loss: 0.0881, Train: 80.08%, Valid: 29.44%, Test: 31.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 155, Loss: 0.0863, Train: 61.17%, Valid: 12.48%, Test: 1.90%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 155, Loss: 0.0863, Train: 71.58%, Valid: 19.39%, Test: 12.05%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 155, Loss: 0.0863, Train: 79.33%, Valid: 27.25%, Test: 26.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 160, Loss: 0.0855, Train: 56.12%, Valid: 9.46%, Test: 4.35%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 160, Loss: 0.0855, Train: 72.28%, Valid: 19.32%, Test: 14.07%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 160, Loss: 0.0855, Train: 82.27%, Valid: 30.48%, Test: 25.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 165, Loss: 0.0834, Train: 53.34%, Valid: 7.82%, Test: 6.60%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 165, Loss: 0.0834, Train: 72.16%, Valid: 18.28%, Test: 14.25%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 165, Loss: 0.0834, Train: 85.05%, Valid: 33.59%, Test: 26.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 170, Loss: 0.0827, Train: 65.36%, Valid: 12.89%, Test: 9.29%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 170, Loss: 0.0827, Train: 75.35%, Valid: 20.26%, Test: 22.74%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 170, Loss: 0.0827, Train: 82.78%, Valid: 29.19%, Test: 32.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 175, Loss: 0.0809, Train: 62.23%, Valid: 10.63%, Test: 7.06%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 175, Loss: 0.0809, Train: 72.84%, Valid: 17.26%, Test: 14.09%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 175, Loss: 0.0809, Train: 80.37%, Valid: 24.88%, Test: 30.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 180, Loss: 0.0816, Train: 59.71%, Valid: 8.93%, Test: 6.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 180, Loss: 0.0816, Train: 72.38%, Valid: 16.38%, Test: 12.46%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 180, Loss: 0.0816, Train: 80.48%, Valid: 24.50%, Test: 24.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 185, Loss: 0.0784, Train: 62.86%, Valid: 9.82%, Test: 7.85%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 185, Loss: 0.0784, Train: 77.69%, Valid: 20.39%, Test: 16.35%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 185, Loss: 0.0784, Train: 82.02%, Valid: 25.52%, Test: 27.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 190, Loss: 0.0781, Train: 66.03%, Valid: 10.77%, Test: 9.01%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 190, Loss: 0.0781, Train: 79.33%, Valid: 21.21%, Test: 19.29%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 190, Loss: 0.0781, Train: 87.35%, Valid: 32.96%, Test: 28.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 195, Loss: 0.0757, Train: 68.85%, Valid: 12.06%, Test: 8.32%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 195, Loss: 0.0757, Train: 77.60%, Valid: 18.80%, Test: 13.33%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 195, Loss: 0.0757, Train: 86.08%, Valid: 29.92%, Test: 28.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 200, Loss: 0.0749, Train: 73.21%, Valid: 14.29%, Test: 6.99%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 200, Loss: 0.0749, Train: 82.60%, Valid: 23.69%, Test: 12.61%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 200, Loss: 0.0749, Train: 88.37%, Valid: 33.00%, Test: 20.02%\n",
      "---\n",
      "Hits@10\n",
      "Run 10:\n",
      "Highest Train: 73.21\n",
      "Highest Valid: 28.26\n",
      "  Final Train: 46.86\n",
      "   Final Test: 6.71\n",
      "Hits@20\n",
      "Run 10:\n",
      "Highest Train: 82.60\n",
      "Highest Valid: 35.12\n",
      "  Final Train: 46.15\n",
      "   Final Test: 21.70\n",
      "Hits@30\n",
      "Run 10:\n",
      "Highest Train: 88.37\n",
      "Highest Valid: 38.62\n",
      "  Final Train: 55.76\n",
      "   Final Test: 18.59\n",
      "Hits@10\n",
      "All runs:\n",
      "Highest Train: 60.90  9.76\n",
      "Highest Valid: 25.57  4.06\n",
      "  Final Train: 39.89  6.27\n",
      "   Final Test: 6.25  3.24\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Train: 75.46  7.60\n",
      "Highest Valid: 34.02  3.21\n",
      "  Final Train: 52.50  8.42\n",
      "   Final Test: 13.62  5.09\n",
      "Hits@30\n",
      "All runs:\n",
      "Highest Train: 83.51  5.95\n",
      "Highest Valid: 39.98  2.10\n",
      "  Final Train: 60.50  12.41\n",
      "   Final Test: 18.88  5.09\n"
     ]
    }
   ],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def train(predictor, x, edge_index, split_edge, optimizer, batch_size):\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(x[edge[0]], x[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(x[edge[0]], x[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(predictor, x, split_edge, evaluator, batch_size):\n",
    "    predictor.eval()\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(x[edge[0]], x[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (MF)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    parser.add_argument('--num_layers', type=int, default=3)\n",
    "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--epochs', type=int, default=200)\n",
    "    parser.add_argument('--eval_steps', type=int, default=5)\n",
    "    parser.add_argument('--runs', type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "    data = dataset[0]\n",
    "    split_edge = dataset.get_edge_split()\n",
    "\n",
    "    # We randomly pick some training samples that we want to evaluate on:\n",
    "    torch.manual_seed(12345)\n",
    "    idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "    idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "    split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "    emb = torch.nn.Embedding(data.num_nodes, args.hidden_channels).to(device)\n",
    "    predictor = LinkPredictor(args.hidden_channels, args.hidden_channels, 1,\n",
    "                              args.num_layers, args.dropout).to(device)\n",
    "\n",
    "    evaluator = Evaluator(name='ogbl-ddi')\n",
    "    Logger_Models_Models = {\n",
    "        'Hits@10': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@20': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@30': Logger_Models_Model(args.runs, args),\n",
    "    }\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        emb.reset_parameters()\n",
    "        predictor.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(emb.parameters()) + list(predictor.parameters()), lr=args.lr)\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(predictor, emb.weight, data.edge_index, split_edge,\n",
    "                         optimizer, args.batch_size)\n",
    "\n",
    "            if epoch % args.eval_steps == 0:\n",
    "                results = test(predictor, emb.weight, split_edge, evaluator,\n",
    "                               args.batch_size)\n",
    "                for key, result in results.items():\n",
    "                    Logger_Models_Models[key].add_result(run, result)\n",
    "\n",
    "                if epoch % args.log_steps == 0:\n",
    "                    for key, result in results.items():\n",
    "                        train_hits, valid_hits, test_hits = result\n",
    "                        print(key)\n",
    "                        print(f'Run: {run + 1:02d}, '\n",
    "                              f'Epoch: {epoch:02d}, '\n",
    "                              f'Loss: {loss:.4f}, '\n",
    "                              f'Train: {100 * train_hits:.2f}%, '\n",
    "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                              f'Test: {100 * test_hits:.2f}%')\n",
    "                    print('---')\n",
    "\n",
    "        for key in Logger_Models_Models.keys():\n",
    "            print(key)\n",
    "            Logger_Models_Models[key].print_statistics(run)\n",
    "\n",
    "    for key in Logger_Models_Models.keys():\n",
    "        print(key)\n",
    "        Logger_Models_Models[key].print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116c9a4",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b54cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T06:27:23.453356Z",
     "start_time": "2022-07-07T06:27:23.428415Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d61b6497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T17:17:00.135484Z",
     "start_time": "2022-07-07T06:27:28.408113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(f='C:\\\\Users\\\\b04753yr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-30e704de-a8cc-40a4-8675-f15ec8e16fa1.json', device=0, log_steps=1, use_sage=False, num_layers=2, hidden_channels=256, dropout=0.5, batch_size=65536, lr=0.005, epochs=200, eval_steps=5, runs=10)\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.6742, Train: 7.81%, Valid: 6.89%, Test: 3.20%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.6742, Train: 9.77%, Valid: 8.58%, Test: 7.13%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.6742, Train: 11.90%, Valid: 10.56%, Test: 10.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 10, Loss: 0.5182, Train: 16.45%, Valid: 14.62%, Test: 5.63%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 10, Loss: 0.5182, Train: 20.27%, Valid: 18.20%, Test: 8.22%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 10, Loss: 0.5182, Train: 23.08%, Valid: 20.80%, Test: 11.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 15, Loss: 0.4362, Train: 20.31%, Valid: 18.13%, Test: 18.38%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 15, Loss: 0.4362, Train: 27.99%, Valid: 25.24%, Test: 21.39%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 15, Loss: 0.4362, Train: 29.97%, Valid: 27.06%, Test: 24.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 20, Loss: 0.3841, Train: 16.22%, Valid: 14.36%, Test: 9.82%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 20, Loss: 0.3841, Train: 25.33%, Valid: 22.66%, Test: 15.60%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 20, Loss: 0.3841, Train: 30.65%, Valid: 27.58%, Test: 19.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 25, Loss: 0.3505, Train: 19.40%, Valid: 17.14%, Test: 5.12%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 25, Loss: 0.3505, Train: 25.88%, Valid: 22.93%, Test: 15.09%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 25, Loss: 0.3505, Train: 30.47%, Valid: 27.24%, Test: 21.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 30, Loss: 0.3310, Train: 23.74%, Valid: 20.89%, Test: 6.49%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 30, Loss: 0.3310, Train: 28.65%, Valid: 25.25%, Test: 19.18%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 30, Loss: 0.3310, Train: 33.92%, Valid: 30.00%, Test: 25.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 35, Loss: 0.3147, Train: 21.01%, Valid: 18.62%, Test: 4.60%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 35, Loss: 0.3147, Train: 27.86%, Valid: 24.64%, Test: 10.00%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 35, Loss: 0.3147, Train: 32.05%, Valid: 28.41%, Test: 19.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 40, Loss: 0.3012, Train: 13.20%, Valid: 11.35%, Test: 4.99%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 40, Loss: 0.3012, Train: 28.76%, Valid: 25.48%, Test: 15.17%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 40, Loss: 0.3012, Train: 32.99%, Valid: 29.35%, Test: 22.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 45, Loss: 0.2901, Train: 30.65%, Valid: 27.11%, Test: 14.80%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 45, Loss: 0.2901, Train: 38.93%, Valid: 34.90%, Test: 22.35%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 45, Loss: 0.2901, Train: 43.39%, Valid: 39.00%, Test: 28.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 50, Loss: 0.2799, Train: 17.33%, Valid: 15.10%, Test: 7.97%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 50, Loss: 0.2799, Train: 27.61%, Valid: 24.12%, Test: 13.11%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 50, Loss: 0.2799, Train: 33.95%, Valid: 29.79%, Test: 22.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 55, Loss: 0.2695, Train: 16.41%, Valid: 14.34%, Test: 13.02%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 55, Loss: 0.2695, Train: 30.63%, Valid: 26.73%, Test: 18.99%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 55, Loss: 0.2695, Train: 41.54%, Valid: 36.75%, Test: 31.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 60, Loss: 0.2626, Train: 19.38%, Valid: 16.84%, Test: 4.02%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 60, Loss: 0.2626, Train: 33.80%, Valid: 29.52%, Test: 13.07%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 60, Loss: 0.2626, Train: 44.04%, Valid: 38.75%, Test: 26.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 65, Loss: 0.2575, Train: 14.64%, Valid: 12.56%, Test: 5.42%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 65, Loss: 0.2575, Train: 30.64%, Valid: 26.96%, Test: 9.55%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 65, Loss: 0.2575, Train: 36.81%, Valid: 32.38%, Test: 18.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 70, Loss: 0.2524, Train: 23.98%, Valid: 20.87%, Test: 8.94%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 70, Loss: 0.2524, Train: 38.22%, Valid: 33.46%, Test: 15.38%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 70, Loss: 0.2524, Train: 44.51%, Valid: 39.13%, Test: 26.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 75, Loss: 0.2492, Train: 29.64%, Valid: 25.59%, Test: 10.77%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 75, Loss: 0.2492, Train: 45.51%, Valid: 39.93%, Test: 18.57%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 75, Loss: 0.2492, Train: 49.32%, Valid: 43.53%, Test: 32.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 80, Loss: 0.2455, Train: 25.73%, Valid: 22.34%, Test: 10.70%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 80, Loss: 0.2455, Train: 39.32%, Valid: 34.29%, Test: 20.81%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 80, Loss: 0.2455, Train: 41.39%, Valid: 36.07%, Test: 30.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 85, Loss: 0.2415, Train: 30.69%, Valid: 26.37%, Test: 8.57%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 85, Loss: 0.2415, Train: 44.71%, Valid: 38.93%, Test: 22.03%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 85, Loss: 0.2415, Train: 51.56%, Valid: 45.20%, Test: 34.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 90, Loss: 0.2391, Train: 28.60%, Valid: 24.73%, Test: 11.46%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 90, Loss: 0.2391, Train: 42.16%, Valid: 36.61%, Test: 22.01%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 90, Loss: 0.2391, Train: 50.97%, Valid: 44.76%, Test: 36.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 95, Loss: 0.2363, Train: 23.80%, Valid: 20.38%, Test: 12.25%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.2363, Train: 42.95%, Valid: 37.28%, Test: 21.75%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 95, Loss: 0.2363, Train: 50.64%, Valid: 44.26%, Test: 36.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 100, Loss: 0.2326, Train: 29.56%, Valid: 25.25%, Test: 10.78%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.2326, Train: 42.80%, Valid: 37.06%, Test: 27.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 100, Loss: 0.2326, Train: 51.18%, Valid: 44.65%, Test: 36.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 105, Loss: 0.2286, Train: 31.16%, Valid: 26.86%, Test: 17.61%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.2286, Train: 45.43%, Valid: 39.34%, Test: 29.84%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 105, Loss: 0.2286, Train: 50.45%, Valid: 43.92%, Test: 36.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 110, Loss: 0.2259, Train: 32.16%, Valid: 27.74%, Test: 15.54%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.2259, Train: 43.15%, Valid: 37.63%, Test: 27.08%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 110, Loss: 0.2259, Train: 48.91%, Valid: 42.81%, Test: 32.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 115, Loss: 0.2205, Train: 29.64%, Valid: 25.44%, Test: 18.56%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.2205, Train: 39.43%, Valid: 34.01%, Test: 29.67%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 115, Loss: 0.2205, Train: 46.63%, Valid: 40.39%, Test: 37.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 120, Loss: 0.2205, Train: 30.19%, Valid: 25.67%, Test: 24.23%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.2205, Train: 50.55%, Valid: 43.69%, Test: 37.43%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 120, Loss: 0.2205, Train: 54.70%, Valid: 47.60%, Test: 47.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 125, Loss: 0.2185, Train: 29.03%, Valid: 25.00%, Test: 19.83%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.2185, Train: 42.54%, Valid: 36.43%, Test: 31.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 125, Loss: 0.2185, Train: 52.26%, Valid: 45.39%, Test: 41.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 130, Loss: 0.2172, Train: 33.65%, Valid: 28.79%, Test: 23.82%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.2172, Train: 48.15%, Valid: 41.56%, Test: 34.54%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 130, Loss: 0.2172, Train: 55.05%, Valid: 47.86%, Test: 47.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 135, Loss: 0.2131, Train: 41.15%, Valid: 35.23%, Test: 29.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.2131, Train: 52.03%, Valid: 44.94%, Test: 40.59%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 135, Loss: 0.2131, Train: 56.98%, Valid: 49.59%, Test: 51.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 140, Loss: 0.2136, Train: 40.57%, Valid: 34.97%, Test: 14.38%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.2136, Train: 53.43%, Valid: 46.53%, Test: 27.80%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 140, Loss: 0.2136, Train: 58.86%, Valid: 51.53%, Test: 46.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 145, Loss: 0.2094, Train: 37.16%, Valid: 31.70%, Test: 23.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.2094, Train: 55.04%, Valid: 47.73%, Test: 37.16%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 145, Loss: 0.2094, Train: 60.92%, Valid: 53.20%, Test: 45.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 150, Loss: 0.2057, Train: 35.02%, Valid: 29.90%, Test: 16.64%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.2057, Train: 47.71%, Valid: 41.04%, Test: 35.24%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 150, Loss: 0.2057, Train: 53.68%, Valid: 46.34%, Test: 43.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 155, Loss: 0.2042, Train: 44.63%, Valid: 38.36%, Test: 18.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.2042, Train: 56.44%, Valid: 49.01%, Test: 38.79%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 155, Loss: 0.2042, Train: 59.47%, Valid: 51.73%, Test: 47.02%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 01, Epoch: 160, Loss: 0.2058, Train: 32.34%, Valid: 27.50%, Test: 21.34%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.2058, Train: 47.36%, Valid: 40.68%, Test: 29.22%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 160, Loss: 0.2058, Train: 56.72%, Valid: 49.27%, Test: 36.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 165, Loss: 0.2022, Train: 40.15%, Valid: 34.28%, Test: 18.90%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.2022, Train: 53.94%, Valid: 46.56%, Test: 37.09%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 165, Loss: 0.2022, Train: 62.37%, Valid: 54.20%, Test: 49.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 170, Loss: 0.2019, Train: 35.75%, Valid: 30.42%, Test: 19.22%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.2019, Train: 49.39%, Valid: 42.39%, Test: 37.40%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 170, Loss: 0.2019, Train: 57.52%, Valid: 49.69%, Test: 40.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 175, Loss: 0.1969, Train: 49.53%, Valid: 42.20%, Test: 17.66%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.1969, Train: 59.60%, Valid: 51.59%, Test: 35.93%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 175, Loss: 0.1969, Train: 65.49%, Valid: 57.02%, Test: 43.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 180, Loss: 0.1970, Train: 53.81%, Valid: 46.33%, Test: 23.15%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.1970, Train: 61.96%, Valid: 53.78%, Test: 30.65%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 180, Loss: 0.1970, Train: 63.95%, Valid: 55.68%, Test: 39.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 185, Loss: 0.1943, Train: 48.88%, Valid: 41.84%, Test: 21.80%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.1943, Train: 60.15%, Valid: 52.12%, Test: 36.29%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 185, Loss: 0.1943, Train: 64.73%, Valid: 56.23%, Test: 44.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 190, Loss: 0.1964, Train: 48.69%, Valid: 41.49%, Test: 19.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.1964, Train: 60.27%, Valid: 52.06%, Test: 34.21%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 190, Loss: 0.1964, Train: 63.18%, Valid: 54.75%, Test: 42.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 195, Loss: 0.1921, Train: 45.52%, Valid: 38.59%, Test: 17.29%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.1921, Train: 59.92%, Valid: 51.66%, Test: 34.22%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 195, Loss: 0.1921, Train: 65.75%, Valid: 57.03%, Test: 42.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 200, Loss: 0.1920, Train: 58.59%, Valid: 50.50%, Test: 27.90%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.1920, Train: 66.87%, Valid: 58.04%, Test: 39.64%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 200, Loss: 0.1920, Train: 68.81%, Valid: 59.86%, Test: 46.84%\n",
      "---\n",
      "Hits@10\n",
      "Run 01:\n",
      "Highest Train: 58.59\n",
      "Highest Valid: 50.50\n",
      "  Final Train: 58.59\n",
      "   Final Test: 27.90\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Train: 66.87\n",
      "Highest Valid: 58.04\n",
      "  Final Train: 66.87\n",
      "   Final Test: 39.64\n",
      "Hits@30\n",
      "Run 01:\n",
      "Highest Train: 68.81\n",
      "Highest Valid: 59.86\n",
      "  Final Train: 68.81\n",
      "   Final Test: 46.84\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.6662, Train: 11.41%, Valid: 10.02%, Test: 5.01%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.6662, Train: 14.04%, Valid: 12.47%, Test: 7.55%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.6662, Train: 15.80%, Valid: 14.22%, Test: 9.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 10, Loss: 0.5047, Train: 12.21%, Valid: 10.72%, Test: 11.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.5047, Train: 21.02%, Valid: 18.80%, Test: 17.35%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 10, Loss: 0.5047, Train: 24.20%, Valid: 21.79%, Test: 20.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 15, Loss: 0.4253, Train: 22.69%, Valid: 20.39%, Test: 12.89%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.4253, Train: 28.71%, Valid: 26.22%, Test: 17.91%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 15, Loss: 0.4253, Train: 32.35%, Valid: 29.82%, Test: 23.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 20, Loss: 0.3839, Train: 13.33%, Valid: 11.77%, Test: 11.96%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.3839, Train: 18.63%, Valid: 16.55%, Test: 19.11%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 20, Loss: 0.3839, Train: 24.47%, Valid: 21.81%, Test: 23.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 25, Loss: 0.3584, Train: 22.74%, Valid: 20.16%, Test: 13.20%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.3584, Train: 32.99%, Valid: 29.70%, Test: 19.61%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 25, Loss: 0.3584, Train: 36.80%, Valid: 33.24%, Test: 25.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 30, Loss: 0.3348, Train: 20.98%, Valid: 18.64%, Test: 5.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.3348, Train: 25.83%, Valid: 23.09%, Test: 9.83%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 30, Loss: 0.3348, Train: 32.33%, Valid: 28.96%, Test: 21.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 35, Loss: 0.3203, Train: 20.13%, Valid: 17.96%, Test: 4.38%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.3203, Train: 25.69%, Valid: 22.96%, Test: 10.34%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 35, Loss: 0.3203, Train: 30.12%, Valid: 26.93%, Test: 15.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 40, Loss: 0.3155, Train: 15.59%, Valid: 13.91%, Test: 4.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.3155, Train: 19.53%, Valid: 17.54%, Test: 10.69%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 40, Loss: 0.3155, Train: 22.72%, Valid: 20.35%, Test: 16.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 45, Loss: 0.2908, Train: 17.51%, Valid: 15.32%, Test: 3.91%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.2908, Train: 22.86%, Valid: 20.00%, Test: 14.37%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 45, Loss: 0.2908, Train: 28.19%, Valid: 24.69%, Test: 29.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 50, Loss: 0.2811, Train: 15.13%, Valid: 13.21%, Test: 2.74%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.2811, Train: 26.04%, Valid: 22.90%, Test: 8.27%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 50, Loss: 0.2811, Train: 32.25%, Valid: 28.31%, Test: 16.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 55, Loss: 0.2776, Train: 12.31%, Valid: 10.63%, Test: 4.85%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.2776, Train: 26.34%, Valid: 22.98%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 55, Loss: 0.2776, Train: 35.56%, Valid: 31.12%, Test: 19.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 60, Loss: 0.2694, Train: 8.71%, Valid: 7.46%, Test: 2.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.2694, Train: 18.83%, Valid: 16.39%, Test: 6.58%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 60, Loss: 0.2694, Train: 29.27%, Valid: 25.72%, Test: 16.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 65, Loss: 0.2612, Train: 19.82%, Valid: 17.15%, Test: 8.45%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.2612, Train: 33.76%, Valid: 29.60%, Test: 15.92%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 65, Loss: 0.2612, Train: 41.63%, Valid: 36.78%, Test: 31.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 70, Loss: 0.2535, Train: 16.43%, Valid: 14.14%, Test: 4.23%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.2535, Train: 33.58%, Valid: 29.37%, Test: 12.97%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 70, Loss: 0.2535, Train: 39.25%, Valid: 34.44%, Test: 18.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 75, Loss: 0.2478, Train: 21.02%, Valid: 18.30%, Test: 7.76%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.2478, Train: 36.18%, Valid: 31.61%, Test: 14.45%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 75, Loss: 0.2478, Train: 42.07%, Valid: 36.88%, Test: 20.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 80, Loss: 0.2449, Train: 28.88%, Valid: 24.74%, Test: 14.10%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.2449, Train: 40.05%, Valid: 34.89%, Test: 23.42%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 80, Loss: 0.2449, Train: 50.31%, Valid: 44.43%, Test: 33.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 85, Loss: 0.2424, Train: 17.99%, Valid: 15.30%, Test: 4.80%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.2424, Train: 30.37%, Valid: 26.24%, Test: 16.27%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 85, Loss: 0.2424, Train: 37.12%, Valid: 32.26%, Test: 24.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 90, Loss: 0.2381, Train: 21.66%, Valid: 18.64%, Test: 10.48%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.2381, Train: 34.26%, Valid: 29.69%, Test: 17.84%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 90, Loss: 0.2381, Train: 45.37%, Valid: 39.65%, Test: 30.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 95, Loss: 0.2314, Train: 14.50%, Valid: 12.22%, Test: 9.72%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.2314, Train: 24.08%, Valid: 20.69%, Test: 21.31%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 95, Loss: 0.2314, Train: 29.94%, Valid: 25.85%, Test: 30.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 100, Loss: 0.2318, Train: 22.63%, Valid: 19.32%, Test: 8.36%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.2318, Train: 38.16%, Valid: 33.13%, Test: 29.43%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 100, Loss: 0.2318, Train: 46.02%, Valid: 40.16%, Test: 40.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 105, Loss: 0.2288, Train: 25.75%, Valid: 22.09%, Test: 14.31%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.2288, Train: 35.56%, Valid: 30.64%, Test: 25.65%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 105, Loss: 0.2288, Train: 50.95%, Valid: 44.59%, Test: 33.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 110, Loss: 0.2258, Train: 25.07%, Valid: 21.33%, Test: 13.72%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.2258, Train: 39.12%, Valid: 33.75%, Test: 26.76%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 110, Loss: 0.2258, Train: 50.59%, Valid: 44.05%, Test: 35.03%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 02, Epoch: 115, Loss: 0.2240, Train: 26.20%, Valid: 22.43%, Test: 8.46%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.2240, Train: 33.05%, Valid: 28.59%, Test: 21.14%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 115, Loss: 0.2240, Train: 38.64%, Valid: 33.52%, Test: 26.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 120, Loss: 0.2190, Train: 38.81%, Valid: 33.33%, Test: 16.81%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.2190, Train: 51.21%, Valid: 44.63%, Test: 31.58%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 120, Loss: 0.2190, Train: 54.91%, Valid: 48.07%, Test: 42.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 125, Loss: 0.2191, Train: 29.27%, Valid: 25.00%, Test: 17.07%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.2191, Train: 42.80%, Valid: 36.95%, Test: 35.18%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 125, Loss: 0.2191, Train: 49.79%, Valid: 43.21%, Test: 40.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 130, Loss: 0.2164, Train: 39.70%, Valid: 34.22%, Test: 12.25%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.2164, Train: 50.22%, Valid: 43.53%, Test: 29.94%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 130, Loss: 0.2164, Train: 56.91%, Valid: 49.75%, Test: 37.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 135, Loss: 0.2130, Train: 32.91%, Valid: 28.28%, Test: 19.61%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.2130, Train: 47.43%, Valid: 41.28%, Test: 32.37%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 135, Loss: 0.2130, Train: 51.45%, Valid: 44.78%, Test: 38.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 140, Loss: 0.2102, Train: 30.20%, Valid: 25.81%, Test: 17.53%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.2102, Train: 45.50%, Valid: 39.29%, Test: 30.76%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 140, Loss: 0.2102, Train: 52.90%, Valid: 45.94%, Test: 39.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 145, Loss: 0.2086, Train: 31.86%, Valid: 27.17%, Test: 20.11%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.2086, Train: 41.75%, Valid: 36.03%, Test: 29.79%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 145, Loss: 0.2086, Train: 50.38%, Valid: 43.52%, Test: 35.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 150, Loss: 0.2084, Train: 41.85%, Valid: 35.91%, Test: 16.15%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.2084, Train: 53.37%, Valid: 46.31%, Test: 31.05%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 150, Loss: 0.2084, Train: 58.45%, Valid: 51.07%, Test: 37.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 155, Loss: 0.2035, Train: 34.70%, Valid: 29.66%, Test: 17.13%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.2035, Train: 47.30%, Valid: 40.76%, Test: 28.09%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 155, Loss: 0.2035, Train: 56.07%, Valid: 48.90%, Test: 35.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 160, Loss: 0.2029, Train: 48.26%, Valid: 41.62%, Test: 20.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.2029, Train: 56.52%, Valid: 49.13%, Test: 35.50%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 160, Loss: 0.2029, Train: 59.82%, Valid: 52.00%, Test: 46.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 165, Loss: 0.2000, Train: 51.83%, Valid: 44.83%, Test: 18.63%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.2000, Train: 61.58%, Valid: 53.59%, Test: 33.28%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 165, Loss: 0.2000, Train: 64.77%, Valid: 56.51%, Test: 47.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 170, Loss: 0.2003, Train: 36.26%, Valid: 30.72%, Test: 13.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.2003, Train: 52.37%, Valid: 45.27%, Test: 20.27%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 170, Loss: 0.2003, Train: 59.86%, Valid: 52.16%, Test: 29.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 175, Loss: 0.1983, Train: 39.82%, Valid: 33.98%, Test: 17.98%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.1983, Train: 55.29%, Valid: 47.79%, Test: 30.63%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 175, Loss: 0.1983, Train: 60.60%, Valid: 52.51%, Test: 37.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 180, Loss: 0.1964, Train: 46.57%, Valid: 39.47%, Test: 23.42%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.1964, Train: 58.70%, Valid: 50.67%, Test: 33.71%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 180, Loss: 0.1964, Train: 64.68%, Valid: 56.30%, Test: 42.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 185, Loss: 0.1954, Train: 51.47%, Valid: 44.46%, Test: 25.45%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.1954, Train: 63.11%, Valid: 54.96%, Test: 42.90%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 185, Loss: 0.1954, Train: 66.82%, Valid: 58.27%, Test: 49.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 190, Loss: 0.1929, Train: 45.60%, Valid: 38.58%, Test: 23.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.1929, Train: 61.38%, Valid: 52.76%, Test: 36.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 190, Loss: 0.1929, Train: 66.47%, Valid: 57.62%, Test: 45.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 195, Loss: 0.1925, Train: 54.82%, Valid: 46.73%, Test: 18.59%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.1925, Train: 66.88%, Valid: 58.20%, Test: 28.99%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 195, Loss: 0.1925, Train: 69.97%, Valid: 61.19%, Test: 41.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 200, Loss: 0.1889, Train: 48.58%, Valid: 41.18%, Test: 14.69%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.1889, Train: 62.42%, Valid: 53.99%, Test: 31.43%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 200, Loss: 0.1889, Train: 65.71%, Valid: 57.05%, Test: 40.22%\n",
      "---\n",
      "Hits@10\n",
      "Run 02:\n",
      "Highest Train: 54.82\n",
      "Highest Valid: 46.73\n",
      "  Final Train: 54.82\n",
      "   Final Test: 18.59\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Train: 66.88\n",
      "Highest Valid: 58.20\n",
      "  Final Train: 66.88\n",
      "   Final Test: 28.99\n",
      "Hits@30\n",
      "Run 02:\n",
      "Highest Train: 69.97\n",
      "Highest Valid: 61.19\n",
      "  Final Train: 69.97\n",
      "   Final Test: 41.11\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.6741, Train: 13.82%, Valid: 12.41%, Test: 6.77%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.6741, Train: 15.27%, Valid: 13.80%, Test: 10.31%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.6741, Train: 17.48%, Valid: 15.95%, Test: 12.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 10, Loss: 0.5066, Train: 16.23%, Valid: 14.38%, Test: 7.84%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 10, Loss: 0.5066, Train: 21.51%, Valid: 19.32%, Test: 15.30%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 10, Loss: 0.5066, Train: 25.22%, Valid: 22.92%, Test: 17.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 15, Loss: 0.4205, Train: 23.96%, Valid: 21.35%, Test: 11.24%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 15, Loss: 0.4205, Train: 30.71%, Valid: 27.79%, Test: 19.70%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 15, Loss: 0.4205, Train: 34.92%, Valid: 31.86%, Test: 24.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 20, Loss: 0.3746, Train: 15.17%, Valid: 13.13%, Test: 7.51%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 20, Loss: 0.3746, Train: 24.36%, Valid: 21.88%, Test: 16.03%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 20, Loss: 0.3746, Train: 27.33%, Valid: 24.58%, Test: 19.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 25, Loss: 0.3463, Train: 15.06%, Valid: 13.21%, Test: 3.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 25, Loss: 0.3463, Train: 23.31%, Valid: 20.58%, Test: 10.81%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 25, Loss: 0.3463, Train: 28.75%, Valid: 25.46%, Test: 21.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 30, Loss: 0.3256, Train: 21.00%, Valid: 18.48%, Test: 4.77%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 30, Loss: 0.3256, Train: 27.98%, Valid: 24.66%, Test: 14.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 30, Loss: 0.3256, Train: 32.77%, Valid: 28.93%, Test: 18.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 35, Loss: 0.3121, Train: 19.74%, Valid: 17.36%, Test: 5.26%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 35, Loss: 0.3121, Train: 29.16%, Valid: 25.75%, Test: 17.02%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 35, Loss: 0.3121, Train: 35.61%, Valid: 31.63%, Test: 22.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 40, Loss: 0.3024, Train: 8.30%, Valid: 7.11%, Test: 2.56%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 40, Loss: 0.3024, Train: 20.78%, Valid: 18.23%, Test: 6.89%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 40, Loss: 0.3024, Train: 29.34%, Valid: 25.90%, Test: 14.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 45, Loss: 0.2868, Train: 14.34%, Valid: 12.50%, Test: 6.75%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 45, Loss: 0.2868, Train: 26.40%, Valid: 23.18%, Test: 11.12%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 45, Loss: 0.2868, Train: 31.60%, Valid: 27.78%, Test: 20.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 50, Loss: 0.2781, Train: 15.61%, Valid: 13.58%, Test: 3.33%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 50, Loss: 0.2781, Train: 30.17%, Valid: 26.62%, Test: 12.86%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 50, Loss: 0.2781, Train: 34.89%, Valid: 31.00%, Test: 19.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 55, Loss: 0.2714, Train: 14.80%, Valid: 12.60%, Test: 5.08%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 55, Loss: 0.2714, Train: 28.81%, Valid: 25.07%, Test: 13.74%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 55, Loss: 0.2714, Train: 32.68%, Valid: 28.52%, Test: 21.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 60, Loss: 0.2642, Train: 24.69%, Valid: 21.46%, Test: 7.63%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 60, Loss: 0.2642, Train: 30.73%, Valid: 26.79%, Test: 12.22%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 60, Loss: 0.2642, Train: 36.46%, Valid: 32.06%, Test: 21.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 65, Loss: 0.2589, Train: 29.09%, Valid: 25.32%, Test: 12.91%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 65, Loss: 0.2589, Train: 43.15%, Valid: 37.91%, Test: 26.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 65, Loss: 0.2589, Train: 46.72%, Valid: 41.19%, Test: 31.28%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 03, Epoch: 70, Loss: 0.2518, Train: 30.00%, Valid: 25.99%, Test: 6.30%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 70, Loss: 0.2518, Train: 45.48%, Valid: 39.84%, Test: 19.63%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 70, Loss: 0.2518, Train: 49.45%, Valid: 43.64%, Test: 30.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 75, Loss: 0.2497, Train: 23.26%, Valid: 19.99%, Test: 10.09%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 75, Loss: 0.2497, Train: 33.60%, Valid: 29.03%, Test: 18.87%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 75, Loss: 0.2497, Train: 43.09%, Valid: 37.69%, Test: 28.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 80, Loss: 0.2440, Train: 39.06%, Valid: 33.93%, Test: 17.61%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 80, Loss: 0.2440, Train: 47.37%, Valid: 41.60%, Test: 30.80%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 80, Loss: 0.2440, Train: 54.75%, Valid: 48.54%, Test: 39.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 85, Loss: 0.2422, Train: 29.70%, Valid: 25.65%, Test: 17.94%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 85, Loss: 0.2422, Train: 38.20%, Valid: 33.15%, Test: 26.86%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 85, Loss: 0.2422, Train: 47.72%, Valid: 41.81%, Test: 33.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 90, Loss: 0.2373, Train: 34.74%, Valid: 29.91%, Test: 13.44%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 90, Loss: 0.2373, Train: 44.56%, Valid: 38.83%, Test: 27.13%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 90, Loss: 0.2373, Train: 50.29%, Valid: 44.15%, Test: 35.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 95, Loss: 0.2330, Train: 27.65%, Valid: 23.70%, Test: 18.62%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 95, Loss: 0.2330, Train: 43.90%, Valid: 38.08%, Test: 37.05%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 95, Loss: 0.2330, Train: 51.11%, Valid: 44.72%, Test: 41.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 100, Loss: 0.2353, Train: 30.99%, Valid: 26.63%, Test: 15.11%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 100, Loss: 0.2353, Train: 38.03%, Valid: 33.00%, Test: 22.24%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 100, Loss: 0.2353, Train: 44.33%, Valid: 38.76%, Test: 30.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 105, Loss: 0.2293, Train: 30.61%, Valid: 26.11%, Test: 20.61%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 105, Loss: 0.2293, Train: 42.50%, Valid: 36.82%, Test: 30.68%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 105, Loss: 0.2293, Train: 50.18%, Valid: 43.90%, Test: 41.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 110, Loss: 0.2273, Train: 25.85%, Valid: 22.10%, Test: 20.36%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 110, Loss: 0.2273, Train: 41.72%, Valid: 36.04%, Test: 39.50%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 110, Loss: 0.2273, Train: 50.06%, Valid: 43.67%, Test: 42.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 115, Loss: 0.2219, Train: 38.92%, Valid: 33.43%, Test: 22.41%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 115, Loss: 0.2219, Train: 49.71%, Valid: 43.17%, Test: 33.28%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 115, Loss: 0.2219, Train: 57.52%, Valid: 50.19%, Test: 43.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 120, Loss: 0.2193, Train: 31.60%, Valid: 27.08%, Test: 21.87%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 120, Loss: 0.2193, Train: 46.67%, Valid: 40.29%, Test: 38.25%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 120, Loss: 0.2193, Train: 54.37%, Valid: 47.38%, Test: 45.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 125, Loss: 0.2187, Train: 30.00%, Valid: 25.63%, Test: 21.66%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 125, Loss: 0.2187, Train: 44.65%, Valid: 38.71%, Test: 38.88%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 125, Loss: 0.2187, Train: 53.75%, Valid: 46.75%, Test: 46.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 130, Loss: 0.2162, Train: 35.31%, Valid: 30.18%, Test: 23.86%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 130, Loss: 0.2162, Train: 47.11%, Valid: 40.54%, Test: 33.51%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 130, Loss: 0.2162, Train: 54.41%, Valid: 47.36%, Test: 46.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 135, Loss: 0.2145, Train: 34.49%, Valid: 29.38%, Test: 31.68%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 135, Loss: 0.2145, Train: 46.22%, Valid: 39.79%, Test: 40.95%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 135, Loss: 0.2145, Train: 51.80%, Valid: 44.80%, Test: 49.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 140, Loss: 0.2119, Train: 28.22%, Valid: 24.08%, Test: 21.44%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 140, Loss: 0.2119, Train: 39.36%, Valid: 33.59%, Test: 32.01%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 140, Loss: 0.2119, Train: 47.10%, Valid: 40.54%, Test: 42.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 145, Loss: 0.2104, Train: 30.19%, Valid: 25.67%, Test: 27.79%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 145, Loss: 0.2104, Train: 42.43%, Valid: 36.45%, Test: 43.46%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 145, Loss: 0.2104, Train: 51.28%, Valid: 44.36%, Test: 52.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 150, Loss: 0.2143, Train: 36.01%, Valid: 30.73%, Test: 25.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 150, Loss: 0.2143, Train: 46.64%, Valid: 40.12%, Test: 35.28%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 150, Loss: 0.2143, Train: 51.89%, Valid: 44.89%, Test: 43.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 155, Loss: 0.2081, Train: 34.80%, Valid: 29.78%, Test: 22.33%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 155, Loss: 0.2081, Train: 48.00%, Valid: 41.64%, Test: 31.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 155, Loss: 0.2081, Train: 53.50%, Valid: 46.64%, Test: 39.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 160, Loss: 0.2046, Train: 41.55%, Valid: 35.58%, Test: 33.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 160, Loss: 0.2046, Train: 54.86%, Valid: 47.57%, Test: 45.46%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 160, Loss: 0.2046, Train: 60.60%, Valid: 52.74%, Test: 53.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 165, Loss: 0.2026, Train: 31.86%, Valid: 27.10%, Test: 29.38%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 165, Loss: 0.2026, Train: 43.12%, Valid: 36.87%, Test: 38.85%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 165, Loss: 0.2026, Train: 48.85%, Valid: 42.18%, Test: 44.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 170, Loss: 0.2020, Train: 33.40%, Valid: 28.17%, Test: 24.04%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 170, Loss: 0.2020, Train: 50.09%, Valid: 42.93%, Test: 32.46%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 170, Loss: 0.2020, Train: 56.58%, Valid: 48.87%, Test: 41.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 175, Loss: 0.2015, Train: 46.67%, Valid: 40.10%, Test: 24.06%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 175, Loss: 0.2015, Train: 52.43%, Valid: 45.19%, Test: 36.93%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 175, Loss: 0.2015, Train: 59.67%, Valid: 51.78%, Test: 42.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 180, Loss: 0.1974, Train: 44.91%, Valid: 38.44%, Test: 28.27%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 180, Loss: 0.1974, Train: 57.11%, Valid: 49.35%, Test: 38.46%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 180, Loss: 0.1974, Train: 61.47%, Valid: 53.31%, Test: 44.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 185, Loss: 0.1996, Train: 44.54%, Valid: 38.01%, Test: 21.30%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 185, Loss: 0.1996, Train: 52.02%, Valid: 44.79%, Test: 31.96%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 185, Loss: 0.1996, Train: 56.60%, Valid: 48.96%, Test: 41.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 190, Loss: 0.1966, Train: 31.04%, Valid: 26.30%, Test: 27.54%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 190, Loss: 0.1966, Train: 51.95%, Valid: 44.70%, Test: 35.91%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 190, Loss: 0.1966, Train: 60.03%, Valid: 52.01%, Test: 45.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 195, Loss: 0.1948, Train: 38.73%, Valid: 32.96%, Test: 34.79%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 195, Loss: 0.1948, Train: 54.23%, Valid: 46.80%, Test: 41.05%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 195, Loss: 0.1948, Train: 60.75%, Valid: 52.61%, Test: 46.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 200, Loss: 0.1934, Train: 38.54%, Valid: 32.71%, Test: 27.00%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 200, Loss: 0.1934, Train: 59.07%, Valid: 51.07%, Test: 39.13%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 200, Loss: 0.1934, Train: 61.72%, Valid: 53.51%, Test: 45.93%\n",
      "---\n",
      "Hits@10\n",
      "Run 03:\n",
      "Highest Train: 46.67\n",
      "Highest Valid: 40.10\n",
      "  Final Train: 46.67\n",
      "   Final Test: 24.06\n",
      "Hits@20\n",
      "Run 03:\n",
      "Highest Train: 59.07\n",
      "Highest Valid: 51.07\n",
      "  Final Train: 59.07\n",
      "   Final Test: 39.13\n",
      "Hits@30\n",
      "Run 03:\n",
      "Highest Train: 61.72\n",
      "Highest Valid: 53.51\n",
      "  Final Train: 61.72\n",
      "   Final Test: 45.93\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.6642, Train: 1.78%, Valid: 1.52%, Test: 0.05%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.6642, Train: 6.15%, Valid: 5.41%, Test: 0.80%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.6642, Train: 10.26%, Valid: 9.07%, Test: 4.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 10, Loss: 0.5178, Train: 14.36%, Valid: 12.75%, Test: 11.41%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 10, Loss: 0.5178, Train: 21.42%, Valid: 19.23%, Test: 14.34%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 10, Loss: 0.5178, Train: 26.21%, Valid: 23.76%, Test: 16.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 15, Loss: 0.4351, Train: 16.11%, Valid: 14.38%, Test: 16.76%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 15, Loss: 0.4351, Train: 21.87%, Valid: 19.55%, Test: 22.31%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 15, Loss: 0.4351, Train: 25.61%, Valid: 23.05%, Test: 24.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 20, Loss: 0.3822, Train: 19.96%, Valid: 17.68%, Test: 8.83%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 20, Loss: 0.3822, Train: 25.31%, Valid: 22.69%, Test: 13.54%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 20, Loss: 0.3822, Train: 28.24%, Valid: 25.32%, Test: 19.06%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 25, Loss: 0.3542, Train: 23.83%, Valid: 21.23%, Test: 10.89%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 25, Loss: 0.3542, Train: 32.17%, Valid: 28.68%, Test: 19.57%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 25, Loss: 0.3542, Train: 37.04%, Valid: 33.35%, Test: 24.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 30, Loss: 0.3305, Train: 21.35%, Valid: 18.94%, Test: 6.29%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 30, Loss: 0.3305, Train: 26.84%, Valid: 23.92%, Test: 14.24%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 30, Loss: 0.3305, Train: 32.09%, Valid: 28.66%, Test: 20.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 35, Loss: 0.3146, Train: 20.45%, Valid: 17.81%, Test: 7.06%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 35, Loss: 0.3146, Train: 30.20%, Valid: 26.69%, Test: 14.84%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 35, Loss: 0.3146, Train: 36.34%, Valid: 32.37%, Test: 21.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 40, Loss: 0.3022, Train: 25.31%, Valid: 22.32%, Test: 6.37%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 40, Loss: 0.3022, Train: 29.54%, Valid: 26.06%, Test: 16.69%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 40, Loss: 0.3022, Train: 38.03%, Valid: 33.77%, Test: 25.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 45, Loss: 0.2900, Train: 26.49%, Valid: 23.09%, Test: 6.73%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 45, Loss: 0.2900, Train: 35.68%, Valid: 31.39%, Test: 22.98%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 45, Loss: 0.2900, Train: 44.22%, Valid: 39.32%, Test: 32.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 50, Loss: 0.2803, Train: 15.23%, Valid: 13.00%, Test: 6.30%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 50, Loss: 0.2803, Train: 23.86%, Valid: 20.66%, Test: 17.38%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 50, Loss: 0.2803, Train: 30.40%, Valid: 26.50%, Test: 24.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 55, Loss: 0.2712, Train: 22.18%, Valid: 19.13%, Test: 10.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 55, Loss: 0.2712, Train: 33.27%, Valid: 28.98%, Test: 26.15%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 55, Loss: 0.2712, Train: 40.36%, Valid: 35.43%, Test: 34.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 60, Loss: 0.2656, Train: 8.94%, Valid: 7.46%, Test: 7.82%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 60, Loss: 0.2656, Train: 25.65%, Valid: 22.08%, Test: 18.07%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 60, Loss: 0.2656, Train: 31.27%, Valid: 27.32%, Test: 22.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 65, Loss: 0.2603, Train: 30.60%, Valid: 26.49%, Test: 17.94%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 65, Loss: 0.2603, Train: 39.17%, Valid: 34.40%, Test: 30.05%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 65, Loss: 0.2603, Train: 45.02%, Valid: 39.94%, Test: 35.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 70, Loss: 0.2525, Train: 19.68%, Valid: 16.70%, Test: 25.96%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 70, Loss: 0.2525, Train: 34.88%, Valid: 30.13%, Test: 36.12%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 70, Loss: 0.2525, Train: 41.93%, Valid: 36.59%, Test: 43.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 75, Loss: 0.2481, Train: 21.68%, Valid: 18.51%, Test: 18.53%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 75, Loss: 0.2481, Train: 31.31%, Valid: 26.94%, Test: 27.55%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 75, Loss: 0.2481, Train: 38.96%, Valid: 33.69%, Test: 37.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 80, Loss: 0.2473, Train: 23.24%, Valid: 19.71%, Test: 24.28%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 80, Loss: 0.2473, Train: 36.28%, Valid: 31.15%, Test: 38.35%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 80, Loss: 0.2473, Train: 45.28%, Valid: 39.49%, Test: 44.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 85, Loss: 0.2423, Train: 20.86%, Valid: 17.74%, Test: 15.47%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 85, Loss: 0.2423, Train: 37.52%, Valid: 32.49%, Test: 26.03%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 85, Loss: 0.2423, Train: 44.52%, Valid: 38.78%, Test: 35.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 90, Loss: 0.2400, Train: 26.78%, Valid: 22.81%, Test: 19.34%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 90, Loss: 0.2400, Train: 45.60%, Valid: 39.75%, Test: 32.32%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 90, Loss: 0.2400, Train: 51.86%, Valid: 45.55%, Test: 43.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 95, Loss: 0.2361, Train: 26.83%, Valid: 22.83%, Test: 23.17%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 95, Loss: 0.2361, Train: 39.88%, Valid: 34.46%, Test: 36.98%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 95, Loss: 0.2361, Train: 47.96%, Valid: 41.72%, Test: 43.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 100, Loss: 0.2296, Train: 32.45%, Valid: 27.93%, Test: 23.71%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 100, Loss: 0.2296, Train: 40.62%, Valid: 35.21%, Test: 36.71%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 100, Loss: 0.2296, Train: 49.53%, Valid: 43.06%, Test: 45.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 105, Loss: 0.2277, Train: 31.10%, Valid: 26.72%, Test: 26.37%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 105, Loss: 0.2277, Train: 44.56%, Valid: 38.55%, Test: 40.12%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 105, Loss: 0.2277, Train: 54.99%, Valid: 48.08%, Test: 52.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 110, Loss: 0.2233, Train: 24.88%, Valid: 21.14%, Test: 16.94%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 110, Loss: 0.2233, Train: 37.83%, Valid: 32.42%, Test: 33.10%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 110, Loss: 0.2233, Train: 47.42%, Valid: 41.18%, Test: 42.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 115, Loss: 0.2215, Train: 28.37%, Valid: 24.26%, Test: 15.76%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 115, Loss: 0.2215, Train: 41.08%, Valid: 35.48%, Test: 32.60%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 115, Loss: 0.2215, Train: 48.76%, Valid: 42.38%, Test: 39.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 120, Loss: 0.2173, Train: 29.35%, Valid: 24.99%, Test: 18.15%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 120, Loss: 0.2173, Train: 36.91%, Valid: 31.59%, Test: 32.61%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 120, Loss: 0.2173, Train: 47.49%, Valid: 40.94%, Test: 39.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 125, Loss: 0.2144, Train: 31.53%, Valid: 27.04%, Test: 17.97%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 125, Loss: 0.2144, Train: 38.96%, Valid: 33.57%, Test: 29.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 125, Loss: 0.2144, Train: 44.39%, Valid: 38.24%, Test: 39.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 130, Loss: 0.2119, Train: 38.93%, Valid: 33.26%, Test: 22.27%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 130, Loss: 0.2119, Train: 52.99%, Valid: 45.96%, Test: 35.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 130, Loss: 0.2119, Train: 57.43%, Valid: 50.05%, Test: 47.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 135, Loss: 0.2120, Train: 33.81%, Valid: 29.03%, Test: 18.75%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 135, Loss: 0.2120, Train: 50.46%, Valid: 43.68%, Test: 36.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 135, Loss: 0.2120, Train: 58.12%, Valid: 50.73%, Test: 43.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 140, Loss: 0.2081, Train: 41.93%, Valid: 35.75%, Test: 18.36%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 140, Loss: 0.2081, Train: 54.22%, Valid: 46.93%, Test: 40.99%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 140, Loss: 0.2081, Train: 57.45%, Valid: 49.94%, Test: 47.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 145, Loss: 0.2061, Train: 39.25%, Valid: 33.66%, Test: 12.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 145, Loss: 0.2061, Train: 49.42%, Valid: 42.69%, Test: 30.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 145, Loss: 0.2061, Train: 57.21%, Valid: 49.78%, Test: 43.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 150, Loss: 0.2067, Train: 40.80%, Valid: 34.99%, Test: 18.76%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 150, Loss: 0.2067, Train: 50.26%, Valid: 43.26%, Test: 28.19%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 150, Loss: 0.2067, Train: 58.51%, Valid: 50.86%, Test: 39.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 155, Loss: 0.2047, Train: 47.96%, Valid: 41.26%, Test: 21.53%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 155, Loss: 0.2047, Train: 59.31%, Valid: 51.61%, Test: 46.02%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 155, Loss: 0.2047, Train: 63.14%, Valid: 55.09%, Test: 57.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 160, Loss: 0.2009, Train: 46.82%, Valid: 40.17%, Test: 26.33%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 160, Loss: 0.2009, Train: 61.87%, Valid: 53.86%, Test: 40.86%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 160, Loss: 0.2009, Train: 65.70%, Valid: 57.39%, Test: 48.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 165, Loss: 0.1987, Train: 43.82%, Valid: 37.72%, Test: 17.24%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 165, Loss: 0.1987, Train: 57.39%, Valid: 49.79%, Test: 28.17%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 165, Loss: 0.1987, Train: 63.86%, Valid: 55.65%, Test: 37.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 170, Loss: 0.1978, Train: 45.03%, Valid: 38.68%, Test: 13.33%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 170, Loss: 0.1978, Train: 52.64%, Valid: 45.53%, Test: 21.52%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 170, Loss: 0.1978, Train: 57.86%, Valid: 50.26%, Test: 29.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 175, Loss: 0.1967, Train: 47.13%, Valid: 40.39%, Test: 17.40%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 175, Loss: 0.1967, Train: 58.05%, Valid: 50.35%, Test: 24.33%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 175, Loss: 0.1967, Train: 63.81%, Valid: 55.48%, Test: 34.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 180, Loss: 0.1958, Train: 37.59%, Valid: 31.67%, Test: 14.64%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 180, Loss: 0.1958, Train: 54.76%, Valid: 47.21%, Test: 26.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 180, Loss: 0.1958, Train: 62.18%, Valid: 53.95%, Test: 30.28%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 185, Loss: 0.1920, Train: 50.35%, Valid: 43.18%, Test: 14.30%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 185, Loss: 0.1920, Train: 62.53%, Valid: 54.22%, Test: 30.07%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 185, Loss: 0.1920, Train: 65.61%, Valid: 57.09%, Test: 38.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 190, Loss: 0.1902, Train: 42.92%, Valid: 36.36%, Test: 18.87%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 190, Loss: 0.1902, Train: 66.51%, Valid: 57.85%, Test: 29.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 190, Loss: 0.1902, Train: 68.63%, Valid: 59.84%, Test: 40.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 195, Loss: 0.1906, Train: 44.97%, Valid: 37.95%, Test: 25.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 195, Loss: 0.1906, Train: 62.01%, Valid: 53.48%, Test: 35.62%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 195, Loss: 0.1906, Train: 66.51%, Valid: 57.69%, Test: 48.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 200, Loss: 0.1901, Train: 36.85%, Valid: 30.87%, Test: 17.57%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 200, Loss: 0.1901, Train: 64.47%, Valid: 55.70%, Test: 28.33%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 200, Loss: 0.1901, Train: 68.45%, Valid: 59.60%, Test: 37.63%\n",
      "---\n",
      "Hits@10\n",
      "Run 04:\n",
      "Highest Train: 50.35\n",
      "Highest Valid: 43.18\n",
      "  Final Train: 50.35\n",
      "   Final Test: 14.30\n",
      "Hits@20\n",
      "Run 04:\n",
      "Highest Train: 66.51\n",
      "Highest Valid: 57.85\n",
      "  Final Train: 66.51\n",
      "   Final Test: 29.76\n",
      "Hits@30\n",
      "Run 04:\n",
      "Highest Train: 68.63\n",
      "Highest Valid: 59.84\n",
      "  Final Train: 68.63\n",
      "   Final Test: 40.93\n",
      "Hits@10\n",
      "Run: 05, Epoch: 05, Loss: 0.6616, Train: 0.13%, Valid: 0.12%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 05, Loss: 0.6616, Train: 4.36%, Valid: 3.73%, Test: 0.06%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 05, Loss: 0.6616, Train: 12.52%, Valid: 11.00%, Test: 5.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 10, Loss: 0.5176, Train: 17.19%, Valid: 15.28%, Test: 10.90%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 10, Loss: 0.5176, Train: 21.16%, Valid: 18.87%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 10, Loss: 0.5176, Train: 24.57%, Valid: 22.09%, Test: 18.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 15, Loss: 0.4510, Train: 16.10%, Valid: 14.55%, Test: 7.37%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 15, Loss: 0.4510, Train: 19.06%, Valid: 17.22%, Test: 11.89%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 15, Loss: 0.4510, Train: 21.71%, Valid: 19.60%, Test: 14.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 20, Loss: 0.3965, Train: 18.21%, Valid: 16.15%, Test: 17.39%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 20, Loss: 0.3965, Train: 25.51%, Valid: 22.87%, Test: 22.17%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 20, Loss: 0.3965, Train: 30.66%, Valid: 27.58%, Test: 25.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 25, Loss: 0.3680, Train: 19.25%, Valid: 16.89%, Test: 9.65%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 25, Loss: 0.3680, Train: 23.76%, Valid: 21.30%, Test: 18.65%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 25, Loss: 0.3680, Train: 26.19%, Valid: 23.51%, Test: 22.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 30, Loss: 0.3489, Train: 23.75%, Valid: 20.86%, Test: 10.22%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 30, Loss: 0.3489, Train: 31.01%, Valid: 27.47%, Test: 15.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 30, Loss: 0.3489, Train: 32.82%, Valid: 29.08%, Test: 24.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 35, Loss: 0.3279, Train: 26.23%, Valid: 23.10%, Test: 9.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 35, Loss: 0.3279, Train: 33.06%, Valid: 29.29%, Test: 17.14%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 35, Loss: 0.3279, Train: 37.28%, Valid: 33.18%, Test: 26.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 40, Loss: 0.3106, Train: 16.38%, Valid: 14.28%, Test: 3.92%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 40, Loss: 0.3106, Train: 26.56%, Valid: 23.41%, Test: 12.11%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 40, Loss: 0.3106, Train: 33.29%, Valid: 29.62%, Test: 19.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 45, Loss: 0.2982, Train: 23.26%, Valid: 20.30%, Test: 5.48%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 45, Loss: 0.2982, Train: 29.30%, Valid: 25.67%, Test: 13.63%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 45, Loss: 0.2982, Train: 38.76%, Valid: 34.06%, Test: 32.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 50, Loss: 0.2850, Train: 20.60%, Valid: 18.03%, Test: 10.16%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 50, Loss: 0.2850, Train: 28.30%, Valid: 24.80%, Test: 18.89%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 50, Loss: 0.2850, Train: 34.96%, Valid: 30.89%, Test: 25.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 55, Loss: 0.2751, Train: 18.90%, Valid: 16.37%, Test: 5.71%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 55, Loss: 0.2751, Train: 31.26%, Valid: 27.20%, Test: 13.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 55, Loss: 0.2751, Train: 38.22%, Valid: 33.52%, Test: 23.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 60, Loss: 0.2679, Train: 25.90%, Valid: 22.41%, Test: 6.94%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 60, Loss: 0.2679, Train: 33.85%, Valid: 29.49%, Test: 16.38%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 60, Loss: 0.2679, Train: 41.31%, Valid: 36.29%, Test: 28.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 65, Loss: 0.2636, Train: 27.03%, Valid: 23.48%, Test: 8.65%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 65, Loss: 0.2636, Train: 36.86%, Valid: 32.14%, Test: 17.36%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 65, Loss: 0.2636, Train: 43.32%, Valid: 38.13%, Test: 26.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 70, Loss: 0.2557, Train: 25.20%, Valid: 21.69%, Test: 6.84%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 70, Loss: 0.2557, Train: 34.59%, Valid: 30.11%, Test: 14.14%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 70, Loss: 0.2557, Train: 41.77%, Valid: 36.58%, Test: 20.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 75, Loss: 0.2507, Train: 10.89%, Valid: 9.16%, Test: 6.63%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 75, Loss: 0.2507, Train: 27.40%, Valid: 23.63%, Test: 15.52%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 75, Loss: 0.2507, Train: 34.50%, Valid: 30.10%, Test: 25.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 80, Loss: 0.2443, Train: 23.81%, Valid: 20.52%, Test: 8.43%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 80, Loss: 0.2443, Train: 36.25%, Valid: 31.40%, Test: 20.52%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 80, Loss: 0.2443, Train: 41.09%, Valid: 35.71%, Test: 31.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 85, Loss: 0.2400, Train: 27.07%, Valid: 23.21%, Test: 21.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 85, Loss: 0.2400, Train: 38.16%, Valid: 32.86%, Test: 31.99%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 85, Loss: 0.2400, Train: 47.82%, Valid: 41.53%, Test: 40.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 90, Loss: 0.2365, Train: 23.20%, Valid: 19.82%, Test: 20.21%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 90, Loss: 0.2365, Train: 35.38%, Valid: 30.46%, Test: 32.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 90, Loss: 0.2365, Train: 45.23%, Valid: 39.40%, Test: 41.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 95, Loss: 0.2352, Train: 26.65%, Valid: 22.69%, Test: 25.64%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 95, Loss: 0.2352, Train: 39.13%, Valid: 33.61%, Test: 41.14%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 95, Loss: 0.2352, Train: 51.17%, Valid: 44.44%, Test: 45.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 100, Loss: 0.2305, Train: 23.42%, Valid: 20.10%, Test: 16.10%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 100, Loss: 0.2305, Train: 34.34%, Valid: 29.55%, Test: 23.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 100, Loss: 0.2305, Train: 40.93%, Valid: 35.38%, Test: 27.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 105, Loss: 0.2273, Train: 25.43%, Valid: 21.59%, Test: 20.14%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 105, Loss: 0.2273, Train: 38.89%, Valid: 33.25%, Test: 31.63%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 105, Loss: 0.2273, Train: 47.25%, Valid: 40.78%, Test: 41.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 110, Loss: 0.2260, Train: 26.20%, Valid: 22.34%, Test: 12.01%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 110, Loss: 0.2260, Train: 35.76%, Valid: 31.02%, Test: 23.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 110, Loss: 0.2260, Train: 44.51%, Valid: 38.69%, Test: 29.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 115, Loss: 0.2234, Train: 25.16%, Valid: 21.38%, Test: 17.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 115, Loss: 0.2234, Train: 37.00%, Valid: 31.73%, Test: 23.48%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 115, Loss: 0.2234, Train: 47.53%, Valid: 41.27%, Test: 38.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 120, Loss: 0.2187, Train: 28.91%, Valid: 24.75%, Test: 25.98%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 120, Loss: 0.2187, Train: 45.22%, Valid: 38.97%, Test: 35.03%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 120, Loss: 0.2187, Train: 49.24%, Valid: 42.54%, Test: 43.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 125, Loss: 0.2171, Train: 35.68%, Valid: 30.35%, Test: 26.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 125, Loss: 0.2171, Train: 45.34%, Valid: 38.77%, Test: 34.10%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 125, Loss: 0.2171, Train: 51.92%, Valid: 44.82%, Test: 42.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 130, Loss: 0.2154, Train: 29.95%, Valid: 25.54%, Test: 19.65%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 130, Loss: 0.2154, Train: 46.73%, Valid: 40.36%, Test: 31.17%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 130, Loss: 0.2154, Train: 53.37%, Valid: 46.39%, Test: 40.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 135, Loss: 0.2124, Train: 28.17%, Valid: 24.12%, Test: 22.80%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 135, Loss: 0.2124, Train: 42.79%, Valid: 36.67%, Test: 32.87%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 135, Loss: 0.2124, Train: 50.62%, Valid: 43.68%, Test: 44.94%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 05, Epoch: 140, Loss: 0.2088, Train: 27.81%, Valid: 23.55%, Test: 36.97%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 140, Loss: 0.2088, Train: 44.92%, Valid: 38.36%, Test: 47.96%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 140, Loss: 0.2088, Train: 56.06%, Valid: 48.42%, Test: 53.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 145, Loss: 0.2080, Train: 30.41%, Valid: 25.89%, Test: 22.65%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 145, Loss: 0.2080, Train: 45.48%, Valid: 39.10%, Test: 31.25%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 145, Loss: 0.2080, Train: 51.79%, Valid: 44.89%, Test: 43.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 150, Loss: 0.2050, Train: 39.44%, Valid: 33.61%, Test: 23.56%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 150, Loss: 0.2050, Train: 54.65%, Valid: 47.31%, Test: 32.50%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 150, Loss: 0.2050, Train: 60.57%, Valid: 52.79%, Test: 48.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 155, Loss: 0.2079, Train: 33.32%, Valid: 28.31%, Test: 24.53%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 155, Loss: 0.2079, Train: 46.48%, Valid: 39.98%, Test: 30.84%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 155, Loss: 0.2079, Train: 53.56%, Valid: 46.33%, Test: 38.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 160, Loss: 0.2018, Train: 36.30%, Valid: 31.02%, Test: 20.89%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 160, Loss: 0.2018, Train: 50.69%, Valid: 43.63%, Test: 30.90%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 160, Loss: 0.2018, Train: 55.39%, Valid: 47.85%, Test: 37.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 165, Loss: 0.2004, Train: 49.20%, Valid: 42.31%, Test: 27.66%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 165, Loss: 0.2004, Train: 62.07%, Valid: 54.04%, Test: 39.64%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 165, Loss: 0.2004, Train: 65.54%, Valid: 57.33%, Test: 48.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 170, Loss: 0.1999, Train: 45.30%, Valid: 38.93%, Test: 22.10%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 170, Loss: 0.1999, Train: 56.11%, Valid: 48.47%, Test: 32.68%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 170, Loss: 0.1999, Train: 61.24%, Valid: 53.09%, Test: 44.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 175, Loss: 0.1994, Train: 47.71%, Valid: 40.77%, Test: 17.64%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 175, Loss: 0.1994, Train: 62.47%, Valid: 54.11%, Test: 34.32%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 175, Loss: 0.1994, Train: 64.42%, Valid: 55.96%, Test: 45.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 180, Loss: 0.1962, Train: 51.79%, Valid: 44.32%, Test: 17.89%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 180, Loss: 0.1962, Train: 63.55%, Valid: 55.18%, Test: 32.32%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 180, Loss: 0.1962, Train: 66.06%, Valid: 57.44%, Test: 41.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 185, Loss: 0.1940, Train: 53.87%, Valid: 46.21%, Test: 28.79%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 185, Loss: 0.1940, Train: 63.70%, Valid: 55.10%, Test: 43.36%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 185, Loss: 0.1940, Train: 68.80%, Valid: 59.97%, Test: 56.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 190, Loss: 0.1936, Train: 53.43%, Valid: 45.77%, Test: 20.02%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 190, Loss: 0.1936, Train: 59.72%, Valid: 51.33%, Test: 38.45%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 190, Loss: 0.1936, Train: 63.91%, Valid: 55.26%, Test: 43.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 195, Loss: 0.1923, Train: 55.93%, Valid: 47.98%, Test: 22.08%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 195, Loss: 0.1923, Train: 63.28%, Valid: 54.77%, Test: 33.24%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 195, Loss: 0.1923, Train: 67.51%, Valid: 58.78%, Test: 43.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 200, Loss: 0.1926, Train: 46.15%, Valid: 39.11%, Test: 12.41%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 200, Loss: 0.1926, Train: 61.31%, Valid: 52.99%, Test: 29.93%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 200, Loss: 0.1926, Train: 64.81%, Valid: 56.22%, Test: 43.61%\n",
      "---\n",
      "Hits@10\n",
      "Run 05:\n",
      "Highest Train: 55.93\n",
      "Highest Valid: 47.98\n",
      "  Final Train: 55.93\n",
      "   Final Test: 22.08\n",
      "Hits@20\n",
      "Run 05:\n",
      "Highest Train: 63.70\n",
      "Highest Valid: 55.18\n",
      "  Final Train: 63.55\n",
      "   Final Test: 32.32\n",
      "Hits@30\n",
      "Run 05:\n",
      "Highest Train: 68.80\n",
      "Highest Valid: 59.97\n",
      "  Final Train: 68.80\n",
      "   Final Test: 56.68\n",
      "Hits@10\n",
      "Run: 06, Epoch: 05, Loss: 0.6729, Train: 0.10%, Valid: 0.09%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 05, Loss: 0.6729, Train: 3.78%, Valid: 3.27%, Test: 0.12%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 05, Loss: 0.6729, Train: 9.63%, Valid: 8.53%, Test: 0.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 10, Loss: 0.5227, Train: 15.08%, Valid: 13.42%, Test: 5.04%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 10, Loss: 0.5227, Train: 19.63%, Valid: 17.47%, Test: 7.72%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 10, Loss: 0.5227, Train: 22.63%, Valid: 20.26%, Test: 10.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 15, Loss: 0.4486, Train: 11.09%, Valid: 9.76%, Test: 5.41%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 15, Loss: 0.4486, Train: 21.29%, Valid: 19.26%, Test: 9.59%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 15, Loss: 0.4486, Train: 24.70%, Valid: 22.36%, Test: 12.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 20, Loss: 0.3833, Train: 11.01%, Valid: 9.68%, Test: 11.42%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 20, Loss: 0.3833, Train: 19.47%, Valid: 17.42%, Test: 14.08%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 20, Loss: 0.3833, Train: 22.67%, Valid: 20.33%, Test: 17.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 25, Loss: 0.3579, Train: 14.95%, Valid: 13.08%, Test: 4.05%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 25, Loss: 0.3579, Train: 26.08%, Valid: 23.17%, Test: 12.72%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 25, Loss: 0.3579, Train: 28.71%, Valid: 25.54%, Test: 20.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 30, Loss: 0.3370, Train: 21.30%, Valid: 18.89%, Test: 6.54%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 30, Loss: 0.3370, Train: 28.93%, Valid: 25.75%, Test: 13.03%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 30, Loss: 0.3370, Train: 37.81%, Valid: 34.09%, Test: 20.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 35, Loss: 0.3178, Train: 22.96%, Valid: 20.25%, Test: 6.58%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 35, Loss: 0.3178, Train: 29.97%, Valid: 26.70%, Test: 16.11%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 35, Loss: 0.3178, Train: 35.32%, Valid: 31.49%, Test: 24.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 40, Loss: 0.3046, Train: 23.52%, Valid: 20.69%, Test: 7.65%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 40, Loss: 0.3046, Train: 34.35%, Valid: 30.47%, Test: 17.09%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 40, Loss: 0.3046, Train: 40.97%, Valid: 36.49%, Test: 24.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 45, Loss: 0.2968, Train: 21.06%, Valid: 18.47%, Test: 7.51%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 45, Loss: 0.2968, Train: 31.51%, Valid: 27.82%, Test: 21.68%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 45, Loss: 0.2968, Train: 36.18%, Valid: 32.08%, Test: 28.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 50, Loss: 0.2856, Train: 21.79%, Valid: 18.93%, Test: 5.95%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 50, Loss: 0.2856, Train: 30.17%, Valid: 26.66%, Test: 16.66%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 50, Loss: 0.2856, Train: 36.88%, Valid: 32.75%, Test: 20.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 55, Loss: 0.2764, Train: 19.38%, Valid: 16.85%, Test: 7.57%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 55, Loss: 0.2764, Train: 31.26%, Valid: 27.65%, Test: 13.82%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 55, Loss: 0.2764, Train: 38.72%, Valid: 34.40%, Test: 20.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 60, Loss: 0.2662, Train: 21.06%, Valid: 18.34%, Test: 5.10%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 60, Loss: 0.2662, Train: 28.18%, Valid: 24.59%, Test: 17.83%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 60, Loss: 0.2662, Train: 35.39%, Valid: 31.17%, Test: 25.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 65, Loss: 0.2618, Train: 20.99%, Valid: 18.12%, Test: 5.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 65, Loss: 0.2618, Train: 35.70%, Valid: 31.07%, Test: 15.20%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 65, Loss: 0.2618, Train: 44.41%, Valid: 39.08%, Test: 20.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 70, Loss: 0.2538, Train: 19.98%, Valid: 17.16%, Test: 11.33%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 70, Loss: 0.2538, Train: 33.99%, Valid: 29.55%, Test: 21.23%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 70, Loss: 0.2538, Train: 42.71%, Valid: 37.53%, Test: 33.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 75, Loss: 0.2483, Train: 25.00%, Valid: 21.34%, Test: 9.27%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 75, Loss: 0.2483, Train: 36.45%, Valid: 31.78%, Test: 20.74%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 75, Loss: 0.2483, Train: 42.38%, Valid: 37.17%, Test: 33.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 80, Loss: 0.2438, Train: 27.20%, Valid: 23.51%, Test: 12.81%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 80, Loss: 0.2438, Train: 40.99%, Valid: 35.75%, Test: 24.77%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 80, Loss: 0.2438, Train: 47.54%, Valid: 41.70%, Test: 37.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 85, Loss: 0.2390, Train: 25.75%, Valid: 22.22%, Test: 19.12%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 85, Loss: 0.2390, Train: 42.29%, Valid: 36.78%, Test: 28.50%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 85, Loss: 0.2390, Train: 50.73%, Valid: 44.62%, Test: 37.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 90, Loss: 0.2345, Train: 27.48%, Valid: 23.72%, Test: 14.32%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 90, Loss: 0.2345, Train: 41.36%, Valid: 35.93%, Test: 31.23%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 90, Loss: 0.2345, Train: 46.56%, Valid: 40.69%, Test: 38.19%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 06, Epoch: 95, Loss: 0.2320, Train: 32.21%, Valid: 27.48%, Test: 18.25%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 95, Loss: 0.2320, Train: 48.82%, Valid: 42.50%, Test: 31.90%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 95, Loss: 0.2320, Train: 52.42%, Valid: 45.94%, Test: 36.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 100, Loss: 0.2282, Train: 24.15%, Valid: 20.68%, Test: 18.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 100, Loss: 0.2282, Train: 38.09%, Valid: 32.85%, Test: 25.41%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 100, Loss: 0.2282, Train: 44.00%, Valid: 38.23%, Test: 31.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 105, Loss: 0.2260, Train: 20.10%, Valid: 17.10%, Test: 20.92%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 105, Loss: 0.2260, Train: 37.68%, Valid: 32.50%, Test: 30.78%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 105, Loss: 0.2260, Train: 45.81%, Valid: 39.70%, Test: 35.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 110, Loss: 0.2233, Train: 27.61%, Valid: 23.70%, Test: 23.67%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 110, Loss: 0.2233, Train: 46.17%, Valid: 40.12%, Test: 32.13%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 110, Loss: 0.2233, Train: 55.22%, Valid: 48.25%, Test: 41.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 115, Loss: 0.2210, Train: 25.94%, Valid: 22.03%, Test: 23.01%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 115, Loss: 0.2210, Train: 35.16%, Valid: 30.07%, Test: 29.74%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 115, Loss: 0.2210, Train: 42.48%, Valid: 36.82%, Test: 39.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 120, Loss: 0.2203, Train: 32.74%, Valid: 28.13%, Test: 21.50%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 120, Loss: 0.2203, Train: 45.73%, Valid: 39.63%, Test: 29.97%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 120, Loss: 0.2203, Train: 53.89%, Valid: 47.08%, Test: 42.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 125, Loss: 0.2147, Train: 32.66%, Valid: 27.87%, Test: 19.09%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 125, Loss: 0.2147, Train: 42.73%, Valid: 36.78%, Test: 32.69%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 125, Loss: 0.2147, Train: 50.77%, Valid: 44.09%, Test: 42.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 130, Loss: 0.2121, Train: 33.16%, Valid: 28.13%, Test: 23.07%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 130, Loss: 0.2121, Train: 46.75%, Valid: 40.40%, Test: 40.53%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 130, Loss: 0.2121, Train: 57.04%, Valid: 49.75%, Test: 49.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 135, Loss: 0.2111, Train: 29.53%, Valid: 25.32%, Test: 20.10%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 135, Loss: 0.2111, Train: 44.46%, Valid: 38.25%, Test: 32.96%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 135, Loss: 0.2111, Train: 51.99%, Valid: 45.13%, Test: 42.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 140, Loss: 0.2079, Train: 34.64%, Valid: 29.61%, Test: 17.61%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 140, Loss: 0.2079, Train: 48.71%, Valid: 42.10%, Test: 29.87%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 140, Loss: 0.2079, Train: 55.67%, Valid: 48.38%, Test: 43.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 145, Loss: 0.2064, Train: 37.03%, Valid: 31.76%, Test: 25.12%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 145, Loss: 0.2064, Train: 49.48%, Valid: 42.68%, Test: 39.11%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 145, Loss: 0.2064, Train: 59.08%, Valid: 51.55%, Test: 51.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 150, Loss: 0.2056, Train: 31.60%, Valid: 26.72%, Test: 22.35%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 150, Loss: 0.2056, Train: 41.79%, Valid: 35.83%, Test: 40.29%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 150, Loss: 0.2056, Train: 52.53%, Valid: 45.37%, Test: 50.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 155, Loss: 0.2056, Train: 38.79%, Valid: 33.19%, Test: 21.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 155, Loss: 0.2056, Train: 47.22%, Valid: 40.64%, Test: 31.71%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 155, Loss: 0.2056, Train: 56.32%, Valid: 48.82%, Test: 39.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 160, Loss: 0.2027, Train: 41.62%, Valid: 35.65%, Test: 24.08%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 160, Loss: 0.2027, Train: 52.09%, Valid: 44.93%, Test: 36.50%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 160, Loss: 0.2027, Train: 58.80%, Valid: 51.10%, Test: 43.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 165, Loss: 0.1989, Train: 51.06%, Valid: 43.79%, Test: 25.06%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 165, Loss: 0.1989, Train: 59.55%, Valid: 51.48%, Test: 39.58%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 165, Loss: 0.1989, Train: 64.91%, Valid: 56.52%, Test: 49.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 170, Loss: 0.1970, Train: 53.97%, Valid: 46.52%, Test: 19.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 170, Loss: 0.1970, Train: 61.98%, Valid: 53.79%, Test: 34.44%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 170, Loss: 0.1970, Train: 64.98%, Valid: 56.53%, Test: 41.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 175, Loss: 0.1971, Train: 49.48%, Valid: 42.50%, Test: 18.13%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 175, Loss: 0.1971, Train: 55.18%, Valid: 47.60%, Test: 32.75%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 175, Loss: 0.1971, Train: 60.85%, Valid: 52.76%, Test: 38.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 180, Loss: 0.1955, Train: 50.39%, Valid: 43.27%, Test: 26.51%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 180, Loss: 0.1955, Train: 61.17%, Valid: 52.87%, Test: 35.92%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 180, Loss: 0.1955, Train: 68.97%, Valid: 60.07%, Test: 46.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 185, Loss: 0.1931, Train: 56.52%, Valid: 48.81%, Test: 19.68%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 185, Loss: 0.1931, Train: 62.82%, Valid: 54.62%, Test: 28.53%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 185, Loss: 0.1931, Train: 66.38%, Valid: 57.77%, Test: 40.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 190, Loss: 0.1929, Train: 50.14%, Valid: 42.76%, Test: 13.32%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 190, Loss: 0.1929, Train: 60.55%, Valid: 52.29%, Test: 28.59%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 190, Loss: 0.1929, Train: 64.42%, Valid: 55.90%, Test: 35.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 195, Loss: 0.1915, Train: 40.61%, Valid: 34.05%, Test: 11.63%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 195, Loss: 0.1915, Train: 64.74%, Valid: 56.15%, Test: 29.25%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 195, Loss: 0.1915, Train: 68.86%, Valid: 60.08%, Test: 35.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 200, Loss: 0.1896, Train: 46.54%, Valid: 39.48%, Test: 14.34%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 200, Loss: 0.1896, Train: 65.87%, Valid: 57.25%, Test: 32.89%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 200, Loss: 0.1896, Train: 68.50%, Valid: 59.69%, Test: 48.59%\n",
      "---\n",
      "Hits@10\n",
      "Run 06:\n",
      "Highest Train: 56.52\n",
      "Highest Valid: 48.81\n",
      "  Final Train: 56.52\n",
      "   Final Test: 19.68\n",
      "Hits@20\n",
      "Run 06:\n",
      "Highest Train: 65.87\n",
      "Highest Valid: 57.25\n",
      "  Final Train: 65.87\n",
      "   Final Test: 32.89\n",
      "Hits@30\n",
      "Run 06:\n",
      "Highest Train: 68.97\n",
      "Highest Valid: 60.08\n",
      "  Final Train: 68.86\n",
      "   Final Test: 35.81\n",
      "Hits@10\n",
      "Run: 07, Epoch: 05, Loss: 0.6669, Train: 0.96%, Valid: 0.80%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 05, Loss: 0.6669, Train: 8.12%, Valid: 7.19%, Test: 1.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 05, Loss: 0.6669, Train: 10.82%, Valid: 9.66%, Test: 6.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 10, Loss: 0.5197, Train: 17.67%, Valid: 15.70%, Test: 9.52%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 10, Loss: 0.5197, Train: 25.52%, Valid: 23.11%, Test: 16.42%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 10, Loss: 0.5197, Train: 27.66%, Valid: 25.19%, Test: 20.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 15, Loss: 0.4409, Train: 25.72%, Valid: 23.12%, Test: 14.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 15, Loss: 0.4409, Train: 28.89%, Valid: 26.22%, Test: 18.39%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 15, Loss: 0.4409, Train: 31.15%, Valid: 28.48%, Test: 21.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 20, Loss: 0.3913, Train: 22.88%, Valid: 20.55%, Test: 11.63%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 20, Loss: 0.3913, Train: 30.40%, Valid: 27.32%, Test: 19.11%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 20, Loss: 0.3913, Train: 33.94%, Valid: 30.63%, Test: 23.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 25, Loss: 0.3674, Train: 24.15%, Valid: 21.74%, Test: 11.05%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 25, Loss: 0.3674, Train: 33.12%, Valid: 29.82%, Test: 18.47%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 25, Loss: 0.3674, Train: 37.65%, Valid: 34.07%, Test: 24.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 30, Loss: 0.3431, Train: 20.60%, Valid: 18.36%, Test: 3.79%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 30, Loss: 0.3431, Train: 27.49%, Valid: 24.59%, Test: 14.25%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 30, Loss: 0.3431, Train: 29.59%, Valid: 26.52%, Test: 23.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 35, Loss: 0.3204, Train: 17.54%, Valid: 15.35%, Test: 4.16%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 35, Loss: 0.3204, Train: 28.06%, Valid: 24.93%, Test: 14.83%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 35, Loss: 0.3204, Train: 29.45%, Valid: 26.25%, Test: 19.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 40, Loss: 0.3084, Train: 20.34%, Valid: 17.93%, Test: 3.86%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 40, Loss: 0.3084, Train: 28.42%, Valid: 25.18%, Test: 12.07%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 40, Loss: 0.3084, Train: 38.92%, Valid: 34.61%, Test: 21.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 45, Loss: 0.2906, Train: 17.26%, Valid: 14.98%, Test: 2.89%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 45, Loss: 0.2906, Train: 25.62%, Valid: 22.44%, Test: 12.20%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 45, Loss: 0.2906, Train: 30.67%, Valid: 26.96%, Test: 23.93%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 07, Epoch: 50, Loss: 0.2820, Train: 18.69%, Valid: 16.24%, Test: 5.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 50, Loss: 0.2820, Train: 27.80%, Valid: 24.47%, Test: 13.71%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 50, Loss: 0.2820, Train: 34.72%, Valid: 30.70%, Test: 20.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 55, Loss: 0.2755, Train: 8.66%, Valid: 7.35%, Test: 7.98%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 55, Loss: 0.2755, Train: 26.08%, Valid: 22.55%, Test: 19.88%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 55, Loss: 0.2755, Train: 32.84%, Valid: 28.86%, Test: 27.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 60, Loss: 0.2687, Train: 15.42%, Valid: 13.03%, Test: 5.00%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 60, Loss: 0.2687, Train: 24.23%, Valid: 21.02%, Test: 12.95%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 60, Loss: 0.2687, Train: 30.17%, Valid: 26.50%, Test: 20.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 65, Loss: 0.2631, Train: 22.11%, Valid: 19.17%, Test: 5.81%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 65, Loss: 0.2631, Train: 36.74%, Valid: 32.14%, Test: 15.52%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 65, Loss: 0.2631, Train: 39.58%, Valid: 34.67%, Test: 27.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 70, Loss: 0.2551, Train: 19.26%, Valid: 16.67%, Test: 9.05%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 70, Loss: 0.2551, Train: 31.47%, Valid: 27.23%, Test: 16.40%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 70, Loss: 0.2551, Train: 41.03%, Valid: 35.83%, Test: 22.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 75, Loss: 0.2504, Train: 19.29%, Valid: 16.48%, Test: 7.84%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 75, Loss: 0.2504, Train: 30.86%, Valid: 26.78%, Test: 14.67%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 75, Loss: 0.2504, Train: 37.35%, Valid: 32.52%, Test: 19.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 80, Loss: 0.2455, Train: 21.98%, Valid: 18.94%, Test: 9.36%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 80, Loss: 0.2455, Train: 34.32%, Valid: 29.68%, Test: 18.85%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 80, Loss: 0.2455, Train: 44.34%, Valid: 38.73%, Test: 29.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 85, Loss: 0.2422, Train: 24.73%, Valid: 21.31%, Test: 6.86%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 85, Loss: 0.2422, Train: 34.60%, Valid: 30.11%, Test: 13.10%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 85, Loss: 0.2422, Train: 42.83%, Valid: 37.39%, Test: 21.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 90, Loss: 0.2393, Train: 24.38%, Valid: 20.88%, Test: 10.08%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 90, Loss: 0.2393, Train: 40.11%, Valid: 34.70%, Test: 20.37%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 90, Loss: 0.2393, Train: 49.89%, Valid: 43.62%, Test: 34.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 95, Loss: 0.2332, Train: 31.95%, Valid: 27.66%, Test: 16.55%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 95, Loss: 0.2332, Train: 39.75%, Valid: 34.46%, Test: 24.45%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 95, Loss: 0.2332, Train: 43.96%, Valid: 38.24%, Test: 35.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 100, Loss: 0.2300, Train: 35.33%, Valid: 30.68%, Test: 13.61%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 100, Loss: 0.2300, Train: 45.89%, Valid: 39.84%, Test: 23.37%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 100, Loss: 0.2300, Train: 53.62%, Valid: 46.82%, Test: 36.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 105, Loss: 0.2296, Train: 30.08%, Valid: 26.09%, Test: 7.63%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 105, Loss: 0.2296, Train: 46.24%, Valid: 40.25%, Test: 17.09%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 105, Loss: 0.2296, Train: 53.47%, Valid: 46.81%, Test: 32.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 110, Loss: 0.2229, Train: 30.91%, Valid: 26.60%, Test: 21.73%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 110, Loss: 0.2229, Train: 44.53%, Valid: 38.71%, Test: 31.26%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 110, Loss: 0.2229, Train: 54.56%, Valid: 47.76%, Test: 36.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 115, Loss: 0.2217, Train: 27.57%, Valid: 23.68%, Test: 18.05%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 115, Loss: 0.2217, Train: 41.81%, Valid: 36.06%, Test: 32.34%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 115, Loss: 0.2217, Train: 49.18%, Valid: 42.49%, Test: 38.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 120, Loss: 0.2192, Train: 32.54%, Valid: 27.94%, Test: 25.12%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 120, Loss: 0.2192, Train: 46.41%, Valid: 40.16%, Test: 43.58%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 120, Loss: 0.2192, Train: 53.10%, Valid: 46.22%, Test: 50.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 125, Loss: 0.2184, Train: 33.06%, Valid: 28.45%, Test: 15.91%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 125, Loss: 0.2184, Train: 43.09%, Valid: 37.49%, Test: 23.45%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 125, Loss: 0.2184, Train: 50.29%, Valid: 43.81%, Test: 32.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 130, Loss: 0.2151, Train: 37.05%, Valid: 32.01%, Test: 20.20%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 130, Loss: 0.2151, Train: 45.68%, Valid: 39.57%, Test: 29.31%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 130, Loss: 0.2151, Train: 51.15%, Valid: 44.49%, Test: 40.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 135, Loss: 0.2122, Train: 32.18%, Valid: 27.62%, Test: 15.80%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 135, Loss: 0.2122, Train: 46.83%, Valid: 40.55%, Test: 26.67%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 135, Loss: 0.2122, Train: 51.78%, Valid: 45.09%, Test: 34.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 140, Loss: 0.2119, Train: 40.75%, Valid: 34.87%, Test: 18.93%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 140, Loss: 0.2119, Train: 54.42%, Valid: 47.17%, Test: 43.18%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 140, Loss: 0.2119, Train: 58.64%, Valid: 51.16%, Test: 53.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 145, Loss: 0.2084, Train: 38.70%, Valid: 33.11%, Test: 18.51%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 145, Loss: 0.2084, Train: 52.31%, Valid: 45.27%, Test: 33.87%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 145, Loss: 0.2084, Train: 57.61%, Valid: 50.04%, Test: 46.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 150, Loss: 0.2056, Train: 37.96%, Valid: 32.47%, Test: 20.98%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 150, Loss: 0.2056, Train: 47.90%, Valid: 41.37%, Test: 24.36%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 150, Loss: 0.2056, Train: 54.86%, Valid: 47.46%, Test: 36.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 155, Loss: 0.2043, Train: 37.84%, Valid: 32.26%, Test: 13.27%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 155, Loss: 0.2043, Train: 52.75%, Valid: 45.53%, Test: 23.79%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 155, Loss: 0.2043, Train: 57.32%, Valid: 49.66%, Test: 36.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 160, Loss: 0.2024, Train: 45.13%, Valid: 38.76%, Test: 13.88%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 160, Loss: 0.2024, Train: 56.76%, Valid: 49.21%, Test: 24.26%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 160, Loss: 0.2024, Train: 61.72%, Valid: 53.79%, Test: 38.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 165, Loss: 0.2023, Train: 49.66%, Valid: 42.72%, Test: 26.18%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 165, Loss: 0.2023, Train: 60.93%, Valid: 53.01%, Test: 39.74%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 165, Loss: 0.2023, Train: 65.14%, Valid: 56.94%, Test: 51.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 170, Loss: 0.1986, Train: 41.20%, Valid: 34.99%, Test: 13.44%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 170, Loss: 0.1986, Train: 53.93%, Valid: 46.48%, Test: 20.72%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 170, Loss: 0.1986, Train: 59.55%, Valid: 51.61%, Test: 28.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 175, Loss: 0.2003, Train: 49.73%, Valid: 42.68%, Test: 16.34%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 175, Loss: 0.2003, Train: 59.84%, Valid: 51.86%, Test: 28.70%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 175, Loss: 0.2003, Train: 63.93%, Valid: 55.70%, Test: 40.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 180, Loss: 0.1962, Train: 51.22%, Valid: 43.85%, Test: 12.79%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 180, Loss: 0.1962, Train: 61.01%, Valid: 52.88%, Test: 26.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 180, Loss: 0.1962, Train: 63.40%, Valid: 54.98%, Test: 39.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 185, Loss: 0.1950, Train: 51.36%, Valid: 43.83%, Test: 19.30%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 185, Loss: 0.1950, Train: 60.84%, Valid: 52.57%, Test: 35.42%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 185, Loss: 0.1950, Train: 66.90%, Valid: 58.17%, Test: 45.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 190, Loss: 0.1927, Train: 41.79%, Valid: 35.48%, Test: 15.78%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 190, Loss: 0.1927, Train: 53.94%, Valid: 46.49%, Test: 23.28%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 190, Loss: 0.1927, Train: 61.66%, Valid: 53.48%, Test: 32.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 195, Loss: 0.1925, Train: 53.75%, Valid: 46.10%, Test: 19.14%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 195, Loss: 0.1925, Train: 60.24%, Valid: 51.95%, Test: 35.12%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 195, Loss: 0.1925, Train: 64.63%, Valid: 55.98%, Test: 48.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 200, Loss: 0.1916, Train: 56.24%, Valid: 48.22%, Test: 20.42%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 200, Loss: 0.1916, Train: 63.40%, Valid: 54.87%, Test: 30.28%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 200, Loss: 0.1916, Train: 68.01%, Valid: 59.11%, Test: 35.62%\n",
      "---\n",
      "Hits@10\n",
      "Run 07:\n",
      "Highest Train: 56.24\n",
      "Highest Valid: 48.22\n",
      "  Final Train: 56.24\n",
      "   Final Test: 20.42\n",
      "Hits@20\n",
      "Run 07:\n",
      "Highest Train: 63.40\n",
      "Highest Valid: 54.87\n",
      "  Final Train: 63.40\n",
      "   Final Test: 30.28\n",
      "Hits@30\n",
      "Run 07:\n",
      "Highest Train: 68.01\n",
      "Highest Valid: 59.11\n",
      "  Final Train: 68.01\n",
      "   Final Test: 35.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 05, Loss: 0.6589, Train: 4.74%, Valid: 4.09%, Test: 0.39%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 05, Loss: 0.6589, Train: 11.32%, Valid: 9.82%, Test: 2.77%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 05, Loss: 0.6589, Train: 15.71%, Valid: 14.17%, Test: 4.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 10, Loss: 0.5112, Train: 14.76%, Valid: 13.13%, Test: 10.73%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 10, Loss: 0.5112, Train: 18.53%, Valid: 16.55%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 10, Loss: 0.5112, Train: 23.69%, Valid: 21.39%, Test: 18.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 15, Loss: 0.4368, Train: 25.64%, Valid: 23.22%, Test: 14.03%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 15, Loss: 0.4368, Train: 28.99%, Valid: 26.46%, Test: 20.59%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 15, Loss: 0.4368, Train: 32.02%, Valid: 29.37%, Test: 26.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 20, Loss: 0.3875, Train: 18.12%, Valid: 15.88%, Test: 9.77%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 20, Loss: 0.3875, Train: 23.38%, Valid: 20.80%, Test: 17.52%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 20, Loss: 0.3875, Train: 30.54%, Valid: 27.50%, Test: 21.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 25, Loss: 0.3664, Train: 20.51%, Valid: 18.30%, Test: 8.26%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 25, Loss: 0.3664, Train: 25.41%, Valid: 22.79%, Test: 14.73%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 25, Loss: 0.3664, Train: 29.98%, Valid: 27.11%, Test: 21.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 30, Loss: 0.3378, Train: 17.37%, Valid: 15.16%, Test: 12.07%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 30, Loss: 0.3378, Train: 26.95%, Valid: 23.96%, Test: 18.87%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 30, Loss: 0.3378, Train: 35.17%, Valid: 31.52%, Test: 23.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 35, Loss: 0.3207, Train: 13.26%, Valid: 11.51%, Test: 4.39%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 35, Loss: 0.3207, Train: 26.14%, Valid: 23.16%, Test: 14.19%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 35, Loss: 0.3207, Train: 30.29%, Valid: 26.88%, Test: 21.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 40, Loss: 0.3029, Train: 15.02%, Valid: 12.92%, Test: 5.90%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 40, Loss: 0.3029, Train: 23.50%, Valid: 20.60%, Test: 15.76%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 40, Loss: 0.3029, Train: 29.85%, Valid: 26.22%, Test: 23.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 45, Loss: 0.2965, Train: 17.10%, Valid: 14.85%, Test: 5.34%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 45, Loss: 0.2965, Train: 28.95%, Valid: 25.35%, Test: 12.54%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 45, Loss: 0.2965, Train: 34.26%, Valid: 30.29%, Test: 20.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 50, Loss: 0.2851, Train: 18.31%, Valid: 15.69%, Test: 4.83%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 50, Loss: 0.2851, Train: 26.23%, Valid: 22.73%, Test: 9.88%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 50, Loss: 0.2851, Train: 32.05%, Valid: 28.13%, Test: 19.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 55, Loss: 0.2794, Train: 23.77%, Valid: 20.74%, Test: 6.57%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 55, Loss: 0.2794, Train: 35.18%, Valid: 30.89%, Test: 11.45%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 55, Loss: 0.2794, Train: 39.64%, Valid: 34.99%, Test: 28.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 60, Loss: 0.2701, Train: 8.35%, Valid: 7.04%, Test: 8.78%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 60, Loss: 0.2701, Train: 22.28%, Valid: 19.36%, Test: 15.07%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 60, Loss: 0.2701, Train: 27.87%, Valid: 24.31%, Test: 22.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 65, Loss: 0.2642, Train: 25.10%, Valid: 21.85%, Test: 11.52%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 65, Loss: 0.2642, Train: 42.41%, Valid: 37.36%, Test: 19.00%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 65, Loss: 0.2642, Train: 46.90%, Valid: 41.49%, Test: 26.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 70, Loss: 0.2614, Train: 22.09%, Valid: 19.06%, Test: 13.28%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 70, Loss: 0.2614, Train: 37.46%, Valid: 32.93%, Test: 23.84%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 70, Loss: 0.2614, Train: 45.10%, Valid: 40.01%, Test: 34.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 75, Loss: 0.2517, Train: 28.97%, Valid: 25.17%, Test: 9.04%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 75, Loss: 0.2517, Train: 37.18%, Valid: 32.46%, Test: 17.77%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 75, Loss: 0.2517, Train: 45.36%, Valid: 39.99%, Test: 27.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 80, Loss: 0.2468, Train: 34.04%, Valid: 29.29%, Test: 15.08%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 80, Loss: 0.2468, Train: 43.77%, Valid: 38.23%, Test: 20.14%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 80, Loss: 0.2468, Train: 49.56%, Valid: 43.59%, Test: 34.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 85, Loss: 0.2440, Train: 30.29%, Valid: 26.15%, Test: 16.59%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 85, Loss: 0.2440, Train: 41.67%, Valid: 36.23%, Test: 26.14%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 85, Loss: 0.2440, Train: 49.07%, Valid: 42.92%, Test: 35.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 90, Loss: 0.2386, Train: 21.57%, Valid: 18.51%, Test: 15.09%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 90, Loss: 0.2386, Train: 38.28%, Valid: 33.02%, Test: 28.20%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 90, Loss: 0.2386, Train: 45.82%, Valid: 39.91%, Test: 35.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 95, Loss: 0.2351, Train: 27.22%, Valid: 23.31%, Test: 27.62%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 95, Loss: 0.2351, Train: 44.84%, Valid: 39.01%, Test: 37.88%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 95, Loss: 0.2351, Train: 50.02%, Valid: 43.88%, Test: 45.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 100, Loss: 0.2305, Train: 27.47%, Valid: 23.46%, Test: 25.06%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 100, Loss: 0.2305, Train: 42.94%, Valid: 37.07%, Test: 34.12%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 100, Loss: 0.2305, Train: 50.16%, Valid: 43.72%, Test: 41.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 105, Loss: 0.2288, Train: 35.58%, Valid: 30.74%, Test: 25.05%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 105, Loss: 0.2288, Train: 47.03%, Valid: 40.96%, Test: 33.59%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 105, Loss: 0.2288, Train: 54.99%, Valid: 48.31%, Test: 43.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 110, Loss: 0.2252, Train: 31.59%, Valid: 26.95%, Test: 37.70%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 110, Loss: 0.2252, Train: 44.68%, Valid: 38.46%, Test: 45.84%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 110, Loss: 0.2252, Train: 53.35%, Valid: 46.31%, Test: 51.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 115, Loss: 0.2219, Train: 29.35%, Valid: 25.12%, Test: 30.42%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 115, Loss: 0.2219, Train: 42.73%, Valid: 36.77%, Test: 38.25%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 115, Loss: 0.2219, Train: 51.29%, Valid: 44.33%, Test: 42.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 120, Loss: 0.2195, Train: 26.57%, Valid: 22.61%, Test: 25.28%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 120, Loss: 0.2195, Train: 39.27%, Valid: 33.72%, Test: 42.36%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 120, Loss: 0.2195, Train: 49.25%, Valid: 42.64%, Test: 51.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 125, Loss: 0.2155, Train: 35.40%, Valid: 30.40%, Test: 26.60%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 125, Loss: 0.2155, Train: 47.21%, Valid: 40.73%, Test: 37.26%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 125, Loss: 0.2155, Train: 54.47%, Valid: 47.40%, Test: 43.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 130, Loss: 0.2143, Train: 29.80%, Valid: 25.39%, Test: 24.98%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 130, Loss: 0.2143, Train: 44.48%, Valid: 38.21%, Test: 35.75%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 130, Loss: 0.2143, Train: 50.37%, Valid: 43.38%, Test: 43.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 135, Loss: 0.2129, Train: 47.23%, Valid: 40.76%, Test: 45.76%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 135, Loss: 0.2129, Train: 56.31%, Valid: 49.04%, Test: 49.88%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 135, Loss: 0.2129, Train: 61.24%, Valid: 53.64%, Test: 58.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 140, Loss: 0.2118, Train: 29.16%, Valid: 24.84%, Test: 26.24%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 140, Loss: 0.2118, Train: 45.73%, Valid: 39.18%, Test: 38.31%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 140, Loss: 0.2118, Train: 51.64%, Valid: 44.56%, Test: 43.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 145, Loss: 0.2081, Train: 34.75%, Valid: 29.34%, Test: 28.34%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 145, Loss: 0.2081, Train: 47.10%, Valid: 40.41%, Test: 36.55%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 145, Loss: 0.2081, Train: 53.83%, Valid: 46.45%, Test: 47.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 150, Loss: 0.2060, Train: 42.96%, Valid: 36.92%, Test: 24.15%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 150, Loss: 0.2060, Train: 54.28%, Valid: 47.20%, Test: 36.17%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 150, Loss: 0.2060, Train: 62.45%, Valid: 54.63%, Test: 42.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 155, Loss: 0.2035, Train: 46.28%, Valid: 39.60%, Test: 35.69%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 155, Loss: 0.2035, Train: 59.18%, Valid: 51.37%, Test: 44.83%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 155, Loss: 0.2035, Train: 64.44%, Valid: 56.39%, Test: 52.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 160, Loss: 0.2034, Train: 41.78%, Valid: 35.76%, Test: 26.66%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 160, Loss: 0.2034, Train: 53.68%, Valid: 46.39%, Test: 37.13%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 160, Loss: 0.2034, Train: 56.77%, Valid: 49.18%, Test: 43.57%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 165, Loss: 0.2031, Train: 44.52%, Valid: 38.34%, Test: 30.74%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 165, Loss: 0.2031, Train: 58.18%, Valid: 50.48%, Test: 42.67%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 165, Loss: 0.2031, Train: 64.45%, Valid: 56.37%, Test: 48.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 170, Loss: 0.1980, Train: 43.05%, Valid: 36.82%, Test: 30.31%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 170, Loss: 0.1980, Train: 52.85%, Valid: 45.41%, Test: 36.81%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 170, Loss: 0.1980, Train: 60.84%, Valid: 52.78%, Test: 44.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 175, Loss: 0.1968, Train: 45.99%, Valid: 39.18%, Test: 20.55%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 175, Loss: 0.1968, Train: 62.02%, Valid: 53.82%, Test: 32.90%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 175, Loss: 0.1968, Train: 66.79%, Valid: 58.34%, Test: 43.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 180, Loss: 0.1958, Train: 49.00%, Valid: 41.75%, Test: 30.00%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 180, Loss: 0.1958, Train: 61.15%, Valid: 52.77%, Test: 51.63%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 180, Loss: 0.1958, Train: 67.71%, Valid: 58.94%, Test: 60.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 185, Loss: 0.1960, Train: 41.91%, Valid: 35.31%, Test: 27.19%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 185, Loss: 0.1960, Train: 58.92%, Valid: 51.01%, Test: 46.91%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 185, Loss: 0.1960, Train: 64.95%, Valid: 56.55%, Test: 53.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 190, Loss: 0.1910, Train: 50.58%, Valid: 43.24%, Test: 24.89%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 190, Loss: 0.1910, Train: 63.22%, Valid: 54.76%, Test: 38.38%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 190, Loss: 0.1910, Train: 68.27%, Valid: 59.48%, Test: 44.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 195, Loss: 0.1917, Train: 55.87%, Valid: 47.83%, Test: 28.54%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 195, Loss: 0.1917, Train: 64.27%, Valid: 55.59%, Test: 40.96%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 195, Loss: 0.1917, Train: 68.02%, Valid: 59.13%, Test: 47.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 200, Loss: 0.1890, Train: 43.51%, Valid: 36.74%, Test: 20.20%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 200, Loss: 0.1890, Train: 59.67%, Valid: 51.51%, Test: 35.36%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 200, Loss: 0.1890, Train: 65.96%, Valid: 57.14%, Test: 46.53%\n",
      "---\n",
      "Hits@10\n",
      "Run 08:\n",
      "Highest Train: 55.87\n",
      "Highest Valid: 47.83\n",
      "  Final Train: 55.87\n",
      "   Final Test: 28.54\n",
      "Hits@20\n",
      "Run 08:\n",
      "Highest Train: 64.27\n",
      "Highest Valid: 55.59\n",
      "  Final Train: 64.27\n",
      "   Final Test: 40.96\n",
      "Hits@30\n",
      "Run 08:\n",
      "Highest Train: 68.27\n",
      "Highest Valid: 59.48\n",
      "  Final Train: 68.27\n",
      "   Final Test: 44.30\n",
      "Hits@10\n",
      "Run: 09, Epoch: 05, Loss: 0.6671, Train: 6.94%, Valid: 6.01%, Test: 0.28%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 05, Loss: 0.6671, Train: 11.78%, Valid: 10.29%, Test: 3.33%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 05, Loss: 0.6671, Train: 15.02%, Valid: 13.43%, Test: 6.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 10, Loss: 0.5184, Train: 16.27%, Valid: 14.47%, Test: 12.67%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 10, Loss: 0.5184, Train: 21.08%, Valid: 18.93%, Test: 16.02%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 10, Loss: 0.5184, Train: 25.57%, Valid: 23.03%, Test: 18.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 15, Loss: 0.4444, Train: 13.22%, Valid: 11.80%, Test: 16.58%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 15, Loss: 0.4444, Train: 18.97%, Valid: 17.00%, Test: 19.78%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 15, Loss: 0.4444, Train: 20.98%, Valid: 18.79%, Test: 22.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 20, Loss: 0.3825, Train: 18.66%, Valid: 16.60%, Test: 11.60%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 20, Loss: 0.3825, Train: 29.00%, Valid: 26.20%, Test: 18.19%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 20, Loss: 0.3825, Train: 32.06%, Valid: 29.19%, Test: 21.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 25, Loss: 0.3533, Train: 14.68%, Valid: 12.95%, Test: 5.34%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 25, Loss: 0.3533, Train: 24.10%, Valid: 21.47%, Test: 18.85%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 25, Loss: 0.3533, Train: 32.35%, Valid: 28.96%, Test: 27.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 30, Loss: 0.3376, Train: 18.77%, Valid: 16.57%, Test: 6.51%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 30, Loss: 0.3376, Train: 25.55%, Valid: 22.79%, Test: 15.59%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 30, Loss: 0.3376, Train: 31.40%, Valid: 28.10%, Test: 20.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 35, Loss: 0.3194, Train: 13.62%, Valid: 11.94%, Test: 4.96%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 35, Loss: 0.3194, Train: 27.81%, Valid: 24.61%, Test: 14.60%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 35, Loss: 0.3194, Train: 35.55%, Valid: 31.58%, Test: 20.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 40, Loss: 0.3064, Train: 11.12%, Valid: 9.79%, Test: 7.95%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 40, Loss: 0.3064, Train: 26.22%, Valid: 23.21%, Test: 11.78%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 40, Loss: 0.3064, Train: 33.47%, Valid: 29.73%, Test: 16.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 45, Loss: 0.2934, Train: 9.61%, Valid: 8.31%, Test: 6.86%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 45, Loss: 0.2934, Train: 25.35%, Valid: 22.29%, Test: 13.70%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 45, Loss: 0.2934, Train: 31.97%, Valid: 28.26%, Test: 19.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 50, Loss: 0.2866, Train: 15.61%, Valid: 13.66%, Test: 5.51%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 50, Loss: 0.2866, Train: 23.32%, Valid: 20.47%, Test: 13.21%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 50, Loss: 0.2866, Train: 30.17%, Valid: 26.65%, Test: 20.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 55, Loss: 0.2766, Train: 11.93%, Valid: 10.24%, Test: 6.45%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 55, Loss: 0.2766, Train: 23.98%, Valid: 20.70%, Test: 14.56%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 55, Loss: 0.2766, Train: 32.01%, Valid: 28.12%, Test: 26.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 60, Loss: 0.2693, Train: 23.33%, Valid: 20.09%, Test: 4.52%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 60, Loss: 0.2693, Train: 32.95%, Valid: 28.80%, Test: 13.01%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 60, Loss: 0.2693, Train: 35.46%, Valid: 31.10%, Test: 26.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 65, Loss: 0.2623, Train: 18.12%, Valid: 15.55%, Test: 2.25%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 65, Loss: 0.2623, Train: 29.97%, Valid: 25.89%, Test: 12.73%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 65, Loss: 0.2623, Train: 37.41%, Valid: 32.66%, Test: 23.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 70, Loss: 0.2592, Train: 14.08%, Valid: 12.11%, Test: 7.04%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 70, Loss: 0.2592, Train: 32.62%, Valid: 28.20%, Test: 16.32%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 70, Loss: 0.2592, Train: 39.72%, Valid: 34.60%, Test: 25.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 75, Loss: 0.2514, Train: 35.19%, Valid: 30.57%, Test: 8.62%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 75, Loss: 0.2514, Train: 44.36%, Valid: 38.93%, Test: 20.94%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 75, Loss: 0.2514, Train: 52.96%, Valid: 47.18%, Test: 35.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 80, Loss: 0.2478, Train: 27.87%, Valid: 24.21%, Test: 5.24%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 80, Loss: 0.2478, Train: 38.83%, Valid: 33.95%, Test: 12.21%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 80, Loss: 0.2478, Train: 44.42%, Valid: 38.96%, Test: 21.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 85, Loss: 0.2439, Train: 33.49%, Valid: 28.95%, Test: 11.94%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 85, Loss: 0.2439, Train: 44.68%, Valid: 39.23%, Test: 21.15%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 85, Loss: 0.2439, Train: 50.13%, Valid: 44.12%, Test: 31.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 90, Loss: 0.2432, Train: 33.58%, Valid: 29.02%, Test: 8.12%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 90, Loss: 0.2432, Train: 40.45%, Valid: 35.13%, Test: 23.81%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 90, Loss: 0.2432, Train: 50.08%, Valid: 43.88%, Test: 31.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 95, Loss: 0.2383, Train: 31.84%, Valid: 27.28%, Test: 10.43%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 95, Loss: 0.2383, Train: 45.71%, Valid: 39.74%, Test: 31.17%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 95, Loss: 0.2383, Train: 52.47%, Valid: 45.92%, Test: 39.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 100, Loss: 0.2347, Train: 25.64%, Valid: 21.93%, Test: 16.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 100, Loss: 0.2347, Train: 39.55%, Valid: 34.20%, Test: 25.49%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 100, Loss: 0.2347, Train: 44.71%, Valid: 38.70%, Test: 35.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 105, Loss: 0.2309, Train: 35.57%, Valid: 30.68%, Test: 12.27%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 105, Loss: 0.2309, Train: 44.76%, Valid: 39.02%, Test: 25.93%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 105, Loss: 0.2309, Train: 49.88%, Valid: 43.66%, Test: 33.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 110, Loss: 0.2280, Train: 30.56%, Valid: 26.37%, Test: 18.70%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 110, Loss: 0.2280, Train: 47.95%, Valid: 41.65%, Test: 29.32%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 110, Loss: 0.2280, Train: 51.20%, Valid: 44.65%, Test: 37.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 115, Loss: 0.2263, Train: 40.34%, Valid: 35.00%, Test: 22.22%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 115, Loss: 0.2263, Train: 48.03%, Valid: 41.93%, Test: 32.23%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 115, Loss: 0.2263, Train: 52.68%, Valid: 46.21%, Test: 44.04%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 09, Epoch: 120, Loss: 0.2212, Train: 29.39%, Valid: 25.09%, Test: 24.63%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 120, Loss: 0.2212, Train: 36.91%, Valid: 31.85%, Test: 34.34%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 120, Loss: 0.2212, Train: 49.06%, Valid: 42.55%, Test: 41.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 125, Loss: 0.2174, Train: 32.88%, Valid: 28.28%, Test: 21.64%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 125, Loss: 0.2174, Train: 44.75%, Valid: 38.71%, Test: 31.28%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 125, Loss: 0.2174, Train: 48.98%, Valid: 42.53%, Test: 37.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 130, Loss: 0.2162, Train: 29.98%, Valid: 25.70%, Test: 26.29%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 130, Loss: 0.2162, Train: 46.69%, Valid: 40.18%, Test: 38.23%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 130, Loss: 0.2162, Train: 53.82%, Valid: 46.76%, Test: 46.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 135, Loss: 0.2134, Train: 33.05%, Valid: 28.28%, Test: 25.96%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 135, Loss: 0.2134, Train: 38.28%, Valid: 32.80%, Test: 31.00%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 135, Loss: 0.2134, Train: 50.07%, Valid: 43.32%, Test: 40.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 140, Loss: 0.2130, Train: 40.96%, Valid: 35.07%, Test: 26.94%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 140, Loss: 0.2130, Train: 49.29%, Valid: 42.63%, Test: 37.44%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 140, Loss: 0.2130, Train: 55.68%, Valid: 48.37%, Test: 46.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 145, Loss: 0.2089, Train: 36.37%, Valid: 31.16%, Test: 20.44%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 145, Loss: 0.2089, Train: 42.76%, Valid: 36.75%, Test: 29.80%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 145, Loss: 0.2089, Train: 48.62%, Valid: 42.00%, Test: 35.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 150, Loss: 0.2069, Train: 37.86%, Valid: 32.55%, Test: 26.62%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 150, Loss: 0.2069, Train: 50.35%, Valid: 43.63%, Test: 34.73%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 150, Loss: 0.2069, Train: 58.34%, Valid: 50.66%, Test: 42.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 155, Loss: 0.2043, Train: 42.97%, Valid: 36.78%, Test: 19.16%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 155, Loss: 0.2043, Train: 52.39%, Valid: 45.46%, Test: 31.51%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 155, Loss: 0.2043, Train: 61.27%, Valid: 53.49%, Test: 39.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 160, Loss: 0.2055, Train: 42.59%, Valid: 36.45%, Test: 24.57%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 160, Loss: 0.2055, Train: 54.37%, Valid: 47.17%, Test: 33.71%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 160, Loss: 0.2055, Train: 59.68%, Valid: 51.87%, Test: 40.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 165, Loss: 0.2011, Train: 37.29%, Valid: 31.70%, Test: 20.14%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 165, Loss: 0.2011, Train: 53.23%, Valid: 45.97%, Test: 30.08%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 165, Loss: 0.2011, Train: 59.04%, Valid: 51.20%, Test: 38.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 170, Loss: 0.2006, Train: 48.45%, Valid: 41.58%, Test: 31.16%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 170, Loss: 0.2006, Train: 55.88%, Valid: 48.17%, Test: 42.18%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 170, Loss: 0.2006, Train: 63.80%, Valid: 55.44%, Test: 49.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 175, Loss: 0.1984, Train: 43.23%, Valid: 36.62%, Test: 21.94%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 175, Loss: 0.1984, Train: 59.14%, Valid: 51.20%, Test: 34.33%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 175, Loss: 0.1984, Train: 64.58%, Valid: 56.05%, Test: 41.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 180, Loss: 0.1964, Train: 50.12%, Valid: 42.92%, Test: 17.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 180, Loss: 0.1964, Train: 58.02%, Valid: 50.16%, Test: 29.59%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 180, Loss: 0.1964, Train: 63.09%, Valid: 54.84%, Test: 38.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 185, Loss: 0.1948, Train: 48.14%, Valid: 41.06%, Test: 16.70%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 185, Loss: 0.1948, Train: 60.51%, Valid: 52.21%, Test: 25.25%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 185, Loss: 0.1948, Train: 64.18%, Valid: 55.68%, Test: 40.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 190, Loss: 0.1934, Train: 42.43%, Valid: 36.02%, Test: 15.65%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 190, Loss: 0.1934, Train: 60.05%, Valid: 51.82%, Test: 26.85%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 190, Loss: 0.1934, Train: 63.98%, Valid: 55.44%, Test: 34.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 195, Loss: 0.1924, Train: 45.72%, Valid: 38.80%, Test: 22.77%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 195, Loss: 0.1924, Train: 59.50%, Valid: 51.26%, Test: 31.86%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 195, Loss: 0.1924, Train: 64.23%, Valid: 55.64%, Test: 40.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 200, Loss: 0.1906, Train: 54.82%, Valid: 47.03%, Test: 19.88%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 200, Loss: 0.1906, Train: 65.74%, Valid: 56.92%, Test: 33.83%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 200, Loss: 0.1906, Train: 69.03%, Valid: 60.05%, Test: 42.31%\n",
      "---\n",
      "Hits@10\n",
      "Run 09:\n",
      "Highest Train: 54.82\n",
      "Highest Valid: 47.03\n",
      "  Final Train: 54.82\n",
      "   Final Test: 19.88\n",
      "Hits@20\n",
      "Run 09:\n",
      "Highest Train: 65.74\n",
      "Highest Valid: 56.92\n",
      "  Final Train: 65.74\n",
      "   Final Test: 33.83\n",
      "Hits@30\n",
      "Run 09:\n",
      "Highest Train: 69.03\n",
      "Highest Valid: 60.05\n",
      "  Final Train: 69.03\n",
      "   Final Test: 42.31\n",
      "Hits@10\n",
      "Run: 10, Epoch: 05, Loss: 0.6362, Train: 14.94%, Valid: 13.60%, Test: 3.67%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 05, Loss: 0.6362, Train: 16.75%, Valid: 15.38%, Test: 7.78%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 05, Loss: 0.6362, Train: 17.95%, Valid: 16.71%, Test: 10.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 10, Loss: 0.5002, Train: 15.92%, Valid: 14.12%, Test: 9.38%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 10, Loss: 0.5002, Train: 20.77%, Valid: 18.69%, Test: 14.92%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 10, Loss: 0.5002, Train: 23.74%, Valid: 21.36%, Test: 19.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 15, Loss: 0.4178, Train: 20.00%, Valid: 17.88%, Test: 11.30%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 15, Loss: 0.4178, Train: 24.36%, Valid: 21.91%, Test: 15.04%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 15, Loss: 0.4178, Train: 28.80%, Valid: 25.98%, Test: 19.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 20, Loss: 0.3824, Train: 22.00%, Valid: 19.61%, Test: 13.96%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 20, Loss: 0.3824, Train: 29.06%, Valid: 26.25%, Test: 19.00%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 20, Loss: 0.3824, Train: 32.70%, Valid: 29.67%, Test: 22.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 25, Loss: 0.3535, Train: 19.22%, Valid: 17.16%, Test: 5.92%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 25, Loss: 0.3535, Train: 28.91%, Valid: 25.91%, Test: 18.17%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 25, Loss: 0.3535, Train: 33.33%, Valid: 30.01%, Test: 23.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 30, Loss: 0.3334, Train: 24.06%, Valid: 21.27%, Test: 5.72%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 30, Loss: 0.3334, Train: 29.01%, Valid: 25.75%, Test: 14.73%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 30, Loss: 0.3334, Train: 34.11%, Valid: 30.46%, Test: 23.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 35, Loss: 0.3152, Train: 23.38%, Valid: 20.68%, Test: 6.68%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 35, Loss: 0.3152, Train: 32.47%, Valid: 28.90%, Test: 16.96%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 35, Loss: 0.3152, Train: 38.24%, Valid: 34.16%, Test: 21.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 40, Loss: 0.3052, Train: 15.49%, Valid: 13.47%, Test: 5.09%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 40, Loss: 0.3052, Train: 31.04%, Valid: 27.43%, Test: 10.85%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 40, Loss: 0.3052, Train: 35.37%, Valid: 31.55%, Test: 19.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 45, Loss: 0.2930, Train: 12.17%, Valid: 10.46%, Test: 3.95%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 45, Loss: 0.2930, Train: 19.03%, Valid: 16.65%, Test: 9.08%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 45, Loss: 0.2930, Train: 24.75%, Valid: 21.85%, Test: 17.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 50, Loss: 0.2884, Train: 23.57%, Valid: 20.65%, Test: 7.01%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 50, Loss: 0.2884, Train: 35.78%, Valid: 31.54%, Test: 13.51%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 50, Loss: 0.2884, Train: 40.54%, Valid: 35.86%, Test: 24.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 55, Loss: 0.2783, Train: 16.15%, Valid: 14.04%, Test: 4.27%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 55, Loss: 0.2783, Train: 32.47%, Valid: 28.58%, Test: 12.05%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 55, Loss: 0.2783, Train: 38.84%, Valid: 34.13%, Test: 20.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 60, Loss: 0.2686, Train: 17.45%, Valid: 15.13%, Test: 5.72%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 60, Loss: 0.2686, Train: 29.35%, Valid: 25.69%, Test: 10.36%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 60, Loss: 0.2686, Train: 37.05%, Valid: 32.54%, Test: 19.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 65, Loss: 0.2655, Train: 16.14%, Valid: 13.91%, Test: 4.24%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 65, Loss: 0.2655, Train: 23.59%, Valid: 20.46%, Test: 9.05%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 65, Loss: 0.2655, Train: 31.51%, Valid: 27.58%, Test: 21.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 70, Loss: 0.2539, Train: 24.66%, Valid: 21.44%, Test: 4.42%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 70, Loss: 0.2539, Train: 38.89%, Valid: 34.15%, Test: 11.28%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 70, Loss: 0.2539, Train: 42.73%, Valid: 37.63%, Test: 17.32%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 10, Epoch: 75, Loss: 0.2502, Train: 22.24%, Valid: 19.20%, Test: 5.09%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 75, Loss: 0.2502, Train: 32.63%, Valid: 28.48%, Test: 12.00%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 75, Loss: 0.2502, Train: 40.35%, Valid: 35.42%, Test: 18.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 80, Loss: 0.2482, Train: 25.09%, Valid: 21.69%, Test: 9.08%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 80, Loss: 0.2482, Train: 35.52%, Valid: 30.78%, Test: 19.38%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 80, Loss: 0.2482, Train: 41.12%, Valid: 35.99%, Test: 28.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 85, Loss: 0.2417, Train: 19.71%, Valid: 16.90%, Test: 5.40%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 85, Loss: 0.2417, Train: 37.94%, Valid: 32.91%, Test: 10.70%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 85, Loss: 0.2417, Train: 42.73%, Valid: 37.25%, Test: 22.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 90, Loss: 0.2390, Train: 15.94%, Valid: 13.47%, Test: 6.38%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 90, Loss: 0.2390, Train: 27.70%, Valid: 23.90%, Test: 13.28%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 90, Loss: 0.2390, Train: 35.38%, Valid: 30.79%, Test: 20.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 95, Loss: 0.2364, Train: 22.02%, Valid: 18.73%, Test: 5.31%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 95, Loss: 0.2364, Train: 30.02%, Valid: 25.96%, Test: 11.75%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 95, Loss: 0.2364, Train: 38.27%, Valid: 33.24%, Test: 18.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 100, Loss: 0.2330, Train: 27.21%, Valid: 23.37%, Test: 13.99%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 100, Loss: 0.2330, Train: 50.31%, Valid: 43.95%, Test: 22.84%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 100, Loss: 0.2330, Train: 53.90%, Valid: 47.35%, Test: 32.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 105, Loss: 0.2281, Train: 31.45%, Valid: 26.90%, Test: 12.92%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 105, Loss: 0.2281, Train: 38.73%, Valid: 33.44%, Test: 17.69%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 105, Loss: 0.2281, Train: 46.64%, Valid: 40.71%, Test: 29.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 110, Loss: 0.2276, Train: 25.67%, Valid: 21.84%, Test: 9.75%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 110, Loss: 0.2276, Train: 35.92%, Valid: 30.98%, Test: 18.48%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 110, Loss: 0.2276, Train: 44.78%, Valid: 38.96%, Test: 24.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 115, Loss: 0.2222, Train: 39.55%, Valid: 34.05%, Test: 24.57%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 115, Loss: 0.2222, Train: 51.43%, Valid: 44.71%, Test: 36.46%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 115, Loss: 0.2222, Train: 59.29%, Valid: 52.02%, Test: 44.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 120, Loss: 0.2217, Train: 45.90%, Valid: 39.73%, Test: 23.93%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 120, Loss: 0.2217, Train: 55.39%, Valid: 48.45%, Test: 33.23%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 120, Loss: 0.2217, Train: 61.67%, Valid: 54.44%, Test: 44.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 125, Loss: 0.2168, Train: 31.03%, Valid: 26.60%, Test: 19.32%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 125, Loss: 0.2168, Train: 38.02%, Valid: 32.57%, Test: 34.47%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 125, Loss: 0.2168, Train: 42.52%, Valid: 36.64%, Test: 38.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 130, Loss: 0.2152, Train: 34.19%, Valid: 29.23%, Test: 15.75%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 130, Loss: 0.2152, Train: 41.61%, Valid: 35.95%, Test: 22.85%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 130, Loss: 0.2152, Train: 47.87%, Valid: 41.73%, Test: 38.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 135, Loss: 0.2194, Train: 39.55%, Valid: 34.02%, Test: 19.86%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 135, Loss: 0.2194, Train: 45.69%, Valid: 39.59%, Test: 30.38%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 135, Loss: 0.2194, Train: 53.26%, Valid: 46.45%, Test: 36.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 140, Loss: 0.2096, Train: 33.11%, Valid: 28.16%, Test: 38.63%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 140, Loss: 0.2096, Train: 49.62%, Valid: 42.99%, Test: 45.20%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 140, Loss: 0.2096, Train: 56.16%, Valid: 48.91%, Test: 52.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 145, Loss: 0.2090, Train: 34.96%, Valid: 29.72%, Test: 24.38%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 145, Loss: 0.2090, Train: 44.20%, Valid: 37.90%, Test: 34.77%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 145, Loss: 0.2090, Train: 51.85%, Valid: 44.93%, Test: 40.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 150, Loss: 0.2052, Train: 37.04%, Valid: 31.62%, Test: 24.59%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 150, Loss: 0.2052, Train: 51.42%, Valid: 44.45%, Test: 39.72%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 150, Loss: 0.2052, Train: 56.70%, Valid: 49.25%, Test: 45.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 155, Loss: 0.2079, Train: 28.94%, Valid: 24.74%, Test: 21.96%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 155, Loss: 0.2079, Train: 41.40%, Valid: 35.42%, Test: 32.79%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 155, Loss: 0.2079, Train: 50.42%, Valid: 43.64%, Test: 38.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 160, Loss: 0.2019, Train: 40.24%, Valid: 34.46%, Test: 28.54%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 160, Loss: 0.2019, Train: 51.23%, Valid: 44.07%, Test: 37.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 160, Loss: 0.2019, Train: 56.54%, Valid: 49.00%, Test: 48.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 165, Loss: 0.2011, Train: 38.85%, Valid: 32.90%, Test: 20.24%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 165, Loss: 0.2011, Train: 47.49%, Valid: 40.70%, Test: 31.79%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 165, Loss: 0.2011, Train: 55.29%, Valid: 47.68%, Test: 38.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 170, Loss: 0.1986, Train: 35.62%, Valid: 30.46%, Test: 18.53%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 170, Loss: 0.1986, Train: 48.52%, Valid: 41.76%, Test: 27.06%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 170, Loss: 0.1986, Train: 52.72%, Valid: 45.55%, Test: 29.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 175, Loss: 0.1969, Train: 33.31%, Valid: 28.07%, Test: 19.82%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 175, Loss: 0.1969, Train: 52.81%, Valid: 45.32%, Test: 31.81%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 175, Loss: 0.1969, Train: 60.72%, Valid: 52.40%, Test: 38.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 180, Loss: 0.1960, Train: 40.73%, Valid: 34.75%, Test: 26.71%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 180, Loss: 0.1960, Train: 54.19%, Valid: 46.74%, Test: 38.00%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 180, Loss: 0.1960, Train: 59.63%, Valid: 51.71%, Test: 45.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 185, Loss: 0.1945, Train: 36.19%, Valid: 30.68%, Test: 19.11%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 185, Loss: 0.1945, Train: 51.95%, Valid: 44.55%, Test: 30.95%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 185, Loss: 0.1945, Train: 59.93%, Valid: 51.89%, Test: 37.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 190, Loss: 0.1920, Train: 51.30%, Valid: 44.02%, Test: 23.33%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 190, Loss: 0.1920, Train: 60.04%, Valid: 51.90%, Test: 26.66%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 190, Loss: 0.1920, Train: 64.81%, Valid: 56.23%, Test: 33.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 195, Loss: 0.1916, Train: 57.25%, Valid: 49.34%, Test: 24.81%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 195, Loss: 0.1916, Train: 63.28%, Valid: 54.98%, Test: 38.13%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 195, Loss: 0.1916, Train: 68.08%, Valid: 59.34%, Test: 48.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 200, Loss: 0.1914, Train: 44.36%, Valid: 37.82%, Test: 15.25%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 200, Loss: 0.1914, Train: 54.14%, Valid: 46.66%, Test: 22.78%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 200, Loss: 0.1914, Train: 62.16%, Valid: 54.11%, Test: 31.60%\n",
      "---\n",
      "Hits@10\n",
      "Run 10:\n",
      "Highest Train: 57.25\n",
      "Highest Valid: 49.34\n",
      "  Final Train: 57.25\n",
      "   Final Test: 24.81\n",
      "Hits@20\n",
      "Run 10:\n",
      "Highest Train: 63.28\n",
      "Highest Valid: 54.98\n",
      "  Final Train: 63.28\n",
      "   Final Test: 38.13\n",
      "Hits@30\n",
      "Run 10:\n",
      "Highest Train: 68.08\n",
      "Highest Valid: 59.34\n",
      "  Final Train: 68.08\n",
      "   Final Test: 48.73\n",
      "Hits@10\n",
      "All runs:\n",
      "Highest Train: 54.71  3.55\n",
      "Highest Valid: 46.97  3.10\n",
      "  Final Train: 54.71  3.55\n",
      "   Final Test: 22.03  4.38\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Train: 64.56  2.39\n",
      "Highest Valid: 56.00  2.17\n",
      "  Final Train: 64.54  2.40\n",
      "   Final Test: 34.59  4.49\n",
      "Hits@30\n",
      "All runs:\n",
      "Highest Train: 68.03  2.29\n",
      "Highest Valid: 59.24  2.09\n",
      "  Final Train: 68.02  2.28\n",
      "   Final Test: 43.83  6.26\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def train(model, predictor, x, adj_t, split_edge, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (GNN)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    parser.add_argument('--use_sage', action='store_true')\n",
    "    parser.add_argument('--num_layers', type=int, default=2)\n",
    "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "    parser.add_argument('--lr', type=float, default=0.005)\n",
    "    parser.add_argument('--epochs', type=int, default=200)\n",
    "    parser.add_argument('--eval_steps', type=int, default=5)\n",
    "    parser.add_argument('--runs', type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "                                     transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    adj_t = data.adj_t.to(device)\n",
    "\n",
    "    split_edge = dataset.get_edge_split()\n",
    "\n",
    "    # We randomly pick some training samples that we want to evaluate on:\n",
    "    torch.manual_seed(12345)\n",
    "    idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "    idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "    split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "    if args.use_sage:\n",
    "        model = SAGE(args.hidden_channels, args.hidden_channels,\n",
    "                     args.hidden_channels, args.num_layers,\n",
    "                     args.dropout).to(device)\n",
    "    else:\n",
    "        model = GCN(args.hidden_channels, args.hidden_channels,\n",
    "                    args.hidden_channels, args.num_layers,\n",
    "                    args.dropout).to(device)\n",
    "\n",
    "    emb = torch.nn.Embedding(data.adj_t.size(0),\n",
    "                             args.hidden_channels).to(device)\n",
    "    predictor = LinkPredictor(args.hidden_channels, args.hidden_channels, 1,\n",
    "                              args.num_layers, args.dropout).to(device)\n",
    "\n",
    "    evaluator = Evaluator(name='ogbl-ddi')\n",
    "    Logger_Models_Models = {\n",
    "        'Hits@10': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@20': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@30': Logger_Models_Model(args.runs, args),\n",
    "    }\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        torch.nn.init.xavier_uniform_(emb.weight)\n",
    "        model.reset_parameters()\n",
    "        predictor.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(model.parameters()) + list(emb.parameters()) +\n",
    "            list(predictor.parameters()), lr=args.lr)\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                         optimizer, args.batch_size)\n",
    "\n",
    "            if epoch % args.eval_steps == 0:\n",
    "                results = test(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                               evaluator, args.batch_size)\n",
    "                for key, result in results.items():\n",
    "                    Logger_Models_Models[key].add_result(run, result)\n",
    "\n",
    "                if epoch % args.log_steps == 0:\n",
    "                    for key, result in results.items():\n",
    "                        train_hits, valid_hits, test_hits = result\n",
    "                        print(key)\n",
    "                        print(f'Run: {run + 1:02d}, '\n",
    "                              f'Epoch: {epoch:02d}, '\n",
    "                              f'Loss: {loss:.4f}, '\n",
    "                              f'Train: {100 * train_hits:.2f}%, '\n",
    "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                              f'Test: {100 * test_hits:.2f}%')\n",
    "                    print('---')\n",
    "\n",
    "        for key in Logger_Models_Models.keys():\n",
    "            print(key)\n",
    "            Logger_Models_Models[key].print_statistics(run)\n",
    "\n",
    "    for key in Logger_Models_Models.keys():\n",
    "        print(key)\n",
    "        Logger_Models_Models[key].print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371a6b5",
   "metadata": {},
   "source": [
    "## Graph Sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef91d89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T22:49:54.662930Z",
     "start_time": "2022-07-08T22:49:54.624968Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b590229d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T06:57:33.608929Z",
     "start_time": "2022-07-08T22:52:07.595290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(f='C:\\\\Users\\\\b04753yr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-30e704de-a8cc-40a4-8675-f15ec8e16fa1.json', device=0, log_steps=1, use_sage=True, num_layers=2, hidden_channels=256, dropout=0.5, batch_size=65536, lr=0.005, epochs=200, eval_steps=5, runs=10)\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.5646, Train: 10.91%, Valid: 9.69%, Test: 3.30%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.5646, Train: 17.74%, Valid: 15.89%, Test: 8.36%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.5646, Train: 22.12%, Valid: 20.14%, Test: 11.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 10, Loss: 0.4070, Train: 19.12%, Valid: 16.52%, Test: 7.65%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 10, Loss: 0.4070, Train: 22.87%, Valid: 20.05%, Test: 11.71%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 10, Loss: 0.4070, Train: 28.42%, Valid: 25.33%, Test: 18.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 15, Loss: 0.3325, Train: 33.58%, Valid: 29.27%, Test: 9.86%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 15, Loss: 0.3325, Train: 39.61%, Valid: 34.80%, Test: 15.72%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 15, Loss: 0.3325, Train: 43.56%, Valid: 38.43%, Test: 23.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 20, Loss: 0.2931, Train: 42.44%, Valid: 36.89%, Test: 13.72%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 20, Loss: 0.2931, Train: 49.31%, Valid: 43.42%, Test: 19.10%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 20, Loss: 0.2931, Train: 53.54%, Valid: 47.35%, Test: 26.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 25, Loss: 0.2652, Train: 43.48%, Valid: 37.49%, Test: 7.01%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 25, Loss: 0.2652, Train: 50.21%, Valid: 43.71%, Test: 15.96%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 25, Loss: 0.2652, Train: 53.99%, Valid: 47.29%, Test: 25.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 30, Loss: 0.2444, Train: 55.02%, Valid: 48.02%, Test: 16.79%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 30, Loss: 0.2444, Train: 60.04%, Valid: 52.75%, Test: 26.51%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 30, Loss: 0.2444, Train: 62.16%, Valid: 54.78%, Test: 32.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 35, Loss: 0.2312, Train: 48.88%, Valid: 41.83%, Test: 30.92%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 35, Loss: 0.2312, Train: 56.29%, Valid: 48.71%, Test: 43.07%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 35, Loss: 0.2312, Train: 60.57%, Valid: 52.73%, Test: 50.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 40, Loss: 0.2199, Train: 50.55%, Valid: 43.04%, Test: 25.95%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 40, Loss: 0.2199, Train: 62.28%, Valid: 54.11%, Test: 38.55%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 40, Loss: 0.2199, Train: 64.29%, Valid: 56.08%, Test: 46.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 45, Loss: 0.2137, Train: 48.67%, Valid: 41.25%, Test: 36.25%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 45, Loss: 0.2137, Train: 59.70%, Valid: 51.42%, Test: 46.45%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 45, Loss: 0.2137, Train: 64.66%, Valid: 56.18%, Test: 53.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 50, Loss: 0.2088, Train: 61.33%, Valid: 53.09%, Test: 32.46%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 50, Loss: 0.2088, Train: 67.75%, Valid: 59.22%, Test: 52.00%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 50, Loss: 0.2088, Train: 69.94%, Valid: 61.31%, Test: 58.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 55, Loss: 0.2031, Train: 57.05%, Valid: 48.39%, Test: 29.67%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 55, Loss: 0.2031, Train: 65.97%, Valid: 57.05%, Test: 46.03%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 55, Loss: 0.2031, Train: 67.84%, Valid: 58.90%, Test: 56.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 60, Loss: 0.1995, Train: 60.45%, Valid: 51.90%, Test: 40.55%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 60, Loss: 0.1995, Train: 68.77%, Valid: 59.78%, Test: 48.67%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 60, Loss: 0.1995, Train: 71.78%, Valid: 62.79%, Test: 59.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 65, Loss: 0.1940, Train: 62.30%, Valid: 53.29%, Test: 42.83%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 65, Loss: 0.1940, Train: 68.59%, Valid: 59.35%, Test: 59.12%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 65, Loss: 0.1940, Train: 71.89%, Valid: 62.55%, Test: 61.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 70, Loss: 0.1907, Train: 65.41%, Valid: 56.50%, Test: 42.52%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 70, Loss: 0.1907, Train: 70.53%, Valid: 61.33%, Test: 55.61%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 70, Loss: 0.1907, Train: 72.77%, Valid: 63.54%, Test: 67.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 75, Loss: 0.1875, Train: 65.58%, Valid: 56.16%, Test: 50.46%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 75, Loss: 0.1875, Train: 71.44%, Valid: 62.03%, Test: 60.06%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 75, Loss: 0.1875, Train: 73.25%, Valid: 63.84%, Test: 66.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 80, Loss: 0.1852, Train: 64.79%, Valid: 55.40%, Test: 29.86%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 80, Loss: 0.1852, Train: 69.83%, Valid: 60.38%, Test: 46.72%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 80, Loss: 0.1852, Train: 73.11%, Valid: 63.66%, Test: 59.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 85, Loss: 0.1821, Train: 64.73%, Valid: 54.86%, Test: 29.07%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 85, Loss: 0.1821, Train: 68.77%, Valid: 58.85%, Test: 53.64%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 85, Loss: 0.1821, Train: 72.80%, Valid: 63.04%, Test: 59.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 90, Loss: 0.1807, Train: 58.58%, Valid: 49.33%, Test: 44.76%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 90, Loss: 0.1807, Train: 70.18%, Valid: 60.58%, Test: 64.27%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 90, Loss: 0.1807, Train: 74.63%, Valid: 65.06%, Test: 70.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 95, Loss: 0.1789, Train: 61.51%, Valid: 52.20%, Test: 41.89%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.1789, Train: 71.74%, Valid: 62.19%, Test: 53.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 95, Loss: 0.1789, Train: 74.05%, Valid: 64.46%, Test: 61.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 100, Loss: 0.1775, Train: 59.53%, Valid: 49.98%, Test: 41.26%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.1775, Train: 71.17%, Valid: 61.36%, Test: 62.00%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 100, Loss: 0.1775, Train: 74.57%, Valid: 64.69%, Test: 70.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 105, Loss: 0.1756, Train: 64.71%, Valid: 55.11%, Test: 43.34%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.1756, Train: 72.98%, Valid: 63.05%, Test: 58.93%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 105, Loss: 0.1756, Train: 74.63%, Valid: 64.70%, Test: 67.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 110, Loss: 0.1753, Train: 66.63%, Valid: 56.57%, Test: 46.59%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.1753, Train: 73.25%, Valid: 63.30%, Test: 57.76%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 110, Loss: 0.1753, Train: 76.22%, Valid: 66.27%, Test: 67.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 115, Loss: 0.1734, Train: 64.86%, Valid: 54.95%, Test: 30.70%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.1734, Train: 74.07%, Valid: 64.06%, Test: 42.65%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 115, Loss: 0.1734, Train: 75.78%, Valid: 65.76%, Test: 58.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 120, Loss: 0.1722, Train: 69.75%, Valid: 59.85%, Test: 45.30%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.1722, Train: 75.08%, Valid: 65.08%, Test: 61.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 120, Loss: 0.1722, Train: 76.52%, Valid: 66.48%, Test: 72.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 125, Loss: 0.1722, Train: 67.80%, Valid: 57.68%, Test: 35.31%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.1722, Train: 75.19%, Valid: 65.14%, Test: 55.45%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 125, Loss: 0.1722, Train: 76.12%, Valid: 66.08%, Test: 66.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 130, Loss: 0.1693, Train: 67.67%, Valid: 57.80%, Test: 51.55%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.1693, Train: 74.63%, Valid: 64.74%, Test: 61.27%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 130, Loss: 0.1693, Train: 77.11%, Valid: 67.23%, Test: 71.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 135, Loss: 0.1684, Train: 63.34%, Valid: 53.08%, Test: 42.49%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.1684, Train: 75.16%, Valid: 64.87%, Test: 61.35%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 135, Loss: 0.1684, Train: 76.61%, Valid: 66.37%, Test: 72.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 140, Loss: 0.1688, Train: 72.33%, Valid: 62.43%, Test: 37.82%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.1688, Train: 75.56%, Valid: 65.55%, Test: 54.38%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 140, Loss: 0.1688, Train: 77.66%, Valid: 67.69%, Test: 69.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 145, Loss: 0.1684, Train: 68.05%, Valid: 57.58%, Test: 22.81%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.1684, Train: 75.77%, Valid: 65.52%, Test: 52.20%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 145, Loss: 0.1684, Train: 77.34%, Valid: 67.20%, Test: 63.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 150, Loss: 0.1688, Train: 70.22%, Valid: 59.97%, Test: 50.76%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.1688, Train: 75.19%, Valid: 65.04%, Test: 66.91%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 150, Loss: 0.1688, Train: 78.02%, Valid: 67.82%, Test: 74.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 155, Loss: 0.1651, Train: 68.39%, Valid: 58.25%, Test: 46.49%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.1651, Train: 75.34%, Valid: 65.16%, Test: 62.05%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 155, Loss: 0.1651, Train: 78.21%, Valid: 68.04%, Test: 71.12%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 01, Epoch: 160, Loss: 0.1667, Train: 66.48%, Valid: 55.77%, Test: 48.98%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.1667, Train: 72.57%, Valid: 61.91%, Test: 59.56%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 160, Loss: 0.1667, Train: 76.14%, Valid: 65.58%, Test: 65.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 165, Loss: 0.1665, Train: 73.28%, Valid: 63.07%, Test: 45.18%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.1665, Train: 77.57%, Valid: 67.48%, Test: 61.49%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 165, Loss: 0.1665, Train: 79.38%, Valid: 69.22%, Test: 73.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 170, Loss: 0.1637, Train: 68.70%, Valid: 57.96%, Test: 36.45%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.1637, Train: 74.37%, Valid: 63.85%, Test: 53.82%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 170, Loss: 0.1637, Train: 77.68%, Valid: 67.34%, Test: 63.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 175, Loss: 0.1629, Train: 55.89%, Valid: 45.40%, Test: 36.92%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.1629, Train: 74.51%, Valid: 63.92%, Test: 56.84%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 175, Loss: 0.1629, Train: 77.00%, Valid: 66.60%, Test: 69.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 180, Loss: 0.1640, Train: 71.70%, Valid: 61.62%, Test: 49.05%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.1640, Train: 77.34%, Valid: 67.12%, Test: 64.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 180, Loss: 0.1640, Train: 79.45%, Valid: 69.26%, Test: 75.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 185, Loss: 0.1622, Train: 69.81%, Valid: 59.30%, Test: 55.73%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.1622, Train: 77.08%, Valid: 66.80%, Test: 68.60%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 185, Loss: 0.1622, Train: 79.16%, Valid: 69.01%, Test: 78.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 190, Loss: 0.1627, Train: 59.98%, Valid: 49.32%, Test: 52.56%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.1627, Train: 75.86%, Valid: 65.45%, Test: 66.50%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 190, Loss: 0.1627, Train: 78.41%, Valid: 68.11%, Test: 69.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 195, Loss: 0.1632, Train: 65.77%, Valid: 55.23%, Test: 45.17%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.1632, Train: 77.43%, Valid: 67.03%, Test: 68.17%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 195, Loss: 0.1632, Train: 79.86%, Valid: 69.65%, Test: 75.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 200, Loss: 0.1632, Train: 68.53%, Valid: 57.38%, Test: 56.44%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.1632, Train: 75.57%, Valid: 64.74%, Test: 67.19%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 200, Loss: 0.1632, Train: 77.95%, Valid: 67.31%, Test: 73.76%\n",
      "---\n",
      "Hits@10\n",
      "Run 01:\n",
      "Highest Train: 73.28\n",
      "Highest Valid: 63.07\n",
      "  Final Train: 73.28\n",
      "   Final Test: 45.18\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Train: 77.57\n",
      "Highest Valid: 67.48\n",
      "  Final Train: 77.57\n",
      "   Final Test: 61.49\n",
      "Hits@30\n",
      "Run 01:\n",
      "Highest Train: 79.86\n",
      "Highest Valid: 69.65\n",
      "  Final Train: 79.86\n",
      "   Final Test: 75.60\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.5703, Train: 10.32%, Valid: 9.22%, Test: 3.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.5703, Train: 14.47%, Valid: 12.93%, Test: 7.07%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.5703, Train: 18.00%, Valid: 16.15%, Test: 8.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 10, Loss: 0.3997, Train: 25.00%, Valid: 21.99%, Test: 6.59%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.3997, Train: 31.16%, Valid: 27.84%, Test: 11.78%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 10, Loss: 0.3997, Train: 35.76%, Valid: 32.15%, Test: 18.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 15, Loss: 0.3248, Train: 36.91%, Valid: 32.04%, Test: 9.43%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.3248, Train: 43.11%, Valid: 37.75%, Test: 20.88%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 15, Loss: 0.3248, Train: 46.06%, Valid: 40.56%, Test: 25.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 20, Loss: 0.2828, Train: 46.86%, Valid: 40.80%, Test: 18.96%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.2828, Train: 55.75%, Valid: 49.09%, Test: 25.45%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 20, Loss: 0.2828, Train: 56.93%, Valid: 50.29%, Test: 31.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 25, Loss: 0.2555, Train: 47.06%, Valid: 40.45%, Test: 20.70%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.2555, Train: 52.68%, Valid: 45.63%, Test: 26.79%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 25, Loss: 0.2555, Train: 56.17%, Valid: 48.74%, Test: 31.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 30, Loss: 0.2384, Train: 50.21%, Valid: 43.26%, Test: 17.26%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.2384, Train: 56.40%, Valid: 48.95%, Test: 35.51%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 30, Loss: 0.2384, Train: 60.42%, Valid: 52.65%, Test: 43.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 35, Loss: 0.2269, Train: 54.29%, Valid: 46.62%, Test: 25.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.2269, Train: 59.43%, Valid: 51.44%, Test: 41.55%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 35, Loss: 0.2269, Train: 61.27%, Valid: 53.13%, Test: 47.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 40, Loss: 0.2184, Train: 59.03%, Valid: 50.85%, Test: 34.85%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.2184, Train: 63.83%, Valid: 55.30%, Test: 52.15%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 40, Loss: 0.2184, Train: 66.59%, Valid: 57.90%, Test: 58.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 45, Loss: 0.2088, Train: 57.97%, Valid: 49.55%, Test: 32.82%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.2088, Train: 64.30%, Valid: 55.58%, Test: 42.93%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 45, Loss: 0.2088, Train: 67.64%, Valid: 58.86%, Test: 50.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 50, Loss: 0.2018, Train: 62.13%, Valid: 53.53%, Test: 37.48%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.2018, Train: 67.22%, Valid: 58.21%, Test: 46.67%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 50, Loss: 0.2018, Train: 70.68%, Valid: 61.61%, Test: 54.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 55, Loss: 0.1988, Train: 55.22%, Valid: 46.41%, Test: 30.32%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.1988, Train: 65.95%, Valid: 56.63%, Test: 47.26%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 55, Loss: 0.1988, Train: 70.12%, Valid: 60.70%, Test: 56.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 60, Loss: 0.1928, Train: 64.85%, Valid: 55.72%, Test: 37.76%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.1928, Train: 71.17%, Valid: 61.81%, Test: 54.67%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 60, Loss: 0.1928, Train: 72.98%, Valid: 63.57%, Test: 61.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 65, Loss: 0.1901, Train: 62.25%, Valid: 52.77%, Test: 27.99%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.1901, Train: 69.33%, Valid: 59.66%, Test: 46.60%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 65, Loss: 0.1901, Train: 73.87%, Valid: 64.23%, Test: 61.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 70, Loss: 0.1858, Train: 67.38%, Valid: 57.81%, Test: 25.68%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.1858, Train: 71.70%, Valid: 62.06%, Test: 47.49%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 70, Loss: 0.1858, Train: 74.18%, Valid: 64.56%, Test: 58.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 75, Loss: 0.1857, Train: 64.09%, Valid: 54.57%, Test: 36.92%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.1857, Train: 71.33%, Valid: 61.72%, Test: 50.24%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 75, Loss: 0.1857, Train: 73.69%, Valid: 63.94%, Test: 61.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 80, Loss: 0.1809, Train: 64.06%, Valid: 54.26%, Test: 31.45%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.1809, Train: 72.48%, Valid: 62.71%, Test: 51.16%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 80, Loss: 0.1809, Train: 75.43%, Valid: 65.63%, Test: 62.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 85, Loss: 0.1803, Train: 55.08%, Valid: 45.72%, Test: 39.10%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.1803, Train: 71.47%, Valid: 61.66%, Test: 51.17%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 85, Loss: 0.1803, Train: 73.59%, Valid: 63.86%, Test: 62.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 90, Loss: 0.1779, Train: 68.75%, Valid: 58.86%, Test: 35.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.1779, Train: 74.56%, Valid: 64.61%, Test: 45.96%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 90, Loss: 0.1779, Train: 76.19%, Valid: 66.29%, Test: 60.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 95, Loss: 0.1759, Train: 67.48%, Valid: 57.70%, Test: 27.91%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.1759, Train: 74.95%, Valid: 65.08%, Test: 47.07%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 95, Loss: 0.1759, Train: 76.06%, Valid: 66.15%, Test: 63.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 100, Loss: 0.1760, Train: 63.95%, Valid: 54.06%, Test: 21.46%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.1760, Train: 73.41%, Valid: 63.47%, Test: 51.32%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 100, Loss: 0.1760, Train: 76.06%, Valid: 66.12%, Test: 63.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 105, Loss: 0.1730, Train: 64.88%, Valid: 54.36%, Test: 28.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.1730, Train: 74.11%, Valid: 63.80%, Test: 46.05%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 105, Loss: 0.1730, Train: 75.85%, Valid: 65.56%, Test: 60.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 110, Loss: 0.1715, Train: 71.00%, Valid: 61.09%, Test: 40.39%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.1715, Train: 76.15%, Valid: 66.31%, Test: 60.49%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 110, Loss: 0.1715, Train: 78.06%, Valid: 68.22%, Test: 70.61%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 02, Epoch: 115, Loss: 0.1717, Train: 66.60%, Valid: 56.57%, Test: 46.29%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.1717, Train: 74.70%, Valid: 64.69%, Test: 67.60%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 115, Loss: 0.1717, Train: 76.49%, Valid: 66.46%, Test: 76.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 120, Loss: 0.1730, Train: 71.97%, Valid: 61.92%, Test: 37.96%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.1730, Train: 76.14%, Valid: 66.08%, Test: 60.42%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 120, Loss: 0.1730, Train: 77.82%, Valid: 67.81%, Test: 73.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 125, Loss: 0.1708, Train: 70.70%, Valid: 60.64%, Test: 34.37%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.1708, Train: 76.09%, Valid: 66.09%, Test: 59.37%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 125, Loss: 0.1708, Train: 77.63%, Valid: 67.69%, Test: 72.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 70.65%, Valid: 60.60%, Test: 54.58%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 75.04%, Valid: 65.00%, Test: 66.62%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 78.44%, Valid: 68.45%, Test: 79.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 135, Loss: 0.1664, Train: 69.06%, Valid: 58.89%, Test: 32.93%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.1664, Train: 76.30%, Valid: 66.08%, Test: 55.31%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 135, Loss: 0.1664, Train: 77.14%, Valid: 66.95%, Test: 68.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 140, Loss: 0.1657, Train: 64.93%, Valid: 54.04%, Test: 34.73%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.1657, Train: 74.00%, Valid: 63.52%, Test: 50.85%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 140, Loss: 0.1657, Train: 76.92%, Valid: 66.61%, Test: 60.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 145, Loss: 0.1644, Train: 67.64%, Valid: 57.27%, Test: 47.08%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.1644, Train: 76.06%, Valid: 65.82%, Test: 65.19%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 145, Loss: 0.1644, Train: 78.80%, Valid: 68.70%, Test: 77.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 150, Loss: 0.1642, Train: 68.11%, Valid: 57.47%, Test: 36.81%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.1642, Train: 75.65%, Valid: 65.34%, Test: 53.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 150, Loss: 0.1642, Train: 78.59%, Valid: 68.41%, Test: 66.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 155, Loss: 0.1644, Train: 74.28%, Valid: 64.05%, Test: 51.92%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.1644, Train: 76.83%, Valid: 66.75%, Test: 64.26%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 155, Loss: 0.1644, Train: 78.88%, Valid: 68.70%, Test: 73.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 160, Loss: 0.1652, Train: 70.29%, Valid: 59.57%, Test: 41.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.1652, Train: 77.07%, Valid: 66.78%, Test: 60.50%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 160, Loss: 0.1652, Train: 78.39%, Valid: 68.18%, Test: 71.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 165, Loss: 0.1636, Train: 65.90%, Valid: 55.43%, Test: 44.49%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.1636, Train: 77.62%, Valid: 67.35%, Test: 65.38%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 165, Loss: 0.1636, Train: 78.71%, Valid: 68.54%, Test: 73.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 170, Loss: 0.1629, Train: 67.93%, Valid: 57.39%, Test: 54.73%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.1629, Train: 76.29%, Valid: 66.01%, Test: 69.87%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 170, Loss: 0.1629, Train: 78.79%, Valid: 68.53%, Test: 77.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 175, Loss: 0.1614, Train: 71.51%, Valid: 61.07%, Test: 43.26%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.1614, Train: 78.68%, Valid: 68.37%, Test: 61.55%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 175, Loss: 0.1614, Train: 80.07%, Valid: 69.86%, Test: 72.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 180, Loss: 0.1616, Train: 66.09%, Valid: 55.35%, Test: 40.63%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.1616, Train: 76.69%, Valid: 66.38%, Test: 61.80%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 180, Loss: 0.1616, Train: 79.49%, Valid: 69.41%, Test: 72.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 185, Loss: 0.1610, Train: 69.04%, Valid: 58.38%, Test: 27.31%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.1610, Train: 77.72%, Valid: 67.37%, Test: 53.17%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 185, Loss: 0.1610, Train: 79.07%, Valid: 68.78%, Test: 65.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 190, Loss: 0.1606, Train: 65.69%, Valid: 54.55%, Test: 33.41%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.1606, Train: 77.31%, Valid: 66.76%, Test: 49.20%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 190, Loss: 0.1606, Train: 79.97%, Valid: 69.63%, Test: 60.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 195, Loss: 0.1627, Train: 71.35%, Valid: 60.62%, Test: 19.97%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.1627, Train: 77.29%, Valid: 66.98%, Test: 44.23%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 195, Loss: 0.1627, Train: 79.74%, Valid: 69.59%, Test: 65.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 200, Loss: 0.1621, Train: 72.95%, Valid: 62.49%, Test: 40.18%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.1621, Train: 77.09%, Valid: 66.77%, Test: 58.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 200, Loss: 0.1621, Train: 78.86%, Valid: 68.49%, Test: 70.92%\n",
      "---\n",
      "Hits@10\n",
      "Run 02:\n",
      "Highest Train: 74.28\n",
      "Highest Valid: 64.05\n",
      "  Final Train: 74.28\n",
      "   Final Test: 51.92\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Train: 78.68\n",
      "Highest Valid: 68.37\n",
      "  Final Train: 78.68\n",
      "   Final Test: 61.55\n",
      "Hits@30\n",
      "Run 02:\n",
      "Highest Train: 80.07\n",
      "Highest Valid: 69.86\n",
      "  Final Train: 80.07\n",
      "   Final Test: 72.07\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.5503, Train: 20.27%, Valid: 18.56%, Test: 4.53%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.5503, Train: 22.57%, Valid: 20.72%, Test: 12.15%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.5503, Train: 24.00%, Valid: 22.03%, Test: 14.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 10, Loss: 0.3968, Train: 26.18%, Valid: 22.90%, Test: 14.34%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 10, Loss: 0.3968, Train: 28.65%, Valid: 25.26%, Test: 18.96%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 10, Loss: 0.3968, Train: 31.95%, Valid: 28.41%, Test: 21.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 15, Loss: 0.3266, Train: 33.01%, Valid: 28.51%, Test: 12.42%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 15, Loss: 0.3266, Train: 37.45%, Valid: 32.58%, Test: 19.57%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 15, Loss: 0.3266, Train: 41.10%, Valid: 35.92%, Test: 23.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 20, Loss: 0.2902, Train: 35.09%, Valid: 29.89%, Test: 8.15%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 20, Loss: 0.2902, Train: 41.98%, Valid: 36.29%, Test: 14.45%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 20, Loss: 0.2902, Train: 45.67%, Valid: 39.72%, Test: 19.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 25, Loss: 0.2634, Train: 39.83%, Valid: 34.00%, Test: 17.23%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 25, Loss: 0.2634, Train: 46.34%, Valid: 39.96%, Test: 26.97%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 25, Loss: 0.2634, Train: 51.21%, Valid: 44.43%, Test: 32.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 30, Loss: 0.2430, Train: 48.58%, Valid: 41.65%, Test: 26.13%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 30, Loss: 0.2430, Train: 56.90%, Valid: 49.40%, Test: 37.55%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 30, Loss: 0.2430, Train: 59.93%, Valid: 52.18%, Test: 45.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 35, Loss: 0.2290, Train: 42.84%, Valid: 36.33%, Test: 18.18%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 35, Loss: 0.2290, Train: 55.92%, Valid: 48.32%, Test: 26.29%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 35, Loss: 0.2290, Train: 61.49%, Valid: 53.41%, Test: 33.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 40, Loss: 0.2191, Train: 58.29%, Valid: 50.22%, Test: 22.17%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 40, Loss: 0.2191, Train: 62.83%, Valid: 54.44%, Test: 36.33%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 40, Loss: 0.2191, Train: 65.06%, Valid: 56.54%, Test: 50.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 45, Loss: 0.2105, Train: 61.04%, Valid: 52.30%, Test: 28.20%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 45, Loss: 0.2105, Train: 64.02%, Valid: 55.22%, Test: 41.33%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 45, Loss: 0.2105, Train: 68.67%, Valid: 59.80%, Test: 47.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 50, Loss: 0.2030, Train: 63.73%, Valid: 55.00%, Test: 22.22%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 50, Loss: 0.2030, Train: 68.45%, Valid: 59.52%, Test: 40.75%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 50, Loss: 0.2030, Train: 70.50%, Valid: 61.49%, Test: 51.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 55, Loss: 0.2001, Train: 62.25%, Valid: 53.46%, Test: 25.55%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 55, Loss: 0.2001, Train: 69.84%, Valid: 60.74%, Test: 43.01%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 55, Loss: 0.2001, Train: 72.35%, Valid: 63.27%, Test: 57.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 60, Loss: 0.1960, Train: 55.89%, Valid: 47.18%, Test: 23.75%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 60, Loss: 0.1960, Train: 67.92%, Valid: 58.67%, Test: 40.42%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 60, Loss: 0.1960, Train: 70.94%, Valid: 61.75%, Test: 51.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 65, Loss: 0.1914, Train: 68.41%, Valid: 59.24%, Test: 41.21%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 65, Loss: 0.1914, Train: 72.72%, Valid: 63.52%, Test: 59.85%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 65, Loss: 0.1914, Train: 73.83%, Valid: 64.50%, Test: 67.03%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 03, Epoch: 70, Loss: 0.1887, Train: 69.07%, Valid: 59.64%, Test: 47.13%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 70, Loss: 0.1887, Train: 70.92%, Valid: 61.46%, Test: 61.89%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 70, Loss: 0.1887, Train: 73.62%, Valid: 64.19%, Test: 71.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 75, Loss: 0.1879, Train: 66.84%, Valid: 57.51%, Test: 55.37%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 75, Loss: 0.1879, Train: 71.31%, Valid: 61.88%, Test: 67.35%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 75, Loss: 0.1879, Train: 73.43%, Valid: 64.01%, Test: 73.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 80, Loss: 0.1831, Train: 67.86%, Valid: 58.43%, Test: 34.04%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 80, Loss: 0.1831, Train: 74.05%, Valid: 64.56%, Test: 53.36%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 80, Loss: 0.1831, Train: 76.38%, Valid: 66.87%, Test: 60.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 85, Loss: 0.1813, Train: 64.71%, Valid: 54.88%, Test: 36.60%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 85, Loss: 0.1813, Train: 71.55%, Valid: 61.77%, Test: 54.50%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 85, Loss: 0.1813, Train: 74.38%, Valid: 64.61%, Test: 68.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 90, Loss: 0.1797, Train: 65.01%, Valid: 55.29%, Test: 42.78%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 90, Loss: 0.1797, Train: 71.66%, Valid: 61.89%, Test: 58.21%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 90, Loss: 0.1797, Train: 74.95%, Valid: 65.23%, Test: 66.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 95, Loss: 0.1784, Train: 69.72%, Valid: 59.94%, Test: 43.30%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 95, Loss: 0.1784, Train: 74.39%, Valid: 64.62%, Test: 59.74%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 95, Loss: 0.1784, Train: 75.81%, Valid: 66.02%, Test: 69.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 100, Loss: 0.1762, Train: 65.66%, Valid: 55.79%, Test: 32.02%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 100, Loss: 0.1762, Train: 73.00%, Valid: 63.09%, Test: 56.38%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 100, Loss: 0.1762, Train: 75.85%, Valid: 65.92%, Test: 67.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 105, Loss: 0.1752, Train: 66.82%, Valid: 56.76%, Test: 27.96%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 105, Loss: 0.1752, Train: 75.82%, Valid: 66.00%, Test: 59.62%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 105, Loss: 0.1752, Train: 78.29%, Valid: 68.49%, Test: 66.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 110, Loss: 0.1736, Train: 71.30%, Valid: 61.38%, Test: 52.42%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 110, Loss: 0.1736, Train: 76.33%, Valid: 66.46%, Test: 65.44%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 110, Loss: 0.1736, Train: 77.85%, Valid: 68.05%, Test: 69.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 115, Loss: 0.1728, Train: 72.08%, Valid: 62.06%, Test: 55.14%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 115, Loss: 0.1728, Train: 75.92%, Valid: 65.94%, Test: 67.79%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 115, Loss: 0.1728, Train: 77.99%, Valid: 68.06%, Test: 74.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 120, Loss: 0.1715, Train: 72.18%, Valid: 62.15%, Test: 42.82%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 120, Loss: 0.1715, Train: 75.22%, Valid: 65.36%, Test: 62.77%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 120, Loss: 0.1715, Train: 77.51%, Valid: 67.70%, Test: 68.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 125, Loss: 0.1687, Train: 70.61%, Valid: 60.35%, Test: 46.49%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 125, Loss: 0.1687, Train: 77.34%, Valid: 67.38%, Test: 62.16%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 125, Loss: 0.1687, Train: 78.53%, Valid: 68.54%, Test: 70.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 130, Loss: 0.1696, Train: 71.88%, Valid: 61.51%, Test: 46.65%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 130, Loss: 0.1696, Train: 76.66%, Valid: 66.44%, Test: 60.90%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 130, Loss: 0.1696, Train: 77.97%, Valid: 67.76%, Test: 71.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 135, Loss: 0.1682, Train: 62.19%, Valid: 51.77%, Test: 44.58%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 135, Loss: 0.1682, Train: 76.26%, Valid: 66.13%, Test: 65.26%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 135, Loss: 0.1682, Train: 77.84%, Valid: 67.79%, Test: 75.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 140, Loss: 0.1679, Train: 71.76%, Valid: 61.60%, Test: 31.90%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 140, Loss: 0.1679, Train: 75.40%, Valid: 65.24%, Test: 43.09%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 140, Loss: 0.1679, Train: 77.82%, Valid: 67.78%, Test: 65.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 145, Loss: 0.1680, Train: 71.15%, Valid: 60.50%, Test: 49.49%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 145, Loss: 0.1680, Train: 75.84%, Valid: 65.51%, Test: 62.66%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 145, Loss: 0.1680, Train: 77.59%, Valid: 67.31%, Test: 71.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 150, Loss: 0.1654, Train: 73.25%, Valid: 63.24%, Test: 48.14%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 150, Loss: 0.1654, Train: 78.30%, Valid: 68.38%, Test: 65.57%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 150, Loss: 0.1654, Train: 79.61%, Valid: 69.67%, Test: 73.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 155, Loss: 0.1668, Train: 70.00%, Valid: 60.03%, Test: 35.23%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 155, Loss: 0.1668, Train: 76.92%, Valid: 66.93%, Test: 63.29%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 155, Loss: 0.1668, Train: 78.93%, Valid: 69.02%, Test: 76.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 160, Loss: 0.1642, Train: 65.74%, Valid: 55.19%, Test: 40.10%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 160, Loss: 0.1642, Train: 74.75%, Valid: 64.15%, Test: 59.39%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 160, Loss: 0.1642, Train: 78.35%, Valid: 68.01%, Test: 70.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 165, Loss: 0.1657, Train: 68.91%, Valid: 58.36%, Test: 48.25%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 165, Loss: 0.1657, Train: 77.70%, Valid: 67.54%, Test: 62.03%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 165, Loss: 0.1657, Train: 79.50%, Valid: 69.42%, Test: 71.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 170, Loss: 0.1647, Train: 74.79%, Valid: 64.39%, Test: 49.06%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 170, Loss: 0.1647, Train: 78.35%, Valid: 68.12%, Test: 70.00%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 170, Loss: 0.1647, Train: 79.42%, Valid: 69.25%, Test: 80.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 175, Loss: 0.1630, Train: 60.45%, Valid: 50.21%, Test: 40.54%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 175, Loss: 0.1630, Train: 76.67%, Valid: 66.39%, Test: 56.13%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 175, Loss: 0.1630, Train: 78.79%, Valid: 68.58%, Test: 69.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 180, Loss: 0.1626, Train: 64.18%, Valid: 53.10%, Test: 41.03%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 180, Loss: 0.1626, Train: 76.88%, Valid: 66.33%, Test: 66.29%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 180, Loss: 0.1626, Train: 78.59%, Valid: 68.24%, Test: 76.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 185, Loss: 0.1606, Train: 69.80%, Valid: 59.11%, Test: 41.78%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 185, Loss: 0.1606, Train: 76.20%, Valid: 65.71%, Test: 60.46%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 185, Loss: 0.1606, Train: 79.00%, Valid: 68.67%, Test: 74.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 190, Loss: 0.1629, Train: 68.35%, Valid: 57.52%, Test: 47.84%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 190, Loss: 0.1629, Train: 76.17%, Valid: 65.73%, Test: 61.48%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 190, Loss: 0.1629, Train: 78.16%, Valid: 67.79%, Test: 74.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 195, Loss: 0.1613, Train: 69.24%, Valid: 58.29%, Test: 31.97%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 195, Loss: 0.1613, Train: 77.67%, Valid: 67.16%, Test: 54.63%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 195, Loss: 0.1613, Train: 78.95%, Valid: 68.44%, Test: 73.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 67.20%, Valid: 56.51%, Test: 32.05%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 78.06%, Valid: 67.78%, Test: 46.08%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 80.18%, Valid: 69.97%, Test: 61.67%\n",
      "---\n",
      "Hits@10\n",
      "Run 03:\n",
      "Highest Train: 74.79\n",
      "Highest Valid: 64.39\n",
      "  Final Train: 74.79\n",
      "   Final Test: 49.06\n",
      "Hits@20\n",
      "Run 03:\n",
      "Highest Train: 78.35\n",
      "Highest Valid: 68.38\n",
      "  Final Train: 78.30\n",
      "   Final Test: 65.57\n",
      "Hits@30\n",
      "Run 03:\n",
      "Highest Train: 80.18\n",
      "Highest Valid: 69.97\n",
      "  Final Train: 80.18\n",
      "   Final Test: 61.67\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.5763, Train: 11.67%, Valid: 10.27%, Test: 3.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.5763, Train: 15.92%, Valid: 14.30%, Test: 8.96%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.5763, Train: 18.46%, Valid: 16.59%, Test: 11.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 10, Loss: 0.3959, Train: 21.46%, Valid: 18.79%, Test: 7.49%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 10, Loss: 0.3959, Train: 28.19%, Valid: 25.06%, Test: 13.52%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 10, Loss: 0.3959, Train: 33.64%, Valid: 30.41%, Test: 16.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 15, Loss: 0.3182, Train: 34.55%, Valid: 29.99%, Test: 6.78%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 15, Loss: 0.3182, Train: 41.18%, Valid: 36.02%, Test: 11.82%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 15, Loss: 0.3182, Train: 44.75%, Valid: 39.31%, Test: 15.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 20, Loss: 0.2845, Train: 41.45%, Valid: 35.93%, Test: 8.50%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 20, Loss: 0.2845, Train: 46.66%, Valid: 40.57%, Test: 18.27%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 20, Loss: 0.2845, Train: 49.26%, Valid: 42.96%, Test: 22.22%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 25, Loss: 0.2587, Train: 45.10%, Valid: 38.81%, Test: 17.10%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 25, Loss: 0.2587, Train: 51.21%, Valid: 44.40%, Test: 22.55%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 25, Loss: 0.2587, Train: 53.62%, Valid: 46.65%, Test: 31.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 30, Loss: 0.2421, Train: 48.08%, Valid: 41.23%, Test: 12.40%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 30, Loss: 0.2421, Train: 55.58%, Valid: 48.05%, Test: 22.29%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 30, Loss: 0.2421, Train: 59.20%, Valid: 51.34%, Test: 28.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 35, Loss: 0.2262, Train: 49.76%, Valid: 42.43%, Test: 12.01%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 35, Loss: 0.2262, Train: 59.45%, Valid: 51.62%, Test: 28.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 35, Loss: 0.2262, Train: 63.70%, Valid: 55.55%, Test: 35.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 40, Loss: 0.2201, Train: 52.06%, Valid: 44.35%, Test: 24.48%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 40, Loss: 0.2201, Train: 60.34%, Valid: 52.19%, Test: 37.59%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 40, Loss: 0.2201, Train: 65.62%, Valid: 57.24%, Test: 47.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 45, Loss: 0.2125, Train: 56.81%, Valid: 48.81%, Test: 17.79%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 45, Loss: 0.2125, Train: 64.16%, Valid: 55.79%, Test: 23.99%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 45, Loss: 0.2125, Train: 67.45%, Valid: 58.85%, Test: 29.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 50, Loss: 0.2073, Train: 62.97%, Valid: 54.60%, Test: 20.90%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 50, Loss: 0.2073, Train: 67.60%, Valid: 58.88%, Test: 39.53%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 50, Loss: 0.2073, Train: 69.03%, Valid: 60.26%, Test: 46.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 55, Loss: 0.2007, Train: 62.35%, Valid: 53.73%, Test: 21.05%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 55, Loss: 0.2007, Train: 66.98%, Valid: 58.05%, Test: 34.09%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 55, Loss: 0.2007, Train: 70.15%, Valid: 61.12%, Test: 46.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 60, Loss: 0.1962, Train: 60.76%, Valid: 51.97%, Test: 24.16%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 60, Loss: 0.1962, Train: 67.44%, Valid: 58.38%, Test: 39.17%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 60, Loss: 0.1962, Train: 71.00%, Valid: 61.81%, Test: 52.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 65, Loss: 0.1932, Train: 62.58%, Valid: 53.73%, Test: 28.30%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 65, Loss: 0.1932, Train: 67.65%, Valid: 58.55%, Test: 41.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 65, Loss: 0.1932, Train: 70.54%, Valid: 61.36%, Test: 54.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 70, Loss: 0.1895, Train: 61.51%, Valid: 52.56%, Test: 41.40%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 70, Loss: 0.1895, Train: 68.77%, Valid: 59.53%, Test: 53.05%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 70, Loss: 0.1895, Train: 71.96%, Valid: 62.63%, Test: 60.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 75, Loss: 0.1880, Train: 64.80%, Valid: 55.62%, Test: 40.51%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 75, Loss: 0.1880, Train: 69.80%, Valid: 60.32%, Test: 48.81%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 75, Loss: 0.1880, Train: 72.77%, Valid: 63.26%, Test: 59.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 80, Loss: 0.1848, Train: 65.06%, Valid: 55.62%, Test: 43.30%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 80, Loss: 0.1848, Train: 70.52%, Valid: 60.93%, Test: 57.63%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 80, Loss: 0.1848, Train: 72.61%, Valid: 62.98%, Test: 64.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 85, Loss: 0.1822, Train: 58.09%, Valid: 48.84%, Test: 34.35%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 85, Loss: 0.1822, Train: 69.17%, Valid: 59.47%, Test: 45.95%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 85, Loss: 0.1822, Train: 74.00%, Valid: 64.19%, Test: 55.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 90, Loss: 0.1829, Train: 64.76%, Valid: 55.35%, Test: 33.48%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 90, Loss: 0.1829, Train: 72.71%, Valid: 63.18%, Test: 45.72%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 90, Loss: 0.1829, Train: 74.16%, Valid: 64.59%, Test: 51.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 95, Loss: 0.1774, Train: 55.89%, Valid: 46.09%, Test: 48.64%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 95, Loss: 0.1774, Train: 71.07%, Valid: 61.31%, Test: 57.71%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 95, Loss: 0.1774, Train: 74.56%, Valid: 64.84%, Test: 65.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 100, Loss: 0.1796, Train: 69.01%, Valid: 59.37%, Test: 29.11%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 100, Loss: 0.1796, Train: 74.09%, Valid: 64.28%, Test: 52.37%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 100, Loss: 0.1796, Train: 75.30%, Valid: 65.54%, Test: 64.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 105, Loss: 0.1748, Train: 60.80%, Valid: 51.25%, Test: 38.13%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 105, Loss: 0.1748, Train: 73.28%, Valid: 63.45%, Test: 52.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 105, Loss: 0.1748, Train: 76.43%, Valid: 66.65%, Test: 66.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 66.46%, Valid: 56.39%, Test: 47.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 73.46%, Valid: 63.51%, Test: 54.64%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 77.01%, Valid: 67.18%, Test: 71.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 115, Loss: 0.1719, Train: 67.72%, Valid: 57.88%, Test: 44.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 115, Loss: 0.1719, Train: 74.53%, Valid: 64.71%, Test: 58.17%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 115, Loss: 0.1719, Train: 76.77%, Valid: 66.91%, Test: 70.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 120, Loss: 0.1702, Train: 67.08%, Valid: 56.99%, Test: 31.64%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 120, Loss: 0.1702, Train: 75.95%, Valid: 66.05%, Test: 47.91%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 120, Loss: 0.1702, Train: 77.63%, Valid: 67.76%, Test: 61.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 125, Loss: 0.1704, Train: 68.24%, Valid: 58.25%, Test: 47.67%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 125, Loss: 0.1704, Train: 76.19%, Valid: 66.17%, Test: 60.95%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 125, Loss: 0.1704, Train: 77.97%, Valid: 68.02%, Test: 70.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 130, Loss: 0.1724, Train: 65.77%, Valid: 55.71%, Test: 15.28%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 130, Loss: 0.1724, Train: 75.84%, Valid: 65.80%, Test: 46.52%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 130, Loss: 0.1724, Train: 76.55%, Valid: 66.52%, Test: 62.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 135, Loss: 0.1703, Train: 71.51%, Valid: 61.49%, Test: 33.94%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 135, Loss: 0.1703, Train: 75.98%, Valid: 65.93%, Test: 55.60%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 135, Loss: 0.1703, Train: 77.84%, Valid: 67.82%, Test: 75.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 140, Loss: 0.1676, Train: 62.79%, Valid: 52.82%, Test: 41.09%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 140, Loss: 0.1676, Train: 75.40%, Valid: 65.20%, Test: 57.34%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 140, Loss: 0.1676, Train: 77.52%, Valid: 67.42%, Test: 71.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 145, Loss: 0.1667, Train: 67.97%, Valid: 57.72%, Test: 34.87%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 145, Loss: 0.1667, Train: 76.19%, Valid: 65.86%, Test: 51.79%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 145, Loss: 0.1667, Train: 77.77%, Valid: 67.50%, Test: 62.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 150, Loss: 0.1670, Train: 59.06%, Valid: 48.80%, Test: 41.70%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 150, Loss: 0.1670, Train: 72.43%, Valid: 61.75%, Test: 56.37%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 150, Loss: 0.1670, Train: 75.59%, Valid: 65.02%, Test: 68.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 155, Loss: 0.1657, Train: 70.51%, Valid: 60.19%, Test: 35.81%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 155, Loss: 0.1657, Train: 76.21%, Valid: 66.04%, Test: 57.58%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 155, Loss: 0.1657, Train: 78.37%, Valid: 68.19%, Test: 75.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 160, Loss: 0.1646, Train: 60.81%, Valid: 50.37%, Test: 46.70%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 160, Loss: 0.1646, Train: 74.84%, Valid: 64.31%, Test: 63.16%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 160, Loss: 0.1646, Train: 77.72%, Valid: 67.39%, Test: 70.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 165, Loss: 0.1634, Train: 67.50%, Valid: 57.44%, Test: 49.70%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 165, Loss: 0.1634, Train: 74.72%, Valid: 64.57%, Test: 62.82%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 165, Loss: 0.1634, Train: 77.67%, Valid: 67.49%, Test: 75.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 170, Loss: 0.1631, Train: 67.63%, Valid: 57.18%, Test: 23.53%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 170, Loss: 0.1631, Train: 75.43%, Valid: 65.23%, Test: 52.52%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 170, Loss: 0.1631, Train: 78.39%, Valid: 68.30%, Test: 66.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 175, Loss: 0.1621, Train: 64.20%, Valid: 53.48%, Test: 23.20%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 175, Loss: 0.1621, Train: 75.24%, Valid: 64.68%, Test: 50.44%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 175, Loss: 0.1621, Train: 77.22%, Valid: 66.76%, Test: 66.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 180, Loss: 0.1616, Train: 67.68%, Valid: 57.18%, Test: 25.95%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 180, Loss: 0.1616, Train: 74.85%, Valid: 64.35%, Test: 42.11%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 180, Loss: 0.1616, Train: 77.82%, Valid: 67.48%, Test: 62.45%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 185, Loss: 0.1612, Train: 62.35%, Valid: 52.15%, Test: 15.61%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 185, Loss: 0.1612, Train: 76.13%, Valid: 65.63%, Test: 52.28%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 185, Loss: 0.1612, Train: 78.74%, Valid: 68.36%, Test: 65.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 190, Loss: 0.1611, Train: 70.79%, Valid: 60.61%, Test: 41.04%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 190, Loss: 0.1611, Train: 75.32%, Valid: 65.08%, Test: 56.46%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 190, Loss: 0.1611, Train: 78.17%, Valid: 68.05%, Test: 68.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 195, Loss: 0.1606, Train: 72.98%, Valid: 62.42%, Test: 30.33%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 195, Loss: 0.1606, Train: 75.48%, Valid: 65.02%, Test: 53.22%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 195, Loss: 0.1606, Train: 78.54%, Valid: 68.14%, Test: 72.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 200, Loss: 0.1611, Train: 70.38%, Valid: 59.79%, Test: 17.86%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 200, Loss: 0.1611, Train: 77.89%, Valid: 67.47%, Test: 41.30%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 200, Loss: 0.1611, Train: 79.90%, Valid: 69.60%, Test: 53.75%\n",
      "---\n",
      "Hits@10\n",
      "Run 04:\n",
      "Highest Train: 72.98\n",
      "Highest Valid: 62.42\n",
      "  Final Train: 72.98\n",
      "   Final Test: 30.33\n",
      "Hits@20\n",
      "Run 04:\n",
      "Highest Train: 77.89\n",
      "Highest Valid: 67.47\n",
      "  Final Train: 77.89\n",
      "   Final Test: 41.30\n",
      "Hits@30\n",
      "Run 04:\n",
      "Highest Train: 79.90\n",
      "Highest Valid: 69.60\n",
      "  Final Train: 79.90\n",
      "   Final Test: 53.75\n",
      "Hits@10\n",
      "Run: 05, Epoch: 05, Loss: 0.5564, Train: 10.67%, Valid: 9.35%, Test: 5.08%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 05, Loss: 0.5564, Train: 14.12%, Valid: 12.60%, Test: 9.44%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 05, Loss: 0.5564, Train: 16.23%, Valid: 14.56%, Test: 11.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 10, Loss: 0.3899, Train: 23.58%, Valid: 20.69%, Test: 5.61%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 10, Loss: 0.3899, Train: 28.13%, Valid: 24.95%, Test: 9.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 10, Loss: 0.3899, Train: 30.79%, Valid: 27.41%, Test: 13.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 15, Loss: 0.3188, Train: 35.73%, Valid: 31.21%, Test: 6.68%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 15, Loss: 0.3188, Train: 45.57%, Valid: 40.53%, Test: 13.90%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 15, Loss: 0.3188, Train: 48.07%, Valid: 42.92%, Test: 20.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 20, Loss: 0.2831, Train: 47.44%, Valid: 41.65%, Test: 14.79%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 20, Loss: 0.2831, Train: 52.51%, Valid: 46.36%, Test: 24.88%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 20, Loss: 0.2831, Train: 55.26%, Valid: 48.90%, Test: 27.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 49.45%, Valid: 42.65%, Test: 13.00%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 55.08%, Valid: 47.98%, Test: 23.40%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 58.12%, Valid: 50.95%, Test: 26.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 30, Loss: 0.2426, Train: 49.71%, Valid: 42.89%, Test: 8.05%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 30, Loss: 0.2426, Train: 57.68%, Valid: 50.19%, Test: 16.24%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 30, Loss: 0.2426, Train: 61.95%, Valid: 54.05%, Test: 20.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 35, Loss: 0.2299, Train: 53.10%, Valid: 45.50%, Test: 12.15%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 35, Loss: 0.2299, Train: 62.33%, Valid: 54.22%, Test: 18.78%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 35, Loss: 0.2299, Train: 64.60%, Valid: 56.33%, Test: 28.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 40, Loss: 0.2188, Train: 62.25%, Valid: 53.91%, Test: 18.23%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 40, Loss: 0.2188, Train: 65.79%, Valid: 57.28%, Test: 29.50%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 40, Loss: 0.2188, Train: 67.60%, Valid: 59.01%, Test: 37.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 45, Loss: 0.2110, Train: 60.16%, Valid: 51.48%, Test: 26.25%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 45, Loss: 0.2110, Train: 65.92%, Valid: 57.08%, Test: 37.78%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 45, Loss: 0.2110, Train: 67.94%, Valid: 59.03%, Test: 44.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 50, Loss: 0.2033, Train: 61.15%, Valid: 52.52%, Test: 22.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 50, Loss: 0.2033, Train: 67.20%, Valid: 58.22%, Test: 42.99%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 50, Loss: 0.2033, Train: 70.40%, Valid: 61.27%, Test: 56.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 55, Loss: 0.2006, Train: 60.85%, Valid: 52.21%, Test: 13.85%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 55, Loss: 0.2006, Train: 68.68%, Valid: 59.65%, Test: 39.38%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 55, Loss: 0.2006, Train: 71.10%, Valid: 62.05%, Test: 50.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 60, Loss: 0.1948, Train: 64.74%, Valid: 55.55%, Test: 29.71%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 60, Loss: 0.1948, Train: 67.96%, Valid: 58.61%, Test: 46.11%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 60, Loss: 0.1948, Train: 72.12%, Valid: 62.77%, Test: 54.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 65, Loss: 0.1922, Train: 59.85%, Valid: 50.89%, Test: 30.83%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 65, Loss: 0.1922, Train: 69.20%, Valid: 59.89%, Test: 49.71%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 65, Loss: 0.1922, Train: 71.86%, Valid: 62.50%, Test: 57.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 57.59%, Valid: 48.74%, Test: 30.30%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 68.17%, Valid: 58.89%, Test: 46.82%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 71.36%, Valid: 61.89%, Test: 52.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 75, Loss: 0.1847, Train: 64.75%, Valid: 55.66%, Test: 32.05%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 75, Loss: 0.1847, Train: 73.29%, Valid: 63.67%, Test: 58.21%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 75, Loss: 0.1847, Train: 74.79%, Valid: 65.20%, Test: 63.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 80, Loss: 0.1839, Train: 63.57%, Valid: 54.47%, Test: 41.10%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 80, Loss: 0.1839, Train: 71.12%, Valid: 61.69%, Test: 52.62%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 80, Loss: 0.1839, Train: 73.64%, Valid: 64.15%, Test: 63.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 85, Loss: 0.1829, Train: 63.11%, Valid: 53.65%, Test: 36.07%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 85, Loss: 0.1829, Train: 71.93%, Valid: 62.27%, Test: 55.78%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 85, Loss: 0.1829, Train: 74.81%, Valid: 65.21%, Test: 68.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 90, Loss: 0.1797, Train: 66.56%, Valid: 56.62%, Test: 41.59%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 90, Loss: 0.1797, Train: 72.10%, Valid: 62.16%, Test: 54.97%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 90, Loss: 0.1797, Train: 74.14%, Valid: 64.25%, Test: 65.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 95, Loss: 0.1772, Train: 64.54%, Valid: 54.84%, Test: 42.47%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 95, Loss: 0.1772, Train: 73.29%, Valid: 63.57%, Test: 60.36%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 95, Loss: 0.1772, Train: 77.13%, Valid: 67.45%, Test: 71.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 100, Loss: 0.1768, Train: 64.89%, Valid: 55.29%, Test: 22.40%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 100, Loss: 0.1768, Train: 73.04%, Valid: 63.31%, Test: 44.03%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 100, Loss: 0.1768, Train: 75.00%, Valid: 65.30%, Test: 56.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 105, Loss: 0.1745, Train: 69.82%, Valid: 60.15%, Test: 53.14%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 105, Loss: 0.1745, Train: 74.20%, Valid: 64.55%, Test: 60.78%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 105, Loss: 0.1745, Train: 77.01%, Valid: 67.22%, Test: 71.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 110, Loss: 0.1733, Train: 71.69%, Valid: 61.83%, Test: 33.44%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 110, Loss: 0.1733, Train: 74.45%, Valid: 64.56%, Test: 56.03%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 110, Loss: 0.1733, Train: 76.79%, Valid: 66.94%, Test: 70.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 115, Loss: 0.1725, Train: 68.89%, Valid: 58.90%, Test: 38.38%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 115, Loss: 0.1725, Train: 73.01%, Valid: 62.96%, Test: 58.51%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 115, Loss: 0.1725, Train: 75.82%, Valid: 65.89%, Test: 70.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 120, Loss: 0.1706, Train: 72.39%, Valid: 62.38%, Test: 50.40%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 120, Loss: 0.1706, Train: 76.08%, Valid: 66.14%, Test: 67.77%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 120, Loss: 0.1706, Train: 78.04%, Valid: 68.12%, Test: 77.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 125, Loss: 0.1688, Train: 71.75%, Valid: 61.81%, Test: 48.90%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 125, Loss: 0.1688, Train: 75.80%, Valid: 65.86%, Test: 69.31%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 125, Loss: 0.1688, Train: 77.89%, Valid: 67.91%, Test: 78.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 130, Loss: 0.1707, Train: 66.44%, Valid: 56.52%, Test: 40.37%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 130, Loss: 0.1707, Train: 75.22%, Valid: 65.17%, Test: 66.04%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 130, Loss: 0.1707, Train: 77.90%, Valid: 67.97%, Test: 76.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 135, Loss: 0.1665, Train: 66.69%, Valid: 56.43%, Test: 35.44%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 135, Loss: 0.1665, Train: 76.65%, Valid: 66.59%, Test: 58.04%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 135, Loss: 0.1665, Train: 77.92%, Valid: 67.90%, Test: 73.74%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 05, Epoch: 140, Loss: 0.1659, Train: 67.04%, Valid: 56.89%, Test: 45.50%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 140, Loss: 0.1659, Train: 75.29%, Valid: 65.24%, Test: 61.28%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 140, Loss: 0.1659, Train: 77.31%, Valid: 67.32%, Test: 68.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 145, Loss: 0.1659, Train: 68.87%, Valid: 58.69%, Test: 47.00%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 145, Loss: 0.1659, Train: 77.46%, Valid: 67.47%, Test: 65.38%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 145, Loss: 0.1659, Train: 78.90%, Valid: 68.86%, Test: 76.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 150, Loss: 0.1653, Train: 65.31%, Valid: 55.06%, Test: 43.67%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 150, Loss: 0.1653, Train: 76.54%, Valid: 66.41%, Test: 61.01%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 150, Loss: 0.1653, Train: 77.94%, Valid: 67.84%, Test: 68.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 155, Loss: 0.1642, Train: 69.79%, Valid: 59.43%, Test: 33.61%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 155, Loss: 0.1642, Train: 74.57%, Valid: 64.28%, Test: 50.39%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 155, Loss: 0.1642, Train: 77.47%, Valid: 67.33%, Test: 68.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 160, Loss: 0.1630, Train: 70.70%, Valid: 60.46%, Test: 46.02%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 160, Loss: 0.1630, Train: 75.89%, Valid: 65.70%, Test: 65.97%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 160, Loss: 0.1630, Train: 79.25%, Valid: 69.20%, Test: 73.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 165, Loss: 0.1641, Train: 70.04%, Valid: 59.38%, Test: 31.49%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 165, Loss: 0.1641, Train: 76.27%, Valid: 65.73%, Test: 63.32%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 165, Loss: 0.1641, Train: 78.67%, Valid: 68.26%, Test: 75.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 170, Loss: 0.1632, Train: 70.14%, Valid: 59.79%, Test: 50.73%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 170, Loss: 0.1632, Train: 77.88%, Valid: 67.75%, Test: 64.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 170, Loss: 0.1632, Train: 78.99%, Valid: 68.93%, Test: 80.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 175, Loss: 0.1636, Train: 69.04%, Valid: 58.50%, Test: 39.72%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 175, Loss: 0.1636, Train: 75.44%, Valid: 65.05%, Test: 55.66%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 175, Loss: 0.1636, Train: 78.76%, Valid: 68.49%, Test: 69.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 180, Loss: 0.1613, Train: 68.71%, Valid: 58.21%, Test: 37.51%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 180, Loss: 0.1613, Train: 78.14%, Valid: 67.92%, Test: 52.56%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 180, Loss: 0.1613, Train: 79.64%, Valid: 69.53%, Test: 69.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 185, Loss: 0.1595, Train: 69.07%, Valid: 58.15%, Test: 41.75%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 185, Loss: 0.1595, Train: 76.33%, Valid: 65.68%, Test: 65.62%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 185, Loss: 0.1595, Train: 78.39%, Valid: 67.96%, Test: 77.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 190, Loss: 0.1603, Train: 70.51%, Valid: 59.62%, Test: 32.06%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 190, Loss: 0.1603, Train: 78.69%, Valid: 68.35%, Test: 51.24%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 190, Loss: 0.1603, Train: 79.76%, Valid: 69.46%, Test: 65.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 195, Loss: 0.1588, Train: 69.11%, Valid: 58.16%, Test: 36.24%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 195, Loss: 0.1588, Train: 76.93%, Valid: 66.33%, Test: 47.23%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 195, Loss: 0.1588, Train: 79.27%, Valid: 68.83%, Test: 67.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 69.57%, Valid: 58.79%, Test: 28.59%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 77.20%, Valid: 66.73%, Test: 55.74%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 79.36%, Valid: 69.14%, Test: 68.14%\n",
      "---\n",
      "Hits@10\n",
      "Run 05:\n",
      "Highest Train: 72.39\n",
      "Highest Valid: 62.38\n",
      "  Final Train: 72.39\n",
      "   Final Test: 50.40\n",
      "Hits@20\n",
      "Run 05:\n",
      "Highest Train: 78.69\n",
      "Highest Valid: 68.35\n",
      "  Final Train: 78.69\n",
      "   Final Test: 51.24\n",
      "Hits@30\n",
      "Run 05:\n",
      "Highest Train: 79.76\n",
      "Highest Valid: 69.53\n",
      "  Final Train: 79.64\n",
      "   Final Test: 69.64\n",
      "Hits@10\n",
      "Run: 06, Epoch: 05, Loss: 0.5911, Train: 6.54%, Valid: 5.61%, Test: 4.09%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 05, Loss: 0.5911, Train: 10.34%, Valid: 9.00%, Test: 7.61%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 05, Loss: 0.5911, Train: 13.10%, Valid: 11.52%, Test: 10.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 10, Loss: 0.4223, Train: 20.13%, Valid: 17.47%, Test: 4.51%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 10, Loss: 0.4223, Train: 25.48%, Valid: 22.30%, Test: 13.54%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 10, Loss: 0.4223, Train: 30.17%, Valid: 26.73%, Test: 19.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 15, Loss: 0.3312, Train: 30.77%, Valid: 26.65%, Test: 11.89%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 15, Loss: 0.3312, Train: 37.77%, Valid: 33.02%, Test: 15.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 15, Loss: 0.3312, Train: 40.49%, Valid: 35.52%, Test: 18.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 20, Loss: 0.2888, Train: 40.66%, Valid: 35.33%, Test: 8.02%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 20, Loss: 0.2888, Train: 47.69%, Valid: 41.79%, Test: 13.79%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 20, Loss: 0.2888, Train: 50.75%, Valid: 44.74%, Test: 20.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 25, Loss: 0.2615, Train: 47.82%, Valid: 41.34%, Test: 8.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 25, Loss: 0.2615, Train: 53.35%, Valid: 46.55%, Test: 18.18%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 25, Loss: 0.2615, Train: 55.86%, Valid: 48.84%, Test: 27.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 30, Loss: 0.2434, Train: 51.43%, Valid: 44.51%, Test: 26.58%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 30, Loss: 0.2434, Train: 59.57%, Valid: 52.12%, Test: 35.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 30, Loss: 0.2434, Train: 61.66%, Valid: 53.99%, Test: 39.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 35, Loss: 0.2314, Train: 46.99%, Valid: 39.88%, Test: 19.97%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 35, Loss: 0.2314, Train: 54.99%, Valid: 47.19%, Test: 25.84%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 35, Loss: 0.2314, Train: 59.09%, Valid: 51.06%, Test: 35.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 40, Loss: 0.2196, Train: 53.64%, Valid: 45.89%, Test: 18.24%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 40, Loss: 0.2196, Train: 60.71%, Valid: 52.53%, Test: 26.75%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 40, Loss: 0.2196, Train: 64.40%, Valid: 56.06%, Test: 41.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 45, Loss: 0.2115, Train: 54.43%, Valid: 46.42%, Test: 28.39%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 45, Loss: 0.2115, Train: 63.51%, Valid: 54.94%, Test: 43.31%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 45, Loss: 0.2115, Train: 67.42%, Valid: 58.77%, Test: 51.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 50, Loss: 0.2051, Train: 49.54%, Valid: 41.54%, Test: 31.20%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 50, Loss: 0.2051, Train: 61.53%, Valid: 52.71%, Test: 42.77%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 50, Loss: 0.2051, Train: 69.04%, Valid: 60.02%, Test: 54.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 55, Loss: 0.2022, Train: 58.75%, Valid: 50.17%, Test: 40.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 55, Loss: 0.2022, Train: 66.39%, Valid: 57.42%, Test: 47.33%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 55, Loss: 0.2022, Train: 67.89%, Valid: 58.88%, Test: 56.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 60, Loss: 0.1982, Train: 63.43%, Valid: 54.81%, Test: 32.25%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 60, Loss: 0.1982, Train: 70.67%, Valid: 61.63%, Test: 50.66%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 60, Loss: 0.1982, Train: 73.12%, Valid: 64.02%, Test: 63.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 65, Loss: 0.1936, Train: 55.23%, Valid: 46.55%, Test: 32.75%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 65, Loss: 0.1936, Train: 66.57%, Valid: 57.34%, Test: 45.22%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 65, Loss: 0.1936, Train: 69.96%, Valid: 60.57%, Test: 61.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 70, Loss: 0.1894, Train: 61.48%, Valid: 52.13%, Test: 27.18%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 70, Loss: 0.1894, Train: 69.15%, Valid: 59.76%, Test: 42.40%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 70, Loss: 0.1894, Train: 71.92%, Valid: 62.46%, Test: 50.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 75, Loss: 0.1869, Train: 60.98%, Valid: 51.70%, Test: 29.91%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 75, Loss: 0.1869, Train: 67.19%, Valid: 57.82%, Test: 37.86%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 75, Loss: 0.1869, Train: 71.60%, Valid: 62.12%, Test: 48.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 80, Loss: 0.1855, Train: 57.10%, Valid: 47.83%, Test: 27.65%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 80, Loss: 0.1855, Train: 69.06%, Valid: 59.45%, Test: 49.03%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 80, Loss: 0.1855, Train: 73.00%, Valid: 63.41%, Test: 63.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 85, Loss: 0.1814, Train: 58.87%, Valid: 49.49%, Test: 39.17%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 85, Loss: 0.1814, Train: 67.65%, Valid: 57.89%, Test: 52.71%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 85, Loss: 0.1814, Train: 71.87%, Valid: 62.00%, Test: 60.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 90, Loss: 0.1808, Train: 67.14%, Valid: 57.42%, Test: 36.37%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 90, Loss: 0.1808, Train: 71.78%, Valid: 61.98%, Test: 50.14%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 90, Loss: 0.1808, Train: 74.71%, Valid: 64.97%, Test: 61.63%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 06, Epoch: 95, Loss: 0.1774, Train: 58.40%, Valid: 48.92%, Test: 31.55%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 95, Loss: 0.1774, Train: 70.40%, Valid: 60.60%, Test: 47.36%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 95, Loss: 0.1774, Train: 73.98%, Valid: 64.27%, Test: 59.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 100, Loss: 0.1769, Train: 58.29%, Valid: 48.48%, Test: 38.78%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 100, Loss: 0.1769, Train: 70.04%, Valid: 59.98%, Test: 53.96%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 100, Loss: 0.1769, Train: 73.87%, Valid: 63.90%, Test: 61.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 105, Loss: 0.1747, Train: 65.08%, Valid: 55.16%, Test: 27.60%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 105, Loss: 0.1747, Train: 71.22%, Valid: 61.30%, Test: 47.75%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 105, Loss: 0.1747, Train: 74.79%, Valid: 64.93%, Test: 62.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 110, Loss: 0.1740, Train: 61.56%, Valid: 51.49%, Test: 39.94%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 110, Loss: 0.1740, Train: 69.11%, Valid: 58.98%, Test: 55.62%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 110, Loss: 0.1740, Train: 74.39%, Valid: 64.43%, Test: 64.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 115, Loss: 0.1742, Train: 62.50%, Valid: 52.66%, Test: 28.19%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 115, Loss: 0.1742, Train: 72.75%, Valid: 62.84%, Test: 53.90%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 115, Loss: 0.1742, Train: 76.12%, Valid: 66.22%, Test: 66.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 120, Loss: 0.1737, Train: 62.70%, Valid: 52.90%, Test: 30.70%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 120, Loss: 0.1737, Train: 75.04%, Valid: 65.24%, Test: 55.36%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 120, Loss: 0.1737, Train: 77.04%, Valid: 67.21%, Test: 67.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 125, Loss: 0.1705, Train: 64.49%, Valid: 54.38%, Test: 42.87%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 125, Loss: 0.1705, Train: 75.69%, Valid: 65.67%, Test: 58.32%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 125, Loss: 0.1705, Train: 76.77%, Valid: 66.82%, Test: 69.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 130, Loss: 0.1699, Train: 61.01%, Valid: 50.45%, Test: 30.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 130, Loss: 0.1699, Train: 72.97%, Valid: 62.54%, Test: 50.05%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 130, Loss: 0.1699, Train: 75.67%, Valid: 65.35%, Test: 59.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 135, Loss: 0.1691, Train: 68.33%, Valid: 58.12%, Test: 49.13%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 135, Loss: 0.1691, Train: 76.08%, Valid: 65.96%, Test: 63.93%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 135, Loss: 0.1691, Train: 77.49%, Valid: 67.51%, Test: 72.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 140, Loss: 0.1683, Train: 60.34%, Valid: 50.02%, Test: 38.54%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 140, Loss: 0.1683, Train: 73.43%, Valid: 63.10%, Test: 56.68%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 140, Loss: 0.1683, Train: 76.85%, Valid: 66.63%, Test: 64.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 145, Loss: 0.1676, Train: 70.17%, Valid: 59.96%, Test: 24.69%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 145, Loss: 0.1676, Train: 77.30%, Valid: 67.30%, Test: 60.95%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 145, Loss: 0.1676, Train: 78.73%, Valid: 68.74%, Test: 72.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 150, Loss: 0.1659, Train: 64.58%, Valid: 53.92%, Test: 33.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 150, Loss: 0.1659, Train: 75.68%, Valid: 65.44%, Test: 57.23%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 150, Loss: 0.1659, Train: 77.26%, Valid: 67.13%, Test: 70.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 155, Loss: 0.1643, Train: 67.22%, Valid: 56.79%, Test: 30.63%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 155, Loss: 0.1643, Train: 76.93%, Valid: 66.70%, Test: 65.13%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 155, Loss: 0.1643, Train: 78.38%, Valid: 68.22%, Test: 76.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 160, Loss: 0.1636, Train: 66.05%, Valid: 55.73%, Test: 33.09%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 160, Loss: 0.1636, Train: 76.37%, Valid: 66.13%, Test: 63.96%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 160, Loss: 0.1636, Train: 78.36%, Valid: 68.19%, Test: 73.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 165, Loss: 0.1644, Train: 71.36%, Valid: 60.74%, Test: 38.03%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 165, Loss: 0.1644, Train: 76.82%, Valid: 66.42%, Test: 53.78%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 165, Loss: 0.1644, Train: 79.30%, Valid: 69.18%, Test: 69.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 170, Loss: 0.1627, Train: 70.17%, Valid: 59.74%, Test: 36.36%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 170, Loss: 0.1627, Train: 75.07%, Valid: 64.75%, Test: 64.06%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 170, Loss: 0.1627, Train: 77.57%, Valid: 67.38%, Test: 74.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 175, Loss: 0.1641, Train: 69.09%, Valid: 58.55%, Test: 42.50%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 175, Loss: 0.1641, Train: 76.10%, Valid: 65.81%, Test: 54.37%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 175, Loss: 0.1641, Train: 78.46%, Valid: 68.26%, Test: 67.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 180, Loss: 0.1631, Train: 68.39%, Valid: 57.88%, Test: 27.92%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 180, Loss: 0.1631, Train: 75.69%, Valid: 65.32%, Test: 51.55%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 180, Loss: 0.1631, Train: 77.60%, Valid: 67.28%, Test: 62.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 185, Loss: 0.1615, Train: 62.35%, Valid: 51.55%, Test: 32.12%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 185, Loss: 0.1615, Train: 73.26%, Valid: 62.44%, Test: 45.12%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 185, Loss: 0.1615, Train: 76.80%, Valid: 66.21%, Test: 61.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 190, Loss: 0.1631, Train: 64.28%, Valid: 53.86%, Test: 35.26%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 190, Loss: 0.1631, Train: 75.85%, Valid: 65.49%, Test: 49.15%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 190, Loss: 0.1631, Train: 78.23%, Valid: 67.98%, Test: 69.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 195, Loss: 0.1605, Train: 67.87%, Valid: 57.19%, Test: 31.44%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 195, Loss: 0.1605, Train: 75.24%, Valid: 64.54%, Test: 50.13%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 195, Loss: 0.1605, Train: 78.40%, Valid: 67.97%, Test: 67.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 200, Loss: 0.1600, Train: 68.09%, Valid: 56.90%, Test: 15.52%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 200, Loss: 0.1600, Train: 77.55%, Valid: 66.97%, Test: 48.06%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 200, Loss: 0.1600, Train: 79.61%, Valid: 69.28%, Test: 63.38%\n",
      "---\n",
      "Hits@10\n",
      "Run 06:\n",
      "Highest Train: 71.36\n",
      "Highest Valid: 60.74\n",
      "  Final Train: 71.36\n",
      "   Final Test: 38.03\n",
      "Hits@20\n",
      "Run 06:\n",
      "Highest Train: 77.55\n",
      "Highest Valid: 67.30\n",
      "  Final Train: 77.30\n",
      "   Final Test: 60.95\n",
      "Hits@30\n",
      "Run 06:\n",
      "Highest Train: 79.61\n",
      "Highest Valid: 69.28\n",
      "  Final Train: 79.61\n",
      "   Final Test: 63.38\n",
      "Hits@10\n",
      "Run: 07, Epoch: 05, Loss: 0.5413, Train: 16.01%, Valid: 14.24%, Test: 4.59%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 05, Loss: 0.5413, Train: 19.00%, Valid: 17.02%, Test: 9.07%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 05, Loss: 0.5413, Train: 21.21%, Valid: 19.15%, Test: 12.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 10, Loss: 0.3849, Train: 27.44%, Valid: 24.17%, Test: 8.97%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 10, Loss: 0.3849, Train: 32.03%, Valid: 28.46%, Test: 13.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 10, Loss: 0.3849, Train: 36.52%, Valid: 32.77%, Test: 18.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 15, Loss: 0.3192, Train: 33.68%, Valid: 29.30%, Test: 9.25%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 15, Loss: 0.3192, Train: 40.83%, Valid: 35.63%, Test: 18.82%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 15, Loss: 0.3192, Train: 44.63%, Valid: 39.27%, Test: 24.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 20, Loss: 0.2805, Train: 40.44%, Valid: 34.72%, Test: 12.45%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 20, Loss: 0.2805, Train: 45.99%, Valid: 39.79%, Test: 19.05%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 20, Loss: 0.2805, Train: 50.64%, Valid: 44.19%, Test: 22.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 25, Loss: 0.2570, Train: 49.67%, Valid: 42.98%, Test: 17.45%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 25, Loss: 0.2570, Train: 53.01%, Valid: 46.07%, Test: 23.36%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 25, Loss: 0.2570, Train: 56.72%, Valid: 49.62%, Test: 30.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 30, Loss: 0.2379, Train: 53.04%, Valid: 45.57%, Test: 19.24%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 30, Loss: 0.2379, Train: 57.53%, Valid: 49.79%, Test: 26.73%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 30, Loss: 0.2379, Train: 60.58%, Valid: 52.67%, Test: 36.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 35, Loss: 0.2252, Train: 52.78%, Valid: 45.05%, Test: 19.85%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 35, Loss: 0.2252, Train: 58.45%, Valid: 50.46%, Test: 28.49%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 35, Loss: 0.2252, Train: 62.18%, Valid: 54.03%, Test: 37.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 40, Loss: 0.2148, Train: 57.96%, Valid: 49.79%, Test: 25.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 40, Loss: 0.2148, Train: 63.36%, Valid: 54.91%, Test: 38.54%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 40, Loss: 0.2148, Train: 66.98%, Valid: 58.32%, Test: 46.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 45, Loss: 0.2077, Train: 59.72%, Valid: 51.26%, Test: 26.09%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 45, Loss: 0.2077, Train: 66.67%, Valid: 57.81%, Test: 38.54%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 45, Loss: 0.2077, Train: 68.43%, Valid: 59.49%, Test: 47.65%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 07, Epoch: 50, Loss: 0.2025, Train: 62.15%, Valid: 53.66%, Test: 40.56%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 50, Loss: 0.2025, Train: 67.98%, Valid: 59.17%, Test: 48.72%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 50, Loss: 0.2025, Train: 69.81%, Valid: 60.94%, Test: 58.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 55, Loss: 0.1981, Train: 65.07%, Valid: 55.97%, Test: 34.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 55, Loss: 0.1981, Train: 69.96%, Valid: 60.70%, Test: 49.64%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 55, Loss: 0.1981, Train: 72.44%, Valid: 63.17%, Test: 58.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 60, Loss: 0.1934, Train: 57.83%, Valid: 48.78%, Test: 23.54%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 60, Loss: 0.1934, Train: 66.20%, Valid: 56.81%, Test: 44.54%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 60, Loss: 0.1934, Train: 70.03%, Valid: 60.64%, Test: 52.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 65, Loss: 0.1893, Train: 63.55%, Valid: 54.33%, Test: 22.71%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 65, Loss: 0.1893, Train: 69.56%, Valid: 60.22%, Test: 45.63%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 65, Loss: 0.1893, Train: 72.24%, Valid: 62.78%, Test: 55.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 70, Loss: 0.1877, Train: 59.84%, Valid: 50.95%, Test: 26.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 70, Loss: 0.1877, Train: 70.61%, Valid: 61.43%, Test: 46.45%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 70, Loss: 0.1877, Train: 73.30%, Valid: 63.99%, Test: 57.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 75, Loss: 0.1852, Train: 56.50%, Valid: 47.26%, Test: 44.90%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 75, Loss: 0.1852, Train: 70.54%, Valid: 60.93%, Test: 58.01%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 75, Loss: 0.1852, Train: 72.56%, Valid: 62.95%, Test: 64.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 80, Loss: 0.1836, Train: 55.15%, Valid: 45.90%, Test: 34.88%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 80, Loss: 0.1836, Train: 70.43%, Valid: 60.83%, Test: 46.60%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 80, Loss: 0.1836, Train: 73.92%, Valid: 64.24%, Test: 59.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 85, Loss: 0.1805, Train: 64.45%, Valid: 55.04%, Test: 48.63%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 85, Loss: 0.1805, Train: 71.25%, Valid: 61.72%, Test: 63.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 85, Loss: 0.1805, Train: 74.43%, Valid: 64.96%, Test: 70.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 90, Loss: 0.1777, Train: 61.19%, Valid: 51.76%, Test: 45.00%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 90, Loss: 0.1777, Train: 72.53%, Valid: 62.94%, Test: 59.53%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 90, Loss: 0.1777, Train: 76.56%, Valid: 66.92%, Test: 68.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 95, Loss: 0.1759, Train: 57.31%, Valid: 47.45%, Test: 44.26%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 95, Loss: 0.1759, Train: 70.70%, Valid: 60.61%, Test: 54.82%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 95, Loss: 0.1759, Train: 74.88%, Valid: 64.91%, Test: 62.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 100, Loss: 0.1748, Train: 63.82%, Valid: 54.13%, Test: 51.66%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 100, Loss: 0.1748, Train: 71.90%, Valid: 62.02%, Test: 60.94%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 100, Loss: 0.1748, Train: 74.61%, Valid: 64.72%, Test: 69.02%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 105, Loss: 0.1752, Train: 60.63%, Valid: 50.76%, Test: 41.56%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 105, Loss: 0.1752, Train: 72.15%, Valid: 62.29%, Test: 55.26%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 105, Loss: 0.1752, Train: 76.69%, Valid: 66.81%, Test: 63.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 110, Loss: 0.1723, Train: 62.08%, Valid: 52.03%, Test: 42.05%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 110, Loss: 0.1723, Train: 70.84%, Valid: 60.65%, Test: 64.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 110, Loss: 0.1723, Train: 74.30%, Valid: 64.15%, Test: 72.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 115, Loss: 0.1714, Train: 64.50%, Valid: 54.29%, Test: 36.68%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 115, Loss: 0.1714, Train: 72.30%, Valid: 62.07%, Test: 53.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 115, Loss: 0.1714, Train: 74.98%, Valid: 64.82%, Test: 64.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 120, Loss: 0.1712, Train: 68.72%, Valid: 58.77%, Test: 43.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 120, Loss: 0.1712, Train: 74.74%, Valid: 64.79%, Test: 64.22%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 120, Loss: 0.1712, Train: 77.54%, Valid: 67.61%, Test: 70.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 125, Loss: 0.1710, Train: 66.69%, Valid: 57.05%, Test: 49.94%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 125, Loss: 0.1710, Train: 73.63%, Valid: 63.83%, Test: 69.72%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 125, Loss: 0.1710, Train: 76.62%, Valid: 66.83%, Test: 76.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 130, Loss: 0.1695, Train: 68.37%, Valid: 57.96%, Test: 36.12%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 130, Loss: 0.1695, Train: 73.85%, Valid: 63.57%, Test: 66.16%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 130, Loss: 0.1695, Train: 77.52%, Valid: 67.51%, Test: 73.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 135, Loss: 0.1684, Train: 65.14%, Valid: 54.96%, Test: 55.78%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 135, Loss: 0.1684, Train: 75.39%, Valid: 65.24%, Test: 66.31%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 135, Loss: 0.1684, Train: 77.94%, Valid: 67.82%, Test: 71.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 140, Loss: 0.1670, Train: 66.61%, Valid: 56.48%, Test: 65.97%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 140, Loss: 0.1670, Train: 75.39%, Valid: 65.28%, Test: 75.05%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 140, Loss: 0.1670, Train: 77.40%, Valid: 67.31%, Test: 81.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 145, Loss: 0.1664, Train: 63.05%, Valid: 52.71%, Test: 52.88%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 145, Loss: 0.1664, Train: 72.42%, Valid: 62.16%, Test: 67.20%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 145, Loss: 0.1664, Train: 76.64%, Valid: 66.41%, Test: 73.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 150, Loss: 0.1659, Train: 65.37%, Valid: 54.81%, Test: 47.28%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 150, Loss: 0.1659, Train: 74.64%, Valid: 64.27%, Test: 67.98%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 150, Loss: 0.1659, Train: 77.04%, Valid: 66.85%, Test: 74.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 155, Loss: 0.1649, Train: 64.98%, Valid: 54.29%, Test: 46.99%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 155, Loss: 0.1649, Train: 76.36%, Valid: 66.03%, Test: 67.52%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 155, Loss: 0.1649, Train: 78.15%, Valid: 67.97%, Test: 73.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 160, Loss: 0.1657, Train: 68.91%, Valid: 58.39%, Test: 51.56%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 160, Loss: 0.1657, Train: 75.46%, Valid: 65.27%, Test: 65.10%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 160, Loss: 0.1657, Train: 77.78%, Valid: 67.60%, Test: 76.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 165, Loss: 0.1631, Train: 64.58%, Valid: 53.80%, Test: 28.19%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 165, Loss: 0.1631, Train: 73.38%, Valid: 62.86%, Test: 47.33%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 165, Loss: 0.1631, Train: 76.23%, Valid: 65.90%, Test: 69.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 170, Loss: 0.1638, Train: 68.63%, Valid: 57.90%, Test: 65.81%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 170, Loss: 0.1638, Train: 75.13%, Valid: 64.67%, Test: 72.26%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 170, Loss: 0.1638, Train: 78.58%, Valid: 68.40%, Test: 77.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 175, Loss: 0.1627, Train: 69.48%, Valid: 59.20%, Test: 50.76%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 175, Loss: 0.1627, Train: 75.08%, Valid: 64.90%, Test: 70.12%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 175, Loss: 0.1627, Train: 78.00%, Valid: 67.92%, Test: 80.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 180, Loss: 0.1621, Train: 71.52%, Valid: 61.10%, Test: 33.77%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 180, Loss: 0.1621, Train: 76.55%, Valid: 66.20%, Test: 56.21%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 180, Loss: 0.1621, Train: 78.51%, Valid: 68.22%, Test: 70.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 185, Loss: 0.1613, Train: 57.49%, Valid: 46.87%, Test: 35.48%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 185, Loss: 0.1613, Train: 75.74%, Valid: 65.28%, Test: 56.47%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 185, Loss: 0.1613, Train: 78.51%, Valid: 68.31%, Test: 74.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 190, Loss: 0.1617, Train: 67.43%, Valid: 57.36%, Test: 42.84%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 190, Loss: 0.1617, Train: 77.25%, Valid: 67.08%, Test: 61.90%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 190, Loss: 0.1617, Train: 79.18%, Valid: 69.09%, Test: 75.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 195, Loss: 0.1611, Train: 66.76%, Valid: 55.96%, Test: 44.97%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 195, Loss: 0.1611, Train: 75.06%, Valid: 64.39%, Test: 60.93%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 195, Loss: 0.1611, Train: 77.26%, Valid: 66.68%, Test: 74.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 200, Loss: 0.1602, Train: 68.06%, Valid: 57.20%, Test: 24.59%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 200, Loss: 0.1602, Train: 77.00%, Valid: 66.55%, Test: 44.34%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 200, Loss: 0.1602, Train: 78.95%, Valid: 68.65%, Test: 60.20%\n",
      "---\n",
      "Hits@10\n",
      "Run 07:\n",
      "Highest Train: 71.52\n",
      "Highest Valid: 61.10\n",
      "  Final Train: 71.52\n",
      "   Final Test: 33.77\n",
      "Hits@20\n",
      "Run 07:\n",
      "Highest Train: 77.25\n",
      "Highest Valid: 67.08\n",
      "  Final Train: 77.25\n",
      "   Final Test: 61.90\n",
      "Hits@30\n",
      "Run 07:\n",
      "Highest Train: 79.18\n",
      "Highest Valid: 69.09\n",
      "  Final Train: 79.18\n",
      "   Final Test: 75.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 05, Loss: 0.5729, Train: 8.48%, Valid: 7.40%, Test: 3.76%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 05, Loss: 0.5729, Train: 12.38%, Valid: 11.00%, Test: 7.96%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 05, Loss: 0.5729, Train: 15.09%, Valid: 13.54%, Test: 8.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 10, Loss: 0.4171, Train: 19.79%, Valid: 17.24%, Test: 6.62%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 10, Loss: 0.4171, Train: 27.04%, Valid: 23.94%, Test: 9.82%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 10, Loss: 0.4171, Train: 30.04%, Valid: 26.96%, Test: 11.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 15, Loss: 0.3328, Train: 26.79%, Valid: 23.20%, Test: 13.47%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 15, Loss: 0.3328, Train: 36.82%, Valid: 32.15%, Test: 18.36%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 15, Loss: 0.3328, Train: 43.41%, Valid: 38.43%, Test: 22.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 20, Loss: 0.2920, Train: 36.83%, Valid: 31.76%, Test: 8.78%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 20, Loss: 0.2920, Train: 42.42%, Valid: 36.91%, Test: 15.16%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 20, Loss: 0.2920, Train: 47.16%, Valid: 41.37%, Test: 20.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 25, Loss: 0.2660, Train: 47.18%, Valid: 40.86%, Test: 16.34%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 25, Loss: 0.2660, Train: 52.05%, Valid: 45.48%, Test: 23.84%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 25, Loss: 0.2660, Train: 55.95%, Valid: 49.22%, Test: 32.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 30, Loss: 0.2487, Train: 45.39%, Valid: 38.87%, Test: 13.42%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 30, Loss: 0.2487, Train: 50.70%, Valid: 43.83%, Test: 21.63%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 30, Loss: 0.2487, Train: 54.97%, Valid: 47.76%, Test: 25.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 35, Loss: 0.2325, Train: 49.75%, Valid: 42.62%, Test: 36.12%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 35, Loss: 0.2325, Train: 58.08%, Valid: 50.19%, Test: 43.84%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 35, Loss: 0.2325, Train: 62.47%, Valid: 54.31%, Test: 50.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 40, Loss: 0.2225, Train: 55.84%, Valid: 47.98%, Test: 18.69%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 40, Loss: 0.2225, Train: 62.50%, Valid: 54.21%, Test: 37.37%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 40, Loss: 0.2225, Train: 66.83%, Valid: 58.23%, Test: 46.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 45, Loss: 0.2152, Train: 50.85%, Valid: 43.01%, Test: 32.41%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 45, Loss: 0.2152, Train: 59.35%, Valid: 50.86%, Test: 44.32%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 45, Loss: 0.2152, Train: 64.50%, Valid: 55.78%, Test: 53.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 50, Loss: 0.2057, Train: 52.17%, Valid: 44.13%, Test: 17.50%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 50, Loss: 0.2057, Train: 61.53%, Valid: 52.98%, Test: 33.07%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 50, Loss: 0.2057, Train: 65.17%, Valid: 56.25%, Test: 38.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 55, Loss: 0.2026, Train: 59.78%, Valid: 51.22%, Test: 22.54%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 55, Loss: 0.2026, Train: 66.28%, Valid: 57.43%, Test: 46.23%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 55, Loss: 0.2026, Train: 69.48%, Valid: 60.36%, Test: 61.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 60, Loss: 0.2004, Train: 57.29%, Valid: 48.60%, Test: 30.29%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 60, Loss: 0.2004, Train: 67.27%, Valid: 58.17%, Test: 50.41%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 60, Loss: 0.2004, Train: 69.12%, Valid: 59.97%, Test: 62.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 65, Loss: 0.1968, Train: 65.54%, Valid: 56.38%, Test: 33.45%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 65, Loss: 0.1968, Train: 68.22%, Valid: 59.04%, Test: 46.83%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 65, Loss: 0.1968, Train: 71.02%, Valid: 61.73%, Test: 56.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 70, Loss: 0.1904, Train: 54.87%, Valid: 45.85%, Test: 17.57%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 70, Loss: 0.1904, Train: 63.40%, Valid: 53.97%, Test: 41.89%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 70, Loss: 0.1904, Train: 67.43%, Valid: 57.86%, Test: 56.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 75, Loss: 0.1869, Train: 62.81%, Valid: 53.57%, Test: 28.76%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 75, Loss: 0.1869, Train: 69.70%, Valid: 60.35%, Test: 44.21%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 75, Loss: 0.1869, Train: 71.98%, Valid: 62.54%, Test: 56.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 80, Loss: 0.1831, Train: 52.17%, Valid: 42.99%, Test: 25.11%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 80, Loss: 0.1831, Train: 71.24%, Valid: 61.51%, Test: 42.03%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 80, Loss: 0.1831, Train: 73.75%, Valid: 63.99%, Test: 54.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 85, Loss: 0.1827, Train: 63.91%, Valid: 54.39%, Test: 17.17%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 85, Loss: 0.1827, Train: 71.62%, Valid: 61.88%, Test: 40.93%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 85, Loss: 0.1827, Train: 74.84%, Valid: 65.15%, Test: 64.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 90, Loss: 0.1813, Train: 54.10%, Valid: 44.68%, Test: 32.99%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 90, Loss: 0.1813, Train: 67.84%, Valid: 58.10%, Test: 44.58%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 90, Loss: 0.1813, Train: 73.99%, Valid: 64.14%, Test: 57.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 95, Loss: 0.1806, Train: 61.25%, Valid: 51.84%, Test: 29.54%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 95, Loss: 0.1806, Train: 68.71%, Valid: 58.95%, Test: 47.79%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 95, Loss: 0.1806, Train: 74.26%, Valid: 64.36%, Test: 61.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 100, Loss: 0.1771, Train: 65.54%, Valid: 55.57%, Test: 31.55%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 100, Loss: 0.1771, Train: 72.64%, Valid: 62.47%, Test: 44.81%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 100, Loss: 0.1771, Train: 75.73%, Valid: 65.71%, Test: 57.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 105, Loss: 0.1763, Train: 70.39%, Valid: 60.42%, Test: 23.93%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 105, Loss: 0.1763, Train: 73.63%, Valid: 63.74%, Test: 44.60%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 105, Loss: 0.1763, Train: 76.71%, Valid: 66.80%, Test: 58.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 110, Loss: 0.1746, Train: 66.51%, Valid: 56.60%, Test: 29.57%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 110, Loss: 0.1746, Train: 73.16%, Valid: 63.16%, Test: 53.47%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 110, Loss: 0.1746, Train: 76.10%, Valid: 66.13%, Test: 59.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 115, Loss: 0.1735, Train: 68.70%, Valid: 58.84%, Test: 10.67%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 115, Loss: 0.1735, Train: 73.34%, Valid: 63.47%, Test: 44.38%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 115, Loss: 0.1735, Train: 77.21%, Valid: 67.34%, Test: 65.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 120, Loss: 0.1725, Train: 67.14%, Valid: 57.13%, Test: 38.70%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 120, Loss: 0.1725, Train: 71.62%, Valid: 61.55%, Test: 64.10%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 120, Loss: 0.1725, Train: 75.75%, Valid: 65.72%, Test: 72.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 125, Loss: 0.1706, Train: 66.41%, Valid: 56.39%, Test: 32.12%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 125, Loss: 0.1706, Train: 74.48%, Valid: 64.41%, Test: 50.79%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 125, Loss: 0.1706, Train: 76.55%, Valid: 66.47%, Test: 66.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 130, Loss: 0.1699, Train: 66.80%, Valid: 56.60%, Test: 33.71%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 130, Loss: 0.1699, Train: 72.58%, Valid: 62.24%, Test: 51.63%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 130, Loss: 0.1699, Train: 76.13%, Valid: 65.91%, Test: 65.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 135, Loss: 0.1700, Train: 67.82%, Valid: 57.51%, Test: 18.62%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 135, Loss: 0.1700, Train: 74.49%, Valid: 64.24%, Test: 58.17%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 135, Loss: 0.1700, Train: 77.57%, Valid: 67.41%, Test: 74.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 140, Loss: 0.1681, Train: 57.57%, Valid: 47.27%, Test: 35.33%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 140, Loss: 0.1681, Train: 71.66%, Valid: 61.04%, Test: 56.01%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 140, Loss: 0.1681, Train: 74.84%, Valid: 64.38%, Test: 67.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 145, Loss: 0.1678, Train: 66.08%, Valid: 55.50%, Test: 43.43%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 145, Loss: 0.1678, Train: 73.95%, Valid: 63.44%, Test: 57.31%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 145, Loss: 0.1678, Train: 76.62%, Valid: 66.24%, Test: 73.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 150, Loss: 0.1673, Train: 66.95%, Valid: 56.68%, Test: 40.19%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 150, Loss: 0.1673, Train: 73.09%, Valid: 62.61%, Test: 61.92%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 150, Loss: 0.1673, Train: 77.34%, Valid: 67.06%, Test: 72.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 155, Loss: 0.1665, Train: 67.83%, Valid: 57.22%, Test: 36.39%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 155, Loss: 0.1665, Train: 75.60%, Valid: 65.22%, Test: 53.82%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 155, Loss: 0.1665, Train: 77.75%, Valid: 67.49%, Test: 69.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 160, Loss: 0.1649, Train: 61.02%, Valid: 50.11%, Test: 46.29%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 160, Loss: 0.1649, Train: 73.39%, Valid: 62.80%, Test: 64.73%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 160, Loss: 0.1649, Train: 76.08%, Valid: 65.63%, Test: 74.12%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 165, Loss: 0.1647, Train: 56.74%, Valid: 46.62%, Test: 34.66%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 165, Loss: 0.1647, Train: 76.31%, Valid: 65.89%, Test: 58.99%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 165, Loss: 0.1647, Train: 78.69%, Valid: 68.50%, Test: 69.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 170, Loss: 0.1640, Train: 67.40%, Valid: 56.38%, Test: 36.44%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 170, Loss: 0.1640, Train: 76.84%, Valid: 66.34%, Test: 59.41%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 170, Loss: 0.1640, Train: 79.20%, Valid: 68.89%, Test: 75.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 175, Loss: 0.1619, Train: 61.30%, Valid: 50.37%, Test: 35.21%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 175, Loss: 0.1619, Train: 73.37%, Valid: 62.67%, Test: 56.97%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 175, Loss: 0.1619, Train: 75.80%, Valid: 65.26%, Test: 66.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 180, Loss: 0.1635, Train: 49.16%, Valid: 39.11%, Test: 24.43%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 180, Loss: 0.1635, Train: 73.30%, Valid: 62.86%, Test: 43.83%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 180, Loss: 0.1635, Train: 77.39%, Valid: 67.07%, Test: 62.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 185, Loss: 0.1626, Train: 72.06%, Valid: 61.51%, Test: 30.98%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 185, Loss: 0.1626, Train: 77.40%, Valid: 67.05%, Test: 54.75%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 185, Loss: 0.1626, Train: 78.71%, Valid: 68.49%, Test: 73.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 190, Loss: 0.1620, Train: 67.18%, Valid: 56.36%, Test: 37.93%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 190, Loss: 0.1620, Train: 73.77%, Valid: 63.15%, Test: 61.21%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 190, Loss: 0.1620, Train: 77.12%, Valid: 66.68%, Test: 70.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 195, Loss: 0.1595, Train: 67.35%, Valid: 56.16%, Test: 17.31%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 195, Loss: 0.1595, Train: 76.72%, Valid: 65.94%, Test: 53.59%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 195, Loss: 0.1595, Train: 79.21%, Valid: 68.69%, Test: 61.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 200, Loss: 0.1611, Train: 72.14%, Valid: 61.37%, Test: 15.96%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 200, Loss: 0.1611, Train: 78.34%, Valid: 67.97%, Test: 47.94%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 200, Loss: 0.1611, Train: 79.16%, Valid: 68.85%, Test: 61.53%\n",
      "---\n",
      "Hits@10\n",
      "Run 08:\n",
      "Highest Train: 72.14\n",
      "Highest Valid: 61.51\n",
      "  Final Train: 72.06\n",
      "   Final Test: 30.98\n",
      "Hits@20\n",
      "Run 08:\n",
      "Highest Train: 78.34\n",
      "Highest Valid: 67.97\n",
      "  Final Train: 78.34\n",
      "   Final Test: 47.94\n",
      "Hits@30\n",
      "Run 08:\n",
      "Highest Train: 79.21\n",
      "Highest Valid: 68.89\n",
      "  Final Train: 79.20\n",
      "   Final Test: 75.44\n",
      "Hits@10\n",
      "Run: 09, Epoch: 05, Loss: 0.5778, Train: 12.08%, Valid: 10.63%, Test: 5.30%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 05, Loss: 0.5778, Train: 14.87%, Valid: 13.28%, Test: 9.48%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 05, Loss: 0.5778, Train: 18.33%, Valid: 16.43%, Test: 11.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 10, Loss: 0.4084, Train: 20.39%, Valid: 17.62%, Test: 9.44%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 10, Loss: 0.4084, Train: 28.14%, Valid: 24.61%, Test: 14.14%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 10, Loss: 0.4084, Train: 32.25%, Valid: 28.49%, Test: 17.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 15, Loss: 0.3264, Train: 36.48%, Valid: 32.27%, Test: 10.43%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 15, Loss: 0.3264, Train: 40.48%, Valid: 36.04%, Test: 16.48%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 15, Loss: 0.3264, Train: 45.25%, Valid: 40.43%, Test: 21.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 20, Loss: 0.2853, Train: 39.23%, Valid: 33.84%, Test: 9.57%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 20, Loss: 0.2853, Train: 44.87%, Valid: 39.09%, Test: 20.38%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 20, Loss: 0.2853, Train: 47.89%, Valid: 41.91%, Test: 24.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 25, Loss: 0.2589, Train: 44.90%, Valid: 38.58%, Test: 9.67%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 25, Loss: 0.2589, Train: 55.21%, Valid: 48.18%, Test: 18.41%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 25, Loss: 0.2589, Train: 57.05%, Valid: 49.84%, Test: 24.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 30, Loss: 0.2444, Train: 52.00%, Valid: 44.95%, Test: 18.38%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 30, Loss: 0.2444, Train: 59.81%, Valid: 52.39%, Test: 31.05%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 30, Loss: 0.2444, Train: 61.43%, Valid: 53.95%, Test: 36.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 35, Loss: 0.2306, Train: 48.78%, Valid: 41.62%, Test: 11.27%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 35, Loss: 0.2306, Train: 57.19%, Valid: 49.45%, Test: 20.35%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 35, Loss: 0.2306, Train: 62.38%, Valid: 54.25%, Test: 28.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 40, Loss: 0.2199, Train: 47.50%, Valid: 40.01%, Test: 19.64%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 40, Loss: 0.2199, Train: 61.11%, Valid: 52.88%, Test: 28.33%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 40, Loss: 0.2199, Train: 62.42%, Valid: 54.10%, Test: 35.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 45, Loss: 0.2129, Train: 56.40%, Valid: 48.36%, Test: 14.48%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 45, Loss: 0.2129, Train: 65.94%, Valid: 57.38%, Test: 33.60%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 45, Loss: 0.2129, Train: 67.46%, Valid: 58.77%, Test: 40.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 50, Loss: 0.2058, Train: 62.00%, Valid: 53.65%, Test: 26.02%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 50, Loss: 0.2058, Train: 65.51%, Valid: 56.99%, Test: 49.96%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 50, Loss: 0.2058, Train: 70.17%, Valid: 61.35%, Test: 57.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 55, Loss: 0.2018, Train: 59.72%, Valid: 51.37%, Test: 28.75%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 55, Loss: 0.2018, Train: 69.28%, Valid: 60.34%, Test: 43.18%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 55, Loss: 0.2018, Train: 71.70%, Valid: 62.71%, Test: 53.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 60, Loss: 0.1968, Train: 60.91%, Valid: 51.94%, Test: 29.65%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 60, Loss: 0.1968, Train: 68.26%, Valid: 59.13%, Test: 46.27%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 60, Loss: 0.1968, Train: 69.83%, Valid: 60.64%, Test: 52.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 65, Loss: 0.1948, Train: 63.87%, Valid: 54.82%, Test: 31.68%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 65, Loss: 0.1948, Train: 69.08%, Valid: 59.94%, Test: 55.82%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 65, Loss: 0.1948, Train: 72.39%, Valid: 63.20%, Test: 60.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 70, Loss: 0.1895, Train: 60.25%, Valid: 51.09%, Test: 30.50%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 70, Loss: 0.1895, Train: 67.62%, Valid: 58.21%, Test: 45.30%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 70, Loss: 0.1895, Train: 71.30%, Valid: 61.80%, Test: 52.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 75, Loss: 0.1868, Train: 65.26%, Valid: 55.89%, Test: 34.37%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 75, Loss: 0.1868, Train: 71.26%, Valid: 61.72%, Test: 49.78%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 75, Loss: 0.1868, Train: 73.52%, Valid: 63.92%, Test: 58.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 80, Loss: 0.1845, Train: 70.79%, Valid: 61.29%, Test: 22.20%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 80, Loss: 0.1845, Train: 72.90%, Valid: 63.30%, Test: 43.70%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 80, Loss: 0.1845, Train: 75.46%, Valid: 65.84%, Test: 59.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 85, Loss: 0.1832, Train: 68.87%, Valid: 59.54%, Test: 52.30%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 85, Loss: 0.1832, Train: 74.04%, Valid: 64.45%, Test: 61.16%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 85, Loss: 0.1832, Train: 76.47%, Valid: 66.77%, Test: 68.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 90, Loss: 0.1807, Train: 66.51%, Valid: 56.83%, Test: 39.12%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 90, Loss: 0.1807, Train: 72.57%, Valid: 62.90%, Test: 57.95%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 90, Loss: 0.1807, Train: 75.11%, Valid: 65.45%, Test: 68.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 95, Loss: 0.1781, Train: 65.57%, Valid: 55.85%, Test: 46.61%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 95, Loss: 0.1781, Train: 71.12%, Valid: 61.47%, Test: 55.63%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 95, Loss: 0.1781, Train: 74.80%, Valid: 65.14%, Test: 72.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 100, Loss: 0.1789, Train: 65.65%, Valid: 56.07%, Test: 42.95%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 100, Loss: 0.1789, Train: 74.94%, Valid: 65.23%, Test: 61.07%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 100, Loss: 0.1789, Train: 77.13%, Valid: 67.37%, Test: 66.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 105, Loss: 0.1759, Train: 64.87%, Valid: 55.13%, Test: 50.37%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 105, Loss: 0.1759, Train: 72.65%, Valid: 62.86%, Test: 60.64%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 105, Loss: 0.1759, Train: 75.06%, Valid: 65.30%, Test: 70.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 110, Loss: 0.1744, Train: 65.81%, Valid: 55.95%, Test: 32.19%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 110, Loss: 0.1744, Train: 74.36%, Valid: 64.42%, Test: 56.71%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 110, Loss: 0.1744, Train: 76.70%, Valid: 66.86%, Test: 73.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 65.71%, Valid: 56.05%, Test: 51.44%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 76.02%, Valid: 66.10%, Test: 63.62%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 77.42%, Valid: 67.51%, Test: 69.32%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 09, Epoch: 120, Loss: 0.1727, Train: 67.05%, Valid: 56.85%, Test: 58.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 120, Loss: 0.1727, Train: 74.64%, Valid: 64.64%, Test: 66.93%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 120, Loss: 0.1727, Train: 76.90%, Valid: 66.93%, Test: 77.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 125, Loss: 0.1721, Train: 57.61%, Valid: 47.98%, Test: 52.36%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 125, Loss: 0.1721, Train: 75.40%, Valid: 65.34%, Test: 64.08%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 125, Loss: 0.1721, Train: 76.44%, Valid: 66.42%, Test: 73.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 130, Loss: 0.1702, Train: 71.01%, Valid: 61.04%, Test: 35.24%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 130, Loss: 0.1702, Train: 75.12%, Valid: 65.14%, Test: 56.03%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 130, Loss: 0.1702, Train: 78.41%, Valid: 68.46%, Test: 69.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 135, Loss: 0.1683, Train: 66.80%, Valid: 56.53%, Test: 39.10%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 135, Loss: 0.1683, Train: 76.64%, Valid: 66.50%, Test: 54.59%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 135, Loss: 0.1683, Train: 77.63%, Valid: 67.53%, Test: 65.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 140, Loss: 0.1677, Train: 62.49%, Valid: 52.08%, Test: 47.81%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 140, Loss: 0.1677, Train: 74.21%, Valid: 63.85%, Test: 60.29%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 140, Loss: 0.1677, Train: 76.35%, Valid: 66.09%, Test: 67.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 145, Loss: 0.1676, Train: 65.01%, Valid: 55.34%, Test: 43.76%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 145, Loss: 0.1676, Train: 73.88%, Valid: 63.95%, Test: 60.51%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 145, Loss: 0.1676, Train: 78.05%, Valid: 67.99%, Test: 70.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 150, Loss: 0.1657, Train: 64.69%, Valid: 54.44%, Test: 47.89%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 150, Loss: 0.1657, Train: 77.25%, Valid: 66.99%, Test: 67.99%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 150, Loss: 0.1657, Train: 78.38%, Valid: 68.24%, Test: 74.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 155, Loss: 0.1661, Train: 70.75%, Valid: 60.30%, Test: 41.67%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 155, Loss: 0.1661, Train: 76.31%, Valid: 66.05%, Test: 57.59%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 155, Loss: 0.1661, Train: 78.58%, Valid: 68.34%, Test: 64.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 160, Loss: 0.1647, Train: 52.59%, Valid: 42.42%, Test: 33.36%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 160, Loss: 0.1647, Train: 73.31%, Valid: 62.70%, Test: 60.02%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 160, Loss: 0.1647, Train: 77.97%, Valid: 67.64%, Test: 68.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 165, Loss: 0.1646, Train: 66.05%, Valid: 55.84%, Test: 30.28%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 165, Loss: 0.1646, Train: 76.29%, Valid: 66.10%, Test: 52.35%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 165, Loss: 0.1646, Train: 77.93%, Valid: 67.71%, Test: 67.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 72.13%, Valid: 61.48%, Test: 51.77%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 77.32%, Valid: 66.91%, Test: 66.17%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 79.75%, Valid: 69.51%, Test: 77.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 175, Loss: 0.1639, Train: 65.59%, Valid: 55.36%, Test: 43.04%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 175, Loss: 0.1639, Train: 77.19%, Valid: 66.99%, Test: 63.29%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 175, Loss: 0.1639, Train: 79.50%, Valid: 69.35%, Test: 75.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 180, Loss: 0.1633, Train: 63.96%, Valid: 53.37%, Test: 50.74%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 180, Loss: 0.1633, Train: 75.11%, Valid: 64.56%, Test: 62.75%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 180, Loss: 0.1633, Train: 78.34%, Valid: 68.05%, Test: 70.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 185, Loss: 0.1621, Train: 70.82%, Valid: 60.38%, Test: 58.94%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 185, Loss: 0.1621, Train: 76.68%, Valid: 66.30%, Test: 69.85%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 185, Loss: 0.1621, Train: 78.97%, Valid: 68.71%, Test: 77.60%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 190, Loss: 0.1613, Train: 66.60%, Valid: 56.20%, Test: 38.32%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 190, Loss: 0.1613, Train: 77.07%, Valid: 66.79%, Test: 63.90%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 190, Loss: 0.1613, Train: 77.68%, Valid: 67.41%, Test: 75.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 195, Loss: 0.1604, Train: 67.09%, Valid: 56.77%, Test: 35.20%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 195, Loss: 0.1604, Train: 76.66%, Valid: 66.39%, Test: 51.51%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 195, Loss: 0.1604, Train: 79.42%, Valid: 69.21%, Test: 67.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 200, Loss: 0.1602, Train: 73.02%, Valid: 62.47%, Test: 48.68%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 200, Loss: 0.1602, Train: 77.14%, Valid: 66.73%, Test: 63.38%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 200, Loss: 0.1602, Train: 79.01%, Valid: 68.70%, Test: 67.99%\n",
      "---\n",
      "Hits@10\n",
      "Run 09:\n",
      "Highest Train: 73.02\n",
      "Highest Valid: 62.47\n",
      "  Final Train: 73.02\n",
      "   Final Test: 48.68\n",
      "Hits@20\n",
      "Run 09:\n",
      "Highest Train: 77.32\n",
      "Highest Valid: 66.99\n",
      "  Final Train: 77.25\n",
      "   Final Test: 67.99\n",
      "Hits@30\n",
      "Run 09:\n",
      "Highest Train: 79.75\n",
      "Highest Valid: 69.51\n",
      "  Final Train: 79.75\n",
      "   Final Test: 77.77\n",
      "Hits@10\n",
      "Run: 10, Epoch: 05, Loss: 0.5701, Train: 15.13%, Valid: 13.54%, Test: 3.01%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 05, Loss: 0.5701, Train: 18.90%, Valid: 16.94%, Test: 9.54%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 05, Loss: 0.5701, Train: 21.48%, Valid: 19.36%, Test: 15.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 10, Loss: 0.3977, Train: 22.91%, Valid: 19.83%, Test: 3.95%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 10, Loss: 0.3977, Train: 27.82%, Valid: 24.35%, Test: 7.18%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 10, Loss: 0.3977, Train: 33.08%, Valid: 29.34%, Test: 10.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 15, Loss: 0.3135, Train: 31.86%, Valid: 27.59%, Test: 15.75%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 15, Loss: 0.3135, Train: 40.88%, Valid: 35.67%, Test: 19.73%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 15, Loss: 0.3135, Train: 43.88%, Valid: 38.44%, Test: 26.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 20, Loss: 0.2740, Train: 39.12%, Valid: 33.50%, Test: 16.52%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 20, Loss: 0.2740, Train: 46.91%, Valid: 40.67%, Test: 25.68%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 20, Loss: 0.2740, Train: 51.58%, Valid: 45.07%, Test: 32.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 25, Loss: 0.2500, Train: 51.12%, Valid: 44.24%, Test: 15.84%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 25, Loss: 0.2500, Train: 56.09%, Valid: 48.89%, Test: 25.17%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 25, Loss: 0.2500, Train: 58.19%, Valid: 50.84%, Test: 30.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 30, Loss: 0.2313, Train: 54.69%, Valid: 47.02%, Test: 19.74%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 30, Loss: 0.2313, Train: 61.33%, Valid: 53.40%, Test: 31.02%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 30, Loss: 0.2313, Train: 63.54%, Valid: 55.52%, Test: 40.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 35, Loss: 0.2228, Train: 52.44%, Valid: 44.59%, Test: 21.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 35, Loss: 0.2228, Train: 56.98%, Valid: 48.87%, Test: 33.49%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 35, Loss: 0.2228, Train: 60.79%, Valid: 52.55%, Test: 39.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 40, Loss: 0.2147, Train: 56.38%, Valid: 48.15%, Test: 25.96%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 40, Loss: 0.2147, Train: 62.51%, Valid: 53.87%, Test: 40.63%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 40, Loss: 0.2147, Train: 64.80%, Valid: 56.17%, Test: 45.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 45, Loss: 0.2087, Train: 56.79%, Valid: 48.76%, Test: 31.65%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 45, Loss: 0.2087, Train: 63.54%, Valid: 55.09%, Test: 45.41%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 45, Loss: 0.2087, Train: 65.98%, Valid: 57.43%, Test: 52.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 50, Loss: 0.2017, Train: 61.19%, Valid: 52.42%, Test: 32.02%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 50, Loss: 0.2017, Train: 66.96%, Valid: 58.07%, Test: 47.08%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 50, Loss: 0.2017, Train: 68.91%, Valid: 59.98%, Test: 56.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 55, Loss: 0.1970, Train: 58.28%, Valid: 49.55%, Test: 38.17%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 55, Loss: 0.1970, Train: 66.92%, Valid: 57.98%, Test: 50.45%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 55, Loss: 0.1970, Train: 68.89%, Valid: 59.87%, Test: 60.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 60, Loss: 0.1941, Train: 59.44%, Valid: 50.65%, Test: 40.10%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 60, Loss: 0.1941, Train: 63.93%, Valid: 54.85%, Test: 57.64%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 60, Loss: 0.1941, Train: 68.85%, Valid: 59.73%, Test: 64.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 65, Loss: 0.1890, Train: 56.19%, Valid: 47.18%, Test: 30.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 65, Loss: 0.1890, Train: 68.79%, Valid: 59.47%, Test: 50.18%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 65, Loss: 0.1890, Train: 70.55%, Valid: 61.15%, Test: 62.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 70, Loss: 0.1878, Train: 59.81%, Valid: 50.23%, Test: 27.65%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 70, Loss: 0.1878, Train: 69.41%, Valid: 59.66%, Test: 49.19%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 70, Loss: 0.1878, Train: 72.24%, Valid: 62.54%, Test: 54.95%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 10, Epoch: 75, Loss: 0.1841, Train: 64.81%, Valid: 55.39%, Test: 31.10%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 75, Loss: 0.1841, Train: 70.51%, Valid: 60.92%, Test: 51.19%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 75, Loss: 0.1841, Train: 72.00%, Valid: 62.33%, Test: 56.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 80, Loss: 0.1828, Train: 64.71%, Valid: 55.57%, Test: 26.72%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 80, Loss: 0.1828, Train: 69.61%, Valid: 60.17%, Test: 43.14%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 80, Loss: 0.1828, Train: 73.32%, Valid: 63.80%, Test: 54.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 85, Loss: 0.1789, Train: 67.36%, Valid: 57.65%, Test: 27.26%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 85, Loss: 0.1789, Train: 71.54%, Valid: 61.88%, Test: 52.40%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 85, Loss: 0.1789, Train: 75.14%, Valid: 65.53%, Test: 68.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 90, Loss: 0.1781, Train: 61.75%, Valid: 51.99%, Test: 24.33%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 90, Loss: 0.1781, Train: 71.96%, Valid: 62.19%, Test: 41.83%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 90, Loss: 0.1781, Train: 74.07%, Valid: 64.34%, Test: 59.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 95, Loss: 0.1764, Train: 56.10%, Valid: 46.61%, Test: 39.49%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 95, Loss: 0.1764, Train: 69.59%, Valid: 59.56%, Test: 58.54%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 95, Loss: 0.1764, Train: 72.72%, Valid: 62.73%, Test: 70.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 53.12%, Valid: 43.45%, Test: 30.82%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 64.63%, Valid: 54.30%, Test: 45.19%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 70.73%, Valid: 60.35%, Test: 56.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 105, Loss: 0.1737, Train: 55.27%, Valid: 45.52%, Test: 48.61%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 105, Loss: 0.1737, Train: 71.49%, Valid: 61.25%, Test: 60.28%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 105, Loss: 0.1737, Train: 73.70%, Valid: 63.49%, Test: 72.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 110, Loss: 0.1717, Train: 61.80%, Valid: 51.82%, Test: 28.82%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 110, Loss: 0.1717, Train: 70.37%, Valid: 60.35%, Test: 58.64%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 110, Loss: 0.1717, Train: 73.58%, Valid: 63.60%, Test: 67.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 115, Loss: 0.1700, Train: 64.72%, Valid: 54.58%, Test: 44.90%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 115, Loss: 0.1700, Train: 74.53%, Valid: 64.36%, Test: 68.18%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 115, Loss: 0.1700, Train: 76.23%, Valid: 66.24%, Test: 75.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 120, Loss: 0.1706, Train: 71.68%, Valid: 61.64%, Test: 34.97%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 120, Loss: 0.1706, Train: 73.12%, Valid: 63.11%, Test: 54.53%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 120, Loss: 0.1706, Train: 74.96%, Valid: 64.94%, Test: 67.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 125, Loss: 0.1702, Train: 56.19%, Valid: 46.10%, Test: 29.34%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 125, Loss: 0.1702, Train: 70.65%, Valid: 60.21%, Test: 49.72%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 125, Loss: 0.1702, Train: 73.14%, Valid: 62.79%, Test: 64.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 130, Loss: 0.1675, Train: 66.42%, Valid: 56.20%, Test: 45.48%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 130, Loss: 0.1675, Train: 72.16%, Valid: 61.91%, Test: 62.23%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 130, Loss: 0.1675, Train: 76.41%, Valid: 66.36%, Test: 73.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 135, Loss: 0.1658, Train: 66.44%, Valid: 55.87%, Test: 38.61%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 135, Loss: 0.1658, Train: 73.62%, Valid: 63.10%, Test: 49.95%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 135, Loss: 0.1658, Train: 76.00%, Valid: 65.58%, Test: 64.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 140, Loss: 0.1683, Train: 66.39%, Valid: 56.05%, Test: 48.74%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 140, Loss: 0.1683, Train: 73.01%, Valid: 62.74%, Test: 59.93%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 140, Loss: 0.1683, Train: 76.87%, Valid: 66.74%, Test: 71.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 145, Loss: 0.1646, Train: 69.69%, Valid: 59.35%, Test: 32.74%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 145, Loss: 0.1646, Train: 74.33%, Valid: 64.19%, Test: 62.33%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 145, Loss: 0.1646, Train: 77.30%, Valid: 67.21%, Test: 75.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 150, Loss: 0.1642, Train: 71.36%, Valid: 61.02%, Test: 17.95%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 150, Loss: 0.1642, Train: 75.25%, Valid: 65.04%, Test: 54.24%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 150, Loss: 0.1642, Train: 77.57%, Valid: 67.34%, Test: 69.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 155, Loss: 0.1646, Train: 64.90%, Valid: 54.90%, Test: 33.14%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 155, Loss: 0.1646, Train: 73.03%, Valid: 62.90%, Test: 51.22%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 155, Loss: 0.1646, Train: 77.12%, Valid: 66.99%, Test: 72.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 160, Loss: 0.1642, Train: 67.28%, Valid: 56.59%, Test: 45.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 160, Loss: 0.1642, Train: 70.17%, Valid: 59.51%, Test: 56.50%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 160, Loss: 0.1642, Train: 75.05%, Valid: 64.59%, Test: 65.11%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 165, Loss: 0.1635, Train: 68.92%, Valid: 58.07%, Test: 26.86%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 165, Loss: 0.1635, Train: 77.07%, Valid: 66.72%, Test: 62.63%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 165, Loss: 0.1635, Train: 78.89%, Valid: 68.60%, Test: 72.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 170, Loss: 0.1622, Train: 68.35%, Valid: 57.72%, Test: 31.47%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 170, Loss: 0.1622, Train: 74.47%, Valid: 63.84%, Test: 51.90%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 170, Loss: 0.1622, Train: 77.47%, Valid: 67.00%, Test: 66.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 175, Loss: 0.1619, Train: 71.03%, Valid: 60.56%, Test: 50.62%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 175, Loss: 0.1619, Train: 75.28%, Valid: 64.93%, Test: 71.44%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 175, Loss: 0.1619, Train: 78.68%, Valid: 68.45%, Test: 83.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 180, Loss: 0.1612, Train: 64.99%, Valid: 54.51%, Test: 30.47%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 180, Loss: 0.1612, Train: 76.04%, Valid: 65.59%, Test: 49.38%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 180, Loss: 0.1612, Train: 78.53%, Valid: 68.22%, Test: 60.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 185, Loss: 0.1600, Train: 68.89%, Valid: 58.26%, Test: 29.07%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 185, Loss: 0.1600, Train: 77.29%, Valid: 66.98%, Test: 50.36%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 185, Loss: 0.1600, Train: 78.87%, Valid: 68.59%, Test: 71.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 190, Loss: 0.1618, Train: 68.04%, Valid: 57.30%, Test: 14.06%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 190, Loss: 0.1618, Train: 76.94%, Valid: 66.47%, Test: 35.73%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 190, Loss: 0.1618, Train: 77.81%, Valid: 67.39%, Test: 45.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 195, Loss: 0.1604, Train: 71.02%, Valid: 60.10%, Test: 26.66%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 195, Loss: 0.1604, Train: 77.44%, Valid: 67.04%, Test: 50.56%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 195, Loss: 0.1604, Train: 80.11%, Valid: 69.94%, Test: 70.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 200, Loss: 0.1590, Train: 70.49%, Valid: 59.87%, Test: 22.94%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 200, Loss: 0.1590, Train: 76.56%, Valid: 66.06%, Test: 49.79%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 200, Loss: 0.1590, Train: 79.00%, Valid: 68.64%, Test: 67.46%\n",
      "---\n",
      "Hits@10\n",
      "Run 10:\n",
      "Highest Train: 71.68\n",
      "Highest Valid: 61.64\n",
      "  Final Train: 71.68\n",
      "   Final Test: 34.97\n",
      "Hits@20\n",
      "Run 10:\n",
      "Highest Train: 77.44\n",
      "Highest Valid: 67.04\n",
      "  Final Train: 77.44\n",
      "   Final Test: 50.56\n",
      "Hits@30\n",
      "Run 10:\n",
      "Highest Train: 80.11\n",
      "Highest Valid: 69.94\n",
      "  Final Train: 80.11\n",
      "   Final Test: 70.16\n",
      "Hits@10\n",
      "All runs:\n",
      "Highest Train: 72.74  1.16\n",
      "Highest Valid: 62.38  1.20\n",
      "  Final Train: 72.74  1.16\n",
      "   Final Test: 41.33  8.56\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Train: 77.91  0.56\n",
      "Highest Valid: 67.64  0.58\n",
      "  Final Train: 77.87  0.59\n",
      "   Final Test: 57.05  8.68\n",
      "Hits@30\n",
      "All runs:\n",
      "Highest Train: 79.76  0.35\n",
      "Highest Valid: 69.53  0.36\n",
      "  Final Train: 79.75  0.35\n",
      "   Final Test: 69.52  7.70\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, predictor, x, adj_t, split_edge, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (GNN)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    parser.add_argument('--use_sage', default = True)\n",
    "    parser.add_argument('--num_layers', type=int, default=2)\n",
    "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "    parser.add_argument('--lr', type=float, default=0.005)\n",
    "    parser.add_argument('--epochs', type=int, default=200)\n",
    "    parser.add_argument('--eval_steps', type=int, default=5)\n",
    "    parser.add_argument('--runs', type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "                                     transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    adj_t = data.adj_t.to(device)\n",
    "\n",
    "    split_edge = dataset.get_edge_split()\n",
    "\n",
    "    # We randomly pick some training samples that we want to evaluate on:\n",
    "    torch.manual_seed(12345)\n",
    "    idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "    idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "    split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "    if args.use_sage:\n",
    "        model = SAGE(args.hidden_channels, args.hidden_channels,\n",
    "                     args.hidden_channels, args.num_layers,\n",
    "                     args.dropout).to(device)\n",
    "    else:\n",
    "        model = GCN(args.hidden_channels, args.hidden_channels,\n",
    "                    args.hidden_channels, args.num_layers,\n",
    "                    args.dropout).to(device)\n",
    "\n",
    "    emb = torch.nn.Embedding(data.adj_t.size(0),\n",
    "                             args.hidden_channels).to(device)\n",
    "    predictor = LinkPredictor(args.hidden_channels, args.hidden_channels, 1,\n",
    "                              args.num_layers, args.dropout).to(device)\n",
    "\n",
    "    evaluator = Evaluator(name='ogbl-ddi')\n",
    "    Logger_Models_Models = {\n",
    "        'Hits@10': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@20': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@30': Logger_Models_Model(args.runs, args),\n",
    "    }\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        torch.nn.init.xavier_uniform_(emb.weight)\n",
    "        model.reset_parameters()\n",
    "        predictor.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(model.parameters()) + list(emb.parameters()) +\n",
    "            list(predictor.parameters()), lr=args.lr)\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                         optimizer, args.batch_size)\n",
    "\n",
    "            if epoch % args.eval_steps == 0:\n",
    "                results = test(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                               evaluator, args.batch_size)\n",
    "                for key, result in results.items():\n",
    "                    Logger_Models_Models[key].add_result(run, result)\n",
    "\n",
    "                if epoch % args.log_steps == 0:\n",
    "                    for key, result in results.items():\n",
    "                        train_hits, valid_hits, test_hits = result\n",
    "                        print(key)\n",
    "                        print(f'Run: {run + 1:02d}, '\n",
    "                              f'Epoch: {epoch:02d}, '\n",
    "                              f'Loss: {loss:.4f}, '\n",
    "                              f'Train: {100 * train_hits:.2f}%, '\n",
    "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                              f'Test: {100 * test_hits:.2f}%')\n",
    "                    print('---')\n",
    "\n",
    "        for key in Logger_Models_Models.keys():\n",
    "            print(key)\n",
    "            Logger_Models_Models[key].print_statistics(run)\n",
    "\n",
    "    for key in Logger_Models_Models.keys():\n",
    "        print(key)\n",
    "        Logger_Models_Models[key].print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806f00f",
   "metadata": {},
   "source": [
    "## Graph Sage with Nueral Link Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76185044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T00:37:34.717643Z",
     "start_time": "2022-07-11T07:36:51.393590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(f='C:\\\\Users\\\\b04753yr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-30e704de-a8cc-40a4-8675-f15ec8e16fa1.json', device=0, log_steps=1, use_sage=True, num_layers=2, hidden_channels=256, dropout=0.5, batch_size=65536, lr=0.005, epochs=200, eval_steps=5, runs=10)\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.5677, Train: 12.61%, Valid: 11.24%, Test: 4.35%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.5677, Train: 19.14%, Valid: 17.31%, Test: 8.01%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.5677, Train: 21.72%, Valid: 19.72%, Test: 12.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 10, Loss: 0.4075, Train: 25.33%, Valid: 22.36%, Test: 15.21%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 10, Loss: 0.4075, Train: 29.39%, Valid: 26.00%, Test: 19.75%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 10, Loss: 0.4075, Train: 34.37%, Valid: 30.75%, Test: 23.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 15, Loss: 0.3307, Train: 23.80%, Valid: 20.49%, Test: 4.21%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 15, Loss: 0.3307, Train: 31.31%, Valid: 27.14%, Test: 9.60%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 15, Loss: 0.3307, Train: 34.94%, Valid: 30.36%, Test: 14.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 20, Loss: 0.2880, Train: 40.27%, Valid: 34.72%, Test: 11.41%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 20, Loss: 0.2880, Train: 45.84%, Valid: 39.81%, Test: 14.76%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 20, Loss: 0.2880, Train: 48.45%, Valid: 42.31%, Test: 19.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 25, Loss: 0.2603, Train: 44.22%, Valid: 37.99%, Test: 18.45%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 25, Loss: 0.2603, Train: 50.59%, Valid: 43.77%, Test: 24.61%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 25, Loss: 0.2603, Train: 54.32%, Valid: 47.19%, Test: 31.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 30, Loss: 0.2412, Train: 52.09%, Valid: 45.09%, Test: 17.08%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 30, Loss: 0.2412, Train: 57.32%, Valid: 49.92%, Test: 29.17%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 30, Loss: 0.2412, Train: 59.94%, Valid: 52.37%, Test: 39.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 35, Loss: 0.2276, Train: 55.32%, Valid: 47.48%, Test: 30.48%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 35, Loss: 0.2276, Train: 61.52%, Valid: 53.41%, Test: 43.62%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 35, Loss: 0.2276, Train: 63.64%, Valid: 55.37%, Test: 50.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 40, Loss: 0.2176, Train: 56.21%, Valid: 48.29%, Test: 20.07%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 40, Loss: 0.2176, Train: 64.68%, Valid: 56.14%, Test: 35.07%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 40, Loss: 0.2176, Train: 66.01%, Valid: 57.40%, Test: 43.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 45, Loss: 0.2111, Train: 59.51%, Valid: 51.01%, Test: 15.92%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 45, Loss: 0.2111, Train: 66.00%, Valid: 57.23%, Test: 37.45%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 45, Loss: 0.2111, Train: 67.95%, Valid: 59.07%, Test: 48.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 50, Loss: 0.2054, Train: 63.43%, Valid: 54.84%, Test: 40.41%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 50, Loss: 0.2054, Train: 66.17%, Valid: 57.52%, Test: 52.10%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 50, Loss: 0.2054, Train: 68.52%, Valid: 59.67%, Test: 59.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 55, Loss: 0.2014, Train: 58.86%, Valid: 50.17%, Test: 26.43%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 55, Loss: 0.2014, Train: 65.85%, Valid: 56.70%, Test: 39.92%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 55, Loss: 0.2014, Train: 67.75%, Valid: 58.49%, Test: 50.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 60, Loss: 0.1956, Train: 62.84%, Valid: 53.88%, Test: 31.32%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 60, Loss: 0.1956, Train: 72.43%, Valid: 63.23%, Test: 47.70%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 60, Loss: 0.1956, Train: 73.94%, Valid: 64.68%, Test: 61.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 65, Loss: 0.1930, Train: 64.91%, Valid: 55.42%, Test: 34.27%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 65, Loss: 0.1930, Train: 69.60%, Valid: 59.95%, Test: 49.20%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 65, Loss: 0.1930, Train: 72.22%, Valid: 62.54%, Test: 58.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 70, Loss: 0.1898, Train: 62.84%, Valid: 53.35%, Test: 27.04%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 70, Loss: 0.1898, Train: 69.75%, Valid: 60.11%, Test: 41.62%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 70, Loss: 0.1898, Train: 71.87%, Valid: 62.17%, Test: 52.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 75, Loss: 0.1869, Train: 59.53%, Valid: 50.20%, Test: 41.77%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 75, Loss: 0.1869, Train: 70.99%, Valid: 61.44%, Test: 48.11%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 75, Loss: 0.1869, Train: 73.95%, Valid: 64.38%, Test: 59.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 80, Loss: 0.1843, Train: 63.46%, Valid: 53.81%, Test: 30.55%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 80, Loss: 0.1843, Train: 70.21%, Valid: 60.34%, Test: 43.78%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 80, Loss: 0.1843, Train: 71.81%, Valid: 62.02%, Test: 59.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 85, Loss: 0.1829, Train: 68.42%, Valid: 58.95%, Test: 50.66%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 85, Loss: 0.1829, Train: 73.53%, Valid: 63.95%, Test: 59.66%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 85, Loss: 0.1829, Train: 74.69%, Valid: 65.10%, Test: 67.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 90, Loss: 0.1801, Train: 67.83%, Valid: 58.11%, Test: 37.31%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 90, Loss: 0.1801, Train: 73.27%, Valid: 63.54%, Test: 55.11%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 90, Loss: 0.1801, Train: 75.06%, Valid: 65.38%, Test: 64.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 95, Loss: 0.1798, Train: 65.24%, Valid: 55.69%, Test: 38.47%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.1798, Train: 73.73%, Valid: 63.95%, Test: 50.41%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 95, Loss: 0.1798, Train: 75.71%, Valid: 65.93%, Test: 61.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 100, Loss: 0.1774, Train: 61.37%, Valid: 51.27%, Test: 32.53%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.1774, Train: 69.98%, Valid: 59.82%, Test: 45.59%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 100, Loss: 0.1774, Train: 72.71%, Valid: 62.59%, Test: 51.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 105, Loss: 0.1753, Train: 70.62%, Valid: 60.80%, Test: 41.67%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.1753, Train: 74.38%, Valid: 64.54%, Test: 65.66%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 105, Loss: 0.1753, Train: 76.20%, Valid: 66.35%, Test: 71.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 110, Loss: 0.1717, Train: 67.56%, Valid: 57.93%, Test: 42.34%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.1717, Train: 74.46%, Valid: 64.54%, Test: 54.12%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 110, Loss: 0.1717, Train: 76.52%, Valid: 66.60%, Test: 67.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 115, Loss: 0.1733, Train: 67.59%, Valid: 57.44%, Test: 36.72%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.1733, Train: 73.47%, Valid: 63.33%, Test: 52.39%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 115, Loss: 0.1733, Train: 75.97%, Valid: 65.81%, Test: 61.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 120, Loss: 0.1720, Train: 68.61%, Valid: 58.84%, Test: 32.09%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.1720, Train: 75.23%, Valid: 65.31%, Test: 53.22%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 120, Loss: 0.1720, Train: 76.99%, Valid: 67.09%, Test: 62.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 125, Loss: 0.1736, Train: 62.98%, Valid: 52.99%, Test: 37.15%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.1736, Train: 71.76%, Valid: 61.69%, Test: 45.01%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 125, Loss: 0.1736, Train: 76.28%, Valid: 66.31%, Test: 55.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 130, Loss: 0.1702, Train: 67.85%, Valid: 57.66%, Test: 50.98%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.1702, Train: 71.28%, Valid: 61.12%, Test: 64.04%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 130, Loss: 0.1702, Train: 77.25%, Valid: 67.22%, Test: 69.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 135, Loss: 0.1681, Train: 68.79%, Valid: 58.87%, Test: 42.43%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.1681, Train: 73.00%, Valid: 63.07%, Test: 54.28%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 135, Loss: 0.1681, Train: 75.60%, Valid: 65.69%, Test: 71.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 140, Loss: 0.1687, Train: 67.04%, Valid: 56.91%, Test: 47.68%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.1687, Train: 73.49%, Valid: 63.50%, Test: 62.15%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 140, Loss: 0.1687, Train: 75.60%, Valid: 65.59%, Test: 68.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 145, Loss: 0.1670, Train: 68.54%, Valid: 58.14%, Test: 38.32%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.1670, Train: 73.56%, Valid: 63.10%, Test: 49.41%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 145, Loss: 0.1670, Train: 77.58%, Valid: 67.40%, Test: 64.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 150, Loss: 0.1673, Train: 69.73%, Valid: 59.73%, Test: 40.02%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.1673, Train: 73.48%, Valid: 63.45%, Test: 57.50%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 150, Loss: 0.1673, Train: 76.73%, Valid: 66.68%, Test: 73.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 155, Loss: 0.1671, Train: 71.74%, Valid: 61.28%, Test: 22.37%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.1671, Train: 75.84%, Valid: 65.51%, Test: 48.80%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 155, Loss: 0.1671, Train: 78.06%, Valid: 67.88%, Test: 76.77%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 01, Epoch: 160, Loss: 0.1656, Train: 66.97%, Valid: 56.37%, Test: 29.31%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.1656, Train: 72.55%, Valid: 62.01%, Test: 54.29%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 160, Loss: 0.1656, Train: 76.08%, Valid: 65.60%, Test: 66.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 165, Loss: 0.1643, Train: 70.27%, Valid: 59.67%, Test: 28.09%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.1643, Train: 74.45%, Valid: 63.88%, Test: 50.63%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 165, Loss: 0.1643, Train: 77.84%, Valid: 67.47%, Test: 63.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 170, Loss: 0.1643, Train: 67.85%, Valid: 57.23%, Test: 40.50%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.1643, Train: 74.45%, Valid: 63.93%, Test: 65.19%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 170, Loss: 0.1643, Train: 77.64%, Valid: 67.30%, Test: 75.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 175, Loss: 0.1639, Train: 59.60%, Valid: 48.86%, Test: 39.41%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.1639, Train: 68.46%, Valid: 57.47%, Test: 52.13%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 175, Loss: 0.1639, Train: 73.32%, Valid: 62.40%, Test: 62.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 180, Loss: 0.1654, Train: 71.97%, Valid: 61.50%, Test: 38.09%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.1654, Train: 76.29%, Valid: 66.01%, Test: 69.33%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 180, Loss: 0.1654, Train: 78.75%, Valid: 68.59%, Test: 77.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 185, Loss: 0.1617, Train: 66.16%, Valid: 55.35%, Test: 31.17%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.1617, Train: 75.63%, Valid: 65.12%, Test: 53.80%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 185, Loss: 0.1617, Train: 78.33%, Valid: 67.90%, Test: 71.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 190, Loss: 0.1620, Train: 64.31%, Valid: 53.43%, Test: 37.82%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.1620, Train: 72.63%, Valid: 61.63%, Test: 46.69%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 190, Loss: 0.1620, Train: 76.50%, Valid: 65.73%, Test: 62.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 195, Loss: 0.1618, Train: 69.41%, Valid: 58.94%, Test: 40.36%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.1618, Train: 76.99%, Valid: 66.65%, Test: 56.00%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 195, Loss: 0.1618, Train: 78.89%, Valid: 68.66%, Test: 64.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 200, Loss: 0.1607, Train: 66.67%, Valid: 55.62%, Test: 37.46%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.1607, Train: 75.16%, Valid: 64.45%, Test: 51.73%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 200, Loss: 0.1607, Train: 77.77%, Valid: 67.16%, Test: 67.24%\n",
      "---\n",
      "Hits@10\n",
      "Run 01:\n",
      "Highest Train: 71.97\n",
      "Highest Valid: 61.50\n",
      "  Final Train: 71.97\n",
      "   Final Test: 38.09\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Train: 76.99\n",
      "Highest Valid: 66.65\n",
      "  Final Train: 76.99\n",
      "   Final Test: 56.00\n",
      "Hits@30\n",
      "Run 01:\n",
      "Highest Train: 78.89\n",
      "Highest Valid: 68.66\n",
      "  Final Train: 78.89\n",
      "   Final Test: 64.28\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.5657, Train: 9.71%, Valid: 8.63%, Test: 5.12%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.5657, Train: 15.61%, Valid: 14.06%, Test: 7.04%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.5657, Train: 19.56%, Valid: 17.80%, Test: 9.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 10, Loss: 0.3965, Train: 28.04%, Valid: 24.75%, Test: 5.32%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.3965, Train: 31.80%, Valid: 28.26%, Test: 12.16%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 10, Loss: 0.3965, Train: 36.00%, Valid: 32.39%, Test: 16.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 15, Loss: 0.3210, Train: 41.83%, Valid: 36.57%, Test: 10.50%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.3210, Train: 46.13%, Valid: 40.56%, Test: 15.26%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 15, Loss: 0.3210, Train: 49.38%, Valid: 43.67%, Test: 22.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 20, Loss: 0.2825, Train: 42.53%, Valid: 36.57%, Test: 12.87%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.2825, Train: 51.03%, Valid: 44.54%, Test: 19.89%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 20, Loss: 0.2825, Train: 53.66%, Valid: 47.04%, Test: 23.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 25, Loss: 0.2554, Train: 47.41%, Valid: 40.82%, Test: 19.77%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.2554, Train: 55.01%, Valid: 47.85%, Test: 31.08%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 25, Loss: 0.2554, Train: 58.95%, Valid: 51.47%, Test: 38.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 30, Loss: 0.2377, Train: 41.72%, Valid: 35.10%, Test: 17.22%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.2377, Train: 51.43%, Valid: 43.83%, Test: 23.57%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 30, Loss: 0.2377, Train: 56.36%, Valid: 48.51%, Test: 29.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 35, Loss: 0.2257, Train: 53.12%, Valid: 45.41%, Test: 22.27%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.2257, Train: 58.53%, Valid: 50.44%, Test: 34.17%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 35, Loss: 0.2257, Train: 61.13%, Valid: 52.90%, Test: 39.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 40, Loss: 0.2179, Train: 60.53%, Valid: 52.32%, Test: 17.23%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.2179, Train: 65.16%, Valid: 56.79%, Test: 41.77%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 40, Loss: 0.2179, Train: 66.73%, Valid: 58.23%, Test: 48.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 45, Loss: 0.2080, Train: 58.36%, Valid: 49.94%, Test: 33.56%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.2080, Train: 64.36%, Valid: 55.59%, Test: 46.12%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 45, Loss: 0.2080, Train: 68.03%, Valid: 59.19%, Test: 53.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 50, Loss: 0.2034, Train: 56.88%, Valid: 48.36%, Test: 28.45%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.2034, Train: 65.67%, Valid: 56.65%, Test: 52.54%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 50, Loss: 0.2034, Train: 68.99%, Valid: 59.89%, Test: 58.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 55, Loss: 0.2007, Train: 64.90%, Valid: 55.83%, Test: 35.61%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.2007, Train: 70.84%, Valid: 61.57%, Test: 52.43%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 55, Loss: 0.2007, Train: 72.80%, Valid: 63.47%, Test: 64.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 60, Loss: 0.1953, Train: 64.88%, Valid: 55.74%, Test: 38.95%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.1953, Train: 69.58%, Valid: 60.31%, Test: 55.20%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 60, Loss: 0.1953, Train: 70.85%, Valid: 61.53%, Test: 60.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 65, Loss: 0.1913, Train: 65.19%, Valid: 55.95%, Test: 27.98%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.1913, Train: 69.96%, Valid: 60.61%, Test: 45.01%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 65, Loss: 0.1913, Train: 72.69%, Valid: 63.10%, Test: 60.37%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 70, Loss: 0.1882, Train: 67.25%, Valid: 58.07%, Test: 35.09%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.1882, Train: 72.70%, Valid: 63.41%, Test: 54.48%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 70, Loss: 0.1882, Train: 74.30%, Valid: 64.97%, Test: 63.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 75, Loss: 0.1862, Train: 69.67%, Valid: 60.30%, Test: 31.63%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.1862, Train: 72.34%, Valid: 62.92%, Test: 64.37%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 75, Loss: 0.1862, Train: 73.95%, Valid: 64.48%, Test: 70.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 80, Loss: 0.1838, Train: 71.25%, Valid: 61.70%, Test: 33.43%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.1838, Train: 73.29%, Valid: 63.78%, Test: 62.36%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 80, Loss: 0.1838, Train: 75.18%, Valid: 65.73%, Test: 66.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 85, Loss: 0.1824, Train: 69.24%, Valid: 59.75%, Test: 36.88%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.1824, Train: 72.64%, Valid: 63.13%, Test: 55.24%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 85, Loss: 0.1824, Train: 75.81%, Valid: 66.29%, Test: 64.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 90, Loss: 0.1796, Train: 64.73%, Valid: 55.12%, Test: 43.97%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.1796, Train: 72.99%, Valid: 63.32%, Test: 56.30%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 90, Loss: 0.1796, Train: 75.04%, Valid: 65.46%, Test: 62.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 95, Loss: 0.1785, Train: 63.54%, Valid: 53.71%, Test: 30.88%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.1785, Train: 71.37%, Valid: 61.49%, Test: 51.46%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 95, Loss: 0.1785, Train: 74.15%, Valid: 64.43%, Test: 57.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 100, Loss: 0.1762, Train: 60.33%, Valid: 50.36%, Test: 44.80%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.1762, Train: 71.36%, Valid: 61.47%, Test: 56.35%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 100, Loss: 0.1762, Train: 75.51%, Valid: 65.70%, Test: 64.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 105, Loss: 0.1748, Train: 63.43%, Valid: 53.21%, Test: 27.32%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.1748, Train: 72.49%, Valid: 62.48%, Test: 59.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 105, Loss: 0.1748, Train: 75.48%, Valid: 65.56%, Test: 69.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 110, Loss: 0.1744, Train: 64.27%, Valid: 54.06%, Test: 41.45%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.1744, Train: 72.94%, Valid: 63.00%, Test: 55.77%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 110, Loss: 0.1744, Train: 76.31%, Valid: 66.44%, Test: 71.39%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 02, Epoch: 115, Loss: 0.1733, Train: 69.93%, Valid: 60.07%, Test: 49.35%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.1733, Train: 74.29%, Valid: 64.49%, Test: 64.70%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 115, Loss: 0.1733, Train: 76.73%, Valid: 66.95%, Test: 72.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 120, Loss: 0.1707, Train: 68.96%, Valid: 58.72%, Test: 45.80%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.1707, Train: 74.97%, Valid: 64.95%, Test: 57.34%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 120, Loss: 0.1707, Train: 76.93%, Valid: 66.93%, Test: 69.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 125, Loss: 0.1705, Train: 68.50%, Valid: 58.39%, Test: 31.91%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.1705, Train: 74.91%, Valid: 64.84%, Test: 60.31%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 125, Loss: 0.1705, Train: 76.41%, Valid: 66.36%, Test: 65.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 70.77%, Valid: 60.75%, Test: 47.35%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 76.42%, Valid: 66.42%, Test: 62.23%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 130, Loss: 0.1695, Train: 78.19%, Valid: 68.22%, Test: 72.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 135, Loss: 0.1683, Train: 71.62%, Valid: 61.24%, Test: 30.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.1683, Train: 74.82%, Valid: 64.58%, Test: 47.89%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 135, Loss: 0.1683, Train: 77.51%, Valid: 67.48%, Test: 62.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 140, Loss: 0.1674, Train: 68.16%, Valid: 57.52%, Test: 45.59%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.1674, Train: 75.39%, Valid: 65.10%, Test: 57.93%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 140, Loss: 0.1674, Train: 77.07%, Valid: 66.84%, Test: 72.21%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 145, Loss: 0.1666, Train: 70.71%, Valid: 60.35%, Test: 44.59%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.1666, Train: 74.78%, Valid: 64.50%, Test: 60.39%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 145, Loss: 0.1666, Train: 77.55%, Valid: 67.47%, Test: 74.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 150, Loss: 0.1655, Train: 57.59%, Valid: 47.22%, Test: 50.97%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.1655, Train: 72.97%, Valid: 62.42%, Test: 67.48%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 150, Loss: 0.1655, Train: 76.97%, Valid: 66.68%, Test: 73.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 155, Loss: 0.1653, Train: 68.55%, Valid: 57.96%, Test: 38.58%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.1653, Train: 75.02%, Valid: 64.70%, Test: 51.46%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 155, Loss: 0.1653, Train: 77.68%, Valid: 67.41%, Test: 70.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 160, Loss: 0.1655, Train: 72.15%, Valid: 61.36%, Test: 46.36%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.1655, Train: 75.68%, Valid: 65.07%, Test: 58.81%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 160, Loss: 0.1655, Train: 78.29%, Valid: 67.97%, Test: 65.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 165, Loss: 0.1650, Train: 68.19%, Valid: 57.44%, Test: 37.31%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.1650, Train: 72.88%, Valid: 62.30%, Test: 54.20%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 165, Loss: 0.1650, Train: 76.78%, Valid: 66.50%, Test: 66.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 170, Loss: 0.1637, Train: 69.19%, Valid: 58.78%, Test: 44.98%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.1637, Train: 76.17%, Valid: 65.85%, Test: 69.16%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 170, Loss: 0.1637, Train: 78.34%, Valid: 68.10%, Test: 78.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 175, Loss: 0.1632, Train: 70.75%, Valid: 60.10%, Test: 49.86%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.1632, Train: 76.98%, Valid: 66.72%, Test: 63.94%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 175, Loss: 0.1632, Train: 78.46%, Valid: 68.32%, Test: 77.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 180, Loss: 0.1630, Train: 71.15%, Valid: 60.70%, Test: 37.20%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.1630, Train: 75.90%, Valid: 65.56%, Test: 59.21%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 180, Loss: 0.1630, Train: 77.79%, Valid: 67.47%, Test: 68.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 185, Loss: 0.1625, Train: 69.96%, Valid: 59.05%, Test: 40.94%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.1625, Train: 76.88%, Valid: 66.30%, Test: 52.98%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 185, Loss: 0.1625, Train: 78.64%, Valid: 68.22%, Test: 64.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 190, Loss: 0.1622, Train: 67.38%, Valid: 56.62%, Test: 48.14%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.1622, Train: 74.92%, Valid: 64.47%, Test: 64.72%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 190, Loss: 0.1622, Train: 77.67%, Valid: 67.32%, Test: 75.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 195, Loss: 0.1614, Train: 66.80%, Valid: 55.95%, Test: 46.69%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.1614, Train: 77.34%, Valid: 66.84%, Test: 54.81%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 195, Loss: 0.1614, Train: 79.66%, Valid: 69.36%, Test: 67.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 200, Loss: 0.1609, Train: 71.53%, Valid: 60.52%, Test: 37.74%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.1609, Train: 76.76%, Valid: 66.17%, Test: 46.44%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 200, Loss: 0.1609, Train: 78.19%, Valid: 67.70%, Test: 69.58%\n",
      "---\n",
      "Hits@10\n",
      "Run 02:\n",
      "Highest Train: 72.15\n",
      "Highest Valid: 61.70\n",
      "  Final Train: 71.25\n",
      "   Final Test: 33.43\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Train: 77.34\n",
      "Highest Valid: 66.84\n",
      "  Final Train: 77.34\n",
      "   Final Test: 54.81\n",
      "Hits@30\n",
      "Run 02:\n",
      "Highest Train: 79.66\n",
      "Highest Valid: 69.36\n",
      "  Final Train: 79.66\n",
      "   Final Test: 67.38\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.5621, Train: 12.33%, Valid: 10.93%, Test: 4.66%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.5621, Train: 16.05%, Valid: 14.35%, Test: 7.74%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.5621, Train: 17.27%, Valid: 15.53%, Test: 10.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 10, Loss: 0.4117, Train: 21.36%, Valid: 18.78%, Test: 10.70%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 10, Loss: 0.4117, Train: 26.68%, Valid: 23.80%, Test: 16.45%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 10, Loss: 0.4117, Train: 32.04%, Valid: 28.86%, Test: 19.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 15, Loss: 0.3334, Train: 29.39%, Valid: 25.34%, Test: 8.65%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 15, Loss: 0.3334, Train: 35.82%, Valid: 31.18%, Test: 15.10%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 15, Loss: 0.3334, Train: 38.94%, Valid: 33.95%, Test: 19.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 20, Loss: 0.2937, Train: 33.33%, Valid: 28.27%, Test: 5.57%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 20, Loss: 0.2937, Train: 39.61%, Valid: 33.95%, Test: 9.89%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 20, Loss: 0.2937, Train: 43.72%, Valid: 37.75%, Test: 14.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 25, Loss: 0.2667, Train: 49.81%, Valid: 43.28%, Test: 15.61%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 25, Loss: 0.2667, Train: 53.40%, Valid: 46.64%, Test: 23.76%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 25, Loss: 0.2667, Train: 55.89%, Valid: 48.92%, Test: 33.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 30, Loss: 0.2436, Train: 52.24%, Valid: 45.22%, Test: 32.46%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 30, Loss: 0.2436, Train: 58.42%, Valid: 50.89%, Test: 40.23%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 30, Loss: 0.2436, Train: 60.63%, Valid: 52.87%, Test: 49.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 35, Loss: 0.2275, Train: 58.99%, Valid: 51.17%, Test: 32.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 35, Loss: 0.2275, Train: 61.20%, Valid: 53.21%, Test: 39.86%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 35, Loss: 0.2275, Train: 63.52%, Valid: 55.49%, Test: 47.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 40, Loss: 0.2192, Train: 58.27%, Valid: 50.28%, Test: 21.96%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 40, Loss: 0.2192, Train: 63.06%, Valid: 54.90%, Test: 38.60%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 40, Loss: 0.2192, Train: 66.64%, Valid: 58.20%, Test: 45.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 45, Loss: 0.2092, Train: 53.39%, Valid: 45.12%, Test: 28.26%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 45, Loss: 0.2092, Train: 61.66%, Valid: 53.03%, Test: 43.19%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 45, Loss: 0.2092, Train: 65.20%, Valid: 56.41%, Test: 49.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 50, Loss: 0.2031, Train: 58.00%, Valid: 49.59%, Test: 33.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 50, Loss: 0.2031, Train: 65.48%, Valid: 56.68%, Test: 52.64%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 50, Loss: 0.2031, Train: 68.10%, Valid: 59.12%, Test: 60.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 55, Loss: 0.1986, Train: 60.96%, Valid: 52.13%, Test: 47.32%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 55, Loss: 0.1986, Train: 67.09%, Valid: 58.08%, Test: 59.90%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 55, Loss: 0.1986, Train: 69.56%, Valid: 60.51%, Test: 67.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 60, Loss: 0.1949, Train: 47.83%, Valid: 39.46%, Test: 22.10%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 60, Loss: 0.1949, Train: 59.66%, Valid: 50.62%, Test: 40.40%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 60, Loss: 0.1949, Train: 70.12%, Valid: 60.54%, Test: 48.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 65, Loss: 0.1918, Train: 56.19%, Valid: 47.31%, Test: 39.49%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 65, Loss: 0.1918, Train: 69.37%, Valid: 59.92%, Test: 52.36%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 65, Loss: 0.1918, Train: 71.20%, Valid: 61.72%, Test: 64.77%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 03, Epoch: 70, Loss: 0.1884, Train: 57.43%, Valid: 48.34%, Test: 42.69%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 70, Loss: 0.1884, Train: 68.50%, Valid: 59.11%, Test: 57.95%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 70, Loss: 0.1884, Train: 71.65%, Valid: 62.18%, Test: 66.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 75, Loss: 0.1849, Train: 61.30%, Valid: 52.09%, Test: 36.94%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 75, Loss: 0.1849, Train: 70.77%, Valid: 61.30%, Test: 53.38%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 75, Loss: 0.1849, Train: 72.48%, Valid: 62.93%, Test: 59.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 80, Loss: 0.1835, Train: 58.58%, Valid: 48.88%, Test: 15.34%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 80, Loss: 0.1835, Train: 69.06%, Valid: 59.14%, Test: 32.21%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 80, Loss: 0.1835, Train: 71.61%, Valid: 61.79%, Test: 40.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 85, Loss: 0.1826, Train: 63.93%, Valid: 54.16%, Test: 44.75%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 85, Loss: 0.1826, Train: 72.55%, Valid: 63.02%, Test: 59.03%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 85, Loss: 0.1826, Train: 74.51%, Valid: 64.93%, Test: 69.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 90, Loss: 0.1804, Train: 62.96%, Valid: 53.28%, Test: 31.71%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 90, Loss: 0.1804, Train: 73.33%, Valid: 63.65%, Test: 45.34%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 90, Loss: 0.1804, Train: 75.73%, Valid: 65.97%, Test: 62.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 95, Loss: 0.1787, Train: 64.82%, Valid: 55.18%, Test: 44.82%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 95, Loss: 0.1787, Train: 72.95%, Valid: 63.19%, Test: 58.59%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 95, Loss: 0.1787, Train: 75.48%, Valid: 65.75%, Test: 69.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 100, Loss: 0.1758, Train: 64.62%, Valid: 54.81%, Test: 39.78%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 100, Loss: 0.1758, Train: 74.28%, Valid: 64.42%, Test: 54.68%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 100, Loss: 0.1758, Train: 75.92%, Valid: 66.02%, Test: 65.12%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 105, Loss: 0.1744, Train: 66.04%, Valid: 56.07%, Test: 50.44%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 105, Loss: 0.1744, Train: 74.76%, Valid: 64.86%, Test: 64.99%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 105, Loss: 0.1744, Train: 77.51%, Valid: 67.55%, Test: 72.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 110, Loss: 0.1746, Train: 57.59%, Valid: 47.66%, Test: 45.45%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 110, Loss: 0.1746, Train: 71.39%, Valid: 61.28%, Test: 54.94%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 110, Loss: 0.1746, Train: 75.38%, Valid: 65.33%, Test: 67.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 115, Loss: 0.1722, Train: 61.74%, Valid: 52.08%, Test: 39.00%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 115, Loss: 0.1722, Train: 74.07%, Valid: 64.26%, Test: 54.22%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 115, Loss: 0.1722, Train: 76.34%, Valid: 66.48%, Test: 64.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 120, Loss: 0.1708, Train: 61.56%, Valid: 51.45%, Test: 43.95%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 120, Loss: 0.1708, Train: 71.59%, Valid: 61.44%, Test: 57.73%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 120, Loss: 0.1708, Train: 76.25%, Valid: 66.21%, Test: 64.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 125, Loss: 0.1705, Train: 71.30%, Valid: 61.16%, Test: 34.32%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 125, Loss: 0.1705, Train: 75.23%, Valid: 65.17%, Test: 54.39%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 125, Loss: 0.1705, Train: 77.56%, Valid: 67.61%, Test: 66.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 130, Loss: 0.1691, Train: 60.50%, Valid: 50.12%, Test: 42.99%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 130, Loss: 0.1691, Train: 71.76%, Valid: 61.37%, Test: 67.08%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 130, Loss: 0.1691, Train: 75.03%, Valid: 64.63%, Test: 71.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 135, Loss: 0.1690, Train: 61.03%, Valid: 50.91%, Test: 42.31%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 135, Loss: 0.1690, Train: 73.18%, Valid: 62.98%, Test: 58.21%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 135, Loss: 0.1690, Train: 76.28%, Valid: 66.10%, Test: 64.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 140, Loss: 0.1687, Train: 66.17%, Valid: 55.83%, Test: 49.36%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 140, Loss: 0.1687, Train: 75.90%, Valid: 65.54%, Test: 62.09%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 140, Loss: 0.1687, Train: 78.13%, Valid: 67.87%, Test: 71.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 145, Loss: 0.1672, Train: 65.46%, Valid: 55.39%, Test: 40.35%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 145, Loss: 0.1672, Train: 76.60%, Valid: 66.52%, Test: 62.55%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 145, Loss: 0.1672, Train: 78.41%, Valid: 68.31%, Test: 78.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 150, Loss: 0.1664, Train: 66.85%, Valid: 56.30%, Test: 17.69%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 150, Loss: 0.1664, Train: 75.03%, Valid: 64.62%, Test: 49.65%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 150, Loss: 0.1664, Train: 77.78%, Valid: 67.43%, Test: 62.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 155, Loss: 0.1643, Train: 52.70%, Valid: 42.40%, Test: 47.75%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 155, Loss: 0.1643, Train: 71.38%, Valid: 60.73%, Test: 62.92%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 155, Loss: 0.1643, Train: 77.22%, Valid: 66.84%, Test: 72.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 160, Loss: 0.1650, Train: 61.48%, Valid: 50.80%, Test: 47.69%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 160, Loss: 0.1650, Train: 73.02%, Valid: 62.40%, Test: 69.37%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 160, Loss: 0.1650, Train: 77.42%, Valid: 67.11%, Test: 75.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 165, Loss: 0.1638, Train: 59.17%, Valid: 48.61%, Test: 33.21%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 165, Loss: 0.1638, Train: 74.19%, Valid: 63.42%, Test: 54.39%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 165, Loss: 0.1638, Train: 77.71%, Valid: 67.14%, Test: 69.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 170, Loss: 0.1626, Train: 56.16%, Valid: 45.74%, Test: 37.01%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 170, Loss: 0.1626, Train: 72.55%, Valid: 61.92%, Test: 58.10%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 170, Loss: 0.1626, Train: 77.55%, Valid: 67.18%, Test: 69.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 175, Loss: 0.1616, Train: 59.07%, Valid: 48.45%, Test: 49.22%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 175, Loss: 0.1616, Train: 74.70%, Valid: 64.17%, Test: 67.47%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 175, Loss: 0.1616, Train: 78.57%, Valid: 68.22%, Test: 78.62%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 180, Loss: 0.1619, Train: 54.04%, Valid: 43.48%, Test: 29.34%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 180, Loss: 0.1619, Train: 75.51%, Valid: 64.92%, Test: 56.40%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 180, Loss: 0.1619, Train: 77.72%, Valid: 67.31%, Test: 70.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 185, Loss: 0.1608, Train: 65.63%, Valid: 55.24%, Test: 46.11%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 185, Loss: 0.1608, Train: 77.00%, Valid: 66.58%, Test: 62.59%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 185, Loss: 0.1608, Train: 79.30%, Valid: 69.05%, Test: 69.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 190, Loss: 0.1622, Train: 62.99%, Valid: 52.57%, Test: 29.48%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 190, Loss: 0.1622, Train: 75.78%, Valid: 65.26%, Test: 46.73%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 190, Loss: 0.1622, Train: 78.60%, Valid: 68.20%, Test: 66.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 195, Loss: 0.1602, Train: 71.73%, Valid: 60.69%, Test: 14.84%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 195, Loss: 0.1602, Train: 77.80%, Valid: 67.08%, Test: 48.05%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 195, Loss: 0.1602, Train: 79.70%, Valid: 69.20%, Test: 63.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 69.49%, Valid: 58.34%, Test: 21.75%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 75.80%, Valid: 64.92%, Test: 37.12%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 200, Loss: 0.1604, Train: 79.30%, Valid: 68.86%, Test: 62.48%\n",
      "---\n",
      "Hits@10\n",
      "Run 03:\n",
      "Highest Train: 71.73\n",
      "Highest Valid: 61.16\n",
      "  Final Train: 71.30\n",
      "   Final Test: 34.32\n",
      "Hits@20\n",
      "Run 03:\n",
      "Highest Train: 77.80\n",
      "Highest Valid: 67.08\n",
      "  Final Train: 77.80\n",
      "   Final Test: 48.05\n",
      "Hits@30\n",
      "Run 03:\n",
      "Highest Train: 79.70\n",
      "Highest Valid: 69.20\n",
      "  Final Train: 79.70\n",
      "   Final Test: 63.48\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.5725, Train: 11.82%, Valid: 10.54%, Test: 6.90%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.5725, Train: 15.37%, Valid: 13.74%, Test: 9.02%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.5725, Train: 18.88%, Valid: 17.06%, Test: 10.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 10, Loss: 0.3955, Train: 19.53%, Valid: 16.83%, Test: 7.88%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 10, Loss: 0.3955, Train: 26.79%, Valid: 23.56%, Test: 14.24%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 10, Loss: 0.3955, Train: 30.79%, Valid: 27.25%, Test: 17.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 15, Loss: 0.3226, Train: 38.06%, Valid: 33.51%, Test: 6.99%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 15, Loss: 0.3226, Train: 43.31%, Valid: 38.32%, Test: 11.09%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 15, Loss: 0.3226, Train: 47.59%, Valid: 42.39%, Test: 16.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 20, Loss: 0.2850, Train: 37.65%, Valid: 32.60%, Test: 9.26%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 20, Loss: 0.2850, Train: 45.56%, Valid: 39.71%, Test: 15.76%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 20, Loss: 0.2850, Train: 50.18%, Valid: 43.97%, Test: 20.51%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 25, Loss: 0.2561, Train: 45.34%, Valid: 39.01%, Test: 14.13%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 25, Loss: 0.2561, Train: 51.36%, Valid: 44.53%, Test: 19.78%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 25, Loss: 0.2561, Train: 56.07%, Valid: 48.95%, Test: 28.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 30, Loss: 0.2389, Train: 51.04%, Valid: 44.03%, Test: 13.08%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 30, Loss: 0.2389, Train: 57.86%, Valid: 50.34%, Test: 19.50%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 30, Loss: 0.2389, Train: 61.43%, Valid: 53.81%, Test: 27.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 35, Loss: 0.2263, Train: 59.19%, Valid: 51.30%, Test: 20.60%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 35, Loss: 0.2263, Train: 62.78%, Valid: 54.75%, Test: 39.40%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 35, Loss: 0.2263, Train: 65.04%, Valid: 56.83%, Test: 46.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 40, Loss: 0.2170, Train: 53.06%, Valid: 45.61%, Test: 21.98%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 40, Loss: 0.2170, Train: 62.88%, Valid: 54.55%, Test: 31.26%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 40, Loss: 0.2170, Train: 66.21%, Valid: 57.61%, Test: 39.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 45, Loss: 0.2078, Train: 59.18%, Valid: 50.85%, Test: 37.53%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 45, Loss: 0.2078, Train: 64.29%, Valid: 55.89%, Test: 49.17%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 45, Loss: 0.2078, Train: 68.60%, Valid: 59.99%, Test: 55.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 50, Loss: 0.2027, Train: 53.40%, Valid: 45.24%, Test: 27.10%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 50, Loss: 0.2027, Train: 62.69%, Valid: 53.91%, Test: 40.10%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 50, Loss: 0.2027, Train: 65.78%, Valid: 56.98%, Test: 46.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 55, Loss: 0.1991, Train: 57.09%, Valid: 48.68%, Test: 23.01%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 55, Loss: 0.1991, Train: 63.87%, Valid: 55.09%, Test: 43.72%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 55, Loss: 0.1991, Train: 69.40%, Valid: 60.19%, Test: 51.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 60, Loss: 0.1925, Train: 63.00%, Valid: 54.12%, Test: 43.59%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 60, Loss: 0.1925, Train: 70.32%, Valid: 61.13%, Test: 51.93%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 60, Loss: 0.1925, Train: 72.65%, Valid: 63.28%, Test: 57.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 65, Loss: 0.1898, Train: 58.70%, Valid: 49.95%, Test: 23.62%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 65, Loss: 0.1898, Train: 68.63%, Valid: 59.46%, Test: 43.63%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 65, Loss: 0.1898, Train: 72.31%, Valid: 62.96%, Test: 60.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 70, Loss: 0.1864, Train: 62.36%, Valid: 53.09%, Test: 20.36%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 70, Loss: 0.1864, Train: 69.37%, Valid: 59.89%, Test: 43.30%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 70, Loss: 0.1864, Train: 72.43%, Valid: 62.85%, Test: 58.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 75, Loss: 0.1863, Train: 69.95%, Valid: 60.48%, Test: 28.60%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 75, Loss: 0.1863, Train: 72.49%, Valid: 62.94%, Test: 56.38%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 75, Loss: 0.1863, Train: 74.30%, Valid: 64.74%, Test: 61.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 80, Loss: 0.1835, Train: 66.57%, Valid: 57.39%, Test: 44.10%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 80, Loss: 0.1835, Train: 73.15%, Valid: 63.76%, Test: 55.66%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 80, Loss: 0.1835, Train: 75.12%, Valid: 65.67%, Test: 66.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 85, Loss: 0.1802, Train: 66.88%, Valid: 57.40%, Test: 13.36%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 85, Loss: 0.1802, Train: 74.33%, Valid: 64.76%, Test: 52.54%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 85, Loss: 0.1802, Train: 76.12%, Valid: 66.55%, Test: 59.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 90, Loss: 0.1789, Train: 58.07%, Valid: 48.65%, Test: 27.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 90, Loss: 0.1789, Train: 70.87%, Valid: 61.15%, Test: 40.05%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 90, Loss: 0.1789, Train: 72.73%, Valid: 62.96%, Test: 45.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 95, Loss: 0.1772, Train: 68.69%, Valid: 58.91%, Test: 36.46%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 95, Loss: 0.1772, Train: 72.32%, Valid: 62.57%, Test: 59.72%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 95, Loss: 0.1772, Train: 75.21%, Valid: 65.43%, Test: 71.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 100, Loss: 0.1739, Train: 64.29%, Valid: 54.55%, Test: 39.61%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 100, Loss: 0.1739, Train: 72.97%, Valid: 62.97%, Test: 69.02%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 100, Loss: 0.1739, Train: 75.83%, Valid: 65.82%, Test: 74.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 105, Loss: 0.1729, Train: 67.39%, Valid: 57.22%, Test: 33.22%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 105, Loss: 0.1729, Train: 74.61%, Valid: 64.50%, Test: 56.89%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 105, Loss: 0.1729, Train: 76.24%, Valid: 66.22%, Test: 60.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 59.67%, Valid: 50.12%, Test: 35.82%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 73.73%, Valid: 63.70%, Test: 51.83%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 110, Loss: 0.1740, Train: 76.30%, Valid: 66.47%, Test: 63.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 115, Loss: 0.1720, Train: 67.56%, Valid: 57.61%, Test: 38.02%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 115, Loss: 0.1720, Train: 74.78%, Valid: 64.79%, Test: 63.94%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 115, Loss: 0.1720, Train: 76.78%, Valid: 66.78%, Test: 70.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 120, Loss: 0.1711, Train: 66.90%, Valid: 56.84%, Test: 27.50%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 120, Loss: 0.1711, Train: 74.13%, Valid: 64.05%, Test: 50.10%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 120, Loss: 0.1711, Train: 76.92%, Valid: 66.89%, Test: 64.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 125, Loss: 0.1697, Train: 62.97%, Valid: 52.79%, Test: 33.19%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 125, Loss: 0.1697, Train: 72.89%, Valid: 62.70%, Test: 53.91%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 125, Loss: 0.1697, Train: 75.19%, Valid: 65.06%, Test: 67.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 130, Loss: 0.1688, Train: 70.87%, Valid: 60.69%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 130, Loss: 0.1688, Train: 75.50%, Valid: 65.44%, Test: 42.15%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 130, Loss: 0.1688, Train: 78.03%, Valid: 67.96%, Test: 57.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 135, Loss: 0.1661, Train: 65.43%, Valid: 55.13%, Test: 41.95%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 135, Loss: 0.1661, Train: 75.11%, Valid: 64.79%, Test: 52.79%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 135, Loss: 0.1661, Train: 77.54%, Valid: 67.31%, Test: 68.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 140, Loss: 0.1670, Train: 69.20%, Valid: 58.96%, Test: 31.47%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 140, Loss: 0.1670, Train: 76.25%, Valid: 66.19%, Test: 57.50%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 140, Loss: 0.1670, Train: 78.29%, Valid: 68.25%, Test: 73.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 145, Loss: 0.1654, Train: 62.14%, Valid: 51.97%, Test: 25.78%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 145, Loss: 0.1654, Train: 73.57%, Valid: 63.25%, Test: 45.68%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 145, Loss: 0.1654, Train: 77.24%, Valid: 67.10%, Test: 60.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 150, Loss: 0.1643, Train: 68.63%, Valid: 57.90%, Test: 36.26%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 150, Loss: 0.1643, Train: 75.31%, Valid: 64.82%, Test: 61.07%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 150, Loss: 0.1643, Train: 77.43%, Valid: 67.07%, Test: 70.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 155, Loss: 0.1642, Train: 57.82%, Valid: 47.66%, Test: 31.50%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 155, Loss: 0.1642, Train: 73.16%, Valid: 62.57%, Test: 46.57%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 155, Loss: 0.1642, Train: 76.03%, Valid: 65.53%, Test: 60.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 160, Loss: 0.1633, Train: 66.74%, Valid: 56.48%, Test: 35.43%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 160, Loss: 0.1633, Train: 75.01%, Valid: 64.88%, Test: 54.15%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 160, Loss: 0.1633, Train: 78.80%, Valid: 68.74%, Test: 72.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 165, Loss: 0.1639, Train: 71.96%, Valid: 61.78%, Test: 40.53%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 165, Loss: 0.1639, Train: 77.17%, Valid: 67.01%, Test: 61.15%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 165, Loss: 0.1639, Train: 79.11%, Valid: 68.93%, Test: 73.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 170, Loss: 0.1618, Train: 70.08%, Valid: 59.60%, Test: 41.45%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 170, Loss: 0.1618, Train: 74.51%, Valid: 64.13%, Test: 57.82%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 170, Loss: 0.1618, Train: 77.77%, Valid: 67.49%, Test: 79.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 175, Loss: 0.1630, Train: 70.78%, Valid: 60.38%, Test: 30.52%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 175, Loss: 0.1630, Train: 76.88%, Valid: 66.68%, Test: 51.80%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 175, Loss: 0.1630, Train: 79.09%, Valid: 68.95%, Test: 66.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 180, Loss: 0.1621, Train: 66.53%, Valid: 55.97%, Test: 31.79%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 180, Loss: 0.1621, Train: 75.45%, Valid: 64.96%, Test: 54.49%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 180, Loss: 0.1621, Train: 78.17%, Valid: 67.85%, Test: 69.23%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 04, Epoch: 185, Loss: 0.1615, Train: 64.55%, Valid: 53.89%, Test: 33.44%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 185, Loss: 0.1615, Train: 75.86%, Valid: 65.45%, Test: 58.97%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 185, Loss: 0.1615, Train: 78.44%, Valid: 68.09%, Test: 72.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 190, Loss: 0.1608, Train: 70.98%, Valid: 60.34%, Test: 40.98%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 190, Loss: 0.1608, Train: 75.51%, Valid: 65.03%, Test: 63.31%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 190, Loss: 0.1608, Train: 78.55%, Valid: 68.18%, Test: 77.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 195, Loss: 0.1592, Train: 71.47%, Valid: 60.71%, Test: 45.47%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 195, Loss: 0.1592, Train: 76.90%, Valid: 66.43%, Test: 61.96%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 195, Loss: 0.1592, Train: 79.45%, Valid: 69.16%, Test: 69.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 200, Loss: 0.1604, Train: 62.57%, Valid: 51.90%, Test: 35.04%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 200, Loss: 0.1604, Train: 76.28%, Valid: 65.63%, Test: 56.40%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 200, Loss: 0.1604, Train: 78.25%, Valid: 67.70%, Test: 67.44%\n",
      "---\n",
      "Hits@10\n",
      "Run 04:\n",
      "Highest Train: 71.96\n",
      "Highest Valid: 61.78\n",
      "  Final Train: 71.96\n",
      "   Final Test: 40.53\n",
      "Hits@20\n",
      "Run 04:\n",
      "Highest Train: 77.17\n",
      "Highest Valid: 67.01\n",
      "  Final Train: 77.17\n",
      "   Final Test: 61.15\n",
      "Hits@30\n",
      "Run 04:\n",
      "Highest Train: 79.45\n",
      "Highest Valid: 69.16\n",
      "  Final Train: 79.45\n",
      "   Final Test: 69.03\n",
      "Hits@10\n",
      "Run: 05, Epoch: 05, Loss: 0.5652, Train: 10.34%, Valid: 9.07%, Test: 2.88%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 05, Loss: 0.5652, Train: 15.61%, Valid: 13.86%, Test: 7.94%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 05, Loss: 0.5652, Train: 17.54%, Valid: 15.73%, Test: 9.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 10, Loss: 0.3909, Train: 23.50%, Valid: 20.70%, Test: 8.13%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 10, Loss: 0.3909, Train: 31.77%, Valid: 28.36%, Test: 10.77%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 10, Loss: 0.3909, Train: 35.06%, Valid: 31.56%, Test: 16.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 15, Loss: 0.3199, Train: 33.70%, Valid: 29.45%, Test: 3.74%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 15, Loss: 0.3199, Train: 39.68%, Valid: 34.84%, Test: 9.55%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 15, Loss: 0.3199, Train: 44.83%, Valid: 39.70%, Test: 12.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 20, Loss: 0.2841, Train: 40.43%, Valid: 34.96%, Test: 9.42%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 20, Loss: 0.2841, Train: 44.67%, Valid: 38.92%, Test: 15.07%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 20, Loss: 0.2841, Train: 48.33%, Valid: 42.23%, Test: 24.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 43.57%, Valid: 37.31%, Test: 18.96%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 49.90%, Valid: 43.19%, Test: 26.29%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 25, Loss: 0.2596, Train: 52.34%, Valid: 45.47%, Test: 34.01%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 30, Loss: 0.2413, Train: 48.58%, Valid: 41.79%, Test: 18.32%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 30, Loss: 0.2413, Train: 54.53%, Valid: 47.18%, Test: 31.49%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 30, Loss: 0.2413, Train: 59.49%, Valid: 51.73%, Test: 35.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 35, Loss: 0.2286, Train: 51.23%, Valid: 43.67%, Test: 19.54%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 35, Loss: 0.2286, Train: 55.84%, Valid: 47.97%, Test: 27.24%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 35, Loss: 0.2286, Train: 58.96%, Valid: 50.90%, Test: 32.96%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 40, Loss: 0.2173, Train: 48.34%, Valid: 40.74%, Test: 19.54%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 40, Loss: 0.2173, Train: 56.96%, Valid: 48.69%, Test: 38.56%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 40, Loss: 0.2173, Train: 62.91%, Valid: 54.32%, Test: 45.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 45, Loss: 0.2082, Train: 56.09%, Valid: 47.78%, Test: 39.49%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 45, Loss: 0.2082, Train: 62.68%, Valid: 53.85%, Test: 50.89%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 45, Loss: 0.2082, Train: 66.55%, Valid: 57.53%, Test: 56.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 50, Loss: 0.2070, Train: 62.83%, Valid: 54.39%, Test: 29.49%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 50, Loss: 0.2070, Train: 68.16%, Valid: 59.35%, Test: 45.46%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 50, Loss: 0.2070, Train: 70.10%, Valid: 61.13%, Test: 58.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 55, Loss: 0.2018, Train: 58.43%, Valid: 49.85%, Test: 23.88%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 55, Loss: 0.2018, Train: 65.88%, Valid: 57.01%, Test: 39.19%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 55, Loss: 0.2018, Train: 69.02%, Valid: 59.99%, Test: 49.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 60, Loss: 0.1928, Train: 65.57%, Valid: 56.34%, Test: 34.98%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 60, Loss: 0.1928, Train: 69.96%, Valid: 60.56%, Test: 48.76%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 60, Loss: 0.1928, Train: 72.51%, Valid: 63.09%, Test: 57.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 65, Loss: 0.1931, Train: 64.52%, Valid: 55.27%, Test: 30.57%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 65, Loss: 0.1931, Train: 69.16%, Valid: 59.79%, Test: 41.90%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 65, Loss: 0.1931, Train: 73.00%, Valid: 63.58%, Test: 48.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 59.92%, Valid: 50.83%, Test: 20.06%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 70.29%, Valid: 60.83%, Test: 33.54%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 70, Loss: 0.1872, Train: 72.93%, Valid: 63.32%, Test: 53.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 75, Loss: 0.1844, Train: 65.85%, Valid: 56.56%, Test: 37.80%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 75, Loss: 0.1844, Train: 71.17%, Valid: 61.84%, Test: 49.20%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 75, Loss: 0.1844, Train: 74.49%, Valid: 65.02%, Test: 65.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 80, Loss: 0.1819, Train: 68.20%, Valid: 58.76%, Test: 31.05%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 80, Loss: 0.1819, Train: 71.21%, Valid: 61.72%, Test: 50.57%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 80, Loss: 0.1819, Train: 74.47%, Valid: 64.92%, Test: 64.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 85, Loss: 0.1830, Train: 67.98%, Valid: 58.68%, Test: 28.41%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 85, Loss: 0.1830, Train: 74.66%, Valid: 65.09%, Test: 50.25%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 85, Loss: 0.1830, Train: 76.29%, Valid: 66.68%, Test: 63.06%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 90, Loss: 0.1790, Train: 57.28%, Valid: 47.94%, Test: 39.84%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 90, Loss: 0.1790, Train: 67.76%, Valid: 58.06%, Test: 48.09%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 90, Loss: 0.1790, Train: 73.18%, Valid: 63.37%, Test: 58.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 95, Loss: 0.1762, Train: 66.84%, Valid: 57.29%, Test: 42.38%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 95, Loss: 0.1762, Train: 73.53%, Valid: 63.75%, Test: 63.01%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 95, Loss: 0.1762, Train: 75.60%, Valid: 65.82%, Test: 69.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 100, Loss: 0.1762, Train: 68.33%, Valid: 58.64%, Test: 47.21%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 100, Loss: 0.1762, Train: 73.36%, Valid: 63.60%, Test: 63.37%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 100, Loss: 0.1762, Train: 75.24%, Valid: 65.51%, Test: 68.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 105, Loss: 0.1748, Train: 68.70%, Valid: 58.87%, Test: 33.83%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 105, Loss: 0.1748, Train: 73.29%, Valid: 63.45%, Test: 56.19%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 105, Loss: 0.1748, Train: 76.44%, Valid: 66.72%, Test: 67.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 110, Loss: 0.1726, Train: 65.87%, Valid: 55.80%, Test: 35.23%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 110, Loss: 0.1726, Train: 72.50%, Valid: 62.40%, Test: 56.33%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 110, Loss: 0.1726, Train: 75.80%, Valid: 65.83%, Test: 67.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 115, Loss: 0.1718, Train: 64.04%, Valid: 54.04%, Test: 32.49%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 115, Loss: 0.1718, Train: 72.14%, Valid: 62.11%, Test: 49.69%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 115, Loss: 0.1718, Train: 76.41%, Valid: 66.45%, Test: 58.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 120, Loss: 0.1702, Train: 64.72%, Valid: 54.82%, Test: 42.15%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 120, Loss: 0.1702, Train: 74.66%, Valid: 64.67%, Test: 64.37%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 120, Loss: 0.1702, Train: 76.29%, Valid: 66.31%, Test: 69.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 125, Loss: 0.1692, Train: 69.33%, Valid: 59.47%, Test: 18.74%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 125, Loss: 0.1692, Train: 74.79%, Valid: 64.95%, Test: 53.90%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 125, Loss: 0.1692, Train: 77.67%, Valid: 67.70%, Test: 63.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 130, Loss: 0.1692, Train: 68.52%, Valid: 58.14%, Test: 40.11%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 130, Loss: 0.1692, Train: 75.62%, Valid: 65.46%, Test: 63.76%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 130, Loss: 0.1692, Train: 78.27%, Valid: 68.20%, Test: 71.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 135, Loss: 0.1671, Train: 65.42%, Valid: 55.53%, Test: 38.13%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 135, Loss: 0.1671, Train: 76.02%, Valid: 65.96%, Test: 62.30%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 135, Loss: 0.1671, Train: 78.33%, Valid: 68.27%, Test: 69.63%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 05, Epoch: 140, Loss: 0.1664, Train: 66.30%, Valid: 55.94%, Test: 7.40%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 140, Loss: 0.1664, Train: 74.96%, Valid: 64.67%, Test: 30.13%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 140, Loss: 0.1664, Train: 77.44%, Valid: 67.23%, Test: 55.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 145, Loss: 0.1663, Train: 70.31%, Valid: 60.08%, Test: 42.48%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 145, Loss: 0.1663, Train: 76.64%, Valid: 66.46%, Test: 71.54%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 145, Loss: 0.1663, Train: 77.94%, Valid: 67.80%, Test: 76.32%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 150, Loss: 0.1639, Train: 55.59%, Valid: 45.36%, Test: 35.87%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 150, Loss: 0.1639, Train: 71.58%, Valid: 60.93%, Test: 53.15%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 150, Loss: 0.1639, Train: 77.01%, Valid: 66.62%, Test: 61.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 155, Loss: 0.1660, Train: 69.59%, Valid: 59.33%, Test: 41.43%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 155, Loss: 0.1660, Train: 74.90%, Valid: 64.67%, Test: 66.35%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 155, Loss: 0.1660, Train: 77.34%, Valid: 67.18%, Test: 73.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 160, Loss: 0.1633, Train: 67.44%, Valid: 57.20%, Test: 40.28%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 160, Loss: 0.1633, Train: 76.52%, Valid: 66.33%, Test: 62.92%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 160, Loss: 0.1633, Train: 78.25%, Valid: 68.11%, Test: 75.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 165, Loss: 0.1618, Train: 70.40%, Valid: 59.72%, Test: 30.93%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 165, Loss: 0.1618, Train: 76.48%, Valid: 66.08%, Test: 56.88%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 165, Loss: 0.1618, Train: 78.50%, Valid: 68.24%, Test: 70.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 170, Loss: 0.1626, Train: 68.04%, Valid: 57.77%, Test: 49.54%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 170, Loss: 0.1626, Train: 76.31%, Valid: 66.00%, Test: 64.08%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 170, Loss: 0.1626, Train: 78.08%, Valid: 67.79%, Test: 74.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 175, Loss: 0.1627, Train: 69.61%, Valid: 59.05%, Test: 33.49%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 175, Loss: 0.1627, Train: 74.51%, Valid: 64.03%, Test: 57.40%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 175, Loss: 0.1627, Train: 77.36%, Valid: 66.97%, Test: 70.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 180, Loss: 0.1615, Train: 68.61%, Valid: 57.98%, Test: 32.82%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 180, Loss: 0.1615, Train: 76.81%, Valid: 66.36%, Test: 50.94%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 180, Loss: 0.1615, Train: 79.19%, Valid: 68.95%, Test: 63.83%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 185, Loss: 0.1613, Train: 60.91%, Valid: 50.40%, Test: 31.30%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 185, Loss: 0.1613, Train: 75.91%, Valid: 65.36%, Test: 49.50%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 185, Loss: 0.1613, Train: 78.37%, Valid: 68.00%, Test: 71.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 190, Loss: 0.1613, Train: 71.19%, Valid: 60.68%, Test: 14.07%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 190, Loss: 0.1613, Train: 77.22%, Valid: 66.94%, Test: 52.94%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 190, Loss: 0.1613, Train: 79.65%, Valid: 69.48%, Test: 70.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 195, Loss: 0.1610, Train: 67.37%, Valid: 56.84%, Test: 37.05%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 195, Loss: 0.1610, Train: 77.51%, Valid: 67.19%, Test: 61.20%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 195, Loss: 0.1610, Train: 78.67%, Valid: 68.37%, Test: 70.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 65.42%, Valid: 54.62%, Test: 44.33%\n",
      "Hits@20\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 75.73%, Valid: 65.15%, Test: 53.98%\n",
      "Hits@30\n",
      "Run: 05, Epoch: 200, Loss: 0.1594, Train: 78.36%, Valid: 67.92%, Test: 68.32%\n",
      "---\n",
      "Hits@10\n",
      "Run 05:\n",
      "Highest Train: 71.19\n",
      "Highest Valid: 60.68\n",
      "  Final Train: 71.19\n",
      "   Final Test: 14.07\n",
      "Hits@20\n",
      "Run 05:\n",
      "Highest Train: 77.51\n",
      "Highest Valid: 67.19\n",
      "  Final Train: 77.51\n",
      "   Final Test: 61.20\n",
      "Hits@30\n",
      "Run 05:\n",
      "Highest Train: 79.65\n",
      "Highest Valid: 69.48\n",
      "  Final Train: 79.65\n",
      "   Final Test: 70.55\n",
      "Hits@10\n",
      "Run: 06, Epoch: 05, Loss: 0.5855, Train: 13.98%, Valid: 12.45%, Test: 1.90%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 05, Loss: 0.5855, Train: 16.29%, Valid: 14.67%, Test: 9.47%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 05, Loss: 0.5855, Train: 18.52%, Valid: 16.74%, Test: 11.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 10, Loss: 0.4219, Train: 18.79%, Valid: 16.57%, Test: 2.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 10, Loss: 0.4219, Train: 24.63%, Valid: 21.80%, Test: 6.07%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 10, Loss: 0.4219, Train: 28.25%, Valid: 25.26%, Test: 9.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 15, Loss: 0.3381, Train: 14.26%, Valid: 12.24%, Test: 2.24%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 15, Loss: 0.3381, Train: 24.64%, Valid: 21.52%, Test: 7.47%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 15, Loss: 0.3381, Train: 30.22%, Valid: 26.51%, Test: 11.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 20, Loss: 0.2967, Train: 36.46%, Valid: 31.63%, Test: 6.09%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 20, Loss: 0.2967, Train: 45.42%, Valid: 39.86%, Test: 10.77%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 20, Loss: 0.2967, Train: 50.60%, Valid: 44.51%, Test: 15.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 25, Loss: 0.2655, Train: 45.42%, Valid: 39.16%, Test: 8.74%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 25, Loss: 0.2655, Train: 49.64%, Valid: 43.22%, Test: 19.93%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 25, Loss: 0.2655, Train: 54.57%, Valid: 47.80%, Test: 28.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 30, Loss: 0.2461, Train: 48.78%, Valid: 42.00%, Test: 16.14%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 30, Loss: 0.2461, Train: 54.25%, Valid: 47.06%, Test: 28.34%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 30, Loss: 0.2461, Train: 58.32%, Valid: 50.80%, Test: 46.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 35, Loss: 0.2326, Train: 53.18%, Valid: 45.43%, Test: 35.04%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 35, Loss: 0.2326, Train: 60.23%, Valid: 52.12%, Test: 44.00%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 35, Loss: 0.2326, Train: 63.50%, Valid: 55.26%, Test: 50.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 40, Loss: 0.2203, Train: 58.12%, Valid: 50.27%, Test: 23.40%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 40, Loss: 0.2203, Train: 62.41%, Valid: 54.33%, Test: 46.63%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 40, Loss: 0.2203, Train: 67.00%, Valid: 58.52%, Test: 52.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 45, Loss: 0.2128, Train: 60.08%, Valid: 51.74%, Test: 32.33%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 45, Loss: 0.2128, Train: 65.72%, Valid: 56.94%, Test: 47.35%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 45, Loss: 0.2128, Train: 68.19%, Valid: 59.38%, Test: 51.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 50, Loss: 0.2056, Train: 55.99%, Valid: 47.77%, Test: 15.01%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 50, Loss: 0.2056, Train: 66.69%, Valid: 57.80%, Test: 29.57%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 50, Loss: 0.2056, Train: 69.74%, Valid: 60.83%, Test: 41.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 55, Loss: 0.1978, Train: 58.29%, Valid: 49.49%, Test: 32.35%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 55, Loss: 0.1978, Train: 68.03%, Valid: 59.00%, Test: 50.33%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 55, Loss: 0.1978, Train: 70.29%, Valid: 61.14%, Test: 58.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 60, Loss: 0.1965, Train: 67.53%, Valid: 58.47%, Test: 38.38%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 60, Loss: 0.1965, Train: 70.67%, Valid: 61.50%, Test: 50.42%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 60, Loss: 0.1965, Train: 73.02%, Valid: 63.76%, Test: 58.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 65, Loss: 0.1938, Train: 63.06%, Valid: 53.70%, Test: 29.38%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 65, Loss: 0.1938, Train: 71.12%, Valid: 61.76%, Test: 42.37%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 65, Loss: 0.1938, Train: 72.66%, Valid: 63.26%, Test: 49.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 70, Loss: 0.1910, Train: 61.64%, Valid: 52.34%, Test: 28.97%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 70, Loss: 0.1910, Train: 67.41%, Valid: 57.99%, Test: 39.14%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 70, Loss: 0.1910, Train: 72.19%, Valid: 62.71%, Test: 48.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 75, Loss: 0.1885, Train: 63.80%, Valid: 54.55%, Test: 37.57%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 75, Loss: 0.1885, Train: 70.48%, Valid: 61.04%, Test: 54.65%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 75, Loss: 0.1885, Train: 73.19%, Valid: 63.71%, Test: 64.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 80, Loss: 0.1841, Train: 66.95%, Valid: 57.47%, Test: 23.08%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 80, Loss: 0.1841, Train: 71.82%, Valid: 62.22%, Test: 43.69%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 80, Loss: 0.1841, Train: 73.52%, Valid: 63.99%, Test: 56.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 85, Loss: 0.1841, Train: 64.65%, Valid: 55.24%, Test: 24.28%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 85, Loss: 0.1841, Train: 71.38%, Valid: 61.85%, Test: 42.40%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 85, Loss: 0.1841, Train: 73.40%, Valid: 63.85%, Test: 51.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 90, Loss: 0.1801, Train: 64.48%, Valid: 54.77%, Test: 20.79%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 90, Loss: 0.1801, Train: 68.84%, Valid: 59.02%, Test: 32.95%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 90, Loss: 0.1801, Train: 72.18%, Valid: 62.29%, Test: 45.29%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 06, Epoch: 95, Loss: 0.1787, Train: 67.61%, Valid: 57.57%, Test: 35.31%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 95, Loss: 0.1787, Train: 72.41%, Valid: 62.45%, Test: 51.61%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 95, Loss: 0.1787, Train: 75.54%, Valid: 65.79%, Test: 60.52%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 100, Loss: 0.1778, Train: 64.47%, Valid: 54.82%, Test: 30.68%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 100, Loss: 0.1778, Train: 74.88%, Valid: 65.19%, Test: 45.57%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 100, Loss: 0.1778, Train: 76.56%, Valid: 66.88%, Test: 60.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 105, Loss: 0.1751, Train: 66.57%, Valid: 56.71%, Test: 23.83%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 105, Loss: 0.1751, Train: 75.06%, Valid: 65.18%, Test: 55.74%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 105, Loss: 0.1751, Train: 76.52%, Valid: 66.60%, Test: 66.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 110, Loss: 0.1728, Train: 56.27%, Valid: 46.41%, Test: 31.58%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 110, Loss: 0.1728, Train: 66.41%, Valid: 56.14%, Test: 42.41%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 110, Loss: 0.1728, Train: 72.60%, Valid: 62.32%, Test: 53.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 115, Loss: 0.1731, Train: 68.11%, Valid: 58.20%, Test: 24.49%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 115, Loss: 0.1731, Train: 73.07%, Valid: 63.20%, Test: 44.80%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 115, Loss: 0.1731, Train: 75.29%, Valid: 65.44%, Test: 63.13%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 120, Loss: 0.1717, Train: 65.48%, Valid: 55.44%, Test: 40.58%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 120, Loss: 0.1717, Train: 73.17%, Valid: 62.85%, Test: 56.45%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 120, Loss: 0.1717, Train: 76.53%, Valid: 66.43%, Test: 68.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 125, Loss: 0.1699, Train: 68.57%, Valid: 58.28%, Test: 24.98%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 125, Loss: 0.1699, Train: 74.84%, Valid: 64.68%, Test: 47.03%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 125, Loss: 0.1699, Train: 77.03%, Valid: 66.97%, Test: 60.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 130, Loss: 0.1716, Train: 69.50%, Valid: 59.29%, Test: 38.10%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 130, Loss: 0.1716, Train: 75.58%, Valid: 65.45%, Test: 58.10%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 130, Loss: 0.1716, Train: 78.55%, Valid: 68.49%, Test: 73.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 135, Loss: 0.1700, Train: 73.57%, Valid: 63.59%, Test: 29.19%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 135, Loss: 0.1700, Train: 77.86%, Valid: 67.85%, Test: 57.99%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 135, Loss: 0.1700, Train: 79.41%, Valid: 69.51%, Test: 65.98%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 140, Loss: 0.1679, Train: 67.02%, Valid: 56.68%, Test: 40.89%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 140, Loss: 0.1679, Train: 75.58%, Valid: 65.50%, Test: 51.34%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 140, Loss: 0.1679, Train: 78.23%, Valid: 68.18%, Test: 64.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 145, Loss: 0.1699, Train: 69.49%, Valid: 59.48%, Test: 47.49%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 145, Loss: 0.1699, Train: 76.57%, Valid: 66.67%, Test: 54.31%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 145, Loss: 0.1699, Train: 77.70%, Valid: 67.82%, Test: 66.28%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 150, Loss: 0.1661, Train: 66.41%, Valid: 55.74%, Test: 44.89%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 150, Loss: 0.1661, Train: 74.77%, Valid: 64.53%, Test: 53.88%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 150, Loss: 0.1661, Train: 77.84%, Valid: 67.70%, Test: 63.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 155, Loss: 0.1660, Train: 73.60%, Valid: 63.44%, Test: 22.95%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 155, Loss: 0.1660, Train: 76.47%, Valid: 66.29%, Test: 35.90%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 155, Loss: 0.1660, Train: 78.55%, Valid: 68.40%, Test: 46.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 160, Loss: 0.1642, Train: 71.58%, Valid: 61.46%, Test: 42.29%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 160, Loss: 0.1642, Train: 75.55%, Valid: 65.38%, Test: 57.17%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 160, Loss: 0.1642, Train: 78.25%, Valid: 68.10%, Test: 69.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 165, Loss: 0.1649, Train: 71.15%, Valid: 60.60%, Test: 26.22%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 165, Loss: 0.1649, Train: 78.03%, Valid: 67.76%, Test: 59.26%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 165, Loss: 0.1649, Train: 79.55%, Valid: 69.35%, Test: 69.68%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 170, Loss: 0.1634, Train: 69.36%, Valid: 58.92%, Test: 31.56%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 170, Loss: 0.1634, Train: 77.13%, Valid: 66.89%, Test: 52.74%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 170, Loss: 0.1634, Train: 79.41%, Valid: 69.31%, Test: 67.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 175, Loss: 0.1636, Train: 69.75%, Valid: 59.40%, Test: 17.68%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 175, Loss: 0.1636, Train: 76.95%, Valid: 66.72%, Test: 38.51%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 175, Loss: 0.1636, Train: 78.44%, Valid: 68.27%, Test: 56.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 180, Loss: 0.1621, Train: 73.33%, Valid: 63.20%, Test: 37.24%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 180, Loss: 0.1621, Train: 75.92%, Valid: 65.72%, Test: 48.60%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 180, Loss: 0.1621, Train: 79.53%, Valid: 69.48%, Test: 68.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 185, Loss: 0.1639, Train: 68.23%, Valid: 57.66%, Test: 32.39%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 185, Loss: 0.1639, Train: 76.26%, Valid: 65.99%, Test: 48.41%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 185, Loss: 0.1639, Train: 79.34%, Valid: 69.24%, Test: 63.54%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 190, Loss: 0.1620, Train: 66.63%, Valid: 55.81%, Test: 16.20%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 190, Loss: 0.1620, Train: 76.94%, Valid: 66.45%, Test: 39.37%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 190, Loss: 0.1620, Train: 79.73%, Valid: 69.52%, Test: 57.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 195, Loss: 0.1616, Train: 71.87%, Valid: 61.16%, Test: 30.95%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 195, Loss: 0.1616, Train: 77.84%, Valid: 67.49%, Test: 52.35%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 195, Loss: 0.1616, Train: 79.18%, Valid: 68.98%, Test: 72.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 06, Epoch: 200, Loss: 0.1605, Train: 72.60%, Valid: 62.19%, Test: 31.08%\n",
      "Hits@20\n",
      "Run: 06, Epoch: 200, Loss: 0.1605, Train: 78.18%, Valid: 67.85%, Test: 48.35%\n",
      "Hits@30\n",
      "Run: 06, Epoch: 200, Loss: 0.1605, Train: 80.26%, Valid: 70.11%, Test: 63.05%\n",
      "---\n",
      "Hits@10\n",
      "Run 06:\n",
      "Highest Train: 73.60\n",
      "Highest Valid: 63.59\n",
      "  Final Train: 73.57\n",
      "   Final Test: 29.19\n",
      "Hits@20\n",
      "Run 06:\n",
      "Highest Train: 78.18\n",
      "Highest Valid: 67.85\n",
      "  Final Train: 78.18\n",
      "   Final Test: 48.35\n",
      "Hits@30\n",
      "Run 06:\n",
      "Highest Train: 80.26\n",
      "Highest Valid: 70.11\n",
      "  Final Train: 80.26\n",
      "   Final Test: 63.05\n",
      "Hits@10\n",
      "Run: 07, Epoch: 05, Loss: 0.5450, Train: 16.46%, Valid: 14.70%, Test: 2.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 05, Loss: 0.5450, Train: 23.08%, Valid: 21.19%, Test: 10.04%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 05, Loss: 0.5450, Train: 25.35%, Valid: 23.41%, Test: 13.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 10, Loss: 0.3881, Train: 23.71%, Valid: 20.62%, Test: 9.99%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 10, Loss: 0.3881, Train: 28.23%, Valid: 24.68%, Test: 16.46%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 10, Loss: 0.3881, Train: 33.06%, Valid: 29.24%, Test: 19.90%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 15, Loss: 0.3187, Train: 33.01%, Valid: 28.43%, Test: 7.39%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 15, Loss: 0.3187, Train: 40.79%, Valid: 35.64%, Test: 15.99%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 15, Loss: 0.3187, Train: 43.38%, Valid: 38.05%, Test: 22.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 20, Loss: 0.2835, Train: 39.62%, Valid: 34.04%, Test: 13.32%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 20, Loss: 0.2835, Train: 44.20%, Valid: 38.20%, Test: 22.04%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 20, Loss: 0.2835, Train: 49.96%, Valid: 43.44%, Test: 26.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 25, Loss: 0.2558, Train: 48.96%, Valid: 41.81%, Test: 8.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 25, Loss: 0.2558, Train: 52.58%, Valid: 45.18%, Test: 24.09%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 25, Loss: 0.2558, Train: 55.21%, Valid: 47.71%, Test: 29.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 30, Loss: 0.2412, Train: 46.56%, Valid: 39.79%, Test: 13.41%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 30, Loss: 0.2412, Train: 56.62%, Valid: 49.13%, Test: 23.91%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 30, Loss: 0.2412, Train: 59.83%, Valid: 52.17%, Test: 33.25%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 35, Loss: 0.2245, Train: 52.06%, Valid: 44.80%, Test: 18.64%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 35, Loss: 0.2245, Train: 61.22%, Valid: 53.06%, Test: 30.39%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 35, Loss: 0.2245, Train: 64.18%, Valid: 55.85%, Test: 42.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 40, Loss: 0.2133, Train: 47.48%, Valid: 40.19%, Test: 30.54%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 40, Loss: 0.2133, Train: 61.58%, Valid: 53.24%, Test: 37.50%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 40, Loss: 0.2133, Train: 64.47%, Valid: 56.02%, Test: 41.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 45, Loss: 0.2070, Train: 59.60%, Valid: 51.12%, Test: 32.29%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 45, Loss: 0.2070, Train: 65.73%, Valid: 56.90%, Test: 46.96%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 45, Loss: 0.2070, Train: 68.76%, Valid: 59.83%, Test: 53.68%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 07, Epoch: 50, Loss: 0.2032, Train: 58.81%, Valid: 50.32%, Test: 28.70%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 50, Loss: 0.2032, Train: 67.00%, Valid: 58.16%, Test: 52.21%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 50, Loss: 0.2032, Train: 69.70%, Valid: 60.70%, Test: 58.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 55, Loss: 0.1960, Train: 61.24%, Valid: 52.37%, Test: 35.98%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 55, Loss: 0.1960, Train: 67.97%, Valid: 58.93%, Test: 50.43%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 55, Loss: 0.1960, Train: 70.36%, Valid: 61.22%, Test: 62.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 60, Loss: 0.1938, Train: 66.72%, Valid: 57.47%, Test: 27.87%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 60, Loss: 0.1938, Train: 68.95%, Valid: 59.57%, Test: 43.71%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 60, Loss: 0.1938, Train: 72.08%, Valid: 62.62%, Test: 59.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 65, Loss: 0.1879, Train: 66.05%, Valid: 56.78%, Test: 17.87%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 65, Loss: 0.1879, Train: 71.03%, Valid: 61.67%, Test: 37.11%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 65, Loss: 0.1879, Train: 72.71%, Valid: 63.27%, Test: 48.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 70, Loss: 0.1853, Train: 60.39%, Valid: 50.90%, Test: 27.66%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 70, Loss: 0.1853, Train: 68.83%, Valid: 59.10%, Test: 47.86%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 70, Loss: 0.1853, Train: 71.53%, Valid: 61.77%, Test: 56.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 75, Loss: 0.1851, Train: 59.66%, Valid: 50.54%, Test: 40.17%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 75, Loss: 0.1851, Train: 67.88%, Valid: 58.45%, Test: 56.39%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 75, Loss: 0.1851, Train: 72.76%, Valid: 63.21%, Test: 61.69%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 80, Loss: 0.1822, Train: 63.03%, Valid: 53.53%, Test: 44.20%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 80, Loss: 0.1822, Train: 68.32%, Valid: 58.85%, Test: 53.99%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 80, Loss: 0.1822, Train: 73.83%, Valid: 64.27%, Test: 65.63%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 85, Loss: 0.1791, Train: 66.12%, Valid: 56.56%, Test: 38.85%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 85, Loss: 0.1791, Train: 73.24%, Valid: 63.65%, Test: 56.23%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 85, Loss: 0.1791, Train: 75.84%, Valid: 66.21%, Test: 69.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 90, Loss: 0.1775, Train: 59.45%, Valid: 49.50%, Test: 26.33%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 90, Loss: 0.1775, Train: 71.67%, Valid: 61.72%, Test: 41.61%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 90, Loss: 0.1775, Train: 74.97%, Valid: 65.06%, Test: 61.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 95, Loss: 0.1776, Train: 67.11%, Valid: 57.37%, Test: 43.49%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 95, Loss: 0.1776, Train: 72.35%, Valid: 62.61%, Test: 58.80%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 95, Loss: 0.1776, Train: 75.88%, Valid: 66.26%, Test: 68.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 100, Loss: 0.1753, Train: 56.59%, Valid: 46.51%, Test: 27.46%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 100, Loss: 0.1753, Train: 72.43%, Valid: 62.47%, Test: 48.32%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 100, Loss: 0.1753, Train: 75.04%, Valid: 65.16%, Test: 51.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 105, Loss: 0.1729, Train: 62.82%, Valid: 52.69%, Test: 40.21%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 105, Loss: 0.1729, Train: 71.23%, Valid: 61.05%, Test: 51.30%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 105, Loss: 0.1729, Train: 73.91%, Valid: 63.83%, Test: 67.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 110, Loss: 0.1721, Train: 60.07%, Valid: 50.31%, Test: 30.05%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 110, Loss: 0.1721, Train: 71.64%, Valid: 61.49%, Test: 49.13%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 110, Loss: 0.1721, Train: 74.54%, Valid: 64.39%, Test: 57.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 115, Loss: 0.1716, Train: 65.86%, Valid: 56.08%, Test: 46.76%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 115, Loss: 0.1716, Train: 73.22%, Valid: 63.40%, Test: 55.69%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 115, Loss: 0.1716, Train: 75.93%, Valid: 66.09%, Test: 67.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 120, Loss: 0.1703, Train: 65.62%, Valid: 55.47%, Test: 42.54%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 120, Loss: 0.1703, Train: 73.77%, Valid: 63.65%, Test: 58.88%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 120, Loss: 0.1703, Train: 76.11%, Valid: 66.02%, Test: 67.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 125, Loss: 0.1691, Train: 68.81%, Valid: 58.76%, Test: 48.02%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 125, Loss: 0.1691, Train: 75.01%, Valid: 65.00%, Test: 62.40%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 125, Loss: 0.1691, Train: 77.73%, Valid: 67.79%, Test: 71.65%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 130, Loss: 0.1689, Train: 69.32%, Valid: 59.17%, Test: 48.18%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 130, Loss: 0.1689, Train: 72.33%, Valid: 62.21%, Test: 56.34%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 130, Loss: 0.1689, Train: 75.48%, Valid: 65.44%, Test: 67.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 135, Loss: 0.1680, Train: 65.97%, Valid: 55.48%, Test: 26.78%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 135, Loss: 0.1680, Train: 73.88%, Valid: 63.61%, Test: 53.37%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 135, Loss: 0.1680, Train: 77.20%, Valid: 67.05%, Test: 63.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 140, Loss: 0.1666, Train: 64.60%, Valid: 54.24%, Test: 27.30%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 140, Loss: 0.1666, Train: 75.08%, Valid: 64.87%, Test: 48.96%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 140, Loss: 0.1666, Train: 76.92%, Valid: 66.74%, Test: 68.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 145, Loss: 0.1651, Train: 61.72%, Valid: 51.38%, Test: 28.74%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 145, Loss: 0.1651, Train: 73.74%, Valid: 63.28%, Test: 51.22%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 145, Loss: 0.1651, Train: 76.87%, Valid: 66.61%, Test: 60.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 150, Loss: 0.1656, Train: 69.94%, Valid: 59.72%, Test: 34.50%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 150, Loss: 0.1656, Train: 75.10%, Valid: 64.97%, Test: 59.59%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 150, Loss: 0.1656, Train: 78.23%, Valid: 68.17%, Test: 68.82%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 155, Loss: 0.1645, Train: 64.66%, Valid: 54.23%, Test: 56.14%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 155, Loss: 0.1645, Train: 71.85%, Valid: 61.43%, Test: 64.33%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 155, Loss: 0.1645, Train: 75.50%, Valid: 65.27%, Test: 72.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 160, Loss: 0.1619, Train: 60.84%, Valid: 50.27%, Test: 38.66%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 160, Loss: 0.1619, Train: 73.56%, Valid: 62.91%, Test: 55.32%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 160, Loss: 0.1619, Train: 76.60%, Valid: 66.21%, Test: 69.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 165, Loss: 0.1648, Train: 67.31%, Valid: 56.91%, Test: 37.33%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 165, Loss: 0.1648, Train: 76.57%, Valid: 66.34%, Test: 66.23%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 165, Loss: 0.1648, Train: 77.89%, Valid: 67.72%, Test: 76.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 170, Loss: 0.1627, Train: 64.32%, Valid: 53.47%, Test: 19.60%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 170, Loss: 0.1627, Train: 74.55%, Valid: 64.01%, Test: 57.66%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 170, Loss: 0.1627, Train: 76.98%, Valid: 66.57%, Test: 69.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 175, Loss: 0.1632, Train: 70.93%, Valid: 60.32%, Test: 34.99%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 175, Loss: 0.1632, Train: 77.09%, Valid: 66.72%, Test: 64.35%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 175, Loss: 0.1632, Train: 78.64%, Valid: 68.31%, Test: 72.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 180, Loss: 0.1613, Train: 63.13%, Valid: 52.50%, Test: 52.19%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 180, Loss: 0.1613, Train: 73.16%, Valid: 62.40%, Test: 60.53%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 180, Loss: 0.1613, Train: 78.39%, Valid: 67.92%, Test: 75.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 185, Loss: 0.1605, Train: 63.25%, Valid: 52.26%, Test: 19.26%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 185, Loss: 0.1605, Train: 73.84%, Valid: 63.14%, Test: 44.91%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 185, Loss: 0.1605, Train: 76.50%, Valid: 65.90%, Test: 56.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 190, Loss: 0.1608, Train: 72.64%, Valid: 61.83%, Test: 28.26%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 190, Loss: 0.1608, Train: 77.75%, Valid: 67.26%, Test: 53.32%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 190, Loss: 0.1608, Train: 79.55%, Valid: 69.20%, Test: 69.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 195, Loss: 0.1614, Train: 69.27%, Valid: 58.22%, Test: 27.56%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 195, Loss: 0.1614, Train: 75.53%, Valid: 64.71%, Test: 53.54%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 195, Loss: 0.1614, Train: 78.46%, Valid: 67.98%, Test: 63.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 07, Epoch: 200, Loss: 0.1624, Train: 68.29%, Valid: 57.24%, Test: 6.00%\n",
      "Hits@20\n",
      "Run: 07, Epoch: 200, Loss: 0.1624, Train: 75.84%, Valid: 65.23%, Test: 43.47%\n",
      "Hits@30\n",
      "Run: 07, Epoch: 200, Loss: 0.1624, Train: 78.11%, Valid: 67.61%, Test: 61.69%\n",
      "---\n",
      "Hits@10\n",
      "Run 07:\n",
      "Highest Train: 72.64\n",
      "Highest Valid: 61.83\n",
      "  Final Train: 72.64\n",
      "   Final Test: 28.26\n",
      "Hits@20\n",
      "Run 07:\n",
      "Highest Train: 77.75\n",
      "Highest Valid: 67.26\n",
      "  Final Train: 77.75\n",
      "   Final Test: 53.32\n",
      "Hits@30\n",
      "Run 07:\n",
      "Highest Train: 79.55\n",
      "Highest Valid: 69.20\n",
      "  Final Train: 79.55\n",
      "   Final Test: 69.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 05, Loss: 0.5707, Train: 11.54%, Valid: 10.39%, Test: 4.85%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 05, Loss: 0.5707, Train: 15.36%, Valid: 13.96%, Test: 8.35%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 05, Loss: 0.5707, Train: 17.56%, Valid: 15.98%, Test: 11.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 10, Loss: 0.4109, Train: 21.66%, Valid: 18.84%, Test: 8.12%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 10, Loss: 0.4109, Train: 25.48%, Valid: 22.39%, Test: 11.31%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 10, Loss: 0.4109, Train: 29.70%, Valid: 26.34%, Test: 16.53%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 15, Loss: 0.3314, Train: 31.36%, Valid: 27.18%, Test: 11.48%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 15, Loss: 0.3314, Train: 37.59%, Valid: 32.91%, Test: 18.98%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 15, Loss: 0.3314, Train: 43.19%, Valid: 38.22%, Test: 23.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 20, Loss: 0.2923, Train: 46.62%, Valid: 40.81%, Test: 10.44%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 20, Loss: 0.2923, Train: 50.56%, Valid: 44.50%, Test: 18.86%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 20, Loss: 0.2923, Train: 54.47%, Valid: 48.10%, Test: 23.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 25, Loss: 0.2632, Train: 52.06%, Valid: 45.29%, Test: 8.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 25, Loss: 0.2632, Train: 55.83%, Valid: 48.89%, Test: 19.25%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 25, Loss: 0.2632, Train: 57.42%, Valid: 50.39%, Test: 26.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 30, Loss: 0.2465, Train: 44.72%, Valid: 38.19%, Test: 12.55%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 30, Loss: 0.2465, Train: 49.35%, Valid: 42.46%, Test: 17.76%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 30, Loss: 0.2465, Train: 55.46%, Valid: 48.13%, Test: 20.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 35, Loss: 0.2340, Train: 55.68%, Valid: 48.30%, Test: 15.20%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 35, Loss: 0.2340, Train: 60.26%, Valid: 52.50%, Test: 26.46%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 35, Loss: 0.2340, Train: 63.57%, Valid: 55.52%, Test: 36.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 40, Loss: 0.2217, Train: 55.97%, Valid: 47.92%, Test: 11.53%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 40, Loss: 0.2217, Train: 62.92%, Valid: 54.61%, Test: 23.39%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 40, Loss: 0.2217, Train: 66.91%, Valid: 58.40%, Test: 31.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 45, Loss: 0.2170, Train: 57.88%, Valid: 49.71%, Test: 19.81%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 45, Loss: 0.2170, Train: 65.17%, Valid: 56.75%, Test: 34.01%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 45, Loss: 0.2170, Train: 68.40%, Valid: 59.83%, Test: 42.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 50, Loss: 0.2097, Train: 55.49%, Valid: 47.01%, Test: 15.85%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 50, Loss: 0.2097, Train: 64.26%, Valid: 55.48%, Test: 35.23%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 50, Loss: 0.2097, Train: 67.82%, Valid: 58.96%, Test: 42.70%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 55, Loss: 0.2037, Train: 61.70%, Valid: 53.07%, Test: 22.29%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 55, Loss: 0.2037, Train: 65.46%, Valid: 56.62%, Test: 41.88%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 55, Loss: 0.2037, Train: 69.07%, Valid: 60.18%, Test: 50.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 60, Loss: 0.2006, Train: 65.38%, Valid: 56.47%, Test: 35.98%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 60, Loss: 0.2006, Train: 70.59%, Valid: 61.43%, Test: 45.87%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 60, Loss: 0.2006, Train: 72.26%, Valid: 63.07%, Test: 55.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 65, Loss: 0.1948, Train: 64.79%, Valid: 55.81%, Test: 30.66%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 65, Loss: 0.1948, Train: 69.35%, Valid: 60.24%, Test: 43.16%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 65, Loss: 0.1948, Train: 72.72%, Valid: 63.50%, Test: 52.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 70, Loss: 0.1918, Train: 61.05%, Valid: 52.00%, Test: 35.09%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 70, Loss: 0.1918, Train: 69.81%, Valid: 60.47%, Test: 49.07%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 70, Loss: 0.1918, Train: 71.86%, Valid: 62.47%, Test: 57.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 75, Loss: 0.1891, Train: 63.15%, Valid: 54.01%, Test: 33.36%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 75, Loss: 0.1891, Train: 69.17%, Valid: 59.85%, Test: 56.20%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 75, Loss: 0.1891, Train: 72.96%, Valid: 63.46%, Test: 63.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 80, Loss: 0.1869, Train: 55.14%, Valid: 46.16%, Test: 28.42%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 80, Loss: 0.1869, Train: 66.11%, Valid: 56.56%, Test: 56.19%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 80, Loss: 0.1869, Train: 72.04%, Valid: 62.20%, Test: 67.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 85, Loss: 0.1831, Train: 64.34%, Valid: 54.93%, Test: 41.08%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 85, Loss: 0.1831, Train: 72.32%, Valid: 62.64%, Test: 57.55%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 85, Loss: 0.1831, Train: 74.75%, Valid: 65.10%, Test: 67.43%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 90, Loss: 0.1822, Train: 67.79%, Valid: 58.27%, Test: 39.80%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 90, Loss: 0.1822, Train: 72.05%, Valid: 62.39%, Test: 58.46%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 90, Loss: 0.1822, Train: 74.92%, Valid: 65.33%, Test: 69.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 95, Loss: 0.1813, Train: 52.70%, Valid: 43.46%, Test: 37.28%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 95, Loss: 0.1813, Train: 67.40%, Valid: 57.52%, Test: 53.60%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 95, Loss: 0.1813, Train: 73.82%, Valid: 63.87%, Test: 64.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 100, Loss: 0.1805, Train: 63.98%, Valid: 54.06%, Test: 35.54%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 100, Loss: 0.1805, Train: 69.99%, Valid: 59.97%, Test: 53.11%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 100, Loss: 0.1805, Train: 74.33%, Valid: 64.25%, Test: 59.73%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 105, Loss: 0.1765, Train: 65.73%, Valid: 56.06%, Test: 28.43%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 105, Loss: 0.1765, Train: 74.80%, Valid: 65.00%, Test: 47.17%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 105, Loss: 0.1765, Train: 76.06%, Valid: 66.25%, Test: 62.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 110, Loss: 0.1738, Train: 65.54%, Valid: 55.80%, Test: 43.83%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 110, Loss: 0.1738, Train: 72.78%, Valid: 62.96%, Test: 62.27%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 110, Loss: 0.1738, Train: 76.09%, Valid: 66.20%, Test: 70.84%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 115, Loss: 0.1731, Train: 59.46%, Valid: 49.25%, Test: 37.85%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 115, Loss: 0.1731, Train: 68.98%, Valid: 58.71%, Test: 55.53%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 115, Loss: 0.1731, Train: 75.24%, Valid: 65.05%, Test: 67.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 120, Loss: 0.1718, Train: 51.67%, Valid: 42.55%, Test: 33.63%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 120, Loss: 0.1718, Train: 70.23%, Valid: 60.10%, Test: 53.32%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 120, Loss: 0.1718, Train: 74.90%, Valid: 64.83%, Test: 64.07%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 125, Loss: 0.1712, Train: 67.29%, Valid: 56.99%, Test: 43.51%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 125, Loss: 0.1712, Train: 75.65%, Valid: 65.55%, Test: 61.87%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 125, Loss: 0.1712, Train: 77.38%, Valid: 67.43%, Test: 66.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 130, Loss: 0.1711, Train: 67.40%, Valid: 57.15%, Test: 38.50%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 130, Loss: 0.1711, Train: 75.66%, Valid: 65.56%, Test: 57.63%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 130, Loss: 0.1711, Train: 78.04%, Valid: 67.97%, Test: 66.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 135, Loss: 0.1707, Train: 57.96%, Valid: 47.58%, Test: 34.96%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 135, Loss: 0.1707, Train: 74.36%, Valid: 64.00%, Test: 51.48%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 135, Loss: 0.1707, Train: 76.65%, Valid: 66.47%, Test: 65.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 140, Loss: 0.1683, Train: 67.54%, Valid: 56.97%, Test: 35.85%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 140, Loss: 0.1683, Train: 75.34%, Valid: 65.07%, Test: 57.19%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 140, Loss: 0.1683, Train: 77.03%, Valid: 66.79%, Test: 67.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 145, Loss: 0.1682, Train: 67.58%, Valid: 57.09%, Test: 15.09%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 145, Loss: 0.1682, Train: 73.51%, Valid: 63.08%, Test: 43.42%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 145, Loss: 0.1682, Train: 76.60%, Valid: 66.27%, Test: 56.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 150, Loss: 0.1707, Train: 51.89%, Valid: 41.75%, Test: 38.64%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 150, Loss: 0.1707, Train: 71.82%, Valid: 61.45%, Test: 46.44%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 150, Loss: 0.1707, Train: 75.38%, Valid: 65.22%, Test: 60.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 155, Loss: 0.1652, Train: 70.55%, Valid: 60.23%, Test: 40.63%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 155, Loss: 0.1652, Train: 76.26%, Valid: 66.01%, Test: 58.40%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 155, Loss: 0.1652, Train: 78.47%, Valid: 68.29%, Test: 66.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 160, Loss: 0.1658, Train: 70.46%, Valid: 60.15%, Test: 37.63%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 160, Loss: 0.1658, Train: 76.93%, Valid: 66.73%, Test: 55.73%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 160, Loss: 0.1658, Train: 78.82%, Valid: 68.70%, Test: 69.32%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 08, Epoch: 165, Loss: 0.1632, Train: 56.39%, Valid: 45.71%, Test: 23.38%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 165, Loss: 0.1632, Train: 72.38%, Valid: 61.48%, Test: 37.51%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 165, Loss: 0.1632, Train: 76.30%, Valid: 65.70%, Test: 48.97%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 170, Loss: 0.1637, Train: 72.20%, Valid: 61.83%, Test: 24.63%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 170, Loss: 0.1637, Train: 77.48%, Valid: 67.24%, Test: 55.54%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 170, Loss: 0.1637, Train: 79.05%, Valid: 68.83%, Test: 70.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 175, Loss: 0.1641, Train: 65.01%, Valid: 54.94%, Test: 36.80%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 175, Loss: 0.1641, Train: 75.86%, Valid: 65.62%, Test: 53.22%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 175, Loss: 0.1641, Train: 78.59%, Valid: 68.38%, Test: 65.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 180, Loss: 0.1627, Train: 63.68%, Valid: 52.25%, Test: 31.46%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 180, Loss: 0.1627, Train: 74.49%, Valid: 63.66%, Test: 48.35%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 180, Loss: 0.1627, Train: 77.74%, Valid: 67.26%, Test: 55.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 185, Loss: 0.1638, Train: 65.79%, Valid: 54.62%, Test: 33.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 185, Loss: 0.1638, Train: 74.41%, Valid: 63.43%, Test: 46.52%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 185, Loss: 0.1638, Train: 77.23%, Valid: 66.45%, Test: 65.18%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 190, Loss: 0.1619, Train: 57.07%, Valid: 46.31%, Test: 20.49%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 190, Loss: 0.1619, Train: 72.96%, Valid: 62.18%, Test: 44.86%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 190, Loss: 0.1619, Train: 77.38%, Valid: 66.89%, Test: 62.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 195, Loss: 0.1618, Train: 64.65%, Valid: 54.44%, Test: 10.93%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 195, Loss: 0.1618, Train: 75.81%, Valid: 65.48%, Test: 38.06%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 195, Loss: 0.1618, Train: 78.17%, Valid: 67.92%, Test: 60.42%\n",
      "---\n",
      "Hits@10\n",
      "Run: 08, Epoch: 200, Loss: 0.1587, Train: 67.84%, Valid: 56.96%, Test: 30.95%\n",
      "Hits@20\n",
      "Run: 08, Epoch: 200, Loss: 0.1587, Train: 75.83%, Valid: 65.35%, Test: 51.06%\n",
      "Hits@30\n",
      "Run: 08, Epoch: 200, Loss: 0.1587, Train: 77.78%, Valid: 67.34%, Test: 66.92%\n",
      "---\n",
      "Hits@10\n",
      "Run 08:\n",
      "Highest Train: 72.20\n",
      "Highest Valid: 61.83\n",
      "  Final Train: 72.20\n",
      "   Final Test: 24.63\n",
      "Hits@20\n",
      "Run 08:\n",
      "Highest Train: 77.48\n",
      "Highest Valid: 67.24\n",
      "  Final Train: 77.48\n",
      "   Final Test: 55.54\n",
      "Hits@30\n",
      "Run 08:\n",
      "Highest Train: 79.05\n",
      "Highest Valid: 68.83\n",
      "  Final Train: 79.05\n",
      "   Final Test: 70.61\n",
      "Hits@10\n",
      "Run: 09, Epoch: 05, Loss: 0.5629, Train: 11.00%, Valid: 9.70%, Test: 6.46%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 05, Loss: 0.5629, Train: 13.75%, Valid: 12.25%, Test: 8.71%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 05, Loss: 0.5629, Train: 16.46%, Valid: 14.66%, Test: 12.08%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 10, Loss: 0.4048, Train: 20.32%, Valid: 17.89%, Test: 5.23%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 10, Loss: 0.4048, Train: 26.99%, Valid: 23.94%, Test: 12.61%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 10, Loss: 0.4048, Train: 30.91%, Valid: 27.63%, Test: 19.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 15, Loss: 0.3272, Train: 23.18%, Valid: 19.92%, Test: 4.11%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 15, Loss: 0.3272, Train: 33.71%, Valid: 29.37%, Test: 9.38%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 15, Loss: 0.3272, Train: 39.66%, Valid: 34.94%, Test: 16.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 20, Loss: 0.2856, Train: 31.71%, Valid: 26.81%, Test: 6.72%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 20, Loss: 0.2856, Train: 39.16%, Valid: 33.57%, Test: 14.35%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 20, Loss: 0.2856, Train: 43.71%, Valid: 37.74%, Test: 18.85%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 25, Loss: 0.2603, Train: 46.20%, Valid: 39.74%, Test: 14.02%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 25, Loss: 0.2603, Train: 52.35%, Valid: 45.46%, Test: 18.28%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 25, Loss: 0.2603, Train: 57.95%, Valid: 50.79%, Test: 29.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 30, Loss: 0.2399, Train: 52.36%, Valid: 45.18%, Test: 15.31%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 30, Loss: 0.2399, Train: 59.52%, Valid: 51.89%, Test: 26.13%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 30, Loss: 0.2399, Train: 61.78%, Valid: 53.96%, Test: 33.51%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 35, Loss: 0.2287, Train: 49.67%, Valid: 42.34%, Test: 13.38%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 35, Loss: 0.2287, Train: 60.98%, Valid: 52.94%, Test: 25.76%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 35, Loss: 0.2287, Train: 63.70%, Valid: 55.57%, Test: 32.77%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 40, Loss: 0.2163, Train: 52.19%, Valid: 44.41%, Test: 17.87%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 40, Loss: 0.2163, Train: 59.65%, Valid: 51.43%, Test: 35.61%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 40, Loss: 0.2163, Train: 64.88%, Valid: 56.53%, Test: 44.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 45, Loss: 0.2087, Train: 60.44%, Valid: 52.17%, Test: 11.47%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 45, Loss: 0.2087, Train: 67.49%, Valid: 58.79%, Test: 27.89%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 45, Loss: 0.2087, Train: 70.28%, Valid: 61.48%, Test: 42.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 50, Loss: 0.2036, Train: 59.60%, Valid: 50.95%, Test: 26.94%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 50, Loss: 0.2036, Train: 66.54%, Valid: 57.72%, Test: 38.52%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 50, Loss: 0.2036, Train: 69.93%, Valid: 60.96%, Test: 48.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 55, Loss: 0.1998, Train: 64.41%, Valid: 55.50%, Test: 24.15%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 55, Loss: 0.1998, Train: 69.48%, Valid: 60.36%, Test: 46.15%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 55, Loss: 0.1998, Train: 71.21%, Valid: 62.06%, Test: 60.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 60, Loss: 0.1942, Train: 58.89%, Valid: 50.11%, Test: 18.78%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 60, Loss: 0.1942, Train: 66.90%, Valid: 57.90%, Test: 41.42%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 60, Loss: 0.1942, Train: 69.64%, Valid: 60.52%, Test: 47.20%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 65, Loss: 0.1927, Train: 52.53%, Valid: 44.27%, Test: 25.04%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 65, Loss: 0.1927, Train: 68.41%, Valid: 59.24%, Test: 50.55%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 65, Loss: 0.1927, Train: 71.53%, Valid: 62.31%, Test: 59.38%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 70, Loss: 0.1883, Train: 61.61%, Valid: 52.33%, Test: 36.65%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 70, Loss: 0.1883, Train: 71.04%, Valid: 61.60%, Test: 51.00%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 70, Loss: 0.1883, Train: 73.25%, Valid: 63.89%, Test: 60.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 75, Loss: 0.1851, Train: 64.37%, Valid: 55.13%, Test: 24.69%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 75, Loss: 0.1851, Train: 71.47%, Valid: 61.99%, Test: 45.01%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 75, Loss: 0.1851, Train: 73.84%, Valid: 64.33%, Test: 56.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 80, Loss: 0.1836, Train: 65.22%, Valid: 56.04%, Test: 40.12%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 80, Loss: 0.1836, Train: 71.60%, Valid: 62.21%, Test: 58.95%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 80, Loss: 0.1836, Train: 74.64%, Valid: 65.16%, Test: 69.26%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 85, Loss: 0.1813, Train: 67.89%, Valid: 58.43%, Test: 40.63%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 85, Loss: 0.1813, Train: 71.97%, Valid: 62.34%, Test: 53.61%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 85, Loss: 0.1813, Train: 74.68%, Valid: 65.03%, Test: 61.34%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 90, Loss: 0.1796, Train: 63.42%, Valid: 54.02%, Test: 44.64%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 90, Loss: 0.1796, Train: 71.77%, Valid: 62.18%, Test: 57.80%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 90, Loss: 0.1796, Train: 72.82%, Valid: 63.18%, Test: 68.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 95, Loss: 0.1797, Train: 60.81%, Valid: 51.11%, Test: 27.82%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 95, Loss: 0.1797, Train: 70.76%, Valid: 60.84%, Test: 39.54%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 95, Loss: 0.1797, Train: 73.02%, Valid: 63.14%, Test: 49.78%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 100, Loss: 0.1760, Train: 61.92%, Valid: 51.96%, Test: 39.73%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 100, Loss: 0.1760, Train: 74.33%, Valid: 64.37%, Test: 51.92%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 100, Loss: 0.1760, Train: 76.71%, Valid: 66.79%, Test: 62.47%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 105, Loss: 0.1760, Train: 62.95%, Valid: 53.18%, Test: 38.77%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 105, Loss: 0.1760, Train: 72.92%, Valid: 62.98%, Test: 52.48%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 105, Loss: 0.1760, Train: 75.21%, Valid: 65.33%, Test: 61.29%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 110, Loss: 0.1741, Train: 64.27%, Valid: 54.53%, Test: 30.88%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 110, Loss: 0.1741, Train: 73.58%, Valid: 63.65%, Test: 48.64%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 110, Loss: 0.1741, Train: 76.62%, Valid: 66.74%, Test: 60.22%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 54.08%, Valid: 44.83%, Test: 35.87%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 70.09%, Valid: 60.11%, Test: 48.17%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 115, Loss: 0.1719, Train: 75.57%, Valid: 65.70%, Test: 57.95%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 09, Epoch: 120, Loss: 0.1713, Train: 66.18%, Valid: 56.16%, Test: 37.63%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 120, Loss: 0.1713, Train: 73.33%, Valid: 63.30%, Test: 51.34%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 120, Loss: 0.1713, Train: 75.91%, Valid: 65.86%, Test: 63.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 125, Loss: 0.1707, Train: 55.29%, Valid: 45.30%, Test: 47.57%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 125, Loss: 0.1707, Train: 73.62%, Valid: 63.30%, Test: 55.19%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 125, Loss: 0.1707, Train: 74.89%, Valid: 64.58%, Test: 65.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 130, Loss: 0.1694, Train: 52.97%, Valid: 43.38%, Test: 34.21%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 130, Loss: 0.1694, Train: 71.66%, Valid: 61.45%, Test: 58.05%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 130, Loss: 0.1694, Train: 75.47%, Valid: 65.30%, Test: 64.23%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 135, Loss: 0.1698, Train: 50.76%, Valid: 41.32%, Test: 21.19%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 135, Loss: 0.1698, Train: 71.81%, Valid: 61.49%, Test: 36.36%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 135, Loss: 0.1698, Train: 76.52%, Valid: 66.37%, Test: 51.87%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 140, Loss: 0.1686, Train: 68.80%, Valid: 58.82%, Test: 43.82%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 140, Loss: 0.1686, Train: 75.64%, Valid: 65.54%, Test: 65.39%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 140, Loss: 0.1686, Train: 77.52%, Valid: 67.38%, Test: 73.16%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 145, Loss: 0.1672, Train: 68.29%, Valid: 57.85%, Test: 30.02%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 145, Loss: 0.1672, Train: 76.28%, Valid: 65.95%, Test: 47.79%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 145, Loss: 0.1672, Train: 78.65%, Valid: 68.48%, Test: 64.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 150, Loss: 0.1661, Train: 64.41%, Valid: 53.70%, Test: 46.42%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 150, Loss: 0.1661, Train: 75.29%, Valid: 64.65%, Test: 62.95%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 150, Loss: 0.1661, Train: 78.21%, Valid: 67.83%, Test: 73.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 155, Loss: 0.1653, Train: 65.76%, Valid: 55.20%, Test: 39.00%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 155, Loss: 0.1653, Train: 74.60%, Valid: 64.13%, Test: 62.61%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 155, Loss: 0.1653, Train: 77.83%, Valid: 67.59%, Test: 70.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 160, Loss: 0.1651, Train: 68.25%, Valid: 57.84%, Test: 26.45%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 160, Loss: 0.1651, Train: 76.51%, Valid: 66.25%, Test: 49.04%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 160, Loss: 0.1651, Train: 78.20%, Valid: 67.91%, Test: 62.24%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 165, Loss: 0.1633, Train: 63.58%, Valid: 53.14%, Test: 46.03%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 165, Loss: 0.1633, Train: 75.69%, Valid: 65.39%, Test: 68.56%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 165, Loss: 0.1633, Train: 78.98%, Valid: 68.76%, Test: 72.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 61.23%, Valid: 50.57%, Test: 35.00%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 74.98%, Valid: 64.51%, Test: 57.89%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 170, Loss: 0.1637, Train: 78.82%, Valid: 68.54%, Test: 66.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 175, Loss: 0.1636, Train: 63.73%, Valid: 53.33%, Test: 45.60%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 175, Loss: 0.1636, Train: 77.41%, Valid: 67.05%, Test: 59.99%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 175, Loss: 0.1636, Train: 78.84%, Valid: 68.60%, Test: 68.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 180, Loss: 0.1635, Train: 63.89%, Valid: 53.21%, Test: 43.76%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 180, Loss: 0.1635, Train: 76.39%, Valid: 65.99%, Test: 69.05%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 180, Loss: 0.1635, Train: 78.91%, Valid: 68.62%, Test: 78.94%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 185, Loss: 0.1609, Train: 68.55%, Valid: 57.69%, Test: 33.69%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 185, Loss: 0.1609, Train: 75.75%, Valid: 65.16%, Test: 48.18%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 185, Loss: 0.1609, Train: 77.88%, Valid: 67.47%, Test: 65.88%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 190, Loss: 0.1624, Train: 67.26%, Valid: 56.02%, Test: 40.70%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 190, Loss: 0.1624, Train: 76.83%, Valid: 66.13%, Test: 59.73%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 190, Loss: 0.1624, Train: 79.73%, Valid: 69.38%, Test: 69.05%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 195, Loss: 0.1625, Train: 69.73%, Valid: 59.40%, Test: 48.61%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 195, Loss: 0.1625, Train: 76.85%, Valid: 66.55%, Test: 64.12%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 195, Loss: 0.1625, Train: 79.19%, Valid: 68.93%, Test: 74.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 09, Epoch: 200, Loss: 0.1607, Train: 63.88%, Valid: 53.56%, Test: 32.74%\n",
      "Hits@20\n",
      "Run: 09, Epoch: 200, Loss: 0.1607, Train: 77.13%, Valid: 66.88%, Test: 56.80%\n",
      "Hits@30\n",
      "Run: 09, Epoch: 200, Loss: 0.1607, Train: 79.00%, Valid: 68.77%, Test: 68.73%\n",
      "---\n",
      "Hits@10\n",
      "Run 09:\n",
      "Highest Train: 69.73\n",
      "Highest Valid: 59.40\n",
      "  Final Train: 69.73\n",
      "   Final Test: 48.61\n",
      "Hits@20\n",
      "Run 09:\n",
      "Highest Train: 77.41\n",
      "Highest Valid: 67.05\n",
      "  Final Train: 77.41\n",
      "   Final Test: 59.99\n",
      "Hits@30\n",
      "Run 09:\n",
      "Highest Train: 79.73\n",
      "Highest Valid: 69.38\n",
      "  Final Train: 79.73\n",
      "   Final Test: 69.05\n",
      "Hits@10\n",
      "Run: 10, Epoch: 05, Loss: 0.5684, Train: 14.55%, Valid: 13.00%, Test: 3.36%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 05, Loss: 0.5684, Train: 16.37%, Valid: 14.74%, Test: 6.52%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 05, Loss: 0.5684, Train: 21.48%, Valid: 19.45%, Test: 11.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 10, Loss: 0.3908, Train: 25.52%, Valid: 22.28%, Test: 5.92%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 10, Loss: 0.3908, Train: 34.16%, Valid: 30.20%, Test: 11.42%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 10, Loss: 0.3908, Train: 36.27%, Valid: 32.27%, Test: 13.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 15, Loss: 0.3156, Train: 34.27%, Valid: 29.79%, Test: 12.54%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 15, Loss: 0.3156, Train: 40.77%, Valid: 35.71%, Test: 18.12%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 15, Loss: 0.3156, Train: 44.97%, Valid: 39.61%, Test: 22.59%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 20, Loss: 0.2781, Train: 43.91%, Valid: 37.94%, Test: 12.16%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 20, Loss: 0.2781, Train: 49.63%, Valid: 43.16%, Test: 22.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 20, Loss: 0.2781, Train: 52.41%, Valid: 45.74%, Test: 27.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 25, Loss: 0.2540, Train: 51.62%, Valid: 44.55%, Test: 13.12%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 25, Loss: 0.2540, Train: 59.32%, Valid: 51.84%, Test: 19.70%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 25, Loss: 0.2540, Train: 60.72%, Valid: 53.21%, Test: 27.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 30, Loss: 0.2361, Train: 52.21%, Valid: 45.01%, Test: 12.06%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 30, Loss: 0.2361, Train: 57.88%, Valid: 50.29%, Test: 24.60%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 30, Loss: 0.2361, Train: 61.56%, Valid: 53.76%, Test: 38.39%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 35, Loss: 0.2226, Train: 38.57%, Valid: 31.73%, Test: 17.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 35, Loss: 0.2226, Train: 56.59%, Valid: 48.37%, Test: 26.39%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 35, Loss: 0.2226, Train: 60.45%, Valid: 51.99%, Test: 34.72%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 40, Loss: 0.2125, Train: 56.39%, Valid: 48.33%, Test: 14.88%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 40, Loss: 0.2125, Train: 66.64%, Valid: 58.14%, Test: 22.63%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 40, Loss: 0.2125, Train: 68.64%, Valid: 59.95%, Test: 33.44%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 45, Loss: 0.2068, Train: 63.75%, Valid: 55.11%, Test: 24.21%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 45, Loss: 0.2068, Train: 68.62%, Valid: 59.87%, Test: 45.25%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 45, Loss: 0.2068, Train: 72.25%, Valid: 63.31%, Test: 56.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 50, Loss: 0.2048, Train: 63.90%, Valid: 55.21%, Test: 25.36%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 50, Loss: 0.2048, Train: 68.21%, Valid: 59.43%, Test: 38.96%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 50, Loss: 0.2048, Train: 71.18%, Valid: 62.33%, Test: 43.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 55, Loss: 0.1965, Train: 44.43%, Valid: 36.38%, Test: 23.45%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 55, Loss: 0.1965, Train: 67.97%, Valid: 58.68%, Test: 41.61%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 55, Loss: 0.1965, Train: 71.88%, Valid: 62.62%, Test: 48.31%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 60, Loss: 0.1945, Train: 67.01%, Valid: 57.69%, Test: 22.47%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 60, Loss: 0.1945, Train: 71.37%, Valid: 62.01%, Test: 43.08%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 60, Loss: 0.1945, Train: 73.42%, Valid: 64.10%, Test: 55.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 65, Loss: 0.1894, Train: 64.77%, Valid: 55.40%, Test: 34.67%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 65, Loss: 0.1894, Train: 70.89%, Valid: 61.54%, Test: 47.54%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 65, Loss: 0.1894, Train: 73.03%, Valid: 63.63%, Test: 60.19%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 70, Loss: 0.1874, Train: 60.97%, Valid: 51.67%, Test: 25.21%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 70, Loss: 0.1874, Train: 69.67%, Valid: 60.12%, Test: 62.51%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 70, Loss: 0.1874, Train: 74.30%, Valid: 64.70%, Test: 69.03%\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Run: 10, Epoch: 75, Loss: 0.1843, Train: 63.78%, Valid: 54.37%, Test: 40.94%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 75, Loss: 0.1843, Train: 71.97%, Valid: 62.48%, Test: 52.96%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 75, Loss: 0.1843, Train: 73.83%, Valid: 64.29%, Test: 63.30%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 80, Loss: 0.1832, Train: 69.27%, Valid: 59.87%, Test: 27.52%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 80, Loss: 0.1832, Train: 72.23%, Valid: 62.71%, Test: 52.17%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 80, Loss: 0.1832, Train: 75.87%, Valid: 66.40%, Test: 65.36%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 85, Loss: 0.1794, Train: 68.23%, Valid: 58.77%, Test: 31.73%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 85, Loss: 0.1794, Train: 73.45%, Valid: 63.99%, Test: 47.94%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 85, Loss: 0.1794, Train: 76.10%, Valid: 66.60%, Test: 66.14%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 90, Loss: 0.1760, Train: 58.45%, Valid: 48.69%, Test: 45.39%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 90, Loss: 0.1760, Train: 72.73%, Valid: 62.97%, Test: 65.09%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 90, Loss: 0.1760, Train: 76.00%, Valid: 66.27%, Test: 75.61%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 95, Loss: 0.1788, Train: 67.57%, Valid: 58.25%, Test: 48.79%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 95, Loss: 0.1788, Train: 74.07%, Valid: 64.45%, Test: 62.57%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 95, Loss: 0.1788, Train: 76.23%, Valid: 66.59%, Test: 75.35%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 61.04%, Valid: 51.35%, Test: 42.65%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 72.52%, Valid: 62.64%, Test: 68.02%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 100, Loss: 0.1743, Train: 76.71%, Valid: 66.89%, Test: 72.93%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 105, Loss: 0.1762, Train: 67.03%, Valid: 57.21%, Test: 54.05%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 105, Loss: 0.1762, Train: 72.80%, Valid: 62.92%, Test: 63.62%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 105, Loss: 0.1762, Train: 76.82%, Valid: 67.13%, Test: 74.58%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 110, Loss: 0.1725, Train: 63.15%, Valid: 53.03%, Test: 25.42%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 110, Loss: 0.1725, Train: 75.43%, Valid: 65.36%, Test: 48.81%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 110, Loss: 0.1725, Train: 76.60%, Valid: 66.57%, Test: 67.46%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 115, Loss: 0.1712, Train: 68.30%, Valid: 58.04%, Test: 52.22%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 115, Loss: 0.1712, Train: 75.21%, Valid: 65.10%, Test: 68.84%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 115, Loss: 0.1712, Train: 77.15%, Valid: 67.12%, Test: 71.95%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 120, Loss: 0.1703, Train: 57.48%, Valid: 47.56%, Test: 52.35%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 120, Loss: 0.1703, Train: 72.76%, Valid: 62.59%, Test: 69.17%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 120, Loss: 0.1703, Train: 76.73%, Valid: 66.62%, Test: 74.00%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 125, Loss: 0.1687, Train: 66.24%, Valid: 56.23%, Test: 42.55%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 125, Loss: 0.1687, Train: 76.58%, Valid: 66.57%, Test: 58.65%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 125, Loss: 0.1687, Train: 78.08%, Valid: 68.11%, Test: 72.55%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 130, Loss: 0.1665, Train: 73.58%, Valid: 63.51%, Test: 47.13%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 130, Loss: 0.1665, Train: 77.08%, Valid: 67.17%, Test: 66.66%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 130, Loss: 0.1665, Train: 78.62%, Valid: 68.71%, Test: 73.66%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 135, Loss: 0.1669, Train: 66.25%, Valid: 56.11%, Test: 47.07%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 135, Loss: 0.1669, Train: 74.76%, Valid: 64.69%, Test: 58.84%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 135, Loss: 0.1669, Train: 76.84%, Valid: 66.85%, Test: 75.91%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 140, Loss: 0.1672, Train: 68.40%, Valid: 58.07%, Test: 46.68%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 140, Loss: 0.1672, Train: 76.15%, Valid: 65.94%, Test: 59.23%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 140, Loss: 0.1672, Train: 78.51%, Valid: 68.39%, Test: 74.67%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 145, Loss: 0.1660, Train: 63.82%, Valid: 53.25%, Test: 36.75%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 145, Loss: 0.1660, Train: 74.51%, Valid: 64.04%, Test: 51.29%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 145, Loss: 0.1660, Train: 77.76%, Valid: 67.49%, Test: 63.04%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 150, Loss: 0.1665, Train: 67.38%, Valid: 57.10%, Test: 26.72%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 150, Loss: 0.1665, Train: 75.51%, Valid: 65.35%, Test: 55.27%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 150, Loss: 0.1665, Train: 77.90%, Valid: 67.83%, Test: 64.33%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 155, Loss: 0.1641, Train: 65.68%, Valid: 55.10%, Test: 42.34%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 155, Loss: 0.1641, Train: 76.25%, Valid: 65.85%, Test: 59.93%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 155, Loss: 0.1641, Train: 78.43%, Valid: 68.14%, Test: 70.76%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 160, Loss: 0.1640, Train: 67.88%, Valid: 57.55%, Test: 28.44%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 160, Loss: 0.1640, Train: 75.39%, Valid: 65.18%, Test: 56.80%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 160, Loss: 0.1640, Train: 77.53%, Valid: 67.40%, Test: 68.40%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 165, Loss: 0.1643, Train: 65.25%, Valid: 54.79%, Test: 32.19%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 165, Loss: 0.1643, Train: 77.28%, Valid: 67.18%, Test: 54.88%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 165, Loss: 0.1643, Train: 79.67%, Valid: 69.63%, Test: 67.17%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 170, Loss: 0.1634, Train: 67.26%, Valid: 56.62%, Test: 44.52%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 170, Loss: 0.1634, Train: 77.13%, Valid: 66.79%, Test: 63.60%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 170, Loss: 0.1634, Train: 78.45%, Valid: 68.23%, Test: 73.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 175, Loss: 0.1629, Train: 65.45%, Valid: 55.31%, Test: 29.63%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 175, Loss: 0.1629, Train: 75.42%, Valid: 65.07%, Test: 48.10%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 175, Loss: 0.1629, Train: 77.92%, Valid: 67.69%, Test: 63.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 180, Loss: 0.1630, Train: 69.69%, Valid: 59.08%, Test: 13.47%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 180, Loss: 0.1630, Train: 77.06%, Valid: 66.76%, Test: 39.98%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 180, Loss: 0.1630, Train: 78.76%, Valid: 68.50%, Test: 53.80%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 185, Loss: 0.1618, Train: 59.47%, Valid: 49.28%, Test: 24.99%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 185, Loss: 0.1618, Train: 74.60%, Valid: 64.15%, Test: 50.29%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 185, Loss: 0.1618, Train: 77.48%, Valid: 67.11%, Test: 64.45%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 190, Loss: 0.1616, Train: 65.72%, Valid: 55.03%, Test: 16.89%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 190, Loss: 0.1616, Train: 76.68%, Valid: 66.26%, Test: 43.69%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 190, Loss: 0.1616, Train: 79.27%, Valid: 68.97%, Test: 54.99%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 195, Loss: 0.1588, Train: 62.95%, Valid: 52.11%, Test: 24.06%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 195, Loss: 0.1588, Train: 77.88%, Valid: 67.39%, Test: 44.00%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 195, Loss: 0.1588, Train: 79.28%, Valid: 68.90%, Test: 57.09%\n",
      "---\n",
      "Hits@10\n",
      "Run: 10, Epoch: 200, Loss: 0.1605, Train: 70.78%, Valid: 59.89%, Test: 30.91%\n",
      "Hits@20\n",
      "Run: 10, Epoch: 200, Loss: 0.1605, Train: 76.90%, Valid: 66.42%, Test: 57.62%\n",
      "Hits@30\n",
      "Run: 10, Epoch: 200, Loss: 0.1605, Train: 79.31%, Valid: 68.91%, Test: 75.95%\n",
      "---\n",
      "Hits@10\n",
      "Run 10:\n",
      "Highest Train: 73.58\n",
      "Highest Valid: 63.51\n",
      "  Final Train: 73.58\n",
      "   Final Test: 47.13\n",
      "Hits@20\n",
      "Run 10:\n",
      "Highest Train: 77.88\n",
      "Highest Valid: 67.39\n",
      "  Final Train: 77.88\n",
      "   Final Test: 44.00\n",
      "Hits@30\n",
      "Run 10:\n",
      "Highest Train: 79.67\n",
      "Highest Valid: 69.63\n",
      "  Final Train: 79.67\n",
      "   Final Test: 67.17\n",
      "Hits@10\n",
      "All runs:\n",
      "Highest Train: 72.07  1.12\n",
      "Highest Valid: 61.70  1.23\n",
      "  Final Train: 71.94  1.17\n",
      "   Final Test: 33.83  10.47\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Train: 77.55  0.35\n",
      "Highest Valid: 67.16  0.33\n",
      "  Final Train: 77.55  0.35\n",
      "   Final Test: 54.24  5.90\n",
      "Hits@30\n",
      "All runs:\n",
      "Highest Train: 79.56  0.38\n",
      "Highest Valid: 69.30  0.41\n",
      "  Final Train: 79.56  0.38\n",
      "   Final Test: 67.43  2.88\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NeuralLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(NeuralLinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x).squeeze()\n",
    "\n",
    "\n",
    "def train(model, predictor, x, adj_t, split_edge, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='OGBL-DDI (GNN)')\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_steps', type=int, default=1)\n",
    "    parser.add_argument('--use_sage', default = True)\n",
    "    parser.add_argument('--num_layers', type=int, default=2)\n",
    "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "    parser.add_argument('--lr', type=float, default=0.005)\n",
    "    parser.add_argument('--epochs', type=int, default=200)\n",
    "    parser.add_argument('--eval_steps', type=int, default=5)\n",
    "    parser.add_argument('--runs', type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "                                     transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    adj_t = data.adj_t.to(device)\n",
    "\n",
    "    split_edge = dataset.get_edge_split()\n",
    "\n",
    "    # We randomly pick some training samples that we want to evaluate on:\n",
    "    torch.manual_seed(12345)\n",
    "    idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "    idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "    split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "    if args.use_sage:\n",
    "        model = SAGE(args.hidden_channels, args.hidden_channels,\n",
    "                     args.hidden_channels, args.num_layers,\n",
    "                     args.dropout).to(device)\n",
    "    else:\n",
    "        model = GCN(args.hidden_channels, args.hidden_channels,\n",
    "                    args.hidden_channels, args.num_layers,\n",
    "                    args.dropout).to(device)\n",
    "\n",
    "    emb = torch.nn.Embedding(data.adj_t.size(0),\n",
    "                             args.hidden_channels).to(device)\n",
    "    predictor = NeuralLinkPredictor(args.hidden_channels, args.hidden_channels, 1,\n",
    "                              args.num_layers, args.dropout).to(device)\n",
    "\n",
    "    evaluator = Evaluator(name='ogbl-ddi')\n",
    "    Logger_Models_Models = {\n",
    "        'Hits@10': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@20': Logger_Models_Model(args.runs, args),\n",
    "        'Hits@30': Logger_Models_Model(args.runs, args),\n",
    "    }\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        torch.nn.init.xavier_uniform_(emb.weight)\n",
    "        model.reset_parameters()\n",
    "        predictor.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(model.parameters()) + list(emb.parameters()) +\n",
    "            list(predictor.parameters()), lr=args.lr)\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                         optimizer, args.batch_size)\n",
    "\n",
    "            if epoch % args.eval_steps == 0:\n",
    "                results = test(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                               evaluator, args.batch_size)\n",
    "                for key, result in results.items():\n",
    "                    Logger_Models_Models[key].add_result(run, result)\n",
    "\n",
    "                if epoch % args.log_steps == 0:\n",
    "                    for key, result in results.items():\n",
    "                        train_hits, valid_hits, test_hits = result\n",
    "                        print(key)\n",
    "                        print(f'Run: {run + 1:02d}, '\n",
    "                              f'Epoch: {epoch:02d}, '\n",
    "                              f'Loss: {loss:.4f}, '\n",
    "                              f'Train: {100 * train_hits:.2f}%, '\n",
    "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                              f'Test: {100 * test_hits:.2f}%')\n",
    "                    print('---')\n",
    "\n",
    "        for key in Logger_Models_Models.keys():\n",
    "            print(key)\n",
    "            Logger_Models_Models[key].print_statistics(run)\n",
    "\n",
    "    for key in Logger_Models_Models.keys():\n",
    "        print(key)\n",
    "        Logger_Models_Models[key].print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9da50b",
   "metadata": {},
   "source": [
    "## EDA on Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3537165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling, convert, to_dense_adj\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe083512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from termcolor import colored\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import en_core_web_sm\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84644df",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_description = pd.read_csv('dataset/ogbl_ddi/mapping/nodeidx2drugid.csv')\n",
    "node_info_df = node_description.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_description = pd.read_csv('dataset/ogbl_ddi/mapping/ddi_description.csv')\n",
    "drug_interaction_info_df = drug_description.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_data = node_description['node idx'].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.linkproppred import PygLinkPropPredDataset\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name = 'ogbl-ddi') \n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb074a",
   "metadata": {},
   "source": [
    "### Drug Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names_1 = drug_description[['first drug id','first drug name']].drop_duplicates()\n",
    "drug_names_1 = drug_names_1.rename(columns = {'first drug id':'drug id','first drug name':'drug name'})\n",
    "drug_names_2 = drug_description[['second drug id','second drug name']].drop_duplicates()\n",
    "drug_names_2 = drug_names_2.rename(columns = {'second drug id':'drug id','second drug name':'drug name'})\n",
    "total_drug_names = pd.concat([drug_names_1,drug_names_2], axis = 0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780841d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info_df_with_names = node_info_df.merge(total_drug_names, on = 'drug id', how = 'left')\n",
    "node_info_df_with_names.head()\n",
    "node_info_df_with_names = node_info_df_with_names.rename(columns = {'node idx': 'first node','drug id':'first drug id','drug name':'first drug name'})\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "data = dataset[0]\n",
    "G = convert.to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce3bdc",
   "metadata": {},
   "source": [
    "### Node Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ac728",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(G.nodes)\n",
    "nodes_neighbours = {}\n",
    "for i in node_list:\n",
    "    nodes_neighbours[i] = [n for n in G.neighbors(i)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree = {}\n",
    "for i in node_list:\n",
    "    node_degree[i] = G.degree[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04144d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree_data = pd.DataFrame()\n",
    "node_degree_data['Nodes'] = node_list_data\n",
    "node_degree_data['Degree'] = node_degree_data['Nodes'].map(node_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3446ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree_data.describe().to_csv('Degree_Stats.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec24e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree_data.to_csv('Node_Degree_Data.txt', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info_df_with_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefff28e",
   "metadata": {},
   "source": [
    "### Mapping node to neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9eb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info_df_with_names['second node'] = node_info_df_with_names['first node'].map(nodes_neighbours)\n",
    "node_info_df_with_names = (node_info_df_with_names.join(pd.DataFrame(node_info_df_with_names.pop('second node')\n",
    "                            .values.tolist())\n",
    "               .stack()\n",
    "               .reset_index(level=1, drop=True)\n",
    "               .rename('second node'))).reset_index(drop=True)\n",
    "node_info_df_with_names['second node'] = node_info_df_with_names['second node'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_second_drug_id = node_info_df_with_names.merge(node_description, left_on = 'second node', right_on = 'node idx')\n",
    "adding_second_drug_id = adding_second_drug_id.drop(['node idx'], axis = 1)\n",
    "adding_second_drug_name = adding_second_drug_id.merge(total_drug_names, on = 'drug id', how = 'left')\n",
    "adding_second_drug_name = adding_second_drug_name.rename(columns = {'drug id':'second drug id','drug name':'second drug name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_node_interaction_df = adding_second_drug_name.merge(drug_interaction_info_df, \n",
    "                              on = ['first drug id','first drug name','second drug id','second drug name'], \n",
    "                             how = 'left')\n",
    "complete_node_interaction_df = complete_node_interaction_df.rename(columns = {'description':'polypharmacy side effect'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2957d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = complete_node_interaction_df[complete_node_interaction_df['polypharmacy side effect'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_reverse_combos(row):\n",
    "    first_node = row[1]\n",
    "    second_node = row[4]\n",
    "    \n",
    "    global complete_node_interaction_df\n",
    "    \n",
    "    get_val = complete_node_interaction_df[(complete_node_interaction_df['first drug id']==second_node) & (complete_node_interaction_df['second drug id']==first_node) ]['polypharmacy side effect']\n",
    "    get_val = get_val.tolist()[0]\n",
    "    \n",
    "    complete_node_interaction_df.loc[(complete_node_interaction_df['second drug id']==second_node) & (complete_node_interaction_df['first drug id']==first_node),'polypharmacy side effect' ] = get_val\n",
    "    \n",
    "empty_data.apply(assign_reverse_combos,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = pd.DataFrame()\n",
    "def check_value(row):\n",
    "    first_node = row[1]\n",
    "    second_node = row[4]\n",
    "    \n",
    "    global mismatch_df\n",
    "    \n",
    "    combination_1 = complete_node_interaction_df[(complete_node_interaction_df['first drug id']==second_node) & (complete_node_interaction_df['second drug id']==first_node) ]['polypharmacy side effect']\n",
    "    combination_1 = combination_1.tolist()[0]\n",
    "    \n",
    "    combination_2 = complete_node_interaction_df[(complete_node_interaction_df['second drug id']==second_node) & (complete_node_interaction_df['first drug id']==first_node) ]['polypharmacy side effect']\n",
    "    combination_2 = combination_2.tolist()[0]\n",
    "    \n",
    "    if combination_1 != combination_2:\n",
    "        mismatch_df.append(row)\n",
    "        \n",
    "complete_node_interaction_df.apply(check_value,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49087d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60d73d5b",
   "metadata": {},
   "source": [
    "### Embedding Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd478e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T09:43:44.552551Z",
     "start_time": "2022-08-27T09:43:43.782293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly sample 2k training edges \n",
    "tsne_edges_train = split_edge['train']['edge']\n",
    "tsne_edges_train = tsne_edges_train.T\n",
    "train_edge_tuples = list(zip(tsne_edges_train[0], tsne_edges_train[1]))\n",
    "tsne_tuples_train = random.sample(train_edge_tuples, 3500)\n",
    "\n",
    "# Randomly sample 2k test edges \n",
    "tsne_edges_test = split_edge['test']['edge']\n",
    "tsne_edges_test = tsne_edges_test.T\n",
    "test_edge_tuples = list(zip(tsne_edges_test[0], tsne_edges_test[1]))\n",
    "tsne_tuples_test = random.sample(test_edge_tuples, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a981a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T09:43:44.675963Z",
     "start_time": "2022-08-27T09:43:44.659009Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ad378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_tsne(emb_filepath, emb_model_name, color):\n",
    "  '''\n",
    "    Generate 2D tSNE representation of node embeddings as specified in \n",
    "    emb_filepath. Generate 3 plots: one with just the node embeddings, another\n",
    "    with node embeddings and 2k randomly sampled edges from the train set, and\n",
    "    a third with node embeddings and 2k randomly sampled edges from the test set. \n",
    "  '''\n",
    "  node_emb = torch.load(filepath, map_location='cpu').to(device)\n",
    "  cpu_emb = node_emb.cpu().data.numpy() # move to cpu, convert to numpy array\n",
    "\n",
    "  # Apply t-SNE transformation on node embeddings\n",
    "  tsne = TSNE(n_components=2)\n",
    "  node_embeddings_2d = tsne.fit_transform(cpu_emb)  \n",
    "\n",
    "\n",
    "  # Define subplots\n",
    "  f, axs = plt.subplots(1,3,figsize=(18,5), dpi=80)\n",
    "\n",
    "  # Plot train set embeddings\n",
    "  emb_color = '#EF8A5A'\n",
    "  alpha = 0.2\n",
    "  axs[0].scatter(\n",
    "      node_embeddings_2d[:, 0],\n",
    "      node_embeddings_2d[:, 1],\n",
    "      s=100,\n",
    "      c=emb_color,\n",
    "      alpha=alpha,\n",
    "  )\n",
    "\n",
    "  plot_title = f'Node Embeddings'\n",
    "  axs[0].set_title(plot_title)\n",
    "\n",
    "  # Plot embeddings with randomly sampled train set edges\n",
    "  train_color = '#F6B53D'\n",
    "  axs[1].scatter(\n",
    "      node_embeddings_2d[:, 0],\n",
    "      node_embeddings_2d[:, 1],\n",
    "      s=100,\n",
    "      c=train_color, \n",
    "      alpha=alpha,\n",
    "  )\n",
    "  for x, y in tsne_tuples_train:\n",
    "      i, j = x.item(), y.item()\n",
    "      x_i, x_j = node_embeddings_2d[i, 0], node_embeddings_2d[j, 0]\n",
    "      y_i, y_j = node_embeddings_2d[i, 1], node_embeddings_2d[j, 1]\n",
    "      axs[1].plot([x_i,x_j],[y_i,y_j],'k-', linewidth=0.10)\n",
    "\n",
    "  plot_title = f'Node Embeddings: Train Edges'\n",
    "  axs[1].set_title(plot_title)\n",
    "  # Plot embeddings with randomly sampled test set edges\n",
    "  test_color = '#15CAB6' #hot pink\n",
    "\n",
    "  axs[2].scatter(\n",
    "      node_embeddings_2d[:, 0],\n",
    "      node_embeddings_2d[:, 1],\n",
    "      s=100,\n",
    "      c=test_color, \n",
    "      alpha=alpha,\n",
    "  )\n",
    "  for x, y in tsne_tuples_test:\n",
    "      i, j = x.item(), y.item()\n",
    "      x_i, x_j = node_embeddings_2d[i, 0], node_embeddings_2d[j, 0]\n",
    "      y_i, y_j = node_embeddings_2d[i, 1], node_embeddings_2d[j, 1]\n",
    "      axs[2].plot([x_i,x_j],[y_i,y_j],'k-', linewidth=0.10)\n",
    "  \n",
    "  plot_title = f'Node Embeddings: Test Edges'\n",
    "  axs[2].set_title(plot_title)\n",
    "\n",
    "  sup_title = f't-SNE Visualization of Train and Test Edge Embeddings using GCN'\n",
    "  f.suptitle(sup_title)\n",
    "  figure_path = f'tsne_{emb_model_name}.png'\n",
    "  plt.savefig(figure_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'graph_sage'\n",
    "run = 0\n",
    "filepath = 'C:/Users/yuvas/Documents/MSc Course/Dissertation/OGB - DDI/Output/training_outputs/'+f'{model_name}_final_emb_{run}.pt'\n",
    "color = '#f794e9'\n",
    "plot_tsne(filepath, model_name, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mf'\n",
    "run = 0\n",
    "filepath = 'C:/Users/yuvas/Documents/MSc Course/Dissertation/OGB - DDI/Output/training_outputs/'+f'{model_name}_final_emb_{run}.pt'\n",
    "color = '#f794e9'\n",
    "plot_tsne(filepath, model_name, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/yuvas/Documents/MSc Course/Dissertation/OGB - DDI/Output/training_outputs/' + 'embedding.pt' # Plot tSNE for Node2Vec embeddings\n",
    "color = '#f794e9'\n",
    "plot_tsne(filepath, 'Node2Vec_256_dim', color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3302e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gnn'\n",
    "run = 0\n",
    "filepath = f'{model_name}_final_emb_{run}.pt'\n",
    "color = '#f794e9'\n",
    "plot_tsne(filepath, model_name, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ce232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
